\documentclass[a4paper,11pt]{report}
\usepackage{Mydef}
\title{My Report about Operator Theory}
\author{Z.~Zhan\\ $<$\href{mailto:thaleszhan@gmail.com}%
            {thaleszhan@gmail.com}$>$}

\begin{document}
\maketitle
\tableofcontents
\chapter{Topological Vector Spaces and Banach Spaces}

\section{Topological Vector Spaces}
Linear operations, i.e addition and scalar multiplication, provide an algebraic structure on a set, therefore constructing a vector space. In the course, linear algebra, we have learn the algebraic structure of finite dimensional vector spaces. But how to deal with infinite dimensional vector spaces? By learning the topological spaces, we know that the topological structure can give us a method to research properties of infinity. Thus, we need to equip a vector space with an additional topological structure, which should coincide with the algebraic structure. This is the reason why we define the topological vector space.

\subsection{Topological Spaces}
\rule{1mm}{1mm} \textbf{Definition:} First, we define the topological structure on a general set.
\begin{defn}
A topological space $X$~=~($X$, $\mathscr{T}_X$) consists of a set $X$, called the underlying space of $X$, and a family $\mathscr{T}_X$ of subsets of $X$ s.t.
	\begin{enumerate}[label=\arabic*)]
		\item $X, \varnothing \in \mathscr{T}_X$.
		\item if $U_\alpha \in \mathscr{T}_X \ \text{for} \ \alpha \in A$, then $\bigcup_{\alpha \in A}U_\alpha \in \mathscr{T}_X$.
		\item if $U_1, U_2 \in \mathscr{T}_X$, then $U_1 \bigcap U_2 \in \mathscr{T}_X$.
	\end{enumerate}
And, $\mathscr{T}_X$ is called a topology on $X$. The element in $\mathscr{T}_X$ is called open set.
\end{defn}

Thus, the topological structure on a set $X$ is totally determined by the family $\mathscr{T}_X$. In particular, from $2)$, we can simplify $\mathscr{T}_X$. In other words, like the basis of a vector space, there is a "basis" of $\mathscr{T}_X$.

\begin{defn}
If $X$ is a set, a basis for a topology on $X$ is a family $\mathscr{B}$ of subsets of $X$, s.t.
	\begin{enumerate}[label=\arabic*)]
		\item $\forall ~ x \in X,~ \exists ~ B \in \mathscr{B},~\text{s.t.}~ x \in B$.
		\item if $x \in B_1 \bigcap B_2$, where $B_1,~B_2 \in \mathscr{B}$, then there is a $B_3 \in \mathscr{B}$, s.t. $B_3 \subset B_1 \bigcap B_2$.
	\end{enumerate}
\end{defn}

$\mathscr{B}$ can generate a topology $\mathscr{T}_X$ on $X$ by doing infinite times union of elements in $\mathscr{B}$. In fact,
\begin{equation*}
	\mathscr{T}_X~ = ~\{~U \subset X \colon U = \bigcup_{~\alpha \in A}U_\alpha,~U_\alpha \in \mathscr{B}~\},~ \text{where A is any index set.}
\end{equation*}

We can do more on the basis by $3)$.
\begin{defn}
A subbasis of a topology on $X$ is a collection $\mathscr{S}$ of subsets of $X$, whose union is $X$. The topology generated by $\mathscr{S}$ is noted by $\mathscr{T}(\mathscr{S})$.
\end{defn}
In fact, we can generate the basis of $\mathscr{T}(\mathscr{S})$ by $\mathscr{S}$, that is,
\begin{equation*}
	\mathscr{B}~ = ~\{~U \subset X \colon U = \bigcap_{\alpha=1}^{n}U_\alpha,~U_\alpha \in \mathscr{S},~n \in \N~\}
\end{equation*}
Therefore, this basis can generate the conincided topology on $X$.\vspace{0.2in}

\rule{1mm}{1mm} \textbf{Continuous maps:} Next, we need to endow the general maps with the topological structure.
\begin{defn}
Let $X$, $Y$ be topological spaces and $f \colon X \sto Y$ be a map. We say $f$ is continous if
	\begin{equation*}
		\forall ~V \in \mathscr{T}_Y,~f^{-1}(V) \in \mathscr{T}_X.
	\end{equation*}
\end{defn} 
In other words, if $f \colon X \sto Y$ is a continuous map, $\mathscr{T}_X$ has "more" elements than $\mathscr{T}_Y$ has. To get more rigorous discription, we define the following concept.
\begin{defn}
	Let $X$ be a set and $\mathscr{T}$, $\mathscr{T}^{'}$ be two topologies on $X$ we say that $\mathscr{T}$ is coaser than $mathscr{T}^{'}$ if $\mathscr{T} \subset \mathscr{T}^{'}$.
\end{defn}
Therefore, if $f \colon X \sto Y$ is a continuous map, the topology $\mathscr{T}(f^{-1}(\mathscr{T}_Y))$ is coaser than $\mathscr{T}_X$. \vspace{0.1in}

\rule{1mm}{1mm} \textbf{Generating topologies:} We use above methods to generate some interested topologies on a set.
\begin{enumerate}[label=\arabic*)]
	\item Inital topology: Given maps $f_\alpha \colon X \sto Y_\alpha ~( \alpha \in A )$ from a set $X$ to a family of topological spaces $\{Y_\alpha \colon \alpha \in A \}$. Let
	\begin{equation*}
		\mathscr{S}~=~\{~f_{\alpha}^{-1}(V) \colon V \in \mathscr{T}_{Y_\alpha},~ \alpha \in A ~\}
	\end{equation*}
	Then $\mathscr{T}(\mathscr{S})$ is the coarsest topology on $X$ such that each $f_\alpha$ is continuous, called the initial topology induced by the family of maps $\{ f_\alpha\ \colon \alpha \in  A \}$.

	\item Final topology: Given maps $f_\alpha \colon X_\alpha \sto Y ~ (\alpha \in A)$ from a family of topological spaces $\{X_\alpha \colon \alpha \in A\}$ to a set $Y$. Let
	\begin{equation*}
		\mathscr{S}~=~\{~ V \colon f_{\alpha}^{-1}(V) \in \mathscr{T}_{X_\alpha},~ \alpha \in A~\}
	\end{equation*}
	Then $\mathscr{T}(\mathscr{S})$ is the finest topology on $Y$ such that each $f_\alpha$ is continuous, called the final topology induced by the family of maps $\{f_\alpha \colon \alpha \in A \}$.
\end{enumerate}
Here is some important examples using above way to generate topologies.
\begin{exam}
	(Initial topology)
	\begin{enumerate}[label=\arabic*)]
		\item Subspace topology: Let $Y$ be a topological space and $X \subset Y$ be a subset of $Y$. The inclusion map $i \colon X \sto Y$ can generate the initial topology $\mathscr{T}_X$ on $X$, then $X$ become a subspace of $Y$. In fact,
		\begin{equation*}
			\mathscr{T}_X ~=~ \{~X \bigcap U \colon U \in \mathscr{T}_Y~\}
		\end{equation*}
		\item Product topology: Let $\{Y_\alpha \colon \alpha \in A\}$ be a family of topological spaces. The product set is 
		\begin{equation*}
			\prod_{\alpha \in A} Y_\alpha ~=~ \{~A \stackrel{f}{\sto} \bigcup_{\alpha \in A} Y_\alpha \colon \forall \alpha \in A,~ f(\alpha) \in Y_\alpha ~\}
		\end{equation*}
		There is a family of maps $\{ p_\beta \colon \prod_{\alpha \in A} Y_\alpha \sto Y_\beta (\beta \in A) \}$. Therefore, these maps can generate the initial topology $\mathscr{T}$ on $\prod_{\alpha \in A} Y_\alpha$ and let $\prod_{\alpha \in A} Y_\alpha$ be the product topological space. In fact,
		\begin{equation*}
			\mathscr{T} ~=~ \{~\prod_{\alpha \in A} V_\alpha \colon V_\alpha \in \mathscr{T}_{Y_\alpha} ~ \& ~ \#\{\alpha \in A \colon V_\alpha \neq Y_\alpha \} < \infty ~\}
		\end{equation*}
		\begin{rem}
			The condition, $\#\{ \alpha \in A \colon V_\alpha \neq Y_\alpha \} < \infty$, is because that when the subbasis generates the basis, only finite many elements can do intersection.
		\end{rem}
	\end{enumerate}
\end{exam}
\begin{exam}
	(Final topology)\\
	Quotient topology: For a topological space $X$ on which an equivalent relation R is fixed, $\pi \colon X \sto X/R$ is the quotient map, then the quotient set can be equiped with the final topology $\mathscr{T}$ generated by the quotient map. Therefore, $X/R$ become a quotient topological space. In fact,
	\begin{equation*}
		\mathscr{T} ~=~ \{~ U \subset X/R \colon \pi^{-1}(U) \in \mathscr{T}_X ~\}
	\end{equation*}
\end{exam}

\rule{1mm}{1mm} \textbf{Countability and metrizability:} When learning the analysis of real functions, we usually use the sequence to discribe the topological properties. But in some general topology, we cannot just use sequence since some properties of "uncountabibily". In this case, the concept of net can be applied to some "uncountable" topologies. Furthermore, there is a class of more special topology, metrizable topology, which has some better properties.

\begin{defn}
	(Net)
	\begin{enumerate}[label=\arabic*)]
		\item Direct set: A direct set $(D,~\geqslant)$ consists of a nonempty set $D$ and a relation $\geqslant$ on D, satisfies:
		\begin{enumerate}[label=\roman*)]
			\item $\forall ~ d \in D,~ d \geqslant d$
			\item $\forall ~ d_1,~d_2,~d_3 \in D, if ~ d_3 \geqslant d_2 ~ \& ~ d_2 \geqslant d_1,~ then ~ d_3 \geqslant d_1$
			\item $\forall ~ d,~ d^{'} \in D,~ \exists ~ d^{''}  ~s.t.~ d^{''} \geqslant d ~ \& ~ d^{''} \geqslant d^{'}$.
		\end{enumerate}
		\item if $X$ is a set, a net is a map $x_. \colon D \sto X$ from a direct set $D$ to $X$
	\end{enumerate}
\end{defn}
\begin{exam}
	If $X$ is a topological space and $x \in X$, then let 
	\begin{equation*}
		D ~=~ \{~ \text{all open neighbourhoods of x} ~\},~ U \geqslant V \Leftrightarrow U \subset V
	\end{equation*}
	Then $D$ is a direct set and $x_\alpha(\alpha \in D)$ is a net.
	And we say $ x_\alpha \sto x$ if and only if \\
	$\forall$ open neighbourhood $U$ of $x$ in $X$, $\exists  \delta \in D,~ \forall ~ \alpha \in D \text{ with } \alpha \geqslant \delta \Rightarrow x_\alpha \in U$
\end{exam}
Nets can be used as sequences in topological spaces. Like, 
\begin{prop}
	If $X$ is a topological space and the net $x_\alpha(\alpha \in D)$ defined above and $A \subset X$, then
	\begin{enumerate}[label=\arabic*)]
		\item $\clo{A} ~=~ \{~ x \in X \colon \exists ~ x_\alpha \text{ in } A,~ x_\alpha \sto x ~\}$
		\item $f \colon X \sto Y$ is continuous between two topological spaces, $x_0 \in X$, $f$ is continuous at $x_0$, if and only if\\
		$\forall$ net $x_\alpha(\alpha \in D)$, s.t. $x_\alpha \sto x_0 \Rightarrow f(x_\alpha) \sto f(x_0)$
	\end{enumerate}
\end{prop}

\begin{defn}
	(Countability)
	\begin{enumerate}[label=\arabic*)]
		\item First countability: For a topological space $X$, $X$ is called first countable if for each point $x \in X$, $x$ has a countable neighbourhood basis.
		\item Second countability: A topological space $X$ is second countable if it has the countable topological basis. 
	\end{enumerate}
\end{defn}
\begin{rem}
	Clearly, the second countable topological space is first countable, but the converse is not true.
\end{rem}
In particular, if $X$ is first countable, sequences can be used to illuminate tpological properties rather than nets. Like,
\begin{prop}
	If $X$ is first countable, then
	\begin{enumerate}[label=\arabic*)]
		\item $U \subset X$ is closed $\Leftrightarrow$ $\forall ~ x \in U,~ \exists ~\text{a sequence} \{x_n\} \subset U,~ s.t.~ x_n \sto x$.
		\item sequential compactness is equivalent to compactness.
	\end{enumerate}
\end{prop}

And for the second countability, it is about the separability.
\begin{defn}
	(Separability)
	\begin{enumerate}[label=\arabic*)]
		\item A subset $A$ of a topological space $X$ is called dense if $\clo{A} ~=~ X$.
		\item A topological space is called separable if it has a countable dense subset.
	\end{enumerate}
\end{defn}

By the definition, we can clearly know that:
\begin{prop}
	If $X$ is a second countable topological space, then it is separable and every open covering of $X$ has a finite subcollection covering $X$.
\end{prop}

We can classify topological spaces into some classes.
\begin{defn}
$X$ is a topological space, then we call $X$ is:
\begin{enumerate}
	\item [($T_0$)] $\forall ~ x,~y \in X,~ \exists ~ \text{open } U \subset X,~ s.t.~ x \in U \text{ but } y \notin U \text{ or } y \in U \text{ but } x \notin U$ (Kolmogorov space)
	\item [($T_1$)] $\forall ~ x,~y \in X,~ \exists ~ \text{open } U,~ V \subset X, ~s.t.~ x \in U \text{ but } y \notin U \text{ and } y \in V \text{ but } x \notin V$\\
	($\Leftrightarrow \forall~ x \in X,~ \{x\} \text{ is closed} $)
	\item [($T_2$)] $\forall ~ x,~y \in X,~ \exists ~ \text{open } U,~ V \subset X, ~s.t.~ x \in U ~\&~ y \in V \text { and } U \bigcap V = \varnothing$ (Hausdorff space)
	\item [($T_3$)] $T_1$ holds and $\forall ~ x \in X$ and closed $C \subset X$, if $x \notin C$, then $\exists ~ \text{open } U,~ V \subset X, ~s.t.~ x \in U ~\&~ C \subset V \text{ and } U \bigcap V = \varnothing$ (regular space)
	\item [($T_4$)] $T_1$ holds and $\forall ~ \text{closed } C_1,~ C_2 \subset X$, if $C_1 \bigcap C_2 = \varnothing$, \\ then $\exists ~ \text{open } U,~ V \subset X, ~s.t.~ C_1 \subset U ~\&~ C_2 \subset V \text{ and } U \bigcap V = \varnothing$ (normal space)
\end{enumerate}
\end{defn}

Then we can specify a class of more powerful topological space.
\begin{defn}
	If $X$ is a topological space, then $X$ is said to be metrizable if there exists a metric $d$ on the set $X$ that induces the topology of $X$.
\end{defn}
\begin{rem}
	Clearly, if $X$ is metrizable, $X$ is second countable and normal.
\end{rem}

Here is two metrization theorems provides the essence of metric spaces.
\begin{thm}
(Metrization theorems)
	\begin{enumerate}
		\item[Urysohn] A topological space is separable and metrizable if and only if it is regular, Hausdorff and second countable.
		\item[Nagata–Smirnov] A topological space is metrizable if and only if regular, Hausdorff and has a $\sigma$-locally finite basis.
	\end{enumerate}
\end{thm}
\vspace{0.2in}
\rule{1mm}{1mm} \textbf{Complete metic space:} For a metric space, we know it is first countable, so the concept of net is unnecessary. And thus sequences are enough to determine the topological structures, like that sequential compactness is equvilent to compactness. 

\begin{prop}
	A compact subset of a metric space is closed, bounded and separable.
\end{prop}
\begin{rem}
	it is clearly, since compactness is also about finity.
\end{rem}

For any metric space, we can use the following theorem to get a completion of that and this completion is unique. Thus, we can always assume a metric space is complete.
\begin{thm}
	Let ($X,~ d$) be a metric space. Then, there exists a metric space ($\hat{X},~ \hat{d}$) with the following properties:
	\begin{enumerate}[label=\arabic*)]
		\item ($\hat{X},~ \hat{d}$) is complete.
		\item There is an embedding $\sigma$ from $X$ to $\hat{X}$.
		\item $\sigma(X)$ is dense in $\hat{X}$.
	\end{enumerate}
	And this ($\hat{X},~ \hat{d}$) is unique with respect to isomorphism.
\end{thm}

Complete metric space is imporatant since it is "sufficiently large". Rigorously, we can the following definition to describe it.

\begin{defn}
	(Baire Category)
	A metric space is said to be of the first category if it can be written as a countable union of sets that are nowhere dense. Otherwise, it is of the second category.
\end{defn}

\begin{prop}
	A complete metric space is a space of the second category.
\end{prop}

\vspace{0.2in}
\rule{1mm}{1mm} \textbf{Filters:} For convenience, we define some terminologies.
\begin{defn}
	A filter on a set $X$ is a family $\mathscr{F} $ of subsets of $X$ satisfying the following conditions:
	\begin{enumerate}[label=\arabic*)]
		\item $\varnothing \notin \mathscr{F}$
		\item $\mathscr{F}$ is closed under finite many intersections
		\item Any subset of $X$ containing a set in $\mathscr{F}$ belongs to $\mathscr{F}$.
	\end{enumerate}
\end{defn}
\begin{exam}\label{exam1}
	For a topological space $X$ and $x \in X$, and let
	\begin{equation*}
		\mathscr{F}(x) ~=~ \{~\text{all neighbourhoods of x}~\}	
	\end{equation*}
	Then $\mathscr{F}(x)$ is a filter and $\mathscr{F}(x)$ satisfies the following properties:
	\begin{enumerate}[label=\arabic*)]
		\item $\forall~ U \in \mathscr{F}(x),~ x \in U$
		\item $\forall~ U \in \mathscr{F}(x),~ \exists ~ V \in \mathscr{F}(x),~ s.t.~ \forall~ y \in V,~ U \in \mathscr{F}(y)$
	\end{enumerate}
	And conversely, if we can find $\mathscr{F}(x)$ for any $x \in X$ with above two properties, these can define a unique topology $\mathscr{T}$ s.t. $\mathscr{F}(x)$ is the filter of neighbourhoods of $x$ for any $x \in X$. In fact,
	\begin{equation*}
		\mathscr{T} = \{~ U \subset X \colon x \in U \Rightarrow U \in \mathscr{F}(x) ~\}
	\end{equation*}
	Also, we can define the basis of $\mathscr{F}(x)$, noted by $\mathscr{B}(x)$. That is $\mathscr{B}(x) \subset \mathscr{F}(x)$ with the following properties:
	\begin{enumerate}[label=\arabic*)]
		\item $\forall~ U \in \mathscr{B}(x),~ x \in U$
		\item $\forall~ U_1 ~\&~ U_2 \in \mathscr{B}(x),~ \exists ~ U_3 \in \mathscr{B}(x),~ s.t.~ U_3 \subset U_1 \bigcap U_2$
		\item If $y \in U \in \mathscr{B}(x),~ \exists ~ W \in \mathscr{B}(y),~ W \subset U$
	\end{enumerate}
\end{exam}

\subsection{Definition and Properties}

\rule{1mm}{1mm} \textbf{Definition:} Now, we need to endow the topological structure on a vector spaces. And the most important thing is that the topological structure should coincide with the algebraic structure.
\begin{defn}
	A vector space $X$ over a field $\K$ (where $\K = \C or \R$) is called a topological vector space if $X$ is equiped with a topology $\mathscr{T}$ s.t. the addition and the scalar multiplication, i.e. 
	\begin{center}
		\begin{tabular}{r @{$\mapsto$} l}
			$(x,~y)~$ & $~x+y$ \\
			$(\lambda,~ x)~$ & $~ \lambda x$
		\end{tabular}
	\end{center}
	are continuous with respect to the topology $\mathscr{T}$.
\end{defn}

In this definition, the most important part is that the addition and the scalar multiplication are continuous. This condition provides some additional properties for the topology and also for the linear operations. First, it can simply the topology.

\begin{prop}
	Given a t.v.s. $X$, 
	\begin{enumerate}[label=\arabic*)]
		\item For any $x_0 \in X$, the map $x \mapsto x+x_0$ is a homeomorphism.
		\item For any $\lambda \in \K$, then map $x \mapsto \lambda x$ is a homeomorphism.
	\end{enumerate}
\end{prop}
\begin{proof}
	It is clearly, since by the definition, $x \mapsto x-x_0$ and $x \mapsto \frac{1}{\lambda}x$ are continuous.
\end{proof}

Therefore, the topology of a t.v.s is completely determined by the filter of neighbourhoods of any point. Or, more rigorously,
\begin{cor}
	For a t.v.s $X$, the filter $\mathscr{F}(x)$ of neighbourhoods of $x \in X$ is as same as $\{~ U+x \colon U \in \mathscr{F}(e) ~\}$, where $e$ is the unit element in $X$.
\end{cor}

Thus, to research the topology of a t.v.s. $X$, we just need to research the filter $\mathscr{F}(e)$ of neighbourhoods of $e$. First, there are two special properties of some subsets of a t.v.s. $X$.
\begin{defn}
	For a subset $U$ of a t.v.s. $X$, 
	\begin{enumerate}[label=\arabic*)]
		\item $U$ is absorbing if $\forall ~ x \in X,~ \exists ~ \rho > 0 ~s.t.~ \forall~ \lambda \in \K$ with $ \abs{\lambda} \leqslant \rho$, we have $\lambda x \in U$.
		\item $U$ is balanced if $\forall ~ x \in U,~ \forall \lambda \in \K$ with $\abs{\lambda} \leqslant 1$, we have $\lambda x \in U$.
	\end{enumerate}
\end{defn}

Then, the following theorem reveals the essence of $\mathscr{F}(e)$.
\begin{thm}
	A filter $\mathscr{F}$ of a vector space $X$ over $\K$ is the filter of neighbourhoods of the unit element $e$ w.r.t. some topology compatible with the algebraic structure of $X$ if and only if 
	\begin{enumerate}[label=\arabic*)]
		\item $\forall ~ U \in \mathscr{F},~ e \in U$
		\item $\forall ~ U \in \mathscr{F},~ \exists ~ V \in \mathscr{F} ~s.t.~ V+V \subset U$
		\item $\forall ~ U \in \mathscr{F},~ \forall ~ \lambda \in \K$ with $\lambda \neq 0$, $\lambda U \in \mathscr{F}$
		\item $\forall ~ U \in \mathscr{F},~ U$ is absorbing
		\item $\forall ~ U \in \mathscr{F},~ \exists ~ V \in \mathscr{F} ~s.t.~ V \subset U$ is balanced
	\end{enumerate}
\end{thm}
\begin{proof}
	If $\mathscr{F} = \mathscr{F}(e)$, these statements clearly hold.\\
	$1)$ is trivial.\\
	$2)$ is true since the addition is continuous.\\
	$3)$ and $4)$ hold since the scalar multiplication is continuous.\\
	For $5)$, because the scalar multiplication is continuous, we can find a $W \in \mathscr{F} ~s.t.~ \lambda W \subset U$ for any $\abs{\lambda} \leqslant \rho$, then let $V = \bigcup_{\abs{\lambda} \leqslant \rho} \lambda W$. Clearly, $V \in \mathscr{F}$ and $V$ is balanced.\\
	Conversely, We can define
	\begin{equation*}
		\mathscr{F}(x) = \{~ U+x \colon U \in \mathscr{F} ~\}
	\end{equation*}
	for any $x \in X$. It can be easily checked that $\mathscr{F}(x)$ satisfies the conditions in Example \ref{exam1} in last subsection. Therefore, these $\mathscr{F}(x)$ can determine a unique topology $\mathscr{T}$ on $X$.\\
	Now, we just need to check the continuity of the addition and the scalar multiplication. The addition is continuous, since $\mathscr{F}$ satisfies $2)$.  Using conditions $2)$ and $4)$ and $5)$ to get a balanced absorbing open neighbourhood in $\mathscr{F}$, and this neighbourhood prove the continuity of the scalar multiplication.
\end{proof}

Here is some simple properties of a t.v.s. $X$. These properties are directly obtained by definition and above theorem.
\begin{prop}
	For a t.v.s. $X$,
	\begin{enumerate}[label=\arabic*)]
		\item proper subspaces of $X$ are never absorbing. In particular, if $M \subset X$ is a open subspace, then $M = X$.
		\item each linear subspace of $X$, endowed with subspace topology, is also a t.v.s.
		\item if $H$ is a linear subspace of $X$, then $\clo{H}$ is also a linear subspace of $X$.
		\item if $Y$ is also a t.v.s. and $f \colon X \sto Y$ is a linear map, then $f$ is continuous if and only if $f$ is continuous at the unit element $e$.
	\end{enumerate}
\end{prop}

\vspace{0.2in}
\rule{1mm}{1mm} \textbf{Hausdorff t.v.s.~:} The Hausdorff Space is important since it can let the concept of limit make sense. And the topology of a t.v.s. can be simplified and has some additional properties, we can get a easier condition that make a t.v.s. become Hausdorff.

\begin{prop}
	A t.v.s $X$ is a Hausdorff space if and only if for any $x \in X$ with $x \neq e$ there exists a $U \in \mathscr{F}(e)$ s.t. $x \notin U$.
\end{prop}
\begin{proof}
	Since the open neighbourhoods of any point in $X$ is completely determined by the open neighbourhoods of $e$, this proposition is equivalent to the statement that ($T_1$) implies Hausdorff.\\
	The proof can be accomplished by obtaining a contradiction to the given condition that $x \neq e$, $\exists ~U \in \mathscr{F}(e)$ s.t. $x \notin U$. For that $U$, there is a balanced $V \in \mathscr{F}(e) ~s.t.~ V+V \subset U$ and the balance implies that $V-V \subset U$. Therefore, $(x+V) \bigcap V = \varnothing$. If not, $x+v_1 = v_2$ for $v_1,~ v_2 \in V$. This implies that $x = v_1 - v_2 \in V-V \subset U$. Thus it is a contradiction.
\end{proof}
The following theorem is more explicit.
\begin{thm} \label{thm1}
	For t.v.s. $X$ the following statements are equivalent.
	\begin{enumerate}[label=\arabic*)]
		\item $X$ is Hausdorff.
		\item the intersection of all neighbourhoods of the unit element $e$ is \{e\}.
		\item \{e\} is closed.
	\end{enumerate}
\end{thm}
\begin{proof}
	Before the rigorously proving, the intuition is clearly. Since in a t.v.s. ($T_1$) is equivalent to Hausdorff, the equivalence of $1)$ and $3)$ is clearly true.
	\begin{enumerate}
		\item[$1) \Rightarrow 2)$] It is because that elements in $\mathscr{F}(e)$ can separate $e$ and other points.
		\item[$2) \Rightarrow 3)$] If $x \in \clo{\{e\}}$, i.e. $\forall V_x \in \mathscr{F}(x),~ V_x \bigcap \clo{\{e\}} \neq \varnothing \Rightarrow e \in V_x$, and $V_x = U + x$ for some $U \in \mathscr{F}(e)$, then $u + x = e$ for some $u \in U$. Thus, $x = -u \in -U$ for all $U \in \mathscr{F}(e)$. That implies $x = e$.
		\item[$3) \Rightarrow 1)$] By above mentioned, it just needs to check that if for any topology space $Y$, $\{y\}$ is closed $\forall y \in Y$, $Y$ is ($T_1$). \\
		Since $\{y_1\}$ is closed, $Y \backslash \{y_1\}$ is open. That means if $y_2 \neq y_1$, there exists a open neighbourhood $U$ of $y_2$ s.t. $y_1 \notin U$. Similarly, we can find a open neighbourhood $V$ of $y_1$ s.t. $y_2 \notin V$. Therefore, $Y$ is ($T_1$). \qedhere
	\end{enumerate}	
\end{proof}

\vspace{0.2in}
\rule{1mm}{1mm} \textbf{Quotient t.v.s.~:} For a linear subspace $M$ of a t.v.s. $X$, the quotient topology on $X/M$ can be obtained by the quotient map $\pi \colon X \sto X/M$. But because of the algebraic structure, it has more properties.
\begin{prop}
	For a linear subspace $M$ of a t.v.s. $X$, the quotient map $\pi \colon X \sto X/M$ is open.
\end{prop}
\begin{proof}
	Let $V \subset X$ be open, then we have
	\begin{equation*}
		\pi^{-1}(\pi(V)) = V + M = \bigcup_{m \in M}(V+m)
	\end{equation*}
	Since $V$ is open, $V+m$ is open. Thus $\pi^{-1}(\pi(V))$ is open. And by the definition of the topology on $X/M$, $\pi(V)$ is open.
\end{proof}
\begin{cor}
	For a linear subspace $M$ of a t.v.s. $X$, the quotient space $X/M$ endowed with the quotient topology is a t.v.s..
\end{cor}
\begin{proof}
	We have the following commutative graph, where $f$ and $g$ are corresponding addition maps or scalar multiplication maps on $X$ and $X/M$.
	\begin{center}
		\begin{tikzcd}
			X \times X \arrow[r, "f"] \arrow[d, "\pi \times \pi"]
				& X \arrow[d, "\pi"] \\
			X/M \times X/M \arrow[r, "g"]
				& X/M
		\end{tikzcd}
	\end{center}
	Then for an open set $V \subset X/M$, since $f$ and $\pi$ are continuous, and $\pi$ is open, $(\pi \times \pi) \circ f^{-1} \circ \pi^{-1}(V)$ is open. By above commutative graph, we have $g \circ (\pi \times \pi) = \pi \circ f$. Therefore, $g^{-1}(V)$ is open, i.e. $g$ is continuous.
\end{proof}

Also, we can find the condition that lets the quotient topological vector space be Hausdorff.
\begin{prop}
	Let $X$ be a t.v.s..
	\begin{enumerate}[label=\arabic*)]
		\item $M$ be a linear subspace of $X$. Then $X/M$ is Hausdorff if and only if $M$ is closed.
		\item $X/\clo{\{e\}}$ is Hausdorff.
	\end{enumerate}	 
\end{prop}
\begin{proof}
	$2)$ is true because $1)$. And $1)$ clearly holds since $M$ is the unit element in $X/M$ and Theorem \ref{thm1} in this subsection.
\end{proof}
\begin{rem}
	By this method, for any t.v.s., we can find a Hausdorff space w.r.t it.
\end{rem}

\subsection{Continuous Linear Maps}

The interesting maps between two topological vector spaces not only preserve the algebraic structure, but also the topological structure, thus these are continuous linear maps.\\
First, for a linear map $f \colon X \sto Y$ between vector spaces $X$ and $Y$, we have the commutative graph, where $\tilde{f}(x+\ker{f}) = f(x)$ is well-defined.
\begin{center}
	\begin{tikzcd}
		X \arrow[r, "f"] \arrow[d, "\pi"]
			& \Img{f} \arrow[r, "i"]
			& Y \\
		X/\ker{f} \arrow[ru, "\tilde{f}"]
	\end{tikzcd}
\end{center}

\begin{prop} \label{prop3}
	Let $f \colon X \sto Y$ be a linear map between two t.v.s.'s $X$ and $Y$.
	\begin{enumerate}[label=\arabic*)]
		\item If $Y$ is Hausdorff and $f$ is continuous, then $\ker{f}$ is closed.
		\item By above notation, $f$ is continuous if and only if $\tilde{f}$ is continous.
	\end{enumerate}
\end{prop}
\begin{proof} 
	$1)$ is because that $\ker{f} = f^{-1}(\{e\})$ and $Y$ is Hausdorff.\\
	For $2)$, if $\tilde{f}$ is continuous, it is clearly that $f = i \circ \tilde{f} \circ \pi$ is continuous. Conversely, it is because of the universal property of quotient maps. And in this case, let $U \subset \Img{f}$ be open, then $f^{-1}(U)$ is open and $\tilde{f}^{-1}(U) = \pi(f^{-1}(U))$. Since $\pi$ is open, $\tilde{f}^{-1}(U)$ is open. Thus, $\tilde{f}$ is continuous.
\end{proof}

\subsection{Complete Topological Vector Spaces}

We have just defined the completeness on a metric space by using sequence, but in metric spaces, we know the topology is so powerful that sequences can do any thing, but in general topology, or the topology in a t.v.s., we need an equivalent concept to describe the completeness.

\begin{defn}
	(Completeness)
	\begin{enumerate}[label=\arabic*)]
		\item A filter $\mathscr{F}$ on a subset $A$ of a t.v.s. $X$ is said to be a Cauchy filter if
			\begin{equation*}
				\forall~ U \in \mathscr{F}(0) \textbf{ in } X,~ \exists ~ M \subset A ~s.t.~ M \in \mathscr{F} ~\&~ M-M \subset U
			\end{equation*}
		\item A subset A of a t.v.s. X is said to be complete if every Cauchy filter on A converges to a point $x \in A$.
	\end{enumerate}
\end{defn}
\begin{rem}
	Said "the filter converges to a point" means that we can define a net on this filter, and this net converge a point. And this definition is also valid without the algebraic structure.
\end{rem}

By this definition, and using the factor that Hausdorff spaces let the limit point of a net uniquely exist, we have similar results comparing with the metric spaces.
\begin{prop}
	Let $X$ be a t.v.s..
	\begin{enumerate}[label=\arabic*)]
		\item If $X$ is Hausdorff, any complete set is closed.
		\item If $X$ is complete, any closed set is complete.
	\end{enumerate}
\end{prop}

We known any metric space can be completion. Similarly, the same result can obtained in any t.v.s..
\begin{thm}
	Let $X$ be a Hausdorff t.v.s., then there exists a complete Hausdorff t.v.s. $\hat{X}$ and a map $i \colon X \sto \hat{X}$ with the following properties.
	\begin{enumerate}[label=\arabic*)]
		\item $i$ is a topological monomorphism.
		\item $\clo{i(X)} = \hat{X}$.
		\item For any complete Hausdorff t.v.s. $Y$ and for every continuous linear map $f \colon X \sto Y$, there exists a continuous map $\hat{f} \colon \hat{X} \sto Y$, s.t. the following graph is commutative
		\begin{center}
			\begin{tikzcd}
				X \arrow[r, "f"] \arrow[d, "i"]
					& Y \\
				\hat{X} \arrow[ru, "\hat{f}"]
			\end{tikzcd}
		\end{center}
	\end{enumerate}
	And ($\hat{X}$, $\hat{f}$) is unique with respect to the isomorphism
\end{thm}
\begin{proof}
	The proof is similar as the proof of the completion of metric spaces, which contructs the $\hat{X}$ as a set of equivalent classes of Cauchy sequences. In a t.v.s., we just need to replace Cauchy sequences by Cauchy filters (in fact, Cauchy nets). Let 
	\begin{center}
		\begin{tabular}{r c l}
			$\tilde{X}$ & $=$ & $\{~ \text{all Cauchy filters in } X ~\}$\\
			$R $ & $\colon$ & $ \mathscr{F} ~R~ \mathscr{G} \Leftrightarrow \forall ~ U \in \mathscr{F}(e),~ \exists ~ A \in \mathscr{F} ~\&~ B \in \mathscr{G} ~s.t.~ A-B \subset U$\\
			$\hat{X}$& $=$ & $\tilde{X} / R$
		\end{tabular}
	\end{center}
	We can easily define linear operations and topology, s.t. $\hat{X}$ become a complete t.v.s.. Then we just need to check the statements in above theorem hold.
\end{proof}

\subsection{Finite Dimensional Topological Vector Spaces}

For a finite dimensional topological vector space, the topology compatible with the algebraic structure has some properties coincided with the "finity". First, continuous linear functionals on a t.v.s. have some properties.

\begin{lem}
	Let $X$ be a t.v.s. over $\K$. Fixed $v \in X$, then the $\phi_{v} \colon \K \sto X$ by $\xi \mapsto \xi v$ is continuous,
\end{lem}
\begin{proof}
	It is because that $\phi_{v} = f \circ \psi_{v}$ where $f$ is the multiplication map.
	\begin{center}
		\begin{tabular}{r l c l r}
			$\K$ & $\stackrel{\psi_{v}}{\rightarrow}$ & $\K \times X$ & $\stackrel{f}{\rightarrow}$ & $X$ \\
			$\xi$ & $\mapsto$ & ($\xi$, $v$) & $\mapsto$ & $\xi v$ 
		\end{tabular} 
	\end{center}
\end{proof}

\begin{lem}
	For a non-zero linear functional $L \colon X \sto \K$, where $X$ is a t.v.s. over $\K$, the following statements are equivalent.
	\begin{enumerate}[label=\arabic*)]
		\item $L$ is continuous,
		\item $\ker{L}$ is closed,
		\item $\ker{L}$ is not dense in $X$,
		\item $L$ is bounded in some neighbourhood of the origin in $X$.
	\end{enumerate}
\end{lem}
\begin{proof}
	The equivalence of $1)$ and $2)$ and $4)$ is clearly.
	\begin{enumerate}
		\item[$1) \Rightarrow 2)$] It is because that $\ker{L} = L^{-1}(\{0\})$.
		\item[$2) \Rightarrow 3)$] Since $L$ is non-zero, it clearly holds.
		\item[$3) \Rightarrow 4)$] By the assumption, there exists a balanced set $V \in \mathscr{F}(e)$ and a point $x \notin \clo{\ker{L}}$ s.t. $(x+V) \bigcap \ker{L} = \varnothing$. $L(V)$ is balanced on $\K$, therefore $L(V)$ is bounded or $L(V) = \K$. But since $(x+V) \bigcap \ker{L} = \varnothing$, $L(V) \neq \K$.
		\item[$4) \Rightarrow 1)$] This implies that $L$ is continuous at $e$. But since $X$ is a t.v.s., $L$ is continuous at every point. \qedhere
	\end{enumerate}
\end{proof}

\begin{thm}
	Let $X$ be a finite dimensional Hausdorff t.v.s. over $\K$ (endowed with the standard topology), and $\dim{X}$ = $d$. Then we have: 
	\begin{enumerate}[label=\arabic*)]
		\item $X$ is topologically isomorphic to $\K^{d}$,
		\item every linear  functional on $X$ is continuous,
		\item every linear map from $X$ to any t.v.s. $Y$ is continuous
	\end{enumerate}
\end{thm}
\begin{proof}
	For $1)$, we just need to find a homeomorphic isomorphism from $\K^{d}$ to $X$, like the following map, where $\{e_i\}_{i=1}^{d}$ is the basis of $X$.
	\begin{center}
		\begin{tabular}{c c c}
			$\K^{d}$ & $\stackrel{\phi}{\longrightarrow}$ & $X$ \\
			$(\lambda_1,~ \lambda_2,~ \cdots,~ \lambda_d)$  & $\longmapsto$ & $\lambda_1 e_1 + \lambda_2 e_2 + \cdots + \lambda_d e_d$
		\end{tabular} 
	\end{center}
	$\phi$ is clearly an algebraic isomorphism. Thus we just need to check $\phi$ is both continuous and open.\\
	Check: $\phi$ is continuous.\\
	When $d = 1$, it is continuous by above lemma. For the general case, since $d$ is finite, $\phi$ is continuous.\\
	Check: $2)$ holds and $\phi$ is open.\\
	When $d = 1$, it is clearly $1)$ and $2)$ are trued. And suppose $1)$ and $2)$ hold for $\dim{X} \leqslant d-1$, then when $\dim{X} = d$, let $L$ be a non-zero linear function on $X$. Then since $\iso{X/\ker{L}}{\Img{L}} \subset \K$, $\dim{\ker{L}} = d-1$. Therefore, $\iso{\ker{L}}{\K^{d-1}} \Rightarrow \ker{L}$ is complete $\Rightarrow \ker{L}$ is closed $\Rightarrow L$ is continuous by above lemma. And,  
	\begin{center}
		\begin{tabular}{c c c}
			$X$ & $\stackrel{\phi^{-1}}{\longrightarrow}$ & $\K^{d}$ \\
			$\lambda_1 e_1 + \lambda_2 e_2 + \cdots + \lambda_d e_d$  & $\longmapsto$ & $(\lambda_1,~ \lambda_2,~ \cdots,~ \lambda_d)$
		\end{tabular} 
	\end{center}
	is continuous since each 
	\begin{equation*}	
			\lambda_1 e_1 + \lambda_2 e_2 + \cdots + \lambda_d e_d \longmapsto \lambda_i
	\end{equation*}
	is continuous.\\
	Then for $3)$, it is clealy since $\dim{\Img{L}} < \infty$. 
\end{proof}
 
\begin{cor}
	~
	\begin{enumerate}[label=\arabic*)]
		\item Every finite dimensional Hausdorff t.v.s. is complete.
		\item Every finite dimensional subspace of a Hausdorff t.v.s. is closed.
		\item For a finite dimensional vector space, there is only one topology w.r.t. homeomorphism that can make it be a Hausdorff t.v.s..
		\item Every bounded subset on a finite dimensional Hausdorff t.v.s. is compact.
	\end{enumerate}
\end{cor}
\begin{proof}
	These properties can be easily obtained by regarding the t.v.s. as $\K^{d}$ endowed with the standard topology.
\end{proof}

Finally, the most important theorem in this subsection is that the converse of $4)$ in above corollary is also true.
\begin{thm}
	A Hausforff t.v.s. is locally compact if and only if it is finite dimensional.
\end{thm}
\begin{proof}
	Let $X$ be a locally compact Hausdorff t.v.s. and K be a compact heighbourhood of $e$ in $X$, i.e.
	\begin{equation*}
		\exists ~ x_1,~ \cdots,~ x_r \in X ~s.t.~ K \subset \bigcup_{i=1}^{r}(x_i+\frac{1}{2}K)
	\end{equation*}
	Let $M = \spn{\{x_1,~ \cdots,~ x_r\}}$, and $M$ is closed. Therefore, $X/M$ is a Hausdorff t.v.s.. Let $\pi \colon X \sto X/M$ be the quotient map.\\
	Since $K \subset M+\frac{1}{2}K$, $\pi(K) \subset \pi(\frac{1}{2}K)$. Thus, by iterating $\pi(2^{n}K) \subset \pi(K)$.\\
	As $K$ is absorbing, $X = \bigcup_{n=1}^{\infty}2^{n}K$,
	\begin{equation*}
		X/M = \pi(X) = \bigcup_{n=1}^{\infty}\pi(2^{n}K) \subset \pi(K) \subset X/M
	\end{equation*}
	And since $\pi$ is continuous, $\pi(K)$ is compact, i.e. $X/M$ is compact.\\
	claim: $\dim{X/M} = 0$ \\
	Suppose $\dim{X/M} > 0$, then for some $\clo{x_0} \in X$ with $\clo{x_0} \neq \clo{e}$, $\R \clo{x_0} \subset X/M$. And since $X/M$ is Hausdorff compact and $\R \clo{x_0}$ is closed, $\R \clo{x_0}$ is compact, which is a contradiction.
\end{proof}

\section{Locally Convex Topological Vector Spaces}

The locally convex topological vector space is a topological vector spaces whose topology is generated by a family of seminorms, thus it can provide more properties.

\subsection{Definition by Convex Sets}

Firstly, the conception of locally convex space can be obtained by convex sets. So, we need to research some elementary traits of convex sets.

\begin{defn}
	~
	\begin{enumerate}[label=\arabic*)]
		\item Let $S$ be any subset of a vector space $X$ over $\K$. The convex hull of $S$, $conv(S)$, is the smallest convex subset containing $S$. In fact, 
		\begin{equation*}
			conv(S) = \{~ \sum_{i=1}^{n}\lambda_i x_i \colon x_i \in S,~ \lambda_i \in [0,1],~ \sum_{i=1}^{n}\lambda_i = 1,~ n \in \N ~\}
		\end{equation*}
		\item A subset $S$ of a vector space $X$ over $\K$ is absolutely convex, if $S$ is convex and balanced
		\item A subset $S$ of a vector space $X$ over $\K$ is called a barrel if $S$ is closed, absorbing and absolutely convex.
	\end{enumerate}
\end{defn}

\begin{prop}
	~
	\begin{enumerate}[label=\arabic*)]
		\item Arbitrary intersections of convex sets are convex sets, and the sum of two convex sets is convex, and linear maps preserve convex.
		\item The convex hull of a balanced set is balanced.
		\item The closure and the interior of a convex set in a t.v.s. is convex.
		\item Every neighbourhood of the origin of a t.v.s. is contained in a neighbourhood of the origin which is a barrel.
	\end{enumerate}
\end{prop}
\begin{proof}
	$1)$ and $2)$ are easily obtained by the definition. \\
	To prove $3)$, for any $\lambda \in [0,1]$, we define the map
	\begin{center}
		\begin{tabular}{l c c l}
			$\phi ~ \colon$ & $X \times X$ & $\longrightarrow$ & $X$ \\
			~ & $(x,y)$ & $\mapsto$ & $\lambda x + (1-\lambda) y$
		\end{tabular}
	\end{center}
	Using the fact that $\phi(S \times S) \subset S$, $S \times S \subset \phi^{-1}(S) \phi^{-1}(\clo{S})$. And since $X$ is a t.v.s., $\phi$ is continuous. Thus $\phi^{-1}(\clo{S})$ is closed, i.e. $\clo{S} \times \clo{S} \subset \phi^{-1}(\clo{S}) \Rightarrow \phi(\clo{S} \times \clo{S}) \subset \clo{S}$. $\clo{S}$ is convex.\\
	Since $z+u = \lambda x + (1-\lambda) y + \lambda u + (1-\lambda) u$ if $z = \lambda x + (1-\lambda) y$, $x + U ~\&~ y + U \subset S \Rightarrow z + U \subset S$. That means $\inte{S}$ is convex.\\
	For $4)$, $\forall ~ U \in \mathscr{F}(e)$, the set
	\begin{equation*}
		\clo{conv\left(\bigcup_{\abs{\lambda} \leqslant 1}\lambda U\right)}
	\end{equation*}
	is a barrel.
\end{proof}
\begin{cor}
	Every neighbourhood of the origin in a t.v.s. $X$ is contained in a neighbourhood of the origin which is absolutely convex.
\end{cor}

Now, we can get the definition of a locally convex t.v.s..
\begin{defn}
	A t.v.s. $X$ is said to be locally convex if there is a basis of neighbourhoods of the origin in $X$ consisting of convex sets.
\end{defn}

By this definition, the structure of the neighbourhoods of the origin in a locally convex t.v.s. can be more explicit by using above proposition.

\begin{prop}
	Let $X$ be a locally convex t.v.s..
	\begin{enumerate}[label=\arabic*)]
		\item $X$ has a basis of neighbourhoods of origin consisting with oepn absorbing absolutely convex sets.
		\item  $X$ has a basis of neighbourhoods of origin consisting with barrels.
	\end{enumerate}
\end{prop}

\begin{thm}
	If $X$ is a locally convex t.v.s., then there exists a basis $\mathscr{B}$ of neighbourhoods of origin consisting of absorbing absolutely convex set s.t.
	\begin{equation*}
		\forall ~ U \in \mathscr{B},~ \forall ~ \rho > 0,~ \exists ~ W \in \mathscr{B} ~s.t.~ W \subset \rho U
	\end{equation*}
	Conversely, if $\mathscr{B}$ is a collection of absorbing absolutely convex subsets of a vector space satisfying above condition, it can generate a unique locally convex t.v.s..
\end{thm}

\subsection{Definition by Seminorms}

\begin{defn}
	Let $X$ be a vector space over $\K$. A map $p \colon X \sto \R^{+}$ is called a seminorm if it satisfies:
	\begin{enumerate}[label=\arabic*)]
		\item $p(x+y) \leqslant p(x)+p(y),~ \forall ~ x,~ y \in X$,
		\item $p(\lambda x) = \abs{\lambda} p(x),~ \forall ~ x \in X,~ \forall ~ \lambda \in \K$.
	\end{enumerate}
\end{defn}
\begin{rem}
	In fact, $\ker{p}$ is a linear sbuspace and if $\ker{p} = \{0\}$, $p$ is called a norm.
\end{rem}

By the intuition, the seminorm could construct the continuity of the addition and multiplication since it satisfies above properties. Now, we can build this rigorously.

\begin{defn}
	Let $X$ be a vector space and $A \subset X$ be a nonempty subset. The Minkowski functional of $A$ is the map
	\begin{center}
		\begin{tabular}{l c c l}
			$p_A ~ \colon$ & $X$ & $\longrightarrow$ & $\R$ \\
			~ & $x$ & $\mapsto$ & $\inff\{~ \lambda > 0 \colon x \in \lambda A ~\}$
		\end{tabular}
	\end{center}
\end{defn}

Let $X$ be a vector space and $p$ is a seminorm on $X$, then let $\inte{U}_p = \{~ x \in X \colon p(x) < 1 ~\}$, $U_p = \{~ x \in X \colon p(x) \leqslant 1 ~\}$. Thus, $U$ may be the basis generating the topology. To see it, the following proposition is helpful.

\begin{prop}
	Let $A \subset X$ be a nonempty subset of a vector space, which is absorbing and absolutely convex, then $p_A$ is a seminorm and $\inte{U}_{p_A} \subset A \subset U_{p_A}$. Conversely, if $q$ is a norm on $X$ then $\inte{U}_q$ is an absorbing absolutely convex set and $q = p_{\inte{U}_q}$.
\end{prop}
\begin{proof}
	Since $A$ is balanced, $\xi A \in \lambda A \Leftrightarrow x \in \frac{\lambda}{\abs{\xi}} A$. Thus,
	\begin{equation*}
		p_A(x) = \abs{\xi} \inff{\{~ \frac{\lambda}{\abs{\xi}} \colon x \in \frac{\lambda}{\abs{\xi}} A~\}} = \abs{\xi} p_A(x)
	\end{equation*}
	And $p_A(x) < \infty  ~( \forall ~ x \in X)$ since $A$ is absorbing.\\
	Fixed $x,~ y \in X$, $\forall \varepsilon > 0,~ \exists ~ \lambda,~ \mu > 0$, s.t. $x \in \lambda A ~\&~ y \in \mu A$ and
	\begin{equation*}
		\lambda \leqslant p_A(x) + \varepsilon ~,~ \mu \leqslant p_A(y) + \varepsilon,
	\end{equation*}
	By convexity of $A$, $\lambda A + \mu A \subset (\lambda + \mu) A$. Thus,
	\begin{equation*}
		p_A(x) = \inff{\{~ \delta > 0 \colon x+y \in \delta A ~\}} \leqslant \lambda + \mu \leqslant p_A(x) + p_A(y) + 2\varepsilon
	\end{equation*}
	$\Rightarrow ~ p_A(x)$ is a seminorm.
	\begin{center}
		\begin{tabular}{r c l}
			$x \in \inte{U}_{p_A}$ & $\Rightarrow$ & $\exists ~ \lambda \in [0,1] ~s.t.~ x \in \lambda A \subset A$ \\
			$x \in A$ &  $\Rightarrow$  & $1 \in \inff\{~ \lambda > 0 \colon x \in \lambda A ~\} ~ \Rightarrow ~ p_A(x) \leqslant 1 \Rightarrow x \in U_{p_A}$
		\end{tabular}
	\end{center}
	That means $\inte{U}_{p_A} \subset A \subset U_{p_A}$.\\
	Finally, the statements for $q$ can be obtained easily by the definition.
\end{proof}

Now, we can give the definition of a locally convex t.v.s. by seminorms coinciding with the definition by convex sets.

\begin{thm}
	Let $X$ be a vector space and $\mathscr{P} = \{p_i\}_{i \in I}$ be a family of seminorms. Then the initial topology $\mathscr{T}_P$ generated by $\mathscr{P}$ makes $X$ be a locally convex t.v.s. In fact, the basis of neighbouhoods of the origin in $X$ is like
	\begin{equation*}
		\mathscr{B} = \left\{~ \{x \in X \colon p_{i_1}(x)<\varepsilon,\cdots,p_{i_n}(x)<\varepsilon\} \colon i_1,\cdots,i_n \in I,n \in \N, \varepsilon > 0 ~\right\}
	\end{equation*}
	Conversely, the topology of any locally convex t.v.s. can be generated by a family of seminorms.
\end{thm}
\begin{proof}
	Each element in the subbasis of $\mathscr{T}_P$ is like $\{ x \in X \colon p_i(x) < \varepsilon \} = \varepsilon \inte{U}_{p_i}$, which is clearly absorbing and absolutely convex. Therefore, every element in $\mathscr{B}$ is convex. $(X,\mathscr{T}_P)$ is a locally convex t.v.s..\\
	Convesrly, if $(X, \mathscr{T})$ is a locally convex t.v.s., the basis of neighbourhoods of the origin in $X$ consists of absorbing and absolutely convex stes, which can generate a family of seminorms by above proposition. Therefore, these seminorms can generate a locolly convex topology $\mathscr{T}_P$. In fact, $\mathscr{T}_P = \mathscr{T}$, since $\inte{U}_{p_A} \subset A \subset U_{p_A}$.
\end{proof}
\begin{rem}
	By this theorem, in a vector space $X$, the seminorms on $X$ can coincide with a locally convex topology making $X$ be a t.v.s..
\end{rem}

There some extra properties for the seminorms on a vector space.
\begin{prop} \label{prop1}
	Let $X$ be a vector space and $p$ be a seminorm on $X$. Then,
	\begin{enumerate}[label=\arabic*)]
		\item $\forall~ r>0,~ r \inte{U}_p=\{x \in X \colon p(x) <r\} = \inte{U}_{\frac{1}{r}p}$.
		\item $\forall x \in X,~ x+\inte{U}_p = \{y \in X \colon p(y-x) < 1\}$.
		\item if $q$ is a seminorm on $X$, $p \leqslant q \Leftrightarrow \inte{U}_q \subset \inte{U}_p$.
		\item if $\{s_i\}_{i=1}^{n}$ are seminorms on $X$, then $s(x) = \max_{i=1,\cdots,n}{s_i(x)}$ is also a seminorm and $\inte{U}_s = \bigcap_{i=1}^{n} \inte{U}_{s_i}$
	\end{enumerate}
\end{prop}

\begin{thm}
	Let $\mathscr{P} = \{p_i\}_{i \in I}$ and $\mathscr{Q} = \{q_j\}_{j \in J}$ be two families of seminorms on a vector space $X$ inducing $\mathscr{T}_P$ and $\mathscr{T}_Q$, then
	\begin{equation*}
		\mathscr{T}_Q \subset \mathscr{T}_P \Leftrightarrow \forall~ q \in \mathscr{Q},~ \exists~ \{i_k\}_{k=1}^{n} \subset I,~ \exists~ C>0,~s.t.~ Cq(x) \leqslant \max_{k=1,\cdots,n}{p_{i_k}(x)}
	\end{equation*}
\end{thm}
\begin{proof}
	This right side of above statement is equivalent to that
	\begin{equation*}
		\forall~ q \in \mathscr{Q},~ \exists~ \{i_k\}_{k=1}^{n} \subset I,~ \exists~ C>0,~s.t.~ C \bigcap_{k=1}^{n} \inte{U}_{p_{i_k}} \subset \inte{U}_q
	\end{equation*}
	So, it is clearly equivalent to $\mathscr{T}_Q \subset \mathscr{T}_P$.
\end{proof}
\begin{rem}
	Because of this, we have the definition of equivalent norms. In fact, two norms $p$ and $q$ are said to be equivalent if and only if there exists $C_1,~ C_2 > 0$, s.t. $C_1p(x) \leqslant q(x) \leqslant C_2 p(x)$, for all $x \in X$. This definition means that two equivalent norms can generate one same topology. 
\end{rem}
\begin{cor} \label{cor1}
	The family $\mathscr{P} = \{p_i\}_{i \in I}$ of seminorms and \\$\mathscr{Q} = \{~ \max_{i \in B} p_i \colon \varnothing \neq B \subset I \text{ with } B \text{ finite} ~\}$ can generate one same topology on $X$
\end{cor}

\subsection{Separability and Metrizability}

For a t.v.s., $(T_1)$ is equivalent to Hausdorff and $(T_1)$ is associated with the ability of a topology separating points. Therefore, wheather a t.v.s. is a Hausdorff space or not is completely determined by wheather the topology of it can separate points or not. Then for a locally convex t.v.s., whose topology is induced by a family of seminorms, this separability is related to these seminorms.

\begin{defn}
	A family of seminorms $\mathscr{P} = \{~p_i~\}_{i \in I}$ on a vector space $X$ is said to be speparating, if
	\begin{equation*}
		\forall~ x \in X \backslash \{0\},~ \exists~ i \in I ~s.t.~ p_i(x) \neq 0
	\end{equation*}
\end{defn}
\begin{rem}
	In fact, above condition is equivalent to 
	\begin{equation*}
		\text{if } p_i(x) = 0, ~\forall~ i \in I \Rightarrow x = 0
	\end{equation*}
\end{rem}	

Now, we can give the condition that makes a locally convex t.v.s. be Hausdorff.

\begin{thm} 
	A locally convex t.v.s. $X$ is Hausdorff if and only if its topology can be induced by a separating family of seminorms $\mathscr{P} = \{~p_i~\}_{i \in I}$ .
\end{thm}
\begin{proof}
	If $\mathscr{P} = \{~p_i~\}_{i \in I}$ is separating, the fact that $\mathscr{T}_P$ is Hausdorff can be obtained easily by the definition.\\
	Conversely, if $X$ is Hausdorff, for $x \neq 0$, we can find a $U \in \mathscr{F}(0)$, s.t. $U$ can separate $x$ and $0$. But since $X$ is locally convex, $U$ can be chosen as $\inte{U}_p$ for a seminorm $p$. Thus, for this $p$, $p(x) \neq 0$.
\end{proof}

For the metrizability of a locally convex t.v.s., the consequece is also easier than general case.
\begin{thm} \label{thm4}
	A locally convex t.v.s. $X$ is metrizable if and only if its topology is determined by a countable separating family of seminorms.
\end{thm}
\begin{proof}
	It can be directly obtained by the Nagata–Smirnov's Metrization Theorem. Also, there is a more explicit proof. If the topology of $X$ is generated by a countable separating family of seminorms $\mathscr{P} = \{~p_n~\}_{n=1}^{\infty}$, we can define the metric $d$ on $X$ by
	\begin{equation*}
		d(x,y) = \sum_{n=1}^{\infty} 2^{-n} \frac{p_n(x-y)}{1+p_n(x-y)}
	\end{equation*} 
	Conversely, if $(X,d)$ is the metric space, the subbasis of the topology generated by this metric is like $U_n = \{x \colon d(x,0) < 1/n\}$. And these $U_n$ can provide a countable separating family of seminorms. In fact, if $\mathscr{Q} = \{~q_i~\}_{i \in I}$ generates the topology of $X$, for each $U_n$, there are $q_1,\cdots,q_k \in \mathscr{Q}$ and $\varepsilon_1,\cdots,\varepsilon_k > 0$, s.t. $\bigcap_{i=1}^{k} \{x \colon q_i(x) < \varepsilon_i\} \subset U_n$. Then let $p_n = \sum_{i=1}^{k} \varepsilon_i^{-1}q_i$. It can check that the family $\{p_n\}_{n=1}^{\infty}$ generate the coincided topology on $X$.
\end{proof}

\subsection{Continuous Linear Maps on LCTVS}

To give the special property of continuous linear maps on LCTVS, we need firstly refine the family of seminorms.
\begin{defn}
	A family $\mathscr{Q} = \{~q_j~\}_{j \in J}$ of seminorms on a vector space $X$ is said to be directed if
	\begin{equation*}
		\forall ~ j_1, \cdots, j_n \in \mathscr{Q},~ \exists ~ j \in J ~\&~ C>0,~ s.t.~ C q_j(x) \geqslant \max_{k=1,\cdots,n} q_{j_k}(x),~ \forall~ x \in X
	\end{equation*}
\end{defn}
\begin{rem}
	By \textbf{Proposition} \ref{prop1} in \textbf{1.2.2}, this definition is equivalent to that
	\begin{equation*}
		\forall~ \inte{U}_{q_{j_1}}, \cdots, \inte{U}_{q_{j_n}},~ \exists~ \inte{U}_{q_j} ~s.t.~ \inte{U}_{q_j} \subset \bigcap_{k=1}^{n} \inte{U}_{j_i}
	\end{equation*}
	And thus the basis of this directed family of seminorms should be like
	\begin{equation*}
		\mathscr{B}_d = \{~ r\inte{U}_q \colon q \in \mathscr{Q},r>0 ~\}
	\end{equation*}
\end{rem}

By this special topology, we can find the condition making linear functional continuous.

\begin{prop}
	Let $\mathscr{T}$ be a locally convex topology on a vector space $X$ generated by a directed family $\mathscr{Q}$ of seminorms on $X$. Then
	\begin{equation*}
		L \colon ~ X \longrightarrow \K
	\end{equation*}
	is a $\mathscr{T}$-continuous linear functional if and only if $\exists ~ q \in \mathscr{Q}$ s.t. $L$ is $q$-continuous, i.e. $\abs{L(x)} \leqslant Cq(x)$ for some $C > 0$.
\end{prop}
\begin{proof}
	In fact, this property of continuous linear functional is because the element in a directed locally convex topology is like $r\inte{U}_q$. In fact, we just need to check the origin point.\\
	If $L$ is continuous, there exists a $r\inte{U}_q$ s.t. $r\inte{U}_q \subset L^{-1}(B_1(0))$, where $B_1(0)$ is the unit ball centered at $0$. This is equivalent to the $q$-continuity of $L$.\\
	Conversely, it is clearly by the fact $\mathscr{T}_q \subset \mathscr{T}$.
\end{proof}

We can easily see that the topology of a locally convex t.v.s. can be always induced by a directed family of seminorms by the \textbf{Corollary} \ref{cor1} in \textbf{1.2.2}. Thus, we have the corollary.

\begin{cor} \label{cor3}
	$(X,\mathscr{T})$ is a locally convex t.v.s. and $\mathscr{T}$ is generated by the family $\mathscr{P} = \{p_i\}_{i \in I}$. Then $L \colon ~ X \longrightarrow \K$ is a continuous linear functional if and only if 
	\begin{equation*}
		\exists ~ i_1,\cdots,i_n \in I,~ \exists ~ C>0 ~s.t.~ \abs{L(x)} \leqslant C \max_{k=1,\cdots,n} p_{i_k}(x),~ \forall ~ x \in X
	\end{equation*}
\end{cor}

And this corollary can be easily extended to linear maps. And the proof is similar as above statement In fact, we just need to replace $B_1(0)$ by $\inte{U}_q$
\begin{thm} \label{thm2}
	Let $X$ and $Y$ be two locally convex t.v.s.'s generated by $\mathscr{P}$ and $\mathscr{Q}$. Then linear map $f \colon X \sto Y$ is continuous if and only if 
	\begin{equation*}
		\forall ~ q \in \mathscr{Q},~ \exists ~ p_1,\cdots,p_n \in \mathscr{P},~ \exists ~ C>0 ~s.t.~ q(f(x)) \leqslant C \max_{i=1,\cdots,n} p_i(x)
	\end{equation*}
\end{thm}

\section{The Hahn-Banach Theorem}
\subsection{Two Forms of Hahn-Banach Theorem}

\begin{thm}[Geometric form]
	Let $X$ be a t.v.s. over $\K$, $N$ be a linear subspace of $X$ and $\Omega$ be a convex open subset of $X$ with $N \bigcap \Omega = \varnothing$. Then there is a closed hyperplane $H$ of $X$ s.t.
	\begin{equation*}
		N \subset H ~~\&~~ H \bigcap \Omega = \varnothing
	\end{equation*}
\end{thm}
\begin{proof}
	Assume that $\Omega \neq \varnothing$.\\
    Let $\mathscr{F} = \{~ \text{all linear subspace } L \text{ of } X \text{ s.t. } N \subset L \text{ and } L \bigcap \Omega = \varnothing ~\}$. \\
	Since $N \in \mathscr{F}$, $\mathscr{F} \neq \varnothing$. And $\mathscr{F}$ can be ordered by "$\subset$". Clearly, for every chain $\mathscr{C} = \{C_i\}_{i \in I} \in \mathscr{F}$, it has a maximal element $C = \bigcup_{i \in I} C_i \in \mathscr{F}$. Then by Zorn's Lemma, there exists a maximal $H \in \mathscr{F}$. And this $H$ is closed because the maximality of $H$.\\
	In fact, we just need to check $\dim{X/H} = 1$. In the case $\K = \R$, if $\dim{X/H} \geqslant 2$, then we can find one dimensional subspace $L$ in $X$ s.t. $L \oplus H$ satisfies above condition. Then it is a contradiction to the maximality of $H$. And for $\K = \C$, using above process to get a real hyperplane $H_0$ and then $H = H_0 \bigcap iH_0$ is the hyperplane we need.\\
	The main difficulty of this proof is to construct $L$. In fact, we just need to find a line $\tilde{L}$ in $X/H$ s.t. $\tilde{L} \bigcap A = \varnothing$, where$A = \bigcup_{\lambda > 0} \lambda \pi(\Omega)$ is a cone. This $\tilde{L}$ can easily be found because we can find $\clo{x}, -\clo{x} \in X/H \backslash A$ with $\clo{x} \neq \clo{0}$ by using the fact that $\dim{X/H} \geqslant 2$.
\end{proof}
\begin{rem}
	In this theorem, if $N$ is an affine linear subspace, then the $H$ can be chosen as a affine hyperplane satisfying above condition. It is clear by using translation.
\end{rem}

\begin{thm}[Analitic form]
	Let $p$ be a seminorm on a vector space $X$ over $\K$, $M$ is a linear space of $X$ and f is a linear functional on $M$ s.t. $\abs{f(x)} \leqslant p(x),~ \forall~ x \in M$. Then there is a linear function $\tilde{f}$ on $X$ s.t. $\tilde{f}(x) = f(x),~ \forall~ x \in M$ and $\abs{\tilde{f}(x)} \leqslant p(x),~ \forall~ x \in X$.
\end{thm}
\begin{proof}
	Let $N = \{x \in M \colon f(x) = 1\}$(affine hyperplane) and $\Omega = \{x \in X \colon  p(x) < 1\}$(open convex set). Then since $N \bigcap \Omega$, we can find a closed affine hyperplane $H$ of $X$, s.t. $N \subset H$ and $H \bigcap \Omega = \varnothing$. Fixed $x_0 \in N \subset H$, $H-x_0$ is a hyperplane, thus it can generate a functional $\tilde{f}$ on $X$. Set $\tilde{f}(x_0) = 1$, then define
	\begin{center}
		\begin{tabular}{l c c l}
			$\tilde{f}~\colon$ & $X=(H-x_0) \oplus \K x_0$ & $\longrightarrow$ & $\K$ \\
			$~$ & $(h-x_0)+\lambda x_0$ & $\longmapsto$ & $\lambda$
		\end{tabular}
	\end{center}
	Since $M = (N-x_0) \oplus \K x_0$ and $f(x_0) = 1$ and $H \bigcap \Omega = \varnothing$, we can easily check that $\tilde{f}(x) = f(x),~ \forall~ x \in M$ and $\abs{\tilde{f}(x)} \leqslant p(x),~ \forall~ x \in X$.
\end{proof}

\subsection{Applications}
By the geometric form of the Hahn-Banach Theorem, it says about hyperplanes can separate some non-intersecting subsets. And moreover, by the analytic form of the Hahn-Banach Theorem, since hyperplanes are linked with functionals, functionals can also separate some some non-intersecting subsets in a t.v.s. First, we can define this association more explicit.

\begin{defn}
	Let $X$ be a t.v.s. over $\R$ and $H$ is a closed affine hyperplane. For $A,~B \subset X$ and $A \bigcap B = \varnothing$, we say $A$ and $B$ separated by $H$, if
	\begin{equation*}
		\exists~ a \in \R,~ s.t.~ H = f^{-1}(\{a\}) \text{ for some } f \colon X \sto \R ~\&~ f(A) \geqslant a,~ f(B) \leqslant  a.
	\end{equation*}
\end{defn}
 
\begin{thm}
	Let $X$ be a t.v.s. over $\R$ and $A,~ B$ be two disjoint convex non-empty subsets of $X$, then we have:
	\begin{enumerate}[label=\arabic*)]
		\item if $A$ is open, then there exists a closed affine hyperplane $H$ of $X$ separating $A$ and $B$.
		\item if $A, B$ are open, $H$ can strictly separate $A$ and $B$.
		\item if $A$ is a cone and $B$ is open, then $H$ can be chosen as a hyperplane.
	\end{enumerate}
\end{thm}
\begin{proof}
	Let $U=A-B$. Clearly, U is open and convex and $N=\{0\} \bigcap H = \varnothing$. Therefore, there exists a continuous functional $f$ on $X$, s.t. $f(U) > 0$ i.e. $f(x) > f(y),~ \forall~ x \in A ~\&~ y \in B$. Since $B \neq \varnothing$, let $a = \inff_{x \in A} f(x) > -\infty$. And thus $1)$ and $2)$ can be obtained. \\
	For $3)$, if $A$ is a cone, then $tf(x) = f(tx) \geqslant a,~ \forall~ t > 0 \Rightarrow f(x) \geqslant \frac{a}{t}$. Thus, $f(A) \geqslant 0$. $H$ can be chosen as a hyperplane. 
\end{proof}

For a locally convex t.v.s $X$, each point in $X$ has some convex heighbourhoods. Therefore, we have following corollaries.

\begin{cor} \label{cor2}
	Let $X$ be a locally convex t.v.s over $\R$.
	\begin{enumerate}[label=\arabic*)]
		\item If $A$ and $B$ are two disjoint closed subsets and $B$ is compact, then $A$ and $B$ are strictly separated.
		\item If A is a closed convex subset of $X$ and $x \notin A$, then x is strictly separated from $A$.
		\item If $A$ is a subset of $X$, then $\clo{\spn{\{A\}}}$ is the intersection of all closed hyperplanes containing $A$.
	\end{enumerate}
\end{cor}

And these consequenses can be extended to $\C$.

\begin{thm} \label{thm3}
	Let $X$ be a locally convex t.v.s over $\C$ and $A,B$ be two disjoint closed convex subsets of $X$. If $B$ is compact, then there is a continuous linear functional $f \colon X \sto \C$, and $\alpha \in \R$, and $\varepsilon > 0$ s.t.
	\begin{equation*}
		\Rea{f(x)} \leqslant \alpha < \alpha +\varepsilon \leqslant \Rea{f(y)},~ \forall~ x \in A,~ \forall~ y \in B
	\end{equation*} 
\end{thm}

\section{Banach Spaces}
The Banach space is a very special locally convex topological space, whose topology is generated by only one seminorm. To make this space be a Hausdorff space, this seminorm is actually a norm. And more, we need it become complete. So, a Banach space is a complete normed space. Because it is definitely a locally convex Hausdorff t.v.s., all results mentioned above can be apllied on it. And we can have more interesting results of the Banach space because of its simple structure.

\subsection{Elementary Properties}

\begin{defn}
	A normed space is a vector space $X$ with a compatible norm $\norm{\cdot}$, which makes it be a locally convex Hausdorff topological vector space. A Banach space is a complete normed space.
\end{defn}
\begin{rem}
	By this definition, we know that any result mentioned above can be also true for the Banach space $(X,\norm{\cdot})$ by replacing the family of seminorms by the $\norm{\cdot}$. Moreover, two equivalent norms on $X$ provide same topology.
\end{rem}

The properties of finite dimensional Banach spaces is in the subsection \textbf{1.1.5}. And for the quotient space of a Banach space, we can get a more explicit expression of the induced quotient norm.

\begin{thm}
	Let $(X, \norm{\cdot})$ be a Banach space and $M$ be a closed linear subspace of $X$ and $\pi \colon X \sto X/M$, then the induced quotient norm on $X/M$ is defined as $\norm{x+M} = \inff{\{\norm{x+y} \colon y \in M\}}$. Thus, using the consequences of the quotient t.v.s., we have following results.
	\begin{enumerate}[label=\arabic*)]
		\item $\pi$ is continuous and $\norm{\pi(x)} \leqslant \norm{x}$.
		\item $X/M$ is a Banach space.
		\item $W \subset X/M$ is open if and only if $\pi^{-1}(W)$ is open.
		\item $\pi$ is open.
		\item if $N$ is a finite dimensional subspace of $X$, then $M+N$ is closed.
	\end{enumerate}
\end{thm}
\begin{proof}
	The element in the subbasis of the topology generated by $\norm{\cdot}$ at $0$ is like $U_\varepsilon=\{x \in X \colon \norm{x} < \varepsilon\}$ for a fixed $\varepsilon > 0$. Therefore, the element $V_\epsilon$ in the subbasis of the induced topology on $X/M$ at $0$ satisfies $\pi^{-1}(V_\epsilon)=\{x \colon \norm{x} < \epsilon\}$ for some $\epsilon > 0$, i.e. $V_\epsilon = \{x+M \colon \norm{x+y_0} < \epsilon, \exists y_0 \in M\}$ .Clearly, $V_\epsilon$ is an absorbing absolutely convex set. Then the Minkowski functional $p_\epsilon$ of $V_\epsilon$ is like
	\begin{eqnarray*}
		p_\epsilon(x+M) &=& \inff \{\lambda > 0 \colon x+M \in \lambda V_\epsilon\} \\
					 &=& \inff \{\lambda > 0 \colon \norm{x+y_0} < \lambda \epsilon,\exists y_0 \in M \} \\
					 &=& \frac{1}{\epsilon} \inff \{{\norm{x+y} \colon y \in M}\}
	\end{eqnarray*}
	Clearly, for any $\epsilon > 0$, $p_\epsilon$ is a norm and it is equivalent to the norm $\norm{x+M}$. Thus the quotient topology is definitely generated by $\norm{x+M}$.\\
	Then, $1)$ and $3)$ clearly hold by the definition. $2)$ is true since $H$ is a Banach space. $4)$ is true for any general t.v.s.. $5)$ holds since $N+M$ is a finite dimensional subspace of $X/M$. 
\end{proof}

Similarly, we can define the norm on the product space of some Banach spaces.
\begin{defn}
	Let $\{X_i\}_{i=1}^{p}$ is a family of Banach spaces with norm $\norm{\cdot}$. Then,
	\begin{enumerate}[label=\arabic*)]
		\item if $1 \leqslant p < \infty$, 
				\begin{equation*}
					\oplus_{i=1}^{p} X_i = \left\{~ x \in \prod_{i}^{p} X_i \colon \norm{x} = \left[ \sum_{i=1}^p \norm{x_i}^p\right]^{1/p} ~\right\}
				\end{equation*}
		\item if $p = \infty$,
				\begin{equation*}
					\oplus_{i=1}^{\infty} X_i = \left\{~ x \in \prod_{i}^{p} X_i \colon \norm{x} = \sup_i \{x(i)\} < \infty ~\right\}
				\end{equation*}
	\end{enumerate}
\end{defn}

\subsection{Linear Transformations and Linear Functionals}

By results in \textbf{Theorem} \ref{thm2} in the subsection \textbf{1.2.4} the linear transformation $T \colon X \sto Y$ between two Banach spaces is continuous if and only if $\exists~ C > 0$, s.t. $\norm{Tx} \leqslant \norm{x}$, $\forall~ x \in X$. Because of this property, we can define the norm of continuous linear transformation.

\begin{defn}
	Let $T \colon X \sto Y$ between two Banach spaces be a linear transformation. Then the norm of $T$ is defined as
	\begin{equation*}
		\norm{T} = \sup_{x \in X,x \neq 0} \frac{\norm{Tx}}{\norm{x}}
	\end{equation*}
\end{defn}
\begin{rem}
	By this definition, we know $T$ is continuous if and only if $\norm{T} < \infty$, and we call $T$ is bounded. Also, the formula of the norm can be
	\begin{equation*}
		\norm{T} = \sup_{\norm{x} = 1} \frac{\norm{Tx}}{\norm{x}}
	\end{equation*}
\end{rem}

Let $\fml{B}(X,Y)=$\{all bounded linear transformations between $X$ and $Y$\}. $\fml{B}(X,Y)$ is a Banach space with this norm. Then in the space $\fml{B}(X,Y)$, there are two topologies. The first one is generated by a family of seminorms $\{p_x\}_{x \in X}$, where $p_x(T) = \norm{Tx}$. And the second one is generated by the norm $\norm{\cdot}$. In fact, the convergence of a sequense in $\fml{B}(X,Y)$ with respect to the first one is about pointwise convergence, and with respect to the second one is about uniform convergence. Clearly, the second one is stronger. But in some case the first one can give some information of the first one.

\begin{thm}[The Principle of Uniform Boundedness]
	Let $X$ be a Banach space and $Y$ be a normed space, and $\{T_i\}_{i \in I}$ be a subset of $\fml{B}(X,Y)$. If for any $x \in X$ $\{\norm{T_i x}\}_{i \in I}$ is bounded, then $\{\norm{T_i}\}_{i \in I}$ is bounded.
\end{thm}
\begin{proof}
	Firstly, there is a open ball $B(x_0, \varepsilon)$ such that for any $x \in B(x_0, \varepsilon)$, $\norm{T_i}x \leqslant K$ for some constant $K$. Asssume it is not true. We can find a family of open balls $B(x_n, \varepsilon_n)$ s.t. $B(x_n, \varepsilon_n) \subset B(x_{n-1}, \varepsilon_{n-1})$, $\varepsilon_n < 1/n$, and a sequence ${i_n} \subset I$, satisfying $\norm{T_{i_n}x} > n$. And since each $\clo{B(x_n, \varepsilon_n)}$ is compact, there is a $z \in \bigcap_{n=1}^{\infty} \clo{B(x_n, \varepsilon_n)}$. This contradicts to the boundedness of $\{T_i z\}_{i \in I}$.\\
	Next, with this $B(x_0, \varepsilon)$, if $y \in X$ and $y \neq 0$, then $z = \frac{\varepsilon}{\norm{y}}y + x_0 \in B(x_0, \varepsilon)$. Therefore,
	\begin{equation*}
		\frac{\varepsilon}{\norm{y}} \norm{T_i y} - \norm{T_i x_0} \leqslant \norm{\frac{\varepsilon}{\norm{y}} \norm{T_i y} + \norm{T_i x_0}} = \norm{T_i z} \leqslant K
	\end{equation*}
	Then since $K^{'} = \sup_{i \in I}{\norm{T_i x_0}} < \infty$, 
	\begin{equation*}
		\norm{T_i y} \leqslant \frac{K+K^{'}}{\varepsilon} \norm{y} < \infty
	\end{equation*}
	Thus ${\norm{T_i}}_{i \in I}$ is bounded.
\end{proof}
\begin{rem}
	Let $X^{*} = \fml{B}(X,\K)$ be the continuous linear functional space. Above theorem can easily apply to it.
\end{rem}
\begin{cor}
	For a Banach space $X$ and $S \subset X^{*}$ a subset, $S$ is norme bounded if and only if for every $x \in X$, $\sup\{\abs{f(x)} \colon f \in S\}$.
\end{cor}

Another important property of the linear transformation betweeen two Banach spaces is that any continuous linear surjective transformation is open.

\begin{thm}[Open Mapping Theorem]
	Let $X$ and $Y$ be two Banach spaces and $T \colon X \sto Y$ be a continuous linear surjection. Then $T$ is open.
\end{thm}
\begin{proof}
	Let $X_\varepsilon$ and $Y_\varepsilon$ be two open balls in $X$ and $Y$ with centering at 0 and and radius $\varepsilon$.
	\begin{enumerate}[label=\arabic*)]
		\item For any $\varepsilon > 0$, there is a $\delta > 0$, s.t. $Y_{\delta} \subset \clo{T(X_{\varepsilon})}$. \\
		By $X = \bigcup_{n=1}^{\infty} n X_{\varepsilon}$, $Y=\bigcup_{n=1}^{\infty} T(nX_{\varepsilon})$. Then since $Y$ is the second Baire category, there exists $n_0$ and a ball $B_r(z) \subset Y$ s.t. $B_r(z) \subset \clo{T(n_0X_{\varepsilon})}$ i.e. $B_{\delta}(y_0) \subset \clo{T(X_{\varepsilon})}$ with $\delta = r/n$ and $y_0 = z/n$. Then since for any $y \in Y_{\delta}$, $y = (y+y_0) - y_0$
		\begin{equation*}
			Y_{\delta} \subset \{y_1-y_2 \colon y_1,y_2 \in B_{\delta}(y_0)\} \subset \clo{T(\{x_1-x_2 \colon x_1,x_2 \in X_{\varepsilon}\})} \subset \clo{T(X_{2\varepsilon})}
		\end{equation*}
		\item For any $\varepsilon_0 > 0$, there is a $\delta_0 > 0$, s.t. $Y_{\delta_0} \subset T(X_{2\varepsilon_0})$. \\
		Choose a positive sequence $\{\varepsilon_n\}$ with $\sum_{n=1}^{\infty} \varepsilon_n < \varepsilon_0$, then there exists a positive sequence $\delta_n$ with $\delta_n \sto 0$ s.t. $Y_{\delta_n} \subset \clo{T(X_{\varepsilon_n})}$\\
		For any $y \in Y_{\delta_0}$, there is a $x_0 \in X_{\varepsilon_0}$, s.t. $\norm{y-Tx_0} < \delta_1$. since $y-Tx_0 \in Y_{\delta_0}$, there is a $x_1 \in X_{\varepsilon_1}$ s.t. $norm{y-Tx_0-Tx_1} < \delta_2$. Thus by induction, we can find a sequence $\{x_n\}$ s.t. $x_n \in X_{\varepsilon_n}$ and
		\begin{equation*}
			 \norm{y-T\left(\sum_{k=0}^{n}x_k\right)} < \delta_{n+1}
		\end{equation*}
		And since $\sum_{n=1}^{\infty} \varepsilon_n < \varepsilon_0$, the sequence $\sum_{k=0}^{n}x_k$ absolutely converges to $x$ in $X$. And
		\begin{equation*}
			\norm{x} \leqslant \sum_{n=1}^{\infty} \norm{x_n} \leqslant \sum_{n=1}^{\infty} \varepsilon_n < 2 \varepsilon_0
		\end{equation*}
		By the continuity of $T$ and $\delta_n \sto 0$, $y=Tx$. Therefore, $Y_{\delta_0} \subset T(X_{2\varepsilon_0})$.
		\item For any open set $G \subset X$ and $y_0 = Tx_0$ with $x_0 \in G$, there is a open ball $Y_\delta$ s.t. $y_0 + Y_\delta \subset T(G)$.\\
		Since $G$ is open, there is a open ball $X_\varepsilon$ with $x_0+X_\varepsilon \subset G$. Then there is a $\delta > 0$ s.t. $Y_{\delta} \subset T(X_\varepsilon)$. Thus
		\begin{equation*}
			y_0+Y_{\delta} \subset Tx_0 + T(X_{\varepsilon}) = T(x_0 + X_{\varepsilon}) \subset T(G)  \qedhere
		\end{equation*}
	\end{enumerate}
\end{proof}

Then there is a directed corollary from the Open Mapping Theorem.
\begin{cor}[The Inverse Mapping Theorem]
	Let $X$ and $Y$ be two Banach spaces and $T \colon X \sto Y$ be a continuous linear isomorphism, then $T^{-1}$ is also bounded.
\end{cor}

\begin{cor}[The Closed Graph Theorem]
	Let $X$ and $Y$ be two Banach spaces and $T \colon X \sto Y$ be a linear transformation. If the graph of $T$, $G = \{x \oplus Tx \colon x \in X\}$ is closed, then $T$ is continuous.
\end{cor}
\begin{proof}
	Since $X$ and $Y$ are two Banach spaces and $G$ is closed, $G$ is also a Banach space. Let $P_1 \colon G \sto X$ be $P_1(x \oplus Tx)=x$ and $P_2 \colon G \sto Y$ be $P_2(x \oplus Tx)=Tx$. Then $P_1$ is bounded and bijective. Therefore, by the Inverse Mapping Theorem, $P_1^{-1} \colon X \sto G$ is continuous. Since $P_2$ is also continuous, $A=P_2 \circ P_1^{-1}$ is continuous.
\end{proof}

The next important theorem is Hahn-Banach Theorem. We have known the Hahn-Banach Theorem holds in any general t.v.s.. But for the Banach space, it can induce some interesting corollaries of the bounded linear functional space. 

\begin{cor}
	Let $X$ be a Banach space. Then, 
	\begin{enumerate}[label=\arabic*)]
		\item if $\{x_i\}_{i=1}^{d}$ is a linearly independent in $X$, and $\{\alpha_i\}_{i=1}^{d}$ are arbitrary scalars, then there is a $f \in X^{*}$ s.t. $f(x_i) = \alpha_i$ for $i=1,\cdots,d$.
		\item if $Y$ is a linear subspace of $X$ and $x_0 \in X$ with $\inff\{\norm{x_0-y} \colon y \in Y \} = d > 0$, then there is a $f \in X^{*}$ s.t. $f(x_0) = 1$ and $f(y) = 0 ~\forall~ y \in Y$ and $\norm{f}=d^{-1}$.
		\item if $x \in X$, then
			\begin{equation*}
				\norm{x} = \sup_{\norm{f} \neq 0} \frac{\abs{f(x)}}{\norm{f}} = \sup \{\abs{f(x)} \colon f \in X^{*},~ \norm{f} \leqslant 1 \}
			\end{equation*}
		\item if $x \neq y$ in $X$, then there is a $f \in X^{*}$ s.t. $f(x) \neq f(y)$.
		\item if $Y$ is a linear subspace of $X$ and $Y$ is not dense, then there is $f \in X^{*}$ with $f \neq 0$ s.t. $f(y) = 0 ~\forall~ y \in Y$.
		\item if $Y$ is a linear subspace of $X$, then
			\begin{equation*}
				\clo{Y} = \bigcap\{\ker{f} \colon f \in X^{*},~ Y \subset \ker{f}\}
			\end{equation*}
	\end{enumerate}
\end{cor}
\begin{proof}
	For $1)$, let $Y= \spn{\{x_i\}_{i=1}^{d}}$ and $g$ be a linear functional on $Y$ with $g(x_i) = \alpha_i$, then $g$ can extend to $f$.\\
	For $2)$, let $Y_1 = \spn{\{Y,\{x_0\}\}}$ and $g$ be a linear functional on $Y_1$ with $g(y+\lambda x_0) = \lambda$. \\Then since $\norm{y+\lambda x_0} = \abs{\lambda}\norm{\frac{1}{\lambda}y+x_0} \geqslant \abs{\lambda} d$, $\norm{g} \leqslant d^{-1}$. Let $\{y_n\} \in Y$ s.t.\\ $\norm{x_0-y_n} \sto d$, then $1 = g(x_0 - y_n) \leqslant \norm{g} \norm{x_0-y_n} \sto \norm{g} d$. \\Thus $\norm{g} = d^{-1}$. $g$ can extend to $f$ on $X$.\\
	For $3)$, clearly, $\norm{x} \geqslant \sup \{\abs{f(x)} \colon f \in X^{*},~ \norm{f} \leqslant 1 \}$. But by above proof, there is a $f(x) = \norm{x}$ with $\norm{f} = 1$.\\
	$4)$ and $5)$ can be easily obtained by the separability of continuous linear fuctionals and the fact that $X$ is locally convex.\\
	$6)$ is a special case of \textbf{Corollary} \ref{cor2} in the subsection \textbf{1.3.2}.
\end{proof}

For linear functionals on a general vector space, there is a interesting result.
\begin{prop} \label{prop2}
	Let $f$, $\{f_k\}_{k=1}^{n}$ be linear functionals on a vector space $X$. If $\bigcap_{k=1}^{n}\ker{f_k} \subset \ker{f}$, then there are scalars $\alpha_1,\cdots,\alpha_n$ such that $f = \sum_{k=1}^{n} f_k$.
\end{prop}
\begin{proof}
	Assume for $1 \leqslant k \leqslant n$, $\bigcap_{j \neq k} \ker{f_j} \neq \bigcap_{j=1}^{n} \ker{f_j}$.\\ Therefore, there is a $y_k \in \bigcap_{j \neq k} \ker{f_j}$ s.t. $y_k \notin \bigcap_{j=1}^{n} \ker{f_j}$, i.e. $f_j(y_k) = 0$ for $j \neq k$ and $f_k(y_k) \neq 0$. \\Thus we can find ${x_k}_{k=1}^{n}$, s.t. $f_k(x_k) = 1$ and $f_j(x_k)=0$ for $j \neq k$. \\Let $\alpha_k = f(x_k)$. For $x \in X$, let $y=x-\sum_{k=1}^{n} f_k(x)x_k$. \\Then $f_j(y)=f_j(x) - \sum_{k=1}^{n} f_k(x)f_j(x_k)=0$. Thus $f(y) = 0$, \\i.e. $f(x) = \sum_{k=1}^{n} \alpha_k f_k(x)$.
\end{proof}

\subsection{Weak Topologies}

In a Banach space $X$, $X^{*}$ denoted the set of all bounded linear functionals is also a Banach space with the induced norm. Then we can also find all bounded linear functionals on the space ($X^{*}$,$\norm{\cdot}$), denoted by $X^{**}$. By the Hahn-Banach Theorem, we can easily know the following proposition.

\begin{prop}
	Let $X$ be a Banach space. Then $X$ can be isometrically embeded in $X^{**}$.
\end{prop}
\begin{proof}
	Define the map $\phi$, where $\hat{x}(f) = f(x)$,
	\begin{center}
		\begin{tabular}{l r c l}
			$\phi \colon$ & $X$ & $\longrightarrow$ & $X^{**}$ \\
			~ & $x$ & $\longmapsto$ & $\hat{x} = \phi(x)$
		\end{tabular}
	\end{center}
	Then by the corollary of Hahn-Banach Theorem, $\norm{\hat{x}}=\norm{x}$.
\end{proof}
\begin{rem}
	In a special case, if $X^{**} = \hat{X}$, where $\hat{X} = \pi(X)$, then $X$ is called a reflexive space.
\end{rem}

For a Banach space $X$ and $X^{*}$, we can define different topologies.

\begin{defn}
	Let $X$ be a Banach space.
	\begin{enumerate}[label=\arabic*)]
		\item The weak topology on $X$, denoted by $wk$, is generated by the family of seminorms $\{p_f \colon f \in X^{*}\}$, where $p_f(x) = \abs{f(x)}$.
		\item The weak$^{*}$ topology on $X^{*}$, denoted by $wk^{*}$, is generated by the family of seminorms $\{p_x \colon x \in X\}$, where $p_x(f) = \abs{f(x)}$.
	\end{enumerate}
\end{defn}
\begin{rem}
	Since the $\abs{f(x)} \leqslant \norm{f}\norm{x}$, we can easily know $wk$ on $X$ and $wk^{*}$ on $X^{*}$ are weaker than the norm topology respectively. 
	\begin{enumerate}[label=\arabic*)]
		\item The subbasis of the weak topology at $x_0$ is like 
			\begin{equation*}
				U_\varepsilon(x_0) = \{x \in X \colon \abs{f(x-x_0)} < 0\}
			\end{equation*}
		Therefore, a net $\{x_\alpha\}$ in $X$ converges weakly to $x_0$ if and only if $f(x_\alpha) \sto f(x)$ for all $f \in X^{*}$.
		\item The subbasis of the weak$^{*}$ topology at $f_0$ is like
			\begin{equation*}
				V_\varepsilon(f_0) = \{f \in X^{*} \colon \abs{(f-f_0)(x)} < 0\}
			\end{equation*}
		Therefore, a net $\{f_\alpha\}$ in $X^{*}$ converges weakly to $f_0$ if and only if $f_\alpha(x) \sto f(x)$ for all $x \in X$.
	\end{enumerate}
\end{rem}

There are some easy properties between these two topologies and the respective norm topology.
\begin{prop}
	Let $X$ be a Banach space. Then we have
	\begin{enumerate}[label=\arabic*)]
		\item $(X,wk)^{*} = X^{*}$
		\item $(X^{*},wk^{*})^{*} = X$
		\item if $A \subset X$ is convex, then $\clo{A}=\clo{A}^{wk}$
	\end{enumerate}
\end{prop}
\begin{proof}
	$1)$ can be obtained easily by the fact that $wk$ is weaker than the norm topology and by the definition of continuous functionals.\\
	For $2)$, because of the \textbf{Corollary} \ref{cor3} in the subsction \textbf{1.2.4} and the \textbf{Propostion} \ref{prop1} in the subsection \textbf{1.2.2} and the \textbf{Propostion} \ref{prop2}. 
	\begin{eqnarray*}
		F \in (X^{*},wk^{*})^{*} &\Rightarrow& \abs{F(f)} \leqslant \sum_{i=1}^{n} \abs{\hat{x}_k} \text{ for some } \{\hat{x}_k\}_{k=1}^{n} \subset \hat{X} \\
		&\Rightarrow& \bigcap_{k=1}^{n}\ker{\hat{x}_k} \subset \ker{F} \Rightarrow F = \sum_{k=1}^{n} \alpha_k \hat{x}_k \in \hat{X} \cong X
	\end{eqnarray*}
	And the converse is because $wk^{*}$ is weaker than norm topology.\\
	For $3)$, because $wk$ is weaker than the norm topology, $\clo{A} \subset \clo{A}^{wk}$ . By the separability of continuous functionals in \textbf{Theorem} \ref{thm3} in the \textbf{1.3.2}, we can fine a $f \in X^{*}$ s.t. $f$ separates $\clo{A}$ and any $x \in X \backslash \clo{A}$ in using a positive real number $\alpha$. But $\clo{A} \subset B=\{y \in X \colon \Rea{f(y)} \leqslant \alpha\}$ and $B$ is clearly $wk$-closed. Therefore, $\clo{A}^{wk} \subset B$. $x \notin \clo{A}$ implies $x \notin B$, thus $x \notin \clo{A}^{wk}$, i.e. $\clo{A}^{wk} \subset \clo{A}$.
\end{proof}

Also, by the Hahn-Banach Theorem and the \textbf{Theorem} \ref{thm2} in the \textbf{1.2.4}, the bounded linear map can be charasterized as the following statement.
\begin{prop}
	Let $T \colon X \sto Y$ be a linear map between two Banach spaces. Then $T$ is bounded if and only if $T \colon (X,wk) \sto (Y,wk)$ is continuous.
\end{prop}
 
By the \textbf{Theorem} \ref{thm4} in the \textbf{1.2.3}, we can easily see how to make $X^{*}$ be $wk^{*}$-metrizable.

\begin{thm}
	If $X$ is a Banach space, then $X^{*}$ is $wk^{*}$-metrizable if and only if $X$ is separable.
\end{thm}
\begin{proof}
	It is because that $wk^{*}$ is generated by $\{p_x \colon x \in X\}$.
\end{proof}

Let $Y$ be a closed subspace a Banach space $X$. We can define the orthogonal complement of $Y$, $Y^{\bot} = \{f \in X^{*} \colon Y \subset \ker{f}\}$ (similar definition in $X^{*}$). Then we have the following theorem.

\begin{thm}
	If $Y$ is a closed subspace a Banach space $X$ and $\pi \colon X \sto X/Y$ is the quotient map, then
	\begin{enumerate}[label=\arabic*)]
		\item the following map is an isometric isomorphism, i.e. $X^{*}/Y^{\bot} \cong Y^{*}$.
			\begin{center}
				\begin{tabular}{l r c l}
					$\rho \colon$ & $X^{*}/Y^{\bot}$ & $\longrightarrow$ & $Y^{*}$ \\
					~ & $f+Y^{\bot}$ & $\longmapsto$ & $f|_Y$
				\end{tabular}
			\end{center}
		\item the the following map is an isometric isomorphism, i.e. $(X/Y)^{*} \cong Y^{\bot}$.
			\begin{center}
				\begin{tabular}{l c c l}
					$\kappa \colon$ & $(X/Y)^{*}$ & $\longrightarrow$ & $Y^{\bot}$ \\
					~ & $f$ & $\longmapsto$ & $f \circ \pi$
				\end{tabular}
			\end{center}
	\end{enumerate}
\end{thm}
\begin{proof}
	For $1)$, clearly, $\rho$ is linear and injective. Since for any $f \in X^{*}$ and $g \in Y^{\bot}$, 
	\begin{equation*}
		\norm{f|_Y} = \norm{(f+g)|_Y} \leqslant \norm{(f+g)}
	\end{equation*}
	we have $\norm{f|_Y} \leqslant \norm{f+Y^{\bot}}$. By the Hahn-Banach Theorem, for any $\phi \in Y^{*}$, there is a $f \in X^{*}$ with $f|_Y = \phi$ and $\norm{\phi} = \norm{f} \geqslant \norm{f+Y^{\bot}}$.\\
	For $2)$, clearly $\norm{\kappa(f)} \leqslant \norm{f}$. We can find a sequence ${x_n+y_n}$ with $x_n \in X$ and $y_n \in Y$ and $\norm{x_n+y_n}<1$ s.t. 
	\begin{equation*}
		\norm{\kappa(f)} \geqslant \abs{\kappa(f)(x_n+y_n)}=f(x_n+Y) \sto \norm{f} 
	\end{equation*}
	thus $\kappa$ is an isometry. And by the universal property of quotient map, in the \textbf{Propostion} \ref{prop3} in the subsection \textbf{1.1.3}, we can prove that $\kappa$ is surjective.
	\begin{center}
	\begin{tikzcd}
		X \arrow[r, "f"] \arrow[d, "\pi"]
			& \K\\
		X/\ker{f} \arrow[ru, "\tilde{f}"] \arrow[r,"i"]
			& X/Y \arrow[u,"f^{'}"]
	\end{tikzcd}
\end{center}
\end{proof}

We have an imprtant theorem to discribe the $wk^{*}$-compactness in dual space.

\begin{thm}[Alaoglu's Theorem]
	Let $X$ be a normed space, then the unit ball in $X^{*}$ is $wk^{*}$-compact.
\end{thm} 
\begin{proof}
	Let $D_x=\{\alpha \in \K \colon \abs{\alpha} \leqslant 1\}$ for any $x \in X$, then put $D=\prod_{x \in X} D_x$. By Tychonoff's Theorem, $D$ is compact. Let the unit ball in $X^{*}$ be denoted by $B$ and $\tau$ be defined as
	\begin{center}
		\begin{tabular}{l c c l}
			$\tau \colon$ & $B$ & $\longrightarrow$ & $D$ \\
			~ & $f$ & $\longmapsto$ & $\tau(f)$
		\end{tabular}
	\end{center}
	where $\tau(f)(x) = f(x)$. Then we can prove that $B$ is homeomorphic to $\tau(B)$ with respect to the induced topology of $D$ and $\tau(B)$ is closed in $D$. Thus $B$ is compact.
	\begin{enumerate}[label=\arabic*)]
		\item Injection: $\tau(f) = \tau(g) \Rightarrow f(x) = g(x) ~\forall~ x \in B \Rightarrow f = g$.
		\item Continuity: $f_i \sto f ~wk^{*} \Rightarrow \tau(f_i)(x) \sto \tau(f)(x) ~\forall~ x \in B \Rightarrow \tau(f_i) \sto \tau(f)$.
		\item Closedness: $\tau(f_i) \sto f \in D \Rightarrow f_i(x) \sto f(x) ~\forall~ x \in B$, then we extend $f$ by defining $\tilde{f}(x) = \alpha^{-1}f(\alpha x)$ for any $x \in X$ and $\alpha > 0$ with $\norm{\alpha x} \leqslant 1$. It is well-defined by the linearity. Then $\tilde{f} \in B$. $\tau(B)$ is closed, and $\tau(B)$ is complete.
		\item Homeorphism: $\tau \colon B \sto \tau(B)$ is continuous linear map between two Banach spaces. Thus it is a homeomorphism.
	\end{enumerate}
\end{proof}

\begin{cor}
	Let $X$ be a Banach space and $Y$ is a closed linear subspace of $X$.
	\begin{enumerate}[label=\arabic*)]
		\item $X$ is reflexive if and only if the unit ball in $X$ is weakly compact.
		\item If $X$ is reflexive and $x_0 \in X \backslash Y$, then there is a point $y_0 \in Y$ s.t. $\norm{x_0-y_0} = \inff{y-x_0 \colon y \in Y}$.
	\end{enumerate}
\end{cor}
\begin{proof}
	For $1)$, by above theorem, the unit ball in $X^{**}$ is $wk^{*}$-compact. Since $X=X^{**}$, the unit ball in $X$ is $wk$-compact. The converse is similar as above proof.\\
	For $2)$, $Y$ is $wk$-compact by above corollary. Since by the Hahn-Bnanch Theorem, for each $x$, we can find a $f \in X^{*}$ with $\norm{f}=1$ and $f(x)=x$. The map $x \mapsto \norm{x-x_0}$ is weakly lower semicontinuous. Therefore, there is a $y_0 \in Y$ s.t. $\norm{x_0-y_0} = \inff\{y-x_0 \colon y \in Y\}$.
\end{proof}

\subsection{Adjoint Operators} \label{sec1}

\begin{defn}
	Let $T \colon X \sto Y$ be a bounded linear map between two Banach spaces. Then the adjoint of operator of $T$ is defined as
		\begin{center}
			\begin{tabular}{l r c l}
				$T^{*} \colon$ & $Y^{*}$ & $\longrightarrow$ & $X^{*}$ \\
				~ & $f$ & $\longmapsto$ & $f \circ T$
			\end{tabular}
		\end{center}	
\end{defn}

There are some easy properties of the adjoint operator, which can be obtained by the definition.
\begin{prop} \label{prop4}
	Let $X$, $Y$ and $Z$ be three Banach spaces and\\ $T \in \fml{B}(X,Y), S \in \fml{B}(Y,Z)$. Then, we have
	\begin{enumerate}[label=\arabic*)]
		\item $T^{**}|_X = T$
		\item the map $T \sto T^{*}$ is an isometric isomorphism.
		\item $(ST)^{*} = T^{*}S^{*}$.
		\item $\ker{T^{*}} = (\ran{T})^{\bot}$ and $\ker{T}=(\ran{T^{*}})^{\bot}$.
	\end{enumerate}
\end{prop}

Then for the $4)$ in above theorem, we can find dual consequences. Firstly, there is a useful lemma.

\begin{lem} \label{lem1}
	Let $T \colon X \sto Y$ be a bounded linear map between two Banach spaces. Then $\ran{T}$ is closed if and only if there exists a constant $C>0$, for any $y \in \ran{T}$ there is a point $x \in X$ s.t. $\norm{y} \geqslant C \norm{x}$.
\end{lem}
\begin{proof}
	By the Open Mapping Theorem, for the unit open ball $B \subset X$ and some $\delta > 0$, s.t.
	\begin{equation*}
		\{y \in \ran{T} \colon \norm{y} < \delta\} \subset T(B)
	\end{equation*}
	Thus for any nonzero $y \in \ran{T}$,
	\begin{equation*}
		\exists~ z \in B ~s.t.~ Tz = \frac{\delta}{2\norm{y}}y \Rightarrow \norm{y} \geqslant \frac{2}{\delta}\norm{x} \text{~where~} x = \frac{2\norm{y}}{\delta} z \text{~with~} Tx = y
	\end{equation*}
	Conversely, if $y \in \clo{\ran{T}}$, there is $\{y_n\} \subset \ran{T}$ with $y_n \sto y$. By the assumption, there is a constant $C>0$ and a sequence $\{x_n\} \subset X$ s.t. $\norm{x_n-x_m} \leqslant C\norm{Tx_n-Tx_m}$. Since $\{y_n\}$ is Cauchy, $\norm{x_n-x_m}$ is Cauchy. Thus there exists a $x \in X$ s.t. $x_n \sto x$ and $Tx=y$.
\end{proof}
\begin{rem}
	There is a more special case for this lemma. $\ker{T}=\{0\}$ and $\ran{T}$ is closed if and ony if there exists a constant $C>0$ s.t. $\norm{Tx} \geqslant C\norm{x}$ for any $x \in X$.
\end{rem}

\begin{thm}
	Let $T \colon X \sto Y$ be a bounded linear map between two Banach spaces.
	\begin{enumerate}[label=\arabic*)]
		\item $\clo{\ran{T}} = (\ker{T^{*}})^{\bot}$.
		\item If $\ran{T}$ is closed, then $\ran{T^{*}}$ is closed and $\ran{T^{*}} = (\ker{T})^{\bot}$.
	\end{enumerate}
\end{thm}
\begin{proof}
	For $1)$, let $y \in \clo{\ran{T}}$ and ${y_n} \subset \ran{T}$ with $y_n \sto y$. If $g \in \ker{T^{*}}$, then 
	\begin{equation*}
		g(y_n) = g(Tx_n) = T^{*}g(x_n) = 0 \sto g(y) \text{ i.e. } y \in (\ker{T^{*}})^{\bot}
	\end{equation*}
	Conversely, if $y_0 \notin \clo{\ran{T}}$, then by the Hahn-Banach Theorem, there is a $g \in Y^{*}$ s.t. 
	\begin{equation*}
		\ran{T} \subset \ker{g} \text{ i.e. } g \in \ker{T^{*}} ~\&~ g(y_0) \neq 0 \Rightarrow y_0 \notin (\ker{T^{*}})^{\bot}
	\end{equation*}
	For $2)$, if $f \in (\ker{T})^{\bot}$ i.e $\ker{T} \subset \ker{f}$, then there is a $\tilde{g} \in (\ran{T})^{*}$ s.t. $\tilde{g}(Tx) = f(x)$ since $\ran{T} \cong X/\ker{T}$. By above lemma, there exists a constant $C>0$ s.t. for any $y \in \ran{T}$ there is a $x \in X$ with $Tx=y$ and $\norm{x} \leqslant C\norm{y}$. Therefore,
	\begin{equation*}
		\abs{\tilde{g}(y)} = \abs{f(x)} \leqslant C\norm{f}\norm{x}
	\end{equation*}
	Thus $\tilde{g}$ can extends to $g$ defining on $Y^{*}$ s.t.
	\begin{equation*}
		T^{*}g(x) = g(Tx) = f(x) ~\text{ i.e. }~ T^{*}g = f
	\end{equation*}
	Therefore, $(\ker{T})^{\bot} \subset \ran{T^{*}}$. \\
	Coversely, if $f \in \ran{T^{*}}$, i.e. there is a $g \in Y^{*}$ with $T^{*}g =f$, then for any $x \in \ker{T}$, $f(x) = T^{*}g(x) = g(Tx) = 0$. Therefore, $f \in (\ker{T})^{\bot}$.
\end{proof}
\begin{cor}
	Let $T \colon X \sto Y$ be a bounded linear map between two Banach spaces. Then $T$ is invertible if and only if $T^{*}$ is invertible. In this case, $(T^{*})^{-1} = (T^{-1})^{*}$.
\end{cor}

%\begin{thm}
% 	Let $T \colon X \sto Y$ be a bounded linear map between two Banach spaces. Then the following statements are equivalent.
% 	\begin{enumerate}[label=\arabic*)]
% 		\item $\ran{T}$ is closed.
% 		\item $\ran{T^{*}}$ is norm closed.
% 		\item $\ran{T^{*}}$ is $wk^{*}$-closed.
% 	\end{enumerate}
%\end{thm}
%\begin{proof}
%	By above theorem, $1)$ implies $2)$. If $T$ is injective and $\clo{\ran{T}} = Y$,then we can get these results.
%	\item $2) \Rightarrow 3)$: 
%\end{proof}

\section{Hilbert Spaces}

A Hilber space is a special Banach space, which is endowed with a inner product. And the structure of inner product can provide better properties of Hilbert spaces.

\subsection{Projection Theorem and Riesz Theorem}

\begin{defn}
	On a vector space $\fml{H}$ over $\C$, an inner product is a map $ \langle \cdot, \cdot \rangle \colon \fml{H} \times \fml{H} \sto \K$ satisfies that for any $\alpha, \beta \in \K$ and $x,y,z \in \fml{H}$,
	\begin{enumerate}[label=\arabic*)]
	 	\item $ \langle \alpha x + \beta y,z \rangle = \alpha  \langle x,z \rangle + \beta  \langle y,z \rangle$
	 	\item $ \langle x,y \rangle = \clo{ \langle y,x \rangle}$
	 	\item $ \langle x,x \rangle \geqslant 0$ and $ \langle x,x \rangle = 0 \Leftrightarrow x = 0$
	\end{enumerate} 
\end{defn}
\begin{rem}
	The vector space $\fml{H}$ with the inner product $ \langle \cdot,\cdot \rangle$ is called an inner product space. And the inner product can induce the CBS-Inequality, 
	\begin{equation*}
		\abs{ \langle x,y \rangle}^{2} \leqslant  \langle x,x \rangle \langle y,y \rangle
	\end{equation*}
	by using the positivity of the inner product, $ \langle x-\alpha y,x-\alpha y \rangle \geqslant$0.
\end{rem}

Then on the $\fml{H}$, a nature norm can be induced by the inner product, defined as $\norm{x}^{2}= \langle x,x \rangle$ for any $x \in \fml{H}$. This definition is valid since the linearity, positivity and CBS-Inequality of the inner product. And there are two forms of the norm.

\begin{prop}
	Let $(\fml{H}, \langle \cdot,\cdot \rangle)$ be an inner product space, and $\norm{\cdot}$ be the coincided with this inner product. Then, we have the following identities.
	\item Polarization identity: 
	\begin{equation*}
		 \langle x,y \rangle = \frac{1}{4}(\norm{x+y}^{2}-\norm{x-y}^{2}+i\norm{x-iy}^{2}-i\norm{x+iy}^{2})
	\end{equation*}
	\item Parallelogram law:
	\begin{equation*}
		\norm{x+y}^{2}+\norm{x-y}^{2} = 2(\norm{x}^{2}+\norm{y}^{2})
	\end{equation*}
\end{prop}
\begin{rem}
	The first identity can be used to construct an inner product, but not all norm can do this successfully. So, the second identity can be used to check whether a norm can construct an inner product on a normed space.
\end{rem}

\begin{defn}
	A Hilbert space is an inner product space, which is complete with respect to the induced norm.
\end{defn}

Therefore, a Hilbert space is indeed a Banach space, whose norm can construct an inner product. Now, we can find the extra properties provided by the inner product. The following theorem is the most important property the Hilbert space has.

\begin{thm}
	If $\fml{H}$ is a Hilbert space and $K$ is a closed convex nonempty subset of $\fml{H}$ and $x \in \fml{H} \backslash K$, then there exists a unique $k_0 \in K$ s.t.
	\begin{equation*}
		\norm{x-k_0} = \inff{\norm{x-k} \colon k \in K}
	\end{equation*}
\end{thm}
\begin{proof}
	Let $d=\inff{\norm{x-k} \colon k \in K}$, then there is a sequence $\{k_n\} \subset K$ s.t. $\norm{x-k_n} \sto d$. By the parallelogram law,
	\begin{equation*}
		4\norm{x-\frac{1}{2}(k_m+k_n)}^{2}+\norm{k_m-k_n}^{2} = 2(\norm{x-k_m}^{2}+\norm{x-k_n}^{2}) \sto 4d^{2}
	\end{equation*}
	Since $\frac{1}{2}(k_m+k_n) \in K$, 
	\begin{equation*}
		4\norm{x-\frac{1}{2}(k_m+k_n)}^{2} \geqslant 4d^{2}
	\end{equation*}
	Thus $\norm{k_m-k_n} \sto 0$. By the facts that $\fml{H}$ is complete and $K$ is closed, there exists $k_0 \in K$ s.t. $k_n \sto k_0$. Then $\norm{x-k_0} = \lim_{n \sto \infty}\norm{x-k_n} = d$.\\
	If there is another $k_1 \in K$, $\norm{x-k_0} = \norm{x-k_1}$.
	\begin{equation*}
		d \leqslant \norm{x-\frac{1}{2}(k_0+k_1)} \leqslant \frac{1}{2}(\norm{x-k_0}+\norm{x-k_1}) = 2d
	\end{equation*}
	Then
	\begin{equation*}
		\norm{x-\frac{1}{2}(k_0+k_1)} = \frac{1}{2}(\norm{x-k_0}+\norm{x-k_1})
	\end{equation*}
	Thus by the parallelogram law, $k_0 = k_1$.
\end{proof}	
\begin{rem}
	The main method of above proof is the parallelogram law, which is the most eesential property of the norm induced by the inner product.
\end{rem}

For $x,y \in \fml{H}$, if $ \langle x,y \rangle=0$, we say $x$ is orthogonal to $y$. Similarly, if $W$ is a subset of $\fml{H}$, we define $W^{\bot} = \{y \in \fml{H} \colon  \langle x,y \rangle=0 ~\forall~ x \in W\}$. Then we can use above theorem to obtain a important structure of a Hilbert space.

\begin{thm}[Projection Theorem]
	Let $\fml{M}$ be a closed subspace of a Hilbert space $H$. Then $\fml{H} = \fml{M} \oplus \fml{M}^{\bot}$.
\end{thm}
\begin{proof}
	Clearly, $\fml{M} \bigcap \fml{M}^{\bot} = \{0\}$. We just need to prove that for any $x \in \fml{H}$, there exist a unique $x_1 \in \fml{M}$ and $x_2 \in \fml{M}^{\bot}$, s.t. $x=x_1+x_2$. If $x \in \fml{M}$, let $x_1=0$ and $x_2=0$.\\
	Assume $x \notin \fml{H}$, then by above theorem, we can find a unique $m_0 \in \fml{M}$ s.t. $\norm{x-m_0}=\inff{\{\norm{x-m} \colon m \in \fml{M}\}}$. Let $x_1 = m_0$. Then $x=x_1 + (x-m_0)$. Therefore, it is sufficient to prove that $x-m_0 \in \fml{M}^{\bot}$.\\
	For any $m \in \fml{M}$ and any $\lambda \in \C$, since $m_0+\lambda m \in \fml{M}$, we have
	\begin{eqnarray*}
		\norm{x-m_0}^{2} &\leqslant& \norm{x-m_0-\lambda m}^{2} \\
		&=& \norm{x-m_0}^{2} -2\Rea{\lambda \langle m,x-m_0 \rangle} + \abs{\lambda}^{2}\norm{m}^{2}
	\end{eqnarray*}
	Thus $-2\Rea{\lambda \langle m,x-m_0 \rangle} + \abs{\lambda}^{2}\norm{m}^{2} \geqslant 0$. Then taking the $\lambda = \varepsilon  > 0$ and let $\varepsilon \sto 0$, therefore
	\begin{equation*}
		\Rea{ \langle m,x-m_0 \rangle} \leqslant 0
	\end{equation*}
	Similarly, taking $\lambda = -i \varepsilon$ and let $\varepsilon \sto 0$,
	\begin{equation*}
		\Img{ \langle m,x-m_0 \rangle} \leqslant 0
	\end{equation*}
	Also, these are true for $-m$. Therefore, $ \langle m,x-m_0 \rangle = 0$ for any $m \in \fml{M}$, i.e. $x-m_0 \in \fml{M}^{\bot}$.
\end{proof}
By the Projection Theorem, we can directly obtained the following corrolary.
\begin{cor} \label{cor4}
	Let $\fml{H}$ be a Hilbert space.
	\begin{enumerate}[label=\arabic*)]
		\item If $\fml{M}$ is a closed subsapce of $\fml{H}$, then $(\fml{M}^{\bot})^{\bot} = \fml{M}$.
		\item If $A \subset \fml{H}$ is a subset, then $(A^{\bot})^{\bot} = \clo{\spn{A}}$.
	\end{enumerate}
\end{cor}

Using the Projection Theorem, the dual space of a Hilbert space can be more explicit.
\begin{thm}[Riesz Theorem]
	Let $\fml{H}$ be a Hilbert space. Then the map $\sigma$ is defined as
	\begin{center}
		\begin{tabular}{l r c l}
			$\sigma \colon$ & $\fml{H}$ & $\longrightarrow$ & $\fml{H}^{*}$ \\
			~ & $x$ & $\longmapsto$ & $L_x$
		\end{tabular}
	\end{center}
	where $L_x(y)= \langle y,x \rangle$. Then $\sigma$ is an isometric antilinear bijection, i.e. $\fml{H} \cong \fml{H}^{*}$.
\end{thm}
\begin{proof}
	Clearly, $L_x$ is antilinear. And by the CBS-Inequality, $\norm{L_x} = \norm{x}$, thus $\sigma$ is definitely an isometry. Then we just need to prove $\sigma$ is surjective. If $L \in \fml{H}^{*}$ is nonzero, then there is a $x_0 \in (\ker{L})^{\bot}$. Thus we can assume $L(x_0) = 1$. If $y \in \fml{H}$, then $y-L(y)x_0 \in \ker{L}$. Therefore,
	\begin{equation*}
		0= \langle y-L(y)x_0,x_0 \rangle= \langle y,x_0 \rangle-L(y)\norm{x_0}^{2}
	\end{equation*}
	Then let $x = \norm{x_0}^{-2} x_0$, $L_x=L$.
\end{proof}
\begin{cor}
	A Hilbert space $\fml{H}$ is relexive. Thus, $\fml{H}$ is weakly complete and a subset in $\fml{H}$ is weakly compact if and only if it is bounded and weakly closed.
\end{cor}

And the Riesz Theorem can extend to bounded sesquilinear forms.
\begin{defn}
	Let $\fml{H}_1$ and $\fml{H}_2$ be two Hilbert spaces. The map 
	\begin{equation*}
		f \colon \fml{H}_1 \times \fml{H}_2 \sto \C
	\end{equation*}
	is called a sesquilinear form, if it satisfies
	\begin{enumerate}[label=\arabic*)]
	 	\item $f(\alpha x + \beta y,z) = \alpha f(x,z) + \beta (y,z)$
	 	\item $f(x,\alpha y + \beta z) = \clo{\alpha} f(x,y) + \clo{\beta} (x,z)$
	\end{enumerate}
\end{defn}
\begin{rem}
	If $f$ is continuous, then we know $\abs{f(x,y)} \leqslant C\norm{x}\norm{y}$ for some $C < 0$. Also, the converse is ture. Then we can define the norm of $f$ as
	\begin{equation*}
		\norm{f} =\sup_{x \in \fml{H}_1, y \in \fml{H}_2} \frac{\abs{f(x,y)}}{\norm{x}\norm{y}}
	\end{equation*} 
\end{rem}

\begin{thm}
	Let $f \colon \fml{H}_1 \times \fml{H}_2 \sto \C$ be a bounded sesquilinear form of two Hilbert spaces $\fml{H}_1$ and $\fml{H}_2$. Then there is a unique bounded linear map with $\norm{S} = \norm{f}$
	\begin{equation*}
		S \colon \fml{H}_1 \sto \fml{H}_2 \text{ s.t. } f(x,y)= \langle Sx,y \rangle ~\forall~ x \in \fml{H}_1 ~\forall~ y \in \fml{H}_2
	\end{equation*}
\end{thm}

\subsection{Adjoint Operators}

Let $T \colon \fml{H} \sto \fml{H}$ be a bounded linear operator on a Hilbert space $\fml{H}$. Since $\fml{H}$ is also a Banach space, we can define the adjoint operator of $T$ as 
\begin{center}
	\begin{tabular}{l r c l}
		$T^{*} \colon$ & $\fml{H}^{*}$ & $\longrightarrow$ & $\fml{H}^{*}$ \\			~ & $f$ & $\longmapsto$ & $T^{*}f$
	\end{tabular}
\end{center}
By the Riesz Theorem, each $f \in \fml{H}^{*}$ can be expressed as $f = \langle \cdot, x \rangle$ for some $x \in \fml{H}$. Then for any $y \in \fml{H}$ we have
\begin{equation*}
	T^{*}(\langle \cdot, x \rangle)(y) = (\langle \cdot, x \rangle)(Ty) =\langle Ty, x \rangle 
\end{equation*}
Clearly, $f(y) = \langle Ty, x \rangle  \in \fml{H}^{*}$, thus there is a unique $\tilde{x} \in \fml{H}$ s.t. $f(y) = \langle y, \tilde{x} \rangle$. Then, we have 
\begin{equation*}
	T^{*}(\langle \cdot, x \rangle)(y) = \langle Ty, x \rangle = \langle y, \tilde{x} \rangle = (\langle \cdot, \tilde{x} \rangle)(y)
\end{equation*}
Thus, we have 
\begin{equation*}
	T^{*}(\langle \cdot, x \rangle) = \langle \cdot, \tilde{x} \rangle
\end{equation*}
Since $\fml{H} \cong \fml{H}^{*}$, in fact $T^{*} \colon \fml{H} \sto \fml{H}$, and by above mention, $T^{*}(x) = \tilde{x}$, where $\tilde{x}$ is determined by the equation
\begin{equation*}
	\langle y, \tilde{x} \rangle = \langle Ty, x \rangle,~~ \forall~ y \in \fml{H}
\end{equation*}

Therefore, we can give the definition of the adjoint operator on a Hilbert space.
\begin{defn}
	Let $T \colon \fml{H} \sto \fml{H}$ be a bounded linear operator on a Hilbert space $\fml{H}$. Then the adjoint operator $T^{*} \colon \fml{H} \sto \fml{H}$ is defined as
	\begin{equation*}
		\langle y, T^{*}x \rangle = \langle Ty, x \rangle ~~ \forall~ y \in \fml{H}
	\end{equation*}
\end{defn}
\begin{rem}
	Equivalently, $\langle T^{*}x, y \rangle = \langle x, Ty \rangle ~ \forall~ y \in \fml{H}$. By above mention, this definition is well-defined and nature.
\end{rem}

Since this definition is induced by the definition of a Banach space, thus all results in the subsection \ref{sec1} also hold for the adjoint operators 0n a Hilbert space, except the $T \sto T^{*}$ is linear. In fact, on a Hilbert space, this map $T \sto T^{*}$ is antilinear, i.e. $((\alpha + \beta)T)^{*} = \clo{\alpha}T^{*}T^{*} + \clo{\beta}T^{*}$. Moreover, Since any Hilbert space is reflexive, the first result in \textbf{Proposition} \ref{prop4} in the subsection \textbf{1.4.4} can be $T^{**} = T$.\\
And by the \textbf{Corollary} \ref{cor4} of the Projection Theorem and the last result in \textbf{Proposition} \ref{prop4} in the subsection \textbf{1.4.4}, we have the following proposition.
\begin{prop}
	Let $T \colon \fml{H} \sto \fml{H}$ be a bounded linear operator on a Hilbert space $\fml{H}$. Then, we have
	\begin{eqnarray*}
		\ker{T^{*}} = (\ran{T})^{\bot} &,& \ker{T}=(\ran{T^{*}})^{\bot} \\
		\clo{\ran{T}} = (\ker{T^{*}})^{\bot} &,& \clo{\ran{T^{*}}} = (\ker{T})^{\bot}
	\end{eqnarray*}
\end{prop}

And there is a result, which provide another important information of operators on a Hilbert space and make it more interesting than the operators defined on a Banach space.

\begin{thm} \label{thm0}
	Let $T \in \oper$ for a Hilbert space. Then
	\begin{equation*}
		\norm{T} = \norm{\st{T}} = \norm{\st{T}T}^{\frac{1}{2}}
	\end{equation*}
\end{thm}  
\begin{proof}
	Firstly, for any $h \in \Hs$ with $\norm{h} \leqslant 1$
	\begin{equation*}
		\norm{Ah}^2 = \langle Ah,Ah \rangle = \langle \st{A}Ah,h \rangle \leqslant \norm{\st{A}Ah}\norm{h} \leqslant \norm{\st{A}A} \leqslant \norm{\st{A}}\norm{A}
	\end{equation*}
	Therefore, $\norm{A}^2  \leqslant \norm{\st{A}A} \leqslant \norm{\st{A}}\norm{A}$. and $\norm{A} \leqslant \norm{\st{A}}$. But $\st{(\st{A})} = A$, thus this identity can hold.
\end{proof}

\subsection{Orthonormal Sets and Schauder Basis}

For a Hilbert space $\fml{H}$, subset $W \subset \fml{H}$ is called orthonormal if  elements in $W$ are pariwise orthogonal and each element has norm $1$. Then we can find a maximal orthonormal set, which is called a Schauder basis. Since the argebraic basis, Hamel basis, of a Hilbert space may be uncountable, we firstly need to define the uncountable summation.

\begin{defn}
	Let $\{h_i \colon i \in I\}$ be family of elements in $\fml{H}$ and $\fml{F}$ be a collection of all finite subsets of $I$. $\fml{F}$ can be endowded with the orter by $\subset$, then $\fml{F}$ is a directed set. Define the net, where $F \in \fml{F}$
	\begin{equation*}
		h_F = \sum \{h_i \colon i \in F\}
	\end{equation*}
	Therefore, we can define sum of $\{h_i \colon i \in I\}$ as
	\begin{equation*}
		\sum \{h_i \colon i \in I\} = \lim h_F
	\end{equation*}
	where the limit is with respect to the norm topology on $H$.
\end{defn}

For finite orthonormal set, the results can be obtained by the algebraic structure. And if the orthonormal set is infinite, we have similar results.
\begin{thm}[Bessel's Inequality]
	If $\{e_n\}_{n=1}^{\infty}$ is an orthonormal set of a Hilbert space and $h \in \fml{H}$, then
	\begin{equation*}
		\sum_{n=1}^{\infty} \abs{ \langle h,e_n \rangle}^{2} \leqslant \norm{h}^{2}
	\end{equation*}
\end{thm}
\begin{proof}
	Let $h_n=h-\sum_{k=1}^{n}  \langle h,e_k \rangle e_k$. Then $h_n$ is clearly orthogonal to $\{e_k\}_{k=1}^{n}$.
	\begin{eqnarray*}
		\norm{h}^{2} &=& \norm{h_n}^{2} + \norm{\sum_{k=1}^{n}  \langle h,e_k \rangle e_k}^{2} \\
		&=& \norm{h_n}^{2} + \sum_{k=1}^{n} \abs{ \langle h,e_k \rangle }^{2} \\
		&\geqslant& \sum_{k=1}^{n} \abs{ \langle h,e_k \rangle }^{2}
	\end{eqnarray*}	
\end{proof}
\begin{cor}
	Let $\fml{H}$ be a Hilbert space and $\fml{E}$ be an orthonormal subset. 
	\begin{enumerate}[label=\arabic*)]
		\item For any $h \in \fml{H}$, $\abs{ \langle h,e \rangle } \neq 0$ for at most a countable many $e \in \fml{E}$.
		\item $\sum_{e \in \fml{E}} \abs{ \langle h,e \rangle }^{2} \leqslant \norm{h}^{2}$.
		\item $\sum \{ \langle h,e \rangle e \colon e \in \fml{E}\}$ is converges.
	\end{enumerate}
\end{cor}
\begin{proof}
	For $1)$, let $\fml{E}_n=\{e \in \fml{E} \colon \abs{ \langle h,e \rangle } \geqslant \frac{1}{n}\}$, then $\fml{E}_n$ has to be finite. But 
	\begin{equation*}
		\bigcup_{n=1}^{\infty} \fml{E}_n = \{e \in \fml{E} \colon \abs{ \langle h,e \rangle } \neq 0\}
	\end{equation*}
	For $2)$, it is clearly by the Bessel's Inequality and above corollary.\\
	For $3)$, it is because the net $h_F = \sum \{h_i \colon i \in F\}$, where $F \subset \fml{E}$ is finite, is Cauchy by using the fact that for any $\varepsilon  >  0$ there is a $N \in \N$ s.t. 
	\begin{equation*}
		\sum_{n=N}^{\infty} \abs{ \langle h,e_n \rangle }  <  \varepsilon
	\end{equation*}
\end{proof}

\begin{defn}[Schauder basis]
	A orthonormal set $\fml{E}$ of a Hilbert space $\fml{H}$ is called a Schauder basis if for any $h \in \fml{H}$,
	\begin{equation*}
		h = \sum \{ \langle h,e \rangle e \colon e \in \fml{E}\}
	\end{equation*}
\end{defn}
\begin{rem}
	By above corollary, this definition is equivalent to that for any $h \in \fml{H}$, there exists $\{e_n\}_{n=1}^{\infty} \subset \fml{E}$, s.t.
	\begin{equation*}
		h = \sum_{n=1}^{\infty}  \langle h,e_n \rangle e_n
	\end{equation*}
	Moreover, by the Zorn's Lemma, every Hilbert space has a Schauder basis.
\end{rem}

By the definition, and above theorem and corollaries, we can find the properties of the Schauder basis.
\begin{thm}
	Let $\fml{H}$ be a Hilbert space and $\fml{E}$ be an orthonormal subset. Then the following statements are equivalent.
	\begin{enumerate}[label=\arabic*)]
		\item $\fml{E}$ is a Schauder basis.
		\item $h \in \fml{H}$ with $h \bot \fml{E}$, then $h=0$.
		\item $g,h \in \fml{H}$, then
			\begin{equation*}
				 \langle g,h \rangle  = \sum \{ \langle g,e \rangle  \langle e,h \rangle  \colon e \in \fml{E}\}
			\end{equation*}
		\item (Parseval's Identity)$h \in \fml{H}$, then
			\begin{equation*}
				\norm{h}^{2} = \sum \{\abs{ \langle h,e \rangle }^{2} \colon e \in \fml{E}\}
			\end{equation*}
	\end{enumerate}
\end{thm}

\begin{prop}
	Let $\fml{H}$ be a Hilbert space and $\fml{E}$ be an orthonormal subset.
	\begin{enumerate}[label=\arabic*)]
		\item $\fml{H}$ is separable if and only if $\fml{E}$ is countable.
		\item Any separable Hilbert space is isometrically isomorphic to $l^{2}(\C)$.
	\end{enumerate}
\end{prop}

\subsection{Unitaries and Projections}

If we can find a bijection, which is continuous and the inverse of which is also continuous, between two topological spaces, these two topological spaces are regarded as same. Also, if there is a bijection, which is linear between two linear spaces, then we say these two linear spaces are same. Now, we also want to use a special map to classify Hilbert spaces. We know the Hilbert space has two structures, linear structure and the inner product structure. So following definition is nature.

\begin{defn}
	Let $\Hs$ and $\fml{K}$ be two Hilbert spaces. If there is a linear isomorphism $U$ from $\Hs$ to $\fml{K}$, s.t $\langle Ux,Uy \rangle = \langle x,y \rangle$, then $U$ is called a unitary.
\end{defn}
\begin{rem}
	In fact, if there exists a unitary $U$ between $\Hs$ and $\fml{K}$, $U$ preserves not only the linear structure, but also the inner product structure of Hilbert spaces. Therefore, these two Hilbert spaces are regarded as same. Moreover, if the $U$ is not assumed bijection, then $U$ is called an isometry.
\end{rem}

As above definition, the following proposition is clearly.

\begin{prop}
	If $U \in \oper$, then the following statements are equivalent.
	\begin{enumerate}[label=\arabic*)]
		\item $U$ is a unitary.
		\item $\st{U}U = U\st{U} = I$.
		\item $U$ is a normal isometry.
	\end{enumerate}
\end{prop}
\begin{rem}
	$A \in \oper$ is called normal, if $\st{A}A=A\st{A}$.
\end{rem}

Now, the another important operator is projection. Like its name showing, the projection can project the elements in a Hilbert space to a corresponding subspace, and because of the Projection Theorem, we can make the definition be well-defined.

\begin{defn}
	Let $\M$ be a any closed subspace of $\Hs$. Then by the Projection Theorem, $\Hs = \M \oplus \M^{\bot}$, i.e. for any $x \in \Hs$, there exist un $x_{//} \in \M$ and $x_{\bot} \in \M^{\bot}$ s.t.$x = x_{\shortparallel} + x_{\bot}$. Therefor we can define a map $P \colon \Hs \sto \M$ as $Px=x_{\shortparallel}$. $P$ is called a projection.
\end{defn}
\begin{rem}
	$P$ is a linear operator can be easily proved.
\end{rem}

There is an equivalent definition of the projection. Firstly, $A \in \oper$ is called self-adjoint if $\st{A} = A$.

\begin{thm}
	Let $\Hs$ be a Hilbert space. $P \in \oper$ is a projection if and only if $P$ is self-adjoint and $P^2=P$.
\end{thm}
\begin{proof}
	Let $\Hs = \M \oplus \M^{\bot}$. If $P$ is a projection to $\M$, $P^2=P$ is clearly true. 
	\begin{eqnarray*}
		\langle P(x = x_{\shortparallel} + x_{\bot}), y = y_{\shortparallel} + y_{\bot} \rangle &=& \langle x_{\shortparallel}, y_{\shortparallel} \rangle \\
		\langle \st{P}(x = x_{\shortparallel} + x_{\bot}), y = y_{\shortparallel} + y_{\bot} \rangle &=& \langle x = x_{\shortparallel} + x_{\bot}, P(y = y_{\shortparallel} + y_{\bot}) \\
		&=& \langle x_{\shortparallel}, y_{\shortparallel} \rangle
	\end{eqnarray*}
	Therefore, $P$ is self-adjoint. \\
	Conversely, $\M=P(\Hs)$ is clearly a subspace. And for any $y \in \M$, let $x=y$, we have $Px = y$. Thus by the \textbf{Lemma} \ref{lem1} in the subsection \textbf{1.4.4}, $\M$ is closed. Since $P$ is sefl-adjoint, 
	\begin{equation*}
		\langle x-Px,Px \rangle = \langle Px-P^2x,x \rangle = 0
	\end{equation*}
	That means $x-Px \in \M^{\bot}$. Therefore, $x=Px+(x-Px)$ is the unique decomposition of $x$ with respect to $\M$. $P$ is a projection. 
\end{proof}
\begin{rem}
	By the fact that $P^2 =P$ and the \textbf{Theorem} \ref{thm0} in the subsection \textbf{1.5.2}, $\norm{P} = 1$. Therefore, $P$ is bounded.
\end{rem}

The one of the importance of projections is that any closed subspace of a Hilbert space can be regarded as a operator on the Hilbert space. And then this can provide us an effective method to research the invariant space.

\begin{defn}
	For $T \in \oper$ and a closed subspace $\M$ of $\Hs$, if $T(\M) \subset \M$, $\M$ is called an invariant space for $T$. If $T(\M) \subset \M$ and $T(\M^{\bot}) \subset \M^{\bot}$, then $\M$ is called a reducing space for $T$.
\end{defn}

\begin{prop}
	Let $\M$ be a closed subspace of a Hilbert space $\Hs$ and $P$ be the projection to $\M$ and $T \in \oper$. $T$ acts on $\Hs=\M \oplus \M^{\bot}$ can be expressed as
	\begin{equation*}
		T = \left(
			\begin{array}{cc}
				W & X \\
				Y & Z
			\end{array}
		\right)
	\end{equation*}
 	Then the following statements are equivalent.
	\begin{enumerate}[label=\arabic*)]
		\item $\M$ is invariant for $T$.
		\item $PTP=TP$.
		\item $Y=0$.
	\end{enumerate}
\end{prop}
\begin{proof}
	$1) \Rightarrow 2)$ is clearly.
	\item $2) \Rightarrow 3)$: The $P$ can be expressed as
	\begin{equation*}
		P = \left(
			\begin{array}{cc}
				I & 0 \\
				0 & 0
			\end{array}
		\right)
	\end{equation*}
	Then by $PTP=TP$, we can find $Y=0$.
	\item $3) \Rightarrow 1)$ is also clearly.
\end{proof}

\begin{prop}
	Let $\M,\Hs$ and $T,P$ be defined as above proposition. Then the following statements are equivalent.
	\begin{enumerate}[label=\arabic*)]
		\item $\M$ reduces $\Hs$.
		\item $PT=TP$.
		\item $X$ and $Y$ are $0$.
		\item $\M$ is invariant for $T$ and $\st{T}$.
	\end{enumerate}
\end{prop}
\begin{proof}
	$1) \Rightarrow 2)$: By above proposition, $PTP=TP$ and $(I-P)T(I-P)=T(I-P)$, thus we have $PT=TP$.
	\item $2) \Rightarrow 3)$: Expressing $P$ as above proposition, then by $PT=TP$, we find $X$ and $Y$ are $0$.
	\item $3) \Rightarrow 4)$: Since $X$ and $Y$ are $0$, then
	\begin{equation*}
		\st{T} = \left(
			\begin{array}{cc}
				\st{W} & 0 \\
				0 & \st{Z}
			\end{array}
		\right)
	\end{equation*}
	Clearly, $\M$ is invariant for $T$ and $\st{T}$.
	\item $4) \Rightarrow 1)$: If $h \in \M^{\bot}$ and $g \in \M$, $\langle g,Ah \rangle = \langle \st{A}g,h \rangle = 0$ since $\st{A}g \in \M$. Therefore, $T(\M^{\bot}) \subset \M^{\bot}$.
\end{proof}

\chapter{Banach Algebras and \texorpdfstring{$C^{*}$-Algebras}{C*-Algebras}}
\section{Banach Algebras}

Let $\fml{H}$ be a Hilbert space. Then $\oper$ is indeed a Banach space. But we have more sructure on it. Any two element $S,T \in \oper$ can do multiplication, defined as $ST = S \circ T$, then $ST \in \oper$ by the definition of norm, and moreover $\norm{ST} \leqslant \norm{S}\norm{T}$. Therefore, $\oper$ is an algebra with the extra property of the multiplication, called a Banach algebra.

\subsection{Elementary Properties}

\begin{defn}
	A Banach algebra $\alg{A}$ is an algebra over $\C$ with a norm $\norm{\cdot}$ relative to which $\alg{A}$ is a Banach space and s.t. for all $a,b \in \alg{A}$,
	\begin{equation*}
		\norm{ab} \leqslant \norm{a}\norm{b}.
	\end{equation*}
\end{defn}
\begin{rem}
	The extra condition guarantees the multiplication is norm continuous. In fact, $\alg{A}$ with the multiplication and the norm is a topological semigroup.
\end{rem}

If $\alg{A}$ has an identity $1$, it assumes $\norm{1}=1$. But if $\alg{A}$ does not have an identity, we can add an identity to it.

\begin{prop}
	If $\alg{A}$ is a Banach algebra without the identity. The let $\tilde{\alg{A}}= \alg{A} \oplus \C$ be an induced vector space. Then we define a norm on $\tilde{\alg{A}}$ as
	\begin{equation*}
		\norm{(a,\lambda)} = \norm{a} + \abs{\lambda}
	\end{equation*}
	and define a multiplication on $\tilde{\alg{A}}$ as
	\begin{equation*}
		(a,\alpha)(b,\beta) = (ab+\alpha b + \beta a, \alpha \beta)
	\end{equation*}
	Then $\alg{A}$ is a Banach algebra with the identity $(0,1)$.
\end{prop}

Then $\alg{A}$ can be isometrically imbedded into $\tilde{\alg{A}}$. Therefore, we can always assume $\alg{A}$ has an identity. For a unit algebra, the invertibility of a element is important. 

\begin{thm}
	Let $\alg{A}$ be a Banach algebra and $a \in \alg{A}$. If $\norm{a-1} < 1$, then $a$ is invertible.
\end{thm}
\begin{proof}
	For a nonzero real number $\lambda \in \R$ with $\abs{\lambda} < 1$, we know 
	\begin{equation*}
		(1-\lambda)^{-1} = \sum_{n=0}^{\infty} \lambda^{n}
	\end{equation*}
	Similar, for $a \in \alg{A}$ with $\norm{a-1} < 1$, set
	\begin{equation*}
		b= \sum_{n=0}^{\infty} (1-a)^{n}
	\end{equation*}
	Firstly, since $\norm{(1-a)^{n}} \leqslant \norm{(1-a)}^{n}$, $b$ is well-defined. Then we can prove $b = (1-(1-a))^{-1} = a^{-1}$.
\end{proof}
\begin{rem}
	This result is important. It says a small perturbation of an invertible element is also invertible. It is because that the multiplication is norm continuous. And by the continuity of multiplication, this result can be true at any point other than 1.
\end{rem}

\begin{cor}
	Let $\alg{A}$ be a Banach algebra and 
	\begin{eqnarray*}
		G_l &=& \{~a \in \alg{A} \colon a \text{ is left invertible}~\}\\
		G_r &=& \{~a \in \alg{A} \colon a \text{ is right invertible}~\}\\
		G &=& G_l \bigcap G_r = \{~a \in \alg{A} \colon a \text{ is invertible}~\}
	\end{eqnarray*}
	Then $G_l$ and $G_r$ and $G$ are open. Moreover, the map $a \sto a^{-1}$ from $G$ to $G$ is continuous.
\end{cor}
\begin{proof}
	$G_l$ and $G_r$ and $G$ are open by above theorem. \\
	We just need to check this map is continuous at $1$ because of the continuity of multiplication. For $\{a_n\} \subset G$ with $a_n \sto 1$, thus $\norm{1-a_n}<\delta<1$. Since
	\begin{equation*}
		a_n^{-1} = (1-(1-a_n))^{-1} = \sum_{k=0}^{\infty} (1-a_n)^{k} = 1+ \sum_{k=1}^{\infty} (1-a_n)^{k}
	\end{equation*}
	Therefore,we have
	\begin{eqnarray*}
		\norm{1-a_n^{-1}} &=& \norm{\sum_{k=1}^{\infty} (1-a_n)^{k}}\\
		&\leqslant&  \sum_{k=1}^{\infty} \norm{1-a_n}^{k}\\
		&<& \frac{\delta}{1+\delta} < \delta = \norm{1-a_n}
	\end{eqnarray*}
	i.e. $\lim a_n = 1$.
\end{proof}

\begin{cor}
	Let $\alg{A}$ be a Banach algebra.
	\begin{enumerate}[label=\arabic*)]
		\item The closure of a proper ideal is a proper ideal.
		\item A maximal ideal is closed.
		\item every ideal contained in a maximal ideal.
	\end{enumerate}
\end{cor}

If $\alg{B}$ is a closed ideal of a Banach algebra $\alg{A}$, then then quotient algbra $\alg{A}/\alg{B}$ with the induced norm is also a Banach algebra since 
\begin{equation*}
	\norm{(a+\alg{B})(b+\alg{B})} = \norm{ab+\alg{B}} \leqslant \norm{(a+b_1)(b+b_2)} \leqslant \norm{(a+b_1)}\norm{(b+b_2)}
\end{equation*}
for any $b_1, b_2 \in \alg{B}$.

\subsection{Spectrum}


\begin{defn}
	Let $\alg{A}$ be a Banach algebra and $a \in \alg{A}$. The spectrum of $a$, denoted by $\sigma(a)$ defined as
	\begin{equation*}
		\sigma(a) = \{~ \lambda \in \C \colon a-\lambda \text{ is invertible}~\}
	\end{equation*}	
	And the resolvents of $a$, $\rho(a) = \C \backslash \sigma(a)$.\\
	Moreover, we can define the spectral radius of $a$ as
	\begin{equation*}
		r(a) = \sup{\{~\abs{\lambda} \colon \lambda \in \sigma(a)~\}}
	\end{equation*}
\end{defn}

Firstly, there are some elementary properties of the spectrum.

\begin{thm}
	Let $\alg{A}$ be a Banach algebra and $a \in \alg{A}$.
	\begin{enumerate}[label=\arabic*)]
		\item If $\abs{\lambda} > \norm{a}$, then $\lambda \notin \sigma(a)$.
		\item $\sigma(a)$ is a compact subset of $\C$.
		\item the map $\lambda \mapsto (a-\lambda)^{-1}$ from $\rho(a)$ to $\alg{A}$ is analytic and $\sigma(a)$ is nonempty.
		\item $r(a)=\lim_{n \sto \infty} \norm{a^{n}}^{\frac{1}{n}}$.
	\end{enumerate}
\end{thm}
\begin{proof}
	$1)$ holds by above theorem. \\
	For $2)$, since $\lambda \sto a-\lambda$ is continuous from $\C$ to $\alg{A}$ and $G$ is open, $\rho(a)$ is open i.e. $\sigma(a)=\C \backslash \rho(a)$ is closed. Then by $1)$, $\sigma(a)$ is compact.\\
	For $3)$, by the identity $a^{-1} - b^{-1} = a^{-1}(b-a)b^{-1}$ and the continuity of $a \sto a^{-1}$, we can compute the derivative of $F(\lambda) = (a-\lambda)^{-1}$,
	\begin{equation*}
		F^{'}(\lambda) = (a-\lambda)^{-2}
	\end{equation*}
	And clearly, $F^{'}(\lambda)$ is continuous. Thus it is analytic and it vanishes at $\infty$. By the Liouville's Theorem, if $\rho(a) = \C$, $F$ is constant. Therefore, $\rho(a) \neq \C$ i.e. $\sigma(a) \neq \varnothing$.\\
	For $4)$, let $U=\{\lambda \in \C \colon \lambda = 0 \text{ or } \lambda^{-1} \in \rho(a)\}$ and 
	\begin{equation*}
		f(\lambda) = 
		\begin{cases}
			(\lambda^{-1}-a)^{-1} & x \neq 0,\\
			0,& x = 0
		\end{cases}
	\end{equation*}
	Then $f$ is analytic on $U$, i.e $f(\lambda)=\lambda\sum_{n=0}^{\infty} \lambda^{n} a^{n}$ is well-defined. Therefore, the convergent radius $R = r(a)^{-1}$
	\begin{equation*}
		R^{-1} = \limsup_{n \sto \infty} \norm{a^{n}}^{\frac{1}{n}} = r(a)
	\end{equation*}
	Conversely, by the identity $(a^{n}-\lambda^{n}) = (a-\lambda)(a^{n-1}+\lambda a^{n-2}+\lambda^{2} a^{n-3} + \cdots + \lambda^{n-1})$. Then, if $(a^{n}-\lambda^{n})$ is invertible, then $(a-\lambda)$ is invertible, i.e. $\sigma(a) \subset \sigma(a^{n})$. Thus $\abs{\lambda}^{n} \leqslant \norm{a^{n}}$ for any $\lambda \in \sigma{a}$. $r(a)=\liminf_{n \sto \infty}\norm{a^{n}}^{\frac{1}{n}}$. Therefore, $r(a)=\lim_{n \sto \infty} \norm{a^{n}}^{\frac{1}{n}}$.
\end{proof}

If $\alg{B} \subset \alg{A}$ is a subalgebra with the same identity of a Banach algebra $\alg{A}$, then we know for any element $b \in \alg{B}$, $\sigma_{\alg{A}}(b) \subset \sigma_{\alg{B}}(b)$. Then we can have more results other than it. Since the spectrum is a subset of $\C$, we need some topological properties results of $\C$.

\begin{lem}
	If $K$ is any compact subset of $\C$, then $\C \backslash K$ has a countable components, only one of which is unbounded. And the boundary of each component is in $K$.
\end{lem}
\begin{proof}
	Let $\tilde{K} = \C \backslash K$, then $\tilde{K}$ is open.
	\item Firstly, the connected component of open set in $\C$ is open. \\
		  Let $U$ be an connected component in $\tilde{K}$ and $x \in U$. For any point $x \in U$, Since any open neighbourhood of $x$ is connected, and $K$ is open, there is a open neighbourhood $V$ of $x$ s.t. $V \subset U$.
	\item Secondly, $\C$ has just at most countable many open sets, which are pairwise disjoint.\\
		  This result is because any open set in $\C$ contains a rational point.
	\item For any two disjoint open sets $A$ and $B$ in $\C$, $\partial A \bigcap B = \varnothing$. Thus the boundary of some compoment of $\tilde{K}$ can not be contained in any component of $\tilde{K}$, i.e. it is contained $K$.
	\item Finally, since $K$ is bounded, there is a closed ball $B$ containing $K$. But the complement of $B$ is connected, thus there is only one component of $\tilde{K}$ containing $B$. Thus the other components of $\tilde{K}$ are bounded.
\end{proof}
\begin{rem}
	The bounded component of $\C \backslash K$ is called a hole of $K$.
\end{rem}

\begin{defn}
	If $f \colon A \sto \C$, where $A$ is a set, then the norm of $f$ on $A$ is defined as
	\begin{equation*}
		\norm{f}_A = \sup{\{\abs{f(x)} \colon x \in A\}}
	\end{equation*}
	For a compact set $K \in \C$, the polynomially convex hull of $K$ is defined as
	\begin{equation*}
		\hat{K} = \{~z \in \C \colon \abs{p(z)} \leqslant \norm{p}_K \text{ for any polynomial } p ~\}
	\end{equation*}
	If $K = \hat{K}$, $K$ is called polynomially convex.
\end{defn}

\begin{prop}
	Let $K$ be a compact subset of $\C$. Then $\C \backslash \hat{K}$ is the unbounded component of $\C \backslash K$. Therefore, $K$ is polynomially convex if and only if $\C \backslash K$ is connected.
\end{prop}
\begin{proof}
	Let $L$ be the set containing $K$ and all bounded component of $\C \backslash K$. Then by the Maximal Principle, $L \subset \hat{K}$. Conversely, if $\alpha \notin L$, then $(z-\alpha)^{-1}$ is analytic in a neighbourhood of $L$. Therefore, there is a sequence of polynomials $\{p_n\}$ s.t. $p_n \sto (z-\alpha)^{-1}$. Let $q_n=(z-\alpha)p_n$. Then $q_n \sto 1$, i.e. $\norm{q_n-1} < \frac{1}{2}$ for some $n$. But $\abs{q_n(\alpha)-1}=1$, this implies $\alpha \notin \hat{K}$, i.e. $\hat{K} \subset L$.
\end{proof}

By above results, now we can provide the relationships betweem $\sigma_{\alg{A}}(b)$ and $\sigma_{\alg{B}}(b)$.

\begin{thm}
	If $\alg{A}$ and $\alg{B}$ are Banach algebras with same identity s.t. $\alg{B} \subset \alg{A}$ and $b \in \alg{B}$, then
	\begin{enumerate}[label=\arabic*)]
		\item $\sigma_{\alg{A}}(b) \subset \sigma_{\alg{B}}(b)$ and $\partial\sigma_{\alg{B}}(b) \subset \partial\sigma_{\alg{A}}(b)$
		\item $\hat{\sigma_{\alg{A}}(b)} = \hat{\sigma_{\alg{B}}(b)}$
		\item if $G$ is a hole of $\sigma_{\alg{A}}(b)$, then $G \subset \sigma_{\alg{B}}(b)$ or $G \bigcap \sigma_{\alg{B}}(b) = \varnothing$
	\end{enumerate}
\end{thm}
\begin{proof}
	\item For $1)$, let $\lambda \in \partial\sigma_{\alg{B}}(b)$. Since $\inte{\sigma_{\alg{A}}(b)} \subset \inte{\sigma_{\alg{B}}(b)}$, it is sufficient to show $\lambda \in \sigma_{\alg{A}}(b)$. Suppose $\lambda \notin \sigma_{\alg{A}}(b)$, i.e. $(b-\lambda)$ is invertible in $\alg{A}$. But since $\lambda \in \partial\sigma_{\alg{B}}(b)$, there are $\lambda_n \in \C \backslash \alg{B}$ with $\lambda_n \sto \lambda$. Thus $(b-\lambda_n)^{-1} \in \alg{B}$. But $(b-\lambda_n)^{-1} \sto (b-\lambda)^{-1} \in \sigma_{\alg{B}}(b)$, contradicting to $\lambda \in \sigma_{\alg{A}}(b)$.
	\item $2)$ holds because of the result of $1)$ and the Maxiamal Principle.
	\item For $3)$, let $G_1 = G \bigcap \sigma_{\alg{B}}(b)$ and $G_2 = G \backslash \sigma_{\alg{B}}(b)$. Since $\partial\sigma_{\alg{B}}(b) \subset \sigma_{\alg{A}}(b)$ and $G \bigcap \sigma_{\alg{A}}(b) = \varnothing$, $G_1 = G \bigcap \inte{\sigma_{\alg{B}}(b)}$ is open. By the facts that $G_2$ is clearly open and $G = G_1 \bigcup G_2$ and $G_1 \bigcap G_2 = \varnothing$, either $G_1$ or $G_2$ is empty.
\end{proof}

Then we can have some useful corollaries.

\begin{cor} \label{cor5}
	Let $\alg{A}$ and $\alg{B}$ be Banach algebras with same identity s.t. $\alg{B} \subset \alg{A}$ and $b \in \alg{B}$.
	\begin{enumerate}[label=\arabic*)]
		\item If $\sigma_{\alg{A}}(b)$ has no holes, then $\sigma_{\alg{A}}(b)=\sigma_{\alg{B}}(b)$.
		\item If $\sigma_{\alg{B}}(b) \subset \R$, then $\sigma_{\alg{A}}(b)=\sigma_{\alg{B}}(b)$.
		\item $\sigma_{\alg{A}}(b)=\sigma_{\alg{B}}(b)$ if and only if $\rho_{\alg{A}}(b)$ is connected.
	\end{enumerate}
\end{cor}
\begin{proof}
	$1)$ is clearly true since ubbouded component does not intersect $\sigma_{\alg{B}}(b)$. $2)$ is because $\C \backslash \sigma_{\alg{A}}(b)$ has no holes. $3)$ is similar as $2)$.
\end{proof}

\subsection{Riesz Functional Calculus}

For any polynomial $p$ with complex coefficients,  
\begin{equation*}
	p(z) = \sum_{k=0}^{n} \alpha_k z^{k}
\end{equation*}
we can define $p(a)$ for some $a \in \alg{A}$, where $\alg{A}$ is a Banach algebra
\begin{equation*}
	p(a) = \sum_{k=0}^{n} \alpha_k a^{k}
\end{equation*}
Clearly, $p(a)$ is well-defined. But we can do more. If $f$ is an analytic funcion on $A \subset \C$, then $f$ can be approximated by a sequence of polynomials
\begin{equation*}
	f(z) = \sum_{n=0}^{\infty} \alpha_n z^{n}
\end{equation*}
Similarly, we can define $f(a)$ for $a \in \alg{A}$ as
\begin{equation*}
	f(a) = \sum_{n=0}^{\infty} \alpha_n a^{n}
\end{equation*}
If the radius of convergence of this sequence is $R$, then it can be well-defined for $\norm{a} \leqslant R$. By the fact that $r(a) \leqslant \norm{a}$, for the analytic function $f$, if $\sigma(a) \subset A$, $f(a)$ can be well-defined.\\
Let $\hol{(a)}$ denote all functions that are analytic in a neighbourhood of $\sigma(a)$. Then there is a map from $\hol{(a)}$ to $\alg{A}$ defined as $f \mapsto f(a)$. Now, we can find more properties of this map. Firstly, we can give another formula of $f(a)$.\\
If $f \in \hol{(a)}$, then for any closed curve $\gamma$ which encloses $\hol{(a)}$ and any point $z_0 \in \hol{(a)}$, 
\begin{equation*}
	f(z_0) = \frac{1}{2 \pi i}\int_{\gamma} f(z) (z-z_0)^{-1} dz
\end{equation*}
Therefore, replacing $z_0$ by $a \in \alg{A}$, then we have 
\begin{equation*}
	f(a) = \frac{1}{2 \pi i}\int_{\gamma} f(z) (z-a)^{-1} dz
\end{equation*}
Clearly, by the Cauchy's Integral Formula, this definition is well-defined and is coincided with above definition. But this definition can provide us a conivient method to research the map $f \mapsto f(a)$.

\begin{thm}[Riesz Functional Calculus]
	Let $\alg{A}$ be a Banach algebra and $a \in \alg{A}$ and the map
	\begin{center}
		\begin{tabular}{l c c l}
			$\rho \colon$ & $\hol{(a)}$ & $\longrightarrow$ & $\alg{A}$ \\
			~ & $f$ & $\longmapsto$ & $f(a)=\frac{1}{2 \pi i}\int_{\gamma} f(z) (z-a)^{-1} dz$
		\end{tabular}
	\end{center}
	has the following properties.
	\begin{enumerate}[label=\arabic*)]
		\item $\rho$ is an algebra homomorphism.
		\item $\rho(1) = 1$ and $\rho(z)=a$.
		\item If $\{f_n\} \subset \hol{(a)}$ and $f \in \alg{A}$ with $f_n \sto f$ uniformly on a compact set of $\hol{(a)}$, then $\rho(f_n) \sto \rho(f)$ in norm.
	\end{enumerate}
	Moreover, if any map $\tau \colon \hol{(a)} \sto \alg{A}$ satifies above conditions, then $\tau = \rho$. 
\end{thm}
\begin{proof}
	For $1)$, $\rho$ is clearly linear. And
		\begin{eqnarray*}
			f(a)g(a)&=& -\frac{1}{4 \pi^{2}}\int_{\gamma_1} f(z) (z-a)^{-1} dz\int_{\gamma_2} g(\zeta) (\zeta-a)^{-1} d\zeta \\
			&=& -\frac{1}{4 \pi^{2}}\int_{\gamma_1}\int_{\gamma_2} f(z)g(\zeta) \frac{(z-a)^{-1}-(\zeta-a)^{-1}}{\zeta-z} d\zeta dz \\
			&=& -\frac{1}{4 \pi^{2}}\int_{\gamma_1}f(z) \int_{\gamma_2} \frac{g(\zeta)}{\zeta-z} d\zeta (z-a)^{-1} dz \\
		    && \negmedspace{} + \frac{1}{4 \pi^{2}}\int_{\gamma_2}g(\zeta) \int_{\gamma_1} \frac{f(z)}{\zeta-z} dz (\zeta-a)^{-1} d\zeta
		\end{eqnarray*}
		We can choose $\gamma_2$ to enclose $\gamma_1$, thus 
		\begin{equation*}
			\int_{\gamma_1} \frac{f(z)}{\zeta-z} dz =0,~ \int_{\gamma_2} \frac{g(\zeta)}{\zeta-z} d\zeta] = 2\pi i g(z)
		\end{equation*}
		Therefore, 
		\begin{equation*}
			f(a)g(a) = {2 \pi i}\int_{\gamma_1} f(z)g(z)(z-a)^{-1} dz = (fg)(a)
		\end{equation*}
	\item For $2)$, let $f(z) = z^k$ and $\gamma = R e^{2 \pi i t}$, where $R>\norm{a}$ and $t \in [0,1]$, then
	\begin{eqnarray*}
		f(a) &=& \frac{1}{2 \pi i}\int_{\gamma} z^k (z-a)^{-1} dz \\
		&=& \frac{1}{2 \pi i}\int_{\gamma} z^{k-1} (1-\frac{a}{z})^{-1} dz \\
		&=& \frac{1}{2 \pi i}\int_{\gamma} z^{k-1} \sum_{n=0}^{\infty} \frac{a^{n}}{z^{n}}dz \\
		&=& \sum_{n=0}^{\infty} (\frac{1}{2 \pi i}\int_{\gamma} \frac{1}{z^{n-k+1}}) a^{n} \\
		&=& a^{k}
	\end{eqnarray*}
	\item For $3)$, 
	\begin{eqnarray*}
		\lefteqn { \norm{\int_{\gamma} f_n(z) (z-a)^{-1} dz - \int_{\gamma} f(z) (z-a)^{-1} dz} }\\
		&=& \norm{\int_{0}^{1}(f_n(\gamma(t))-f(\gamma(t)))(\gamma(t)-a)^{-1}d\gamma(t)}\\
		&\leqslant& \int_{0}^{1} \abs{f_n(\gamma(t))-f(\gamma(t))}\norm{(\gamma(t)-a)^{-1}}d\abs{\gamma}(t) \\
		&\leqslant& M \norm{\gamma} \sup{\{\abs{f_n(z)-f(z)} \colon z \in \gamma(t)\}}
	\end{eqnarray*}
	where $M$ is the bound of $\norm{(\gamma(t)-a)^{-1}}$ since $t \mapsto \norm{(\gamma(t)-a)^{-1}}$ is continuous on $\gamma(t)$. Therefore, by the fact that $f_n \sto f$ uniformly,
	\begin{equation*}
		\norm{f_n(a)-f(a)} \sto 0
	\end{equation*}
	\item Finally, the uniquness is because any $f \in \hol{(a)}$ can be approximated uniformly by a sequence of polynomials. Thus, $1)$ and $2)$ means $\tau(p) = \rho(p)$ for any polynomial $p$, and $3)$ provides the fact that $\tau(f) = \rho(f)$ for any $f \in \hol{(a)}$.
\end{proof}
\begin{rem}
	we have mentioned that the integral definition is coincided with the convergent difinition. In fact, by $2)$, this statement can be proved rigorously.
\end{rem}

\begin{thm}[Spectral Mapping Theorem]
	If $a \in \alg{A}$ and $f \in \hol{(a)}$, then
	\begin{equation*}
		\sigma(f(a)) = f(\sigma(a))
	\end{equation*}
\end{thm}
\begin{proof}
	Firstly, there is a $g \in \hol{(a)}$ s.t. for $\alpha \in \sigma(a)$, $f(z)-f(\alpha) = (z-\alpha)g(z)$, that means $f(\sigma(a)) \subset \sigma(f(a))$.
	\item Conversely, if $\alpha \notin f(\sigma(a))$, $g(z)=(f(z)-\alpha)^{-1} \in \hol{(a)}$. Thus, $g(a)(f(a)-\alpha) = 1$. Therefore, $\alpha \notin \sigma(f(a))$.
\end{proof}

\begin{prop}
	Let $\alg{A}$ be a Banach algebra and $a \in \alg{A}$. $\sigma(a) = F_1 \bigcup F_2$, where $F_1$ and $F_2$ are disjoint nonempty closed sets. Then there is a nontrial idempotent $e$, i.e. $e^{2}=e$, s.t.
	\begin{enumerate}[label=\arabic*)]
		\item if $ab=ba$, then $eb=be$.
		\item if $a_1=ae$ and $a_2=a(1-e)$, then $a_1a_2=a_2a_1=0$.
		\item $\sigma(a_1)=F_1 \bigcup \{0\}$ and $\sigma(a_2)=F_2 \bigcup \{0\}$.
	\end{enumerate}
\end{prop}
\begin{proof}
	Since $F_1$ and $F_2$ are disjoint closed set, there are two disjoint open sets $G_1$ and $G_2$ separating $F_1$ and $F_2$. Let $f$ be the characteristic function of $G_1$ and $e=f(a)$. Thus $e^{2}=e$ by $f^{2}=f$.
	\item For $1)$, there is a more genera result, $f(a)b=bf(a)$ for any $f \in \hol{(a)}$. It is because by extending the fact $p(a)b=bp(a)$ for any polynomial $p$.
	\item $2)$ is clearly true.
	\item Let $f_1(z)=zf(z)$ and $f_2(z)=z(1-f(z))$. Then $a_j = f_j(a)$ for $j=1,2$. Then by the Spectral Mapping Theorem $\sigma(a_j) = f_j(\sigma(a_j)) = F_j \bigcup \{0\}$.
\end{proof}

\subsection{Abelian Banach Algebras} \label{sec2}
 
 \begin{thm}[Gelfand-Mazur Theorem]
	If $\alg{A}$ is a Banach algebra and a division ring, then $\alg{A} = \C$.
\end{thm}
\begin{proof}
	It is because that for any $a \in \alg{A}$, $\sigma(a) \neq \varnothing$.
\end{proof}

Next, we reach the structure of an abelian Banach algebra. The structure of abelian Banach algebras can be explicit by constructing a map from an abelian Banach algebra to a continuous function space on a compact space. Firstly, we can find this compact space. Let 
\begin{eqnarray*}
	\Sigma(\alg{A}) &=& \{ \text{all algebra homomorphism } h \colon \alg{A} \sto \C\}\\
	\fml{M} &=& \{\text{all maximal ideals of } \alg{A}\}
\end{eqnarray*}
for an abelian Banach algebra $\alg{A}$. Then we can find the relationship between $\Sigma(\alg{A})$ and $\fml{M}$.

\begin{thm}
	Let $\alg{A}$ be an abelian Banach algebra. Define a map
	\begin{center}
		\begin{tabular}{l c c l}
			$\gamma \colon$ & $\Sigma(\alg{A})$ & $\longrightarrow$ & $\fml{M}$ \\
			~ & $h$ & $\longmapsto$ & $\ker{h}$
		\end{tabular}
	\end{center}
	Then $\gamma$ is a bijection.
\end{thm}
\begin{proof}
	Since $\alg{A} / \ker{h} \cong \C$, $\ker{h} \in \fml{M}$, i.e. $\gamma$ is well-defined.
	\item Check: $\alg{A} / M \cong \C$ for any $M \in \fml{M}$\\
		Let $\pi \colon \alg{A} \sto \alg{A} / M$. If $\pi(a)$ is not invertible, then $\pi(a\alg{A})$ is a proper ideal in $\alg{A} / M$. Thus $I = \pi^{-1}(\pi(a\alg{A}))$ is a proper ideal in $\alg{A}$ and $M \subset I$. Then by the maximality of $M$, $I=M$, i.e. $\pi(a)=0$. In fact, for any commutative ring, this result is true. Therefore, by Gelfand-Mazur Theorem, $\alg{A} / M \cong \C$.
	\item Check: $\gamma$ is surjective.
		Let $M \in \fml{M}$. Define $\tilde{h} \colon \alg{A} / M \sto \C$ as the algebraic isomorphism. Then $h=\pi \circ \tilde{h} \in \Sigma(\alg{A})$ with $\ker{h} = M$.
	\item Check: $\gamma$ is injective.
		If $\ker{h} = \ker{h^{'}}$ for $h,h^{'} \in \Sigma(\alg{A})$, then by the \textbf{Propostion} \ref{prop2} in the subsection \textbf{1.4.2}, $h = \alpha h^{'}$. And since $h(1) = h^{'}(1)=1$, $h=h^{'}$.
\end{proof}

Then we have some properties of $h \in \Sigma(\alg{A})$.

\begin{prop} \label{prop5}
	Let $\alg{A}$ be an abelian Banach algebra and $h \in \Sigma(\alg{A})$.
	\begin{enumerate}[label=\arabic*)]
		\item $h$ is continuous.
		\item $\norm{h}=1$ for $h \neq 0$.
	\end{enumerate}
\end{prop}
\begin{proof}
	$1)$ holds since $\ker{h}$ is maximal, thus it is closed.
	\item Let $\lambda = h(a)$. Suppose $\abs{\lambda} > \norm{a}$. Then $1-\frac{1}{\lambda}$ is invertible. Set $b = (1-\frac{1}{\lambda})^{-1}$, then 
	\begin{equation*}
		1=h(b(1-\frac{1}{\lambda})) = h(b) - \frac{h(b)h(a)}{\lambda} =0
	\end{equation*}
	Therefore, $\abs{h(a)} \leqslant \norm{a}$ i.e $\norm{n} \leqslant 1$. Since $h(1) = 1$, $\norm{h}=1$.
\end{proof}

\begin{defn}
	Let $\alg{A}$ be an abelian Banach algebra. Then $\Sigma(\alg{A}) \subset \alg{A}^{*}$ endowed with the induced $wk^{*}$-topology, is called the maximal ideal space of $\alg{A}$.
\end{defn}

\begin{prop} \label{prop6}
	If $\alg{A}$ is an abelian Banach algebra, then $\Sigma(\alg{A})$ is a compact Hausdorff space. Moreover, if $a \in \alg{A}$, then
	\begin{equation*}
		\sigma(a) = \Sigma(a) = \{~ h(a) \colon h \in \Sigma(\alg{A}) ~\}
	\end{equation*}
\end{prop}
\begin{proof}
	Since $\Sigma(\alg{A}) \subset \alg{A}^{*}$, we just need to show $\Sigma(\alg{A})$ is $wk^{*}$-closed. Let $\{h_i\}$ be a net in $\Sigma(\alg{A})$ s.t. $h_i \sto h$ $wk^{*}$ for some $h$ in the unit closed ball of $\alg{A}^{*}$. Then for $a,b \in \alg{A}$,
	\begin{equation*}
		h(ab) = \lim_{i} h_i(ab) = \lim_{i} h_i(a)h_i(b) = h(a)h(b)
	\end{equation*}
	and $h(1)=\lim_{i}h_i(1)=1$, thus $h \in \Sigma(\alg{A})$. $\Sigma(\alg{A})$ is compact.
	\item If $h\in \Sigma(\alg{A})$ and $h-h(a) \in \ker{h} \in \fml{M}$, then $h-h(a)$ is not invertible, i.e. $\Sigma(a) \subset \sigma(a)$. Conversely, if $a-\lambda$ is not invertible, $(a-\lambda)\alg{A}$ is a proper ideal, which can be contained in a maximal ideal. Then $(a-\lambda) \in \ker{h}$ with some $h \in \Sigma(\alg{A})$, $\lambda = h(a) \in \Sigma(a)$.
\end{proof}

Therefore, $\Sigma(\alg{A})$ is the compact space we need. Then we define the map from $\alg{A}$ to $C(\Sigma(\alg{A}))$.

\begin{thm} \label{thm5}
	If $\alg{A}$ is an abelian Banach algebra, the Gelfand transform is defined as
	\begin{center}
		\begin{tabular}{l c c l}
			$\Gamma \colon$ & $\alg{A}$ & $\longrightarrow$ & $C(\Sigma(\alg{A}))$ \\
			~ & $a$ & $\longmapsto$ & $\hat{a} = \Gamma(a)$
		\end{tabular}
	\end{center}
	where $\hat{a}(h)=h(a)$.
	\begin{enumerate}[label=\arabic*)]
		\item $\Gamma$ is a continuous homomorphsim.
		\item $\norm{\Gamma}=1$.
		\item $\ker{\Gamma}=\bigcap\{M \colon M \in \fml{M}\}$.
		\item $\norm{\hat{a}}_{\infty}=r(a)$.
	\end{enumerate}
\end{thm}
\begin{proof}
	Firstly, for $1)$ if $h_i \sto h$ in $wk^{*}$, $\hat{a}(h_i) = h_i(a) \sto h(a) = \hat{a}(h)$. Thus $\Gamma$ is well-defined. And
	\begin{equation*}
		\Gamma(ab)(h) = h(ab) = h(a)h(b) = \Gamma(a)(h)\Gamma(b)(h)
	\end{equation*}
	Thus $\Gamma$ is a homormophsim.
	\item For $2)$, since $\abs{\hat{a}(h)} = \abs{h(a)} \leqslant \norm{a}$, $\norm{\hat{a}}_{\infty} \leqslant \norm{a}$. Then $\norm{\Gamma} \leqslant 1$. By $\Gamma(1) = 1$, $\norm{\Gamma} = 1$.
	\item For $3)$, $a \in \ker{\Gamma}$ if and only if $h(a) = 0$ for any $h \in \Sigma(\alg{A})$, i.e. $a \in \bigcap\{M \colon M \in \fml{M}\}$. 
	\item For $4)$, it holds since $\sigma(a) = \{~ h(a) \colon h \in \Sigma(\alg{A}) ~\}$.
\end{proof}

If $a \in \alg{A}$ s.t. $\clo{\{p(a) \colon p \text{ is any polynomial}\}} = \alg{A}$, then $a$ is called a generator of $\alg{A}$. Clearly, this $\alg{A}$ is commutative. Then we can find an extral property of this special algebra.

\begin{prop} \label{prop7}
	If $\alg{A}$ is an abelian Banach algebra with a generator $a$, then there is a homeomorphism $\tau \colon \Sigma(\alg{A}) \sto \sigma(a)$ s.t. $\Gamma(p(a)) = p \circ \tau$.
\end{prop}
\begin{proof}
	In fact, $\tau$ can be defined as $\tau(h)=h(a)$. By above mention, $\tau$ is continuous and surjective. If $\tau{h_1}=\tau{h_2}$, then $ h_1(a) = h_2(a)$. By the fact that $h_1,h_2 \in \alg{A}$ and $a$ is a generator of $\alg{A}$, $h_1=h_2$. Thus $\tau$ is a bijection. And because $\Sigma(\alg{A})$ is compact, $f$ is a closed map, i.e. $f$ is a homeomorphism.
	\begin{equation*}
		\Gamma(p(a))(h) = p(\Gamma(a))(h) = p(\Gamma(a)(h)) = p(\tau(h))
	\end{equation*}
\end{proof}
\begin{rem}
	If $\alg{A}$ is generate by $a$, then $\Gamma \colon \alg{A} \sto C(\sigma(a))$ can be defined as $\Gamma(p(a)) = p$. 
\end{rem}

In fact, above proposition can extends to $n$ generators. If $\{a_i\}_{i=1}^{n}$ are generators of $\alg{A}$, i.e $\clo{\{p(a_1,\cdots,a_n) \colon p \text{ is any } n \text{ variables polynomial}\}} = \alg{A}$, then we have similar results as above proposition.


\section{\texorpdfstring{$C^{*}$-Algebras}{C*-Algebras}}

Now, we have known $\oper$ is a Banach algebra. But there is another algebraic operation on $\oper$, which let $\oper$ be more interesting than the general Banach algebra. This operation is a map $T \sto T^{*}$ on $\oper$, called an involution, and moreover, it satisfies the condition $\norm{T} = \norm{T^{*}}$. This identity provides a strong relation between the topological structure and the algebraic structure on $\oper$. In fact, the topology is completely determined by the algebraic structure on $\oper$. In order to research this structure, we firstly define an general algebra satisfying above condition, called a $C^{*}$-algebra. By digging its topological structures and algebraic structures, we can embed it into $\oper$ for some Hilbert space $\fml{H}$. Therefore, any $C^{*}$-algebra can be regarded as a subalgebra of $\oper$.

\subsection{Elementary Properties}
\begin{defn}
	If $\alg{A}$ is a Banach algebra, an involution is a map $a \sto a^{*}$ from $\alg{A}$ to $\alg{A}$ satisfying for any $a,b \in \alg{A}$ and any $\alpha \in \C$, 
	\begin{enumerate}[label=\arabic*)]
		\item $(a^{*})^{*}=a$,
		\item $(ab)^{*}=b^{*}a^{*}$,
		\item $(\alpha a+b)^{*} = \clo{\alpha} a^{*}+b^{*}$.
	\end{enumerate}
\end{defn}

\begin{defn}
	A $C^{*}$-algebra is a Banach algebra $\alg{A}$ with an involution s.t. for every $a \in \alg{A}$,
	\begin{equation*}
		\norm{\st{a}a} = \norm{a}^{2}
	\end{equation*}
\end{defn}

Then we can get some easy properties for the norm and the involution.

\begin{prop}
	Let $\A$ be a \Cs and $a \in \A$.
	\begin{enumerate}[label=\arabic*)]
		\item $\norm{\st{a}} = \norm{a}$.
		\item $\norm{a\st{a}}=\norm{a}^{2}$.
		\item $\norm{a}=\sup{\{\norm{ax} \colon \norm{x} \leqslant 1\}} = \sup{\{\norm{xa} \colon \norm{x} \leqslant 1\}}$.
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, $\norm{a}^{2} = \norm{\st{a}a} \leqslant \norm{\st{a}}\norm{a}$, thus $\norm{a} \leqslant \norm{\st{a}}$. Taking the involution, $\norm{\st{a}} \leqslant \norm{a}$.
	\item $2)$, $\norm{a\st{a}} = \norm{\st{(\st{a})}} = \norm{\st{a}}^{2} = \norm{a}^{2}$.
	\item For $3)$, let $\alpha$ be the supremum, then $\alpha \leqslant \norm{a}$. $a = 0$ is clearly true. For $a \neq 0$, let $x = \st{a} / \norm{a}$. Thus $\alpha \geqslant \norm{a}$.
\end{proof}

If a \Cs $\A$ is without the identity, we can use same method of the Banach algebra to extend it to a unit \Cs $\tilde{\A}$. The only thing we need to prove is the identity. And this can be obtained the result in above proposition. Therefore, we always assume a \Cs is with the identity.

\begin{defn}
	Let $\A$ be a \Cs and $a \in \A$.
	\begin{enumerate}[label=\arabic*)]
		\item $a$ is self-adjoint if $a = \st{a}$.
		\item $a$ is normal if $a\st{a} = \st{a}a$.
		\item $a$ is unitary if $a\st{a}=\st{a}a=1$.
		\item $a$ is a projection if $a$ is self-adjoint and $a=a^{2}$.
	\end{enumerate}
\end{defn}

Then we can see the algebraic strucuture on a \Cs completely determine its norm topology.

\begin{thm}
	Let $\A$ be a \Cs and $a \in \A$. If $a$ is self-adjoint, then
	\begin{equation*}
		r(a) = \norm{a}
	\end{equation*}
\end{thm}
\begin{proof}
	Since $a$ is sef-sdjoint,
	\begin{equation*}
		\norm{a}^{2} = \norm{\st{a}a} = \norm{a^{2}}
	\end{equation*}
	Thus by induction, we have $\norm{a}^{2n} = \norm{a^{2n}}$. Then
	\begin{equation*}
		r(a) = \lim_{n \sto \infty} \norm{a^{n}}^{\frac{1}{n}} = \lim_{n \sto \infty} \norm{a^{2n}}^{\frac{1}{2n}} = \norm{a} \qedhere
	\end{equation*}
\end{proof}
\begin{rem}
	For any $b \in \A$, we know $\st{b}b$ is self-adjoint,
	\begin{equation*}
		r(\st{b}b) = \norm{\st{b}b} = \norm{b}^{2}
	\end{equation*}
	Thus, the norm in a \Cs is completely determined by the spectral radius, which is totally an algebraic trait.
\end{rem}

Now, we can see how the algebraic property influences the topological structure.

\begin{prop} \label{prop8}
	Let $\rho \colon \A \sto \B$ be a $*$-homomorphsim between two $C^{*}$-algebras.
	\begin{enumerate}[label=\arabic*)]
		\item $\rho$ is continuous, and moreover $\norm{\rho(a)} \leqslant \norm{a}$.
		\item If $\rho$ is a $*$-isomorphism, then $\rho$ is an isometry.
	\end{enumerate}
\end{prop}
\begin{proof}
	$2)$ is the direct corollary from $1)$. For $1)$, clearly $\sigma(\rho(a)) \subset \sigma(a)$, thus
	\begin{equation*}
		\norm{\rho(a)}^{2} = r(\rho(\st{a}a)) \leqslant r(\st{a}a) = \norm{a}^{2} \qedhere
	\end{equation*}
\end{proof}

Let $\Rea{\A}$ denote the set of all self-adjoint elements in a \Cs $\A$. Then, for any $a \in \A$, there are $x,y \in \Rea{\A}$, s.t.
\begin{equation*}
	a = x + iy, \text{ where } x = \frac{a + \st{a}}{2}, y = \frac{a-\st{a}}{2i}
\end{equation*}
Therefore, any element in a \Cs $\A$ can be combined by two self-adjoint elements. And the self-adjoint element play a important role in the algebraic structure of a \Cs. 

\begin{prop}
	If $h \colon \A \sto \C$ is an algebraic homomorphis on a \Cs $\A$. 
	\begin{enumerate}[label=\arabic*)]
		\item If $a \in \Rea{\A}$, $h(a) \in \R$.
		\item For any $a \in \A$, $h(\st{a})=\clo{h(a)}$.
		\item $h(\st{a}a) \geqslant 0$ $\forall~ a \in \A$.
		\item If $u \in \A$ is a unitary, then $\abs{u} = 1$.
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, let $h(a) = \alpha +i \beta$ for $\alpha,\beta \in \R$ and $\Cg{a+it}$ be the \Cs generated by $a+it$ and $1$, which is abelian. Therefore, $\norm{h}_{\Cg{a+it}} = 1$ by \textbf{Proposition} \ref{prop5} in the subsection \textbf{2.1.4}. Then we have
	\begin{eqnarray*}
		\abs{h(a+it)} &\leqslant& \norm{a+it}^{2} \\
		&=& \norm{\st{(a+it)}(a+it)} \\
		&=& \norm{a^{2}+t^{2}} \\
		&\leqslant& \norm{a}^{2}+t^2
	\end{eqnarray*}
	i.e.
	\begin{eqnarray*}
		\norm{a}^{2}+t^2 &\geqslant& \abs{\alpha +i(t+\beta)}^2 \\
		&=& \alpha^2 + (\beta+t)^2 \\
		&=& \alpha^2 + \beta^2 +2 \beta t + t^2
	\end{eqnarray*}
	Therefore, for any $t \in \R$, $\norm{a}^2 \geqslant \alpha^2 + \beta^2 +2 \beta t$. Thus, $\beta = 0$. \\
	$2)$ and $3)$ and $4)$ is the direct results from $1)$.
\end{proof}

\begin{cor}
	If $a \in \Rea{A}$, then $\sigma(a) \subset \R$.
\end{cor}
\begin{proof}
	Let $\Cg(a)$ be the \Cs generated by $1$ and $a$. Thus $\Cg(a)$ is abelian. Then by \textbf{Proposition} \ref{prop6} in the subsection \textbf{2.1.4}, 
	\begin{equation*}
		\sigma_{\Cg{a}}(a) = \{~ h(a) \colon h \in \Sigma(\alg{A}) ~\} \subset \R
	\end{equation*} 
	And by the $Corollary$ \ref{cor5} in the subsection \textbf{2.1.2},
	\begin{equation*}
		\sigma(a) = \sigma_{\Cg{a}}(a) \subset \R
	\end{equation*}
\end{proof}

And the spectrum of a element in a \Cs has better property.

\begin{thm}
	If $\B$ is a $C^{*}$-subalgebra of a \Cs $\A$ and $b \in \B$, then
	\begin{equation*}
		\sigma_{\B}(b) = \sigma_{\A}(b)
	\end{equation*}
\end{thm} 
\begin{proof}
	It suffices to show that if $b$ is invertible in $\A$ with the inverse $x$, then $x \in \B$. Then $(a^{*}a)(xx^{*})=1$. Since $a^{*}a \in \B$ and by above corollary, we know $xx^{*} \in \B$. But $x = (x\st{x})\st{a}$, thus $x \in \B$.
\end{proof}

\subsection{Abelian \texorpdfstring{$C^{*}$-Algebras}{C*-Algebras}}

The abelian \Cs is firstly an ablian Banach algebra, thus all results in the subsection \ref{sec2} can be applied to it. But since the involution and the related norm provide more information, we can have better results than the general abelian Banach algebra has. Firsly, we strengthen the \textbf{Theorem} \ref{thm5} in subsection \textbf{2.1.4}.

\begin{thm}
	If $\A$ is an abelian \Cs, then the Gelfand transform $\Gamma \colon \A \sto C(\Sigma(\A))$ is an isometric $*$-isomorphism.
\end{thm}
\begin{proof}
	Firstly, $\Gamma$ is a $*$-homormophism, since the result in \textbf{Theorem} \ref{thm5} and
	\begin{equation*}
		\Gamma(\st{a})(h) = h(\st{a}) = \clo{h(a)} = \clo{\Gamma(a)}(h)
	\end{equation*}
	Now, we can easily see $\Gamma$ is an isometry by $4)$ in the \textbf{Theorem} \ref{thm5},
	\begin{equation*}
		\norm{\hat{a}}_{\infty}^{2} = \norm{\hat{\st{a}a}}_{\infty} = r(\st{a}a) = \norm{a}^2
	\end{equation*}
	Finally, we need to check $\Gamma$ is surjective. It is because $\Gamma(\A)$ is a closed subalgebra of $C(\Sigma(\A))$, which is closed under the complex conjugate and separates points in $\Sigma(\A)$. Then by the Stone-Weierstrass Theorem $\Gamma(\A)=C(\Sigma(\A))$
\end{proof}

We know if $\A = \Cg{a}$ for some normal element $a$, then $\A$ is an abelian \Cs. In fact, 
\begin{equation*}
	\A = \clo{\{~p(a,\st{a}) \colon p(z,\clo{z}) \text{ is a polynomial} ~\}}
\end{equation*}

Then, we can modify the result in the \textbf{Propostion} \ref{prop7} in subsection \textbf{2.1.4}.

\begin{thm}
	Let $\A = \Cg{a}$ for some normal element $a$. Then there is a unique isometric $*$-isomorphism $\rho \colon \A \sto C(\sigma(a))$.
\end{thm}
\begin{proof}
	Firstly, we have a similar homeomorphism
	\begin{center}
		\begin{tabular}{l c c l}
			$\tau \colon$ & $\Sigma(\A)$ & $\longrightarrow$ & $\sigma(a)$ \\
			~ & $h$ & $\longmapsto$ & $h(a)$
		\end{tabular}
	\end{center}
	Then $\rho(x) = \Gamma(x) \circ \tau^{-1}$ is indeed an isometric $*$-isomorphism by the property of Gelfand transform. And moreover, by the result of \textbf{Propostion} \ref{prop7}, for any $z \in \sigma(a)$, $z = h(a)$ for some $h \in \Sigma(\A)$
	\begin{eqnarray*}
		\rho(p(a,\st{a}))(z) &=& \rho(p(a,\st{a}))(h(a)) = \Gamma(p(a,\st{a})) \circ \tau^{-1} (h(a)) \\
		&=& \Gamma(p(a,\st{a}))(h) = h(p(a,\st{a})) \\
		&=& p(h(a), h(\st{a})) = p(h(a), \clo{h(a)}) \\
		&=& p(z,\clo(z))
	\end{eqnarray*}
	That means that $\rho$ maps the polynomials in $\A$ to polynomails in $\sigma(a)$. Therefore, $\rho$ is unique.
\end{proof}

By the Riesz Functional Calculus, we have the map $f \mapsto f(a)$ from $\hol{(a)}$ to $\A$ for a \Cs $\A$ and any element $a \in \A$. Now, we can extend this definition a $C(\sigma(a))$ by above $\rho$, but we need $a$ is normal, then
\begin{center}
	\begin{tabular}{l c c l}
		$\rho^{-1} \colon$ & $C(\sigma(a))$ & $\longrightarrow$ & $\Cg{a}$ \\
		~ & $f$ & $\longmapsto$ & $f(a)$
	\end{tabular}
\end{center}
defined above is an isometric isomorphism and $\rho^{-1}$ maps
\begin{center}
	\begin{tabular}{r @{$~\longmapsto$~} l}
		$1$ & $1$ \\
		$z$ & $a$ \\
		$\clo{z}$ & $\st{a}$ \\
		$z^{-1}$ & $a^{-1}$\\
		$p(z,\clo{z})$ & $p(a,\st{a})$ 
	\end{tabular}
\end{center}

Therefore, this map is unique and it is clearly the extension of the Riesz Functional Calculus, called Continuous Functional Calculus. Like the Riesz Functional Calculus, there is also a Spectral Theorem.
\begin{thm}[Spectral Theorem]
	Let $\A$ be a \Cs and $a \in \A$ be a normal element, then for $f \in C(\sigma(a))$, 
	\begin{equation*}
		\sigma(f(a)) = f(\sigma(a))
	\end{equation*}
\end{thm}
\begin{proof}
	For some compact space $X$ and $f \in C(X)$, then $C(X)$ with the supremum norm is a \Cs and $\sigma(f) = \ran{f}$. Then since $f \mapsto f(a)$ is a $*$-isomorphism, 
	\begin{equation*}
		\sigma(f(a)) = \sigma_{C(\sigma(a))}(f) = \ran{f} = f(\sigma(a)) \qedhere
	\end{equation*}
\end{proof}


There is an important example.
\begin{exam} 
	Let $\mu$ be a compactly supported, regular Borel measure on $\C$ and ($X,\Omega,\mu$) be the measure space. For each $\pi \in \lfs{\infty}(\mu)$, we define the map
	\begin{center}
		\begin{tabular}{l c c l}
			$M_{\phi} \colon$ & $\lfs{2}(\mu)$ & $\longrightarrow$ & $\lfs{2}(\mu)$ \\
			~ & $f(z)$ & $\longmapsto$ & $\phi(z)f(z)$
		\end{tabular} 
	\end{center}
	Then clearly $M_{\phi}$ is in $\fml{B}(\lfs{2}(\mu))$.
	\begin{enumerate}[label=\arabic*)]
		\item $\st{(M_{\phi})} = M_{\clo{\phi}}$ and $M_{\phi}$ is a normal element in $\fml{B}(\lfs{2}(\mu))$.
		\item $\phi \mapsto M_{\phi}$ is a $*$-homomorphism from $\lfs{\infty}(\mu)$ to $\lfs{2}(\mu)$.
		\item $\norm{M_{\phi}} = \norm{\phi}_{\infty}$.
		\item $\sigma(M_{\phi})= \bigcap\{\clo{\phi(U)} \colon U \in \Omega ~\&~ \mu(X \backslash U) = 0\}$.
		\item If $f \in C(\sigma(M_{\phi}))$, then $f(M_{\phi}) = M_{f \circ \phi}$.
	\end{enumerate}
	If $\phi(z) = z$, we set denote $N_{\mu} = M_{\phi}$ and in fact, $\sigma(N_{\mu}) = \supp{\mu}$.
\end{exam}


\subsection{Positive Elements and Positive Functionals}

We have known that self-adjoint elements play a important role in a \Cs $\A$. The self-adjoint element $a$ in $\A$ is like the real number in $\C$, and the relationship between them can be revealed by the fact $a \in \Rea{\A}$ if and only if $\sigma(a) \subset \R$. The converse is obtained by the Continuous Functional Calculus. In fact, Continuous functional calculus can provide more relation between the element in $\A$ and the elment in $\C$, like positivity.

\begin{defn}
	Let $\A$ be a \Cs and $a \in \Rea{\A}$. Then $a$ is called a positive element if and only if $\sigma(a) \subset \R^{+}$, denoted by $a \geqslant 0$. And let $\A_{+}$ be the set of all positive elements.
\end{defn}

This definition is nature by above mention, but it may not be very explicit. So we need to show more direct equivalent definitions of positive elements.

\begin{thm}
	Let $\A$ be a \Cs. Then the following statements are equivalent.
	\begin{enumerate}[label=\arabic*)]
		\item $a \geqslant 0$.
		\item $a = b^2$ for some $b \geqslant 0$.
		\item $a \in \Rea{\A}$ and $\norm{t - a} \leqslant 0$ for all $t \geqslant \norm{a}$.
		\item $a \in \Rea{\A}$ and $\norm{t - a} \leqslant 0$ for some $t \geqslant \norm{a}$
	\end{enumerate}
\end{thm}
\begin{proof}
	All of these can be done by the functional calculus. And our goal is to find some vilid functions in $C(\sigma(a))$ to complete these.
	\item $1) \Rightarrow 2)$ Let $f(x) = \sqrt{x}$ in $C(\sigma(a))$ and since $\sigma(a) \subset \R^{+}$, $f$ is well-defined. Let $b = f(a)$. Then, we have $a = b^{2}$. And by Spectral Theorem, $\sigma(b) = \sigma(f(a)) \subset \R{+}$.
	\item $2) \Rightarrow 3)$ Let $f(x) = x^2$ defined on $\sigma(b)$, then $a = f(b)$ and $\norm{a} = \norm{f}_{\infty}$. By this condition, $f(x) \geqslant 0$. Thus $\sigma(a) = f(\sigma(b)) \subset \R^{+}$.
	\item $3) \Rightarrow 4)$ It is trivial.
	\item $4) \Rightarrow 1)$ Let $f(x) = x$ defined on $\sigma(a) \subset \R$. Then this condition means 
	\begin{equation*}
		\norm{t-f}_{\infty} = \norm{t-f(a)} =\norm{t-a} \leqslant t
	\end{equation*}
	for some $t \geqslant \norm{a} = \norm{f}_{\infty}$. Therefore, $f(x) \geqslant 0$ for all $x \in \sigma(a)$. Thus $\sigma(a) = f(\sigma(a)) \subset \R^{+}$.
\end{proof}

Like the fact that any element in a \Cs can be combined by two self-ajoint elements, any self-adjoint element can be combined by two positive elements.

\begin{prop}
	Let $\A$ be a \Cs. If $a \in \Rea{\A}$, then there are unique $u,v \in \R^{+}$, s.t.
	\begin{equation*}
		a = u - v ~~\&~~ uv = vu = 0
	\end{equation*}
\end{prop}
\begin{proof}
	Let $f(x) = \max{x,0}$ and $g(x) = - \min{x,0}$. Then $f,g \in C(\sigma(a))$ and $f(x)-g(x)=x$ and $f(x)g(x)=0$. Then $u = f(a)$ and $v = g(a)$ satisfy above conditions.\\
	If $a=u_1-v_1$, then we can know $\Cg(a,u,v,u_1,v_1)$ is an abelian \Cs, thus for some compact space $X$, $\Cg(a,u,v,u_1,v_1) \cong C(X)$. And this uniqueness can be proved in a continuous function space.
\end{proof}

\begin{cor}
	Let $\A$ be a \Cs. Then $\A_{+}$ is a cone.
\end{cor}
\begin{proof}
	Let $\{a_n\} \subset \A_{+}$ be a sequence s.t. $a_n \sto a$. Then by above proposition, $\norm{a_n-\norm{a_n}} \leqslant \norm{a_n}$. Taking norm limit, 
	$\norm{a-\norm{a}} \leqslant \norm{a}$, thus $a \in \A_{+}$.\\
	Clearly, $\alpha \A_{+} \subset \A_{+}$ for any $\alpha >0$. For $a, b \in \A$, we can assume that $\norm{a} \leqslant 1$ and $\norm{b} \leqslant 1$, then
	\begin{equation*}
		\norm{1-\frac{1}{2}(a+b)} = \frac{1}{2}\norm{(1-a)+(1-b)} \leqslant 1
	\end{equation*}
	Thus $\frac{1}{2}(a+b) \in \A_{+}$, i.e. $a+b \in \A_{+}$.
\end{proof}

Then, we can build an order on $\Rea{\A}$ by defining $a \leqslant b \Leftrightarrow b-a \in \A_{+}$. And moreover, let $\A_{-} = - \A_{+}$, then $\A_{-} \bigcap \A_{+} = \{0\}$. There are other properties of positivity.

\begin{prop}
	Let $\A$ be a \Cs.
	\begin{enumerate}[label=\arabic*)]
		\item If $a \geqslant 0$, then there is a unique $b \geqslant 0$ s.t. $a = b^n$.
		\item If $a \in \A$, then $\st{a}a \in \A_{+}$.
		\item If $a \leqslant b$ in $\Rea{\A}$, then $\st{c}ac \leqslant \st{c}bc$ for any $c \in \A$.
		\item For any $a \in \Rea{\A}$, $-\norm{a} \leqslant a \leqslant \norm{a}$ and if $a \in \A$, $0 \leqslant \st{a}a \leqslant \norm{a}^2$.
		\item If $0 \leqslant a \leqslant b$, then $b^{-1} \leqslant a^{-1}$.
		\item For any $a \in \A$, we define $\abs{a} = \sqrt{\st{a}a}$, then $\abs{a} = a_{+}+a_{-}$.
		\item If $0 \leqslant a \leqslant b \in \A$, then $\norm{a} \leqslant \norm{b}$.
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, let $f(x)= \sqrt[n]{x}$ defined on $\sigma(a) \subset \R$, then $b=f(a)$ sastisfying $ a = b^{n}$.
	\item For $2)$, let $b = \st{a}a = b_{+} - b_{-}$ and $c = \sqrt{b_{+}}$  and $d=ac$. Since $\st{d}d = b_{-}^2 \in \A_{+}$, $\st{d}d \in \A_{-}$. Let $d = x + iy$, then $d\st{d} + \st{d}d = 2(x^2+y^2) \in \A_{+}$. Thus
	\begin{equation*}
		d\st{d} = d\st{d} + \st{d}d -\st{d}d \in \A_{+}
	\end{equation*}
	By the fact that $\sigma(d\st{d})\bigcup\{0\} = \sigma(\st{d}d)\bigcup\{0\}$, $b_{-}^2 = -\st{d}d =0$. Therefore, $b = \st{a}a \in \A_{+}$.
	\item For $3)$, let $d = \sqrt{b-a}$, then 
	\begin{equation*}
		\st{c}bc - \st{c}ac = \st{c}(b-a)c = \st{c}\st{d}dc = \st{(dc)}dc \in \A_{+}
 	\end{equation*}
 	\item For $4)$, if $x \in \sigma(a)$, $\abs{x} \leqslant \norm{a}$. Therefore, $f(x) = \norm{a}-x$ and $g(x) = \norm{a}+x$ are positive on $\sigma(a)$.
 	\item For $5)$, since $0 \leqslant a \leqslant b$,
 	\begin{equation*}
 		1-b^{-\frac{1}{2}}ab^{-\frac{1}{2}} = b^{-\frac{1}{2}}(b-a)b^{-\frac{1}{2}} \geqslant 0
 	\end{equation*}
 	i.e. $\st{(a^{\frac{1}{2}} b^{-\frac{1}{2}})}(a^{\frac{1}{2}} b^{-\frac{1}{2}}) \leqslant 1$, therefore $\norm{a^{\frac{1}{2}} b^{-\frac{1}{2}}} \leqslant 1$ by functional calculus as similar as $4)$. And thus $1 \geqslant (a^{\frac{1}{2}} b^{-\frac{1}{2}})\st{(a^{\frac{1}{2}} b^{-\frac{1}{2}})} = a^{\frac{1}{2}}b^{-1}a^{\frac{1}{2}}$. Therefore, $a^{-1}=a^{-\frac{1}{2}}1a^{-\frac{1}{2}} \geqslant b^{-1}$.
 	\item $6)$ holds by the functional calculus and the uniqueness is by $1)$.
 	\item For $7)$, $\sigma(a) = \{h(a) \colon h \in \Sigma(\A)\} \subset \R^{+}$ and $\sigma(b) = \{h(b) \colon h \in \Sigma(\A)\} \subset \R^{+}$ and $\sigma(b-a) = \{h(b-a) \colon h \in \Sigma(\A)\} \subset \R^{+}$, therefore $h(b) \geqslant h(a) \geqslant 0$ for any $h \in \Sigma(\A)$. That means $r(b) \geqslant r(a)$, i.e. $\norm{b} \geqslant \norm{a}$.
\end{proof}

\subsection{Approximate Identities}

When we research the proper ideal of an algebra, this ideal does not contain the identity. So for the ideal of a $\st{C}$-algebra, we want to find some element has similar property as the identity has in the ideal.

\begin{defn}
	Let $\A$ be a \Cs and $\{e_i\}$ be a net in $\A$ s.t.
	\begin{enumerate}[label=\arabic*)]
		\item $0 \leqslant e_i \leqslant 1$ for all $i$,
		\item $e_i \leqslant e_j$ for $i \leqslant j$,
		\item $\lim_{i} ae_i = \lim_{i} e_ia = a$ for any $a \in \A$,
	\end{enumerate}
	Then $\{e_i\}$ is called an approximate identity for $\A$.
\end{defn}

\begin{thm}
	Every \Cs $\A$ has an approximate identity.
\end{thm}
\begin{proof}
	Firstly, let $\Lambda = \{e \in \A_{+} \colon e < 1\}$. We can check $\Lambda$ is indeed a direct set with respect to $\leqslant$. Define two functions as
	\begin{eqnarray*}
		f(t) &=& \frac{t}{1-t},~ \forall~ t \in [0,1),\\
		g(t) &=& \frac{t}{1+t} = 1 - \frac{1}{1+t},~ \forall~ t \in [0,\infty).
	\end{eqnarray*}
	In fact, $g(f(t))=t$. Then for any $a,b \in \Lambda$, let $y=f(a)+f(b)$ and $c = g(y)$. And since $\norm{g}_{\infty} < 1$, $c \in \Lambda$. The fact that $x=f(a) \leqslant y$ implies $1+x \leqslant 1+y$. Then $(1+x)^{-1} \geqslant (1+y)^{-1}$.
	\begin{equation*}
		a = g(f(a)) = g(x) = 1 - (1+x)^{-1} \leqslant 1-(1+y)^{-1} =c
	\end{equation*}
	Similarly, $b \leqslant c$. Therefore, $\Lambda$ is direct.
	\item If $a \in \A_{+}$, let $e_n=g(na) \in \Lambda$. Define
	\begin{equation*}
		h(t) = t^2(1-g(nt)) = \frac{t^2}{1+nt} \leqslant \frac{t}{n}
	\end{equation*}
	Thus $h(a)= a^2(1-g(na)) = a(1-e_n)a$, that means
	\begin{equation*}
		\norm{a(1-e_n)a} = \norm{h}_{\infty} \leqslant \frac{\norm{a}}{n}
	\end{equation*}
	For any $\varepsilon > 0$, we can choose a $N$, s.t. for $n > N$, $\norm{a(1-e_n)a} < \varepsilon$. Moreover, since for $0 \leqslant d \leqslant b \leqslant 1 \in \A$, $\st{c}(1-b)c \leqslant \st{c}(1-d)c$ for any $c \in \A$. Therefore, 
	\begin{equation*}
		\norm{\st{c}(1-b)c} \leqslant \norm{\st{c}(1-d)c}
	\end{equation*}
	And combining above mention and the fact for $0 \leqslant d \leqslant b \leqslant 1 \in \A$,
	\begin{eqnarray*}
		\norm{c-dc}^2 &\leqslant& \norm{\st{c}(1-d)c} \\
		\norm{c-cd}^2 &\leqslant& \norm{\st{c}(1-d)c}
	\end{eqnarray*}
	implies for $e \geqslant e_N$, 
	\begin{eqnarray*}
		\norm{a-ea}^2 &<& \varepsilon \\
		\norm{a-ae}^2 &<& \varepsilon
	\end{eqnarray*}
	Therefore, 
	\begin{equation*}
		\lim_{i} ae_i = \lim_{i} e_ia = a,~~\forall~~a \in \A 
	\end{equation*}
	For arbitrary $a \in \A$, $a$ can be write as the linear combination of four positive elements.
\end{proof}
\begin{rem}
	The result that $\Lambda$ is direct is also true for $\A$ without the identity, since $g(0)=f(0)=0$, which means $x, y, c \in \A$. And if $\A$ is separable, we can find a sequential approximate identity in its countable dense subset. Moreover, this sequential approximate identity can apply in whole $\A$.
\end{rem}

Then we can use the approximate identity to get some interesting results. First, we need a lemma.

\begin{lem}
	If $\A$ is a \Cs and $x,y \in \A$, $a \in \A_{+}$ s.t. $\st{x}x \leqslant a^{\alpha}$ and $\st{y}y \leqslant a^{\beta}$ for some positive scalars $\alpha$ and $\beta$ with $\alpha + \beta > 1$, then the sequence $u_n = x(n^{-1}+a)^{-\frac{1}{2}}$y converges to a $u \in \A$ with $\norm{u} \leqslant \norm{a^{\frac{1}{2}(\alpha+\beta-1)}}$.
\end{lem}
\begin{proof}
	Let $d_nm = (n^{-1}+a)^{-\frac{1}{2}}-(m^{-1}+a)^{-\frac{1}{2}}$.
	\begin{eqnarray*}
		\norm{u_n-u_m}^2 &=& \norm{xd_nmy}^2 = \norm{\st{y}d_nm\st{x}xd_nmy} \\
		&\leqslant& \norm{a^{\frac{\alpha}{2}}d_nmy}^2 = \norm{a^{\frac{\alpha}{2}}d_nm\st{y}yd_nma^{\frac{\alpha}{2}}} \\
		&\leqslant& \norm{a^{\frac{\alpha}{2}}d_nm a^{\beta} d_nma^{\frac{\alpha}{2}}} \\
		&=& \norm{d_nm a^{\frac{\alpha+\beta}{2}}}^2
	\end{eqnarray*}
	Since $f_n(t) = (n^{-1}+t)t^{\frac{\alpha+\beta}{2}}$ is an increasing positive sequence, $d_n=(n^{-1}+a)a^{\frac{\alpha+\beta}{2}}$ is an increasing positive sequence in $\A_{+}$. By Dini's Theorem, since $\sigma(a)$ is compact, there is a continuous fuction $f$ s.t. $f_n \sto f$ uniformly. Let $d = f(a)$, thus $d_n \sto d$ in norm. Thus $\{u_n\}$ is Cauchy and there exists $u = \lim_{n \sto \infty} u_n$.
	\begin{equation*}
		\norm{u_n} = \norm{x(n^{-1}+a)^{-\frac{1}{2}}} \leqslant \norm{(n^{-1}+a)a^{\frac{\alpha+\beta}{2}}} \leqslant \norm{a^{\frac{1}{2}(\alpha+\beta-1)}} \qedhere
	\end{equation*}
\end{proof}

\begin{prop}
	If $\A$ is a \Cs and $a \in \A{+}$ and $x \in \A$ with $\st{x}x \leqslant a$, and $0<\alpha<\frac{1}{2}$, then there exists $u \in \A$ with $\norm{u} \leqslant \norm{a^{\frac{1}{2}-\alpha}}$ and $x=ua^{\alpha}$.
\end{prop}
\begin{proof}
	Let $u_n=x(n^{-1}+a)^{-\frac{1}{2}}a^{\frac{1}{2}-\alpha}$. By above lemma, $u_n \sto u$ with $\norm{u} \leqslant \norm{a^{\frac{1}{2}-\alpha}}$. We use similar prove as above lemma, 
	\begin{eqnarray*}
		\norm{x-u_na^{\alpha}}^2 &=& \norm{x(1-(n^{-1}+a)^{-\frac{1}{2}}a^{\frac{1}{2}})}^2 \\
		&\leqslant& \norm{(1-(n^{-1}+a)^{-\frac{1}{2}}a^{\frac{1}{2}})a(1-(n^{-1}+a)^{-\frac{1}{2}}a^{\frac{1}{2}})} \\ 
		&=& \norm{a^{\frac{1}{2}}(1-(n^{-1}+a)^{-\frac{1}{2}}a^{\frac{1}{2}})}^2 \\
		&=& \norm{a^{\frac{1}{2}}-(n^{-1}+a)^{-\frac{1}{2}}a}
	\end{eqnarray*}
	By the Dini's Theorem, $(n^{-1}+a)^{-\frac{1}{2}}a \sto a$ in norm. Therefore, $u_na^{\alpha} \sto a$ i.e. $a = ua^{\alpha}$.
\end{proof}
\begin{cor}
	If $\A$ is a \Cs and $x \in \A$ and $0 < \beta <1$, then there is a $u \in \A$ s.t.
	\begin{equation*}
		x = u\abs{x}^{\beta}	
	\end{equation*}
\end{cor}

\subsection{Ideals and Quotients}

Firstly, there are two easy results of closed ideal in a $\st{C}$-algebra.

\begin{prop}
	Let $\A$ be a $\st{C}$-algebra.
	\begin{enumerate}[label=\arabic*)]
		\item If $\I$ is a closed left or right ideal of $\A$, $a \in \I$ with $a=\st{a}$, then for $f \in C(\sigma(a))$ with $f(0)=0$, $f(a) \in \A$.
		\item If $\I$ is a closed ideal, then $a \in \I$ implies $\st{a} \in \A$.
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, if $\I$ is proper, $0 \in \sigma(a)$. Then $f(0) = 0 and \sigma(a) \subset \R$, $f$ can be approximated by a sequence of polynomials $p_n$ with $p_n(0) = 0$. Therefore, $p_n(a) \in \I$ and by the fact that $\I$ is closed, $f(a) \in \I$.
	\item For $a \in \I$, by the corollary in above subsection, we know there is a $u \in \A$ s.t. $a=u\abs{a}^{\frac{1}{2}}$. By $1)$, $\abs{a}^{\frac{1}{2}} \in \I$. Therefor,
	\begin{equation*}
		\st{a} = \abs{a}^{\frac{1}{2}} u \in \I \qedhere
	\end{equation*}
\end{proof}

\begin{defn}
	If $\A$ is a \Cs and $\B$ is a $*$-subalgebra of $\A$, then $\B$ is called hereditary if for any $b \in \B_{+}$ and $x \in \A$ with $0 \leqslant x \leqslant b$, $x \in \B$.
\end{defn}

Now, we can give more profound properties of the closed left ideals.

\begin{thm} \label{thm6}
	Let $\A$ be a $\st{C}$-algebra.
	\begin{enumerate}[label=\arabic*)]
		\item If $\I$ is a closed left ideal of $\A$ and $\B = \I \bigcap \st{\I}$, then $\B$ is a hereditary subalgebra of $\A$.
		\item If $\B$ is a hereditary subalgebra of $\A$ and $\I = \{x\in \A \colon \st{x}x \in \B\}$, then $\I$ is a closed left ideal of $\A$.
		\item If $\I$ is a closed left ideal of $\A$ and $\B = \I \bigcap \st{\I}$, then $\I = \{x\in \A \colon \st{x}x \in \B\}$.
		\item If $\B$ is a hereditary subalgebra of $\A$ and $\I = \{x\in \A \colon \st{x}x \in \B\}$, then $\B = \I \bigcap \st{\I}$.
	\end{enumerate}
\end{thm}
\begin{proof}
	For $1)$, clearly, $\B$ is a $\st{C}$-algebra. Let $0 \leqslant x \leqslant b$ for some $b \in \B_{+}$. Since $x^{\frac{1}{2}}x^{\frac{1}{2}} \leqslant b$ there is a $u \in \A$, s.t. $x^{\frac{1}{2}} = u b^{\frac{1}{3}}$. But $b^{\frac{1}{3}} \in \B_{+} \subset \I$. Therefore, $x^{\frac{1}{2}} \in \I$ and thus $x \in \I$. Since $x$ is self-adjoint, $x \in \B$.
	\item For $2)$, if $x \in \I$ and $a \in \A$, then 
	\begin{equation*}
		\st{(ax)}ax = \st{x}\st{a}ax \leqslant \norm{a}^2 \st{x}x \in \B.
	\end{equation*}
	Therefore, $\st{(ax)}ax \in \B$, i.e. $ax \in \I$. If $x,y \in I$, then 
	\begin{equation*}
		\st{(x+y)}x+y \leqslant \st{(x+y)}(x+y)+\st{(x-y)}(x-y) = 2 (\st{x}x+\st{y}y) \in \B
	\end{equation*}
	Thus, $\I$ is a closed left ideal.
	\item For $3)$, if $x \in \A$ and $\st{x}x \in \B$, $\st{x}x \in \I$. Thus $\abs{x}^{\frac{1}{2}} \in \I$ since $\I$ is a closed left ideal. Therefore, $x = u \abs{x}^{\frac{1}{2}} \in \I$. The converse is clearly true.
	\item For $4)$, if $x \in \I_{+}$, then $x^2 \in \B$. So $x = \sqrt{x^2} \in \B_{+}$. Conversely, $x \in \B_{+}$ means $\st{(x^{\frac{1}{2}})}(x^{\frac{1}{2}}) = x \in \B$, $x^{\frac{1}{2}} \in \I_{+}$. Therefore, $\B_{+} = \I_{+}$. Thus, $\B = \I \bigcap \st{\I}$. 
\end{proof}

\begin{thm}
	If $\I$ is a closed ideal of a \Cs $\A$, then the quotient algebra $\A / \I$ with the induced norm and the induced involution, i.e. $\st{a+\I} = \st{a}+\I$ is also a \Cs and the norm can be
	\begin{equation*}
		\norm{a+\I} = \inf{\{~\norm{a-ax} \colon x \in \I_{+}, \norm{x} \leqslant 1~\}}
	\end{equation*}
\end{thm}
\begin{proof}
	Firstly, let $\{e_i\}$ be an approximate identity for $\I$. Since $0 \leqslant e_i \leqslant 1$, if $a \in \A$ and $y \in \I$, $\norm{(a+y)(1-e_i)} \leqslant \norm{a+y}$.
	\begin{eqnarray*}
		\norm{a+y} &\geqslant& \liminf_{i} \norm{(a+y)(1-e_i)} \\
		&=& \liminf_{i} \norm{(a-ae_i)+(y-ye_i)} \\
		&=& \liminf_{i} \norm{(a-ae_i)}
	\end{eqnarray*}
	The converse is clearly true.
	\item The involution defined on the quotient algebra is well-defined and satifies the conditions since $\I$ is self-adjoint. We just need to show the induced norm satisfies the $\st{C}$-identity. For $a \in \A$, we have $\norm{\st{a}+\I} = \norm{a+\I}$, and 
	\begin{eqnarray*}
		\norm{a+\I}^2 &=& \norm{(\st{a}+\I)(a+\I)} \\
		&\leqslant& \norm{\st{a}+\I}\norm{a+\I} \\
		&=& \norm{a+\I}^2
	\end{eqnarray*}
	Conversely,
	\begin{eqnarray*}
		\norm{a+\I}^2 &=& \inf{\{~\norm{a-ax}^2 \colon x \in \I_{+}, \norm{x} \leqslant 1~\}}\\
		&=& \inf{\{~\norm{(1-x)\st{a}a(1-x)} \colon x \in \I_{+}, \norm{x} \leqslant 1~\}}\\
		&\leqslant& \inf{\{~\norm{\st{a}a(1-x)} \colon x \in \I_{+}, \norm{x} \leqslant 1~\}}\\
		&=& \norm{\st{a}a+\I}
	\end{eqnarray*}
	Therefore, $\A / \I$ is indeed a $\st{C}$-algebra.
\end{proof}

Then it can provide a \Cs with some similar results as general rings have. These results can also show us how the algebraic structure in a \Cs affect the topological structure. In my oppion, for researching a \Cs, researching the algebraic structure may be more important.

\begin{cor}
	Let $\A$ and $\mathfrak{C}$ be two $\st{C}$-algebras.
	\begin{enumerate}[label=\arabic*)]
		\item If $\rho \colon \A \sto \mathfrak{C}$ is a $*$-homomorphism, then $\ran{\rho}$ is a \Cs and the induced map $\tilde{\rho} \colon \A / \ker{\rho} \sto \ran{\rho}$ is an $*$-isomorphism.
		\item If $\I$ is a closed ideal of $\A$ and $\B$ is a subalgebra of $\A$, then there is a $*$-isomorphism
		\begin{equation*}
			 \B / (\B \cap \I) \cong (\B+\I) / \I
		\end{equation*}
	\end{enumerate}
\end{cor}
\begin{proof}
	For $1)$, we just need to show $\ran{\rho}$ is closed.\\ Since $\tilde{\rho}$ is a $*$-monomorphism from $\A / \ker{\rho}$ to $\C$, by the result in \textbf{Proposition} \ref{prop8} in the subsection \textbf{2.1.1}, $\rho$ is an isometry. Thus $\ran{\rho}=\rho(\A)$ is closed.
	\item For $2)$, there is a commutative graph like
	\begin{center}
		\begin{tikzcd}
			\B \arrow[r, "i"] \arrow[d, "Q"]
				& \A \arrow[ld, "\pi"] \\
			\A / \I
		\end{tikzcd}
	\end{center}
	$Q=\pi \circ i \colon \B \sto \B / \I$ and thus $\pi^{-1}(Q(\B)) = \B + \I$. By restricting $\pi$ on $\B + \I$, then we have
	\begin{equation*}
		(\B+\I) / \I \cong Q(\B) \cong \B / (\B \cap \I) \qedhere
	\end{equation*}
\end{proof}

\subsection{Positive Functionals and GNS Construction}

We have known that $\oper$ is a $\st{C}$-algebra. In fact, defining the general \Cs is to research the operator algebra. Moreover, by the properties, we can see any \Cs is a $*$-subalgebra of $\oper$ for some $\Hs$. To prove that, we just need to find a faithful representation of the fixed $\st{C}$-algebra. Therefore, the main idea is to construct a representation $(\pi,\Hs)$. How to construct it is a question. But, fortunately, some special functionals can provide us a method.

\begin{defn}
	Let $\A$ be \Cs and $\phi$ is a linear functional on $\A$. $\phi$ is called positive if for any $a \in \A_{+}$, $\phi(a) \leqslant 0$. A positive linear functional $\phi$ is called a state if $\phi(1) = 1$.
\end{defn}
\begin{rem}
	Let $\St_{\A}$ denote the set of all states on $\A$.
\end{rem}

Then there are some properties of positive functionals.

\begin{prop}
	Let $\A$ be a \Cs and $\phi$ be a positive functional.
	\begin{enumerate}[label=\arabic*)]
		\item For any $x,y \in \A$, then
		\begin{equation*}
			\abs{\phi(\st{y}x)} \leqslant \phi(\st{x}x)\phi(\st{y}y)
		\end{equation*}
		\item $\phi$ is bounded and if $\{e_i\}$ is an approximate identity of $\A$, then
		\begin{equation*}
			\norm{\phi} = \lim_{i} \phi(e_i)
		\end{equation*}
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, it can easily check that $<x,y> = \phi(\st{y}x)$ is a semi-inner product, thus by the CBS inequality, above inequality is true.
	\item Assume $\A$ without identity.  If $\phi$ is unbounded, then there is a sequence $\{a_k\} \in \A_{+}$ with $\norm{a_k} \leqslant 1$ s.t. $\phi(a_k) > 2^k$. Let $a = \sum_{k=1}^{\infty} 2^{-k} a_k$. Then
	\begin{equation*}
		\phi(a) \geqslant \phi(\sum_{k=1}^{n} 2^{-k} a_k) > n
	\end{equation*}
	which is a contradiction.
	\begin{equation*}
		\alpha = \sup{\{~\phi(a) \colon a \in \A_{+}, \norm{a} \leqslant 1~\}} < \infty
	\end{equation*} 
	Since any element in $\A$ can be a linear combination of four positive elements, $\norm{\phi} \leqslant 4\alpha$. Therefore, $\phi$ is bounded.\\
	Let $\beta = \lim_{i}\phi(e_i)$. Clearly, $\beta \leqslant \norm{\phi}$. And since for $a \in \A$ with $\norm{a} \leqslant 1$ then $0 \leqslant \st{a}a \leqslant 1$
	\begin{equation*}
		\abs{\phi(a)}^2 = \lim_{i} \abs{\phi(e_ia)}^2 \leqslant \lim_{i}\phi(e_i)\phi(\st{a}a) \leqslant \beta \norm{\phi}
	\end{equation*}	
	\begin{equation*}
		\norm{\phi}^2 \leqslant \beta \norm{\phi}
	\end{equation*}
	i.e. $\norm{\phi} \leqslant \beta$.
\end{proof}
\begin{rem}
	For $2)$, if $\A$ has an identity, then $\norm{\phi} = \phi(1)$. It is because for $a \in \A$ with $\norm{a} \leqslant 1$
	\begin{equation*}
		\abs{\phi(a)}^2 \leqslant \phi(\st{a}a)\phi(1) \leqslant \phi(1)^2
	\end{equation*}
	i.e. $\abs{\phi(a)} \leqslant \phi(1)$.
\end{rem}

In fact, the converse of $2)$ in above proposition is also true.
\begin{prop}
	Let $\A$ be \Cs and $\phi$ is a bounded linear functional with $\norm{\phi} = \phi(1)$, then $\phi \leqslant 0$.
\end{prop}
\begin{proof}
	If $\A=C(X)$ for some compact space $X$, $\phi$ is a measure $\mu$ with $\mu(X)=\norm{\mu}$, then $\mu \geqslant 0$, i.e. $\phi$ is positive. Then for any $\A$, if $a \in \A_{+}$, $\B=\Cg{a} \cong C(\sigma(a))$. Then $\phi|_\B(1) \leqslant \norm{\phi} = \phi(1) = \phi|_\B(1)$, thus $\phi|_\B(a) = \phi(a) \geqslant 0$.
\end{proof}
Using above proposition and the Hahn-Banach Theorem, we can get the corollary.
\begin{cor}
	If $\A$ is a \Cs and $\B$ is a $\st{C}$-subalgebra of $\A$, then every state on $\B$ can extend to $\A$.
\end{cor}	

Now, we can construct the a representation of a $\st{C}$-algebra. A representation $(\pi,\Hs)$ of a \Cs $\A$ is called cyclic if there is a unit cyclic vector $e$ s.t. $\clo{\pi(\A)e} = \Hs$.

\begin{thm}[Gelfand-Naimark-Segal Construction]
	Let $\A$ be a \Cs and $\St_{\A}$ be the coincided state space.
	\begin{enumerate}[label=\arabic*)]
		\item If $\phi \in \St_{\A}$, then there is a cyclic representation $(\pi_{\phi},\Hs_{\phi})$ with the unit cyclic vector $e_{\phi}$ s.t.
		\begin{equation*}
			\phi(a) = \langle \pi_{\phi}(a)e_{\phi},e_{\phi} \rangle ,~~\forall~ a \in \A
		\end{equation*}
		\item If $(\pi,\Hs)$ is a cyclic representation with the unit cyclic vector $e$, then there is a $\phi \in \St_{\A}$ defined as 
		\begin{equation*}
			\phi(a) = \langle \pi(a)e, e \rangle,~~ \text{for}~ a \in \A
		\end{equation*}
		And for the $(\pi_{\phi},\Hs_{\phi})$ defined as above mention, $\pi_{\phi} \cong \pi$.
	\end{enumerate}
\end{thm}
\begin{proof}
	For $1)$, the prove can be completed by several nature steps.
	\begin{enumerate}[label=\arabic*)]
		\item Constructing semi-inner product: Define a semi-inner product $\langle \cdot, \cdot \rangle$ on $\A$ like
		\begin{equation*}
			\langle x,y \rangle = \phi(\st{y}x),~~ \text{for}~ x,y \in \A
		\end{equation*}
		\item Constructing $\Hs_{\phi}$: $\langle \cdot, \cdot \rangle$ is just a semi-inner product on $\A$, thus we need to make it be nondegenerate. The nature method is constructing a equilaten relation or a closed ideal, and then inducing a quotient space. Naturally, we define
		\begin{equation*}
			\B = \{~x \in \A \colon \phi(x) = 0~\}
		\end{equation*}
		Clearly, $\B$ is a hereditary subalgebra. Then by the \textbf{Theorem} \ref{thm6} in the subsection \textbf{2.2.5}, $\B$ can induced a closed left ideal
		\begin{equation*}
			\I = \{~x \in \A \colon \st{x}x \in \B~\} = \{~x \in \A \colon \phi(\st{x}x) = 0~\}
		\end{equation*}
		And define the inner product on $\A / \I$ as
		\begin{equation*}
			\langle x+\I,y+\I \rangle = \phi(\st{y}x)
		\end{equation*}
		Therefore, we can easily check that $\A / \I$ is a inner product space. Then let $\Hs_{\phi}$ be the completion of $\A / \I$.
		\item Constructing $\pi_{\phi}$: Firstly, let $\pi_{\phi}(a)$ be defined on $\A / \I$ for $a \in \A$.
		\begin{center}
		\begin{tabular}{l c c l}
			$\pi_{\phi}(a) \colon$ & $\A / \I$ & $\longrightarrow$ & $\A / \I$ \\
			~ & $x+\I$ & $\longmapsto$ & $ax+\I$
		\end{tabular}
		\end{center}
		But since
		\begin{eqnarray*}
			\norm{ax+\I}^2 &=& \langle ax+\I,ax+\I \rangle = \phi(\st{ax}ax) \\
		 	&\leqslant& \norm{a}^2 \phi(\st{x}x) = \norm{a}^2\norm{x+\I}^2
		\end{eqnarray*}
		$\norm{\pi_{\phi}(a)} \leqslant \norm{a}$. Therefore, $\pi_{\phi}(a)$ can extend to $\Hs_{\phi}$ for any $a \in \A$. $\pi_{\phi} \colon \A \sto \fml{B}(\Hs_{\phi})$ is a representation.
		\item Check the conditions: Let $e_{\phi} = 1+\I$. Then
		\begin{equation*}
			\pi_{\phi}(\A)e_{\phi} = \{~a+\I \colon a \in \A~\} = \A / \I
		\end{equation*}
		Therefore, $\pi_{\phi}$ with $e_{\phi}$ is indeed a cyclic representation of $\A$. And clearly,
		\begin{equation*}
			\langle \pi_{\phi}(a)e_{\phi}, e_{\phi} \rangle = \phi(a)
		\end{equation*}
	\end{enumerate}
	For $2)$, we just need to construct a unitary from $\Hs_{\phi}$ to $\Hs$. By observation, 
	\begin{equation*}
		\langle \pi_{\phi}(a)e_{\phi}, e_{\phi} \rangle =\langle \pi(a)e, e \rangle
	\end{equation*}
	and the facts that $\Hs_{\phi}=\clo{\pi_{\phi}(\A)e_{\phi}}$ and $\Hs=\clo{\pi(\A)e}$, we can find the unitary $U$. Firstly, let $U$ be defined on $\pi_{\phi}(\A)e_{\phi}$ 
	\begin{center}
		\begin{tabular}{l c c l}
			$U \colon$ & $\pi_{\phi}(\A)e_{\phi}$ & $\longrightarrow$ & $\pi(\A)e$ \\
			~ & $\pi_{\phi}(a)e_{\phi}$ & $\longmapsto$ & $\pi(a)e$
		\end{tabular}
	\end{center}
	Since
	\begin{equation*}
		\norm{\pi(a)e}^2 = \langle \pi(a)e, \pi(a)e \rangle = \phi(\st{a}a) = \norm{\pi_{\phi}(a)e_{\phi}}^2
	\end{equation*}
	$U$ can extend to an unitary from $\Hs_{\phi}$ to $\Hs$. And
	\begin{equation*}
		U\pi_{\phi}(a)(\pi_{\phi}(x)e_{\phi}) = U\pi_{\phi}(ax)e_{\phi}=\pi(ax)e = \pi(a)(\pi(x)e) = \pi(a)U(\pi_{\phi}(x)e_{\phi})
	\end{equation*}
	Then $U\pi_{\phi}\st{U} = \pi$, $\pi_{\phi} \cong \pi$.
\end{proof}
\begin{rem}
	In fact, in above theorem, if $\phi$ is a positive functional, the results is also true.
\end{rem}

By above theorem, our faithful representation of a \Cs can not be constructed by a state, since $\pi_{\phi}$ is not injective. But we may choose enough many states to construct a faithful representation. Therefore, we need more properties of states.

\begin{prop}
	If $\A$ is \Cs and $a \in \A$ is self-adjoint, let $\alpha = \min{\sigma(a)}$ and $\alpha = \max{\sigma(a)}$, then
	\begin{equation*}
		[\alpha,\beta]= \{~\phi(a) \colon \phi \in \St_{\A}~\}
	\end{equation*}
\end{prop}
\begin{proof}
	Let $\B = \Cg{a}$. Then $\B = \{f(a) \colon f \in C(\sigma(a))\}$. For $\phi \in \St_{\A}$ and $\phi_0 =\phi|_{\B}$, then there is a measure $\mu$ s.t.
	\begin{equation*}
		\phi(f(a))=\phi_0(f(a)) = \int_{\sigma(a)} f d \mu,~~ \forall~ f \in C(\sigma)
	\end{equation*}
	In particular, $\phi(a) = \int_{\sigma(a)} t d \mu \in [\alpha, \beta]$.\\
	Conversely, if $\alpha \leqslant t_0 \leqslant \beta$, define $\phi_0 \in \St_{\B}$ as
	\begin{equation*}
		\phi_0(f(a)) = \frac{t_0 - \alpha}{\beta-\alpha}f(\alpha)+\frac{\beta - t_0}{\beta-\alpha}f(\alpha)
	\end{equation*}
	Then $\phi_0$ can extend to $\A$, and $t_0 = \phi(\alpha)$.
\end{proof}

By this proposition, we can get an important corollary.

\begin{cor}
	If $\A$ is a \Cs and $a \in \A$ and $\St_{}$ is $wk^{*}$-dense subset of $\St_{\A}$, then
	\begin{equation*}
		\norm{a}^2 = \sup{\{~\phi(\st{a}a) \colon \phi \in \St_{}~\}}
	\end{equation*}
\end{cor}
\begin{rem}
	In fact, we can easily check that $\St_{\A} \subset \st{\A}$ is a $wk^{*}$-compact convex subset. And this corollary is equivalent to saying that $\St_{}$ can seperate the points in $\A_{+}$.
\end{rem}

Now, using this corollary, we can finally construct a faithful representation.

\begin{thm}[Gelfand-Naimark Theorem]
	Every \Cs $\A$ has a faithful representation $(\pi,\Hs)$. Moreover, $\Hs$ is separable if and only if there are countable number of states on $\A$ that can separates points in $\A_{+}$, each of which defines a separable representation. In particular, each separable \Cs has a faithful, separable representation.
\end{thm}
\begin{proof}
	Let $\St_{}$ be $wk^{*}$-dense subset of $\St_{\A}$. Define
	\begin{equation*}
		\Hs = \oplus \{~\Hs_{\phi} \colon \phi \in \St_{}~\}
	\end{equation*} 
	\begin{equation*}
		\pi = \oplus \{~\pi_{\phi} \colon \phi \in \St_{}~\}
	\end{equation*}
	Then we can see
	\begin{eqnarray*}
		\norm{a}^2 &=& \sup \{~\phi(\st{a}a) \colon \phi \in \St_{}~\}\\ 
		&=& \sup \{~\langle \pi_{\phi}(a)e_{\phi},\pi_{\phi}(a)e_{\phi} \rangle \colon \phi \in \St_{}~\} \\
		&=& \sup \{~\norm{\pi_{\phi}(a)e_{\phi}}^2 \colon \phi \in \St_{}~\} \\
		&=&	\norm{\pi(a)e}^2\\
		&\leqslant& \norm{\pi(a)}^2
	\end{eqnarray*}
	And in the GNS Construction, we have seen $\norm{\pi_{\phi}(a)} \leqslant \norm{a}$ for any $\phi \in \St_{\A}$. Therefore,
	\begin{equation*}
		\norm{a} \geqslant \norm{\pi(a)}
	\end{equation*}
	Thus $\norm{\pi(a)} = \norm{a}$ i.e. $(\pi,\Hs)$ is indeed a faithful representation.
	\item If $\Hs$ is separable, let $\{e_n\}$ be the dense subset of $\{h \in \Hs \colon \norm{h} =1\}$. Define $\Hs_n = \clo{\pi(\A)e_n}$ and $\pi_n = \pi|_{\Hs_n}$. Therefore, in above construction,
	\begin{equation*}
		\{(\pi_{\phi},\Hs_{\phi},e_{\phi}) \colon \phi \in \St_{}\}
	\end{equation*}
	can be replaced by
	\begin{equation*}
		\{(\pi_n,\Hs_n,e_n) \colon n \in \N\}
	\end{equation*}
	Then for $a \in \A_{+}$, there exists $b \in \A$ s.t. $a = \st{b}b$, if for $n \in \N$
	\begin{equation}
		0=\phi_n(a) = \langle \pi_n(\st{b}b)e_n,e_n \rangle = \norm{\pi(b)e_n}^2 \tag{$*$}
	\end{equation}
	But $\norm{b} = \sup_{n} \norm{\pi(b)e_n}$, that implies $a = 0$.\\
	Conversely, if $\{\phi_n\}$ is these states, we can use the GNS Construction to get $\{(\pi_n,\Hs_n,e_n) \colon n \in \N\}$. Similarly, we can use direct sum to get the representation $(\pi,\Hs)$. Then by using the $(*)$, we can know this representation is definitely faithful.
	\item Finally, if $\A$ is separable, then the closed unit ball in $\A^{*}$ is $wk^{*}$-compactly metrizable. Therefore, there is a countable $wk^{*}$-dense subset of $\St_{\A}$. Thus by above corollary, this subset can separate the points in $\A_{+}$
\end{proof}
\begin{rem}
	Therefore, any \Cs can be isometrically imbedded in a operator algebra on some Hilbert space. Researching a abstract \Cs is actually researching the $\st{C}$-subalgebra of an operator algebra on some Hilbert space.
\end{rem}






\end{document}
