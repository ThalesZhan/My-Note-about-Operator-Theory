\documentclass[a4paper,11pt]{report}
\usepackage{Mydef}
\title{My Report about Operator Theory}
\author{Zhiyuan~Zhan\\ $<$\href{mailto:thaleszhan@gmail.com}%
            {thaleszhan@gmail.com}$>$}

\begin{document}
\maketitle
\tableofcontents

\chapter{Introduction}

The most of this report is based on the two books, A Course in Functional Analysis and A Course in Operator Theory by John B. Conway. However, I reorgnized the contents under my understanding and added some other materials to help me understand the structure of the knowledge of the fundamental operator theory.

 My understanding of this structure is based on "General-to-special" order. Like, we firstly research the general space, and then by adding more other structure on it, we get a more special space with more interesting properties. Conversely, these properties also revealed the essential traits of the more special space. Then we can strengthen the traits the special space has, thus a more special space is born. Using this order, the appearance of $\st{C}$-algebra and von Neumann algebra is very nature for me.

 Firstly, I have seen the structure of finite dimensional linear space, but how to research the infinite dimensional linear space is a question. Clearly, the algebraic structure cannot provide enough information about the infinite dimension. However, by learning topological spaces, I know that the topology can provide a method to research the infinite sets, thus equipping the infinite dimensional linear space with an appropriate topology is a good ideal. Naturally, this topology should be compatible with the original linear structure. Therefore, topological vector spaces is important, and there are many interesting properties generated by the merge of the topology and the algebra. If the topology of the T.V.S. can be more special, like the pre-"length" of elements is continuous with respect to the topology, then we get a locally convex topological vector space with more interesting properties than the general T.V.S. has. When learning the finite dimensional linear space, I saw the corresponding dual space is very "like" with the original space. But how do these properties change in the infinite dimensional case? The Hahn-Banach Theorem provides an answer.

 Now, the locally convex T.V.S. can be more special. If there is only one seminorm generating the locally convex T.V.S., how can the space become? In order to make the space be Hausdorff, the seminorm need to a norm. Moreover, since completed topological space is more interesting, this special space should be completion. Therefore, we get a Banach space. And then all of above properties the general T.V.S. and locally convex T.V.S. have can be applied to the Banach space and have more powerful form. Moreover, the space consisting of all continuous maps between the Banach spaces can be equipped with more interesting structure, which can also be a Banach space with the induced norm.

 The norm generating a Banach space can be more special. If the norm, which satisfies the Parallelogram Law, can be generated by an inner product, then the Banach space with this inner product is a Hilbert space. Because of this extra inner product structure, the Hilbert space has the Projection Theorem, and thus the dual space is as same as the original space, and thus the the space consisting of all continuous maps between the same Hilbert space can contain the adjoint version of each of them. This space is the operator space.

For researching the operator space, similarly, we can firstly research a more general version. The main difference between the operator space and the Banach space is that the operator space can do multiplication, defined as composition. Moreover, this multiplication is continuous with respect to the norm topology. Therefore, the general version of the operator space is a Banach space with a extra continuous multiplication, then it becomes a Banach algebra. Comparing the Banach space, the Banach algebra has one more algebraic structure, and the invertibility is an important property with respect to this structure. Thus, the appearance of the concept of spectrum is naturally. Besides, the commutative Banach algebra can have an explicit expression. 

Besides, the operator algebra has one more operation than the general Banach algebra have, the involution. And the involution is not only continuous with respect to the norm topology. In fact, it provides an identity. That means the topology is determined by the algebraic structure. Then, the general version is $\st{C}$-algebra, whose topology is completely determined the algebraic structure it has. Because of the strong relation between the topology and the algebra, $\st{C}$-algebra has some similar properties to the complex number system. By the GNS construction, any $\st{C}$-algebra can be embedded in a operator algebra. It is amazing, since the general version of operator algebra is itself. Thus, researching operator algebras is enough.

However, the $\st{C}$-subalgebras of an operator algebra may be too small to contain enough "interesting" elements. Thus, finding a weaker topology and extending the $\st{C}$-algebra to a larger subalgebra are good ideals. But how can we do is? The Continuous Functional Calculus can provide a clue. We have known that the continuous function space on a compact is weakly dense in the bounded Borel function space and the Gelfand transform maps the continuous function space to the operator algebra. So it is natural to find a method of extending the map from the continuous function space to the bounded Borel function space. In general, we should define the operator-valued measure, thus the integral of operator makes sense. Comparing this progress to the progress embedding the continuous function space in the bounded Borel function space, the new topologies we need appeared naturally. That is the weak operator topology and the strong operator topology. Then the new algebra is born, von Neumann algebra. And in fact, these "interesting" elements are projections. And since the norm topology is determined by the algebraic structure, it can also use the algebraic properties to construct von Neumann algebras. Similarly, the structure of an abelian von Neumann algebra may be easier. There is a particular abelian von Neumann algebra, which is generated by the normal operator. By extending the Gelfand transform, the structure of this von Neumann algebra can become concrete. Moreover, any abelian von Neumann algebra has same structure.

From finite rank operators to infinite rank operators, there is a special class of operators, which can be approximated by a sequence of finite rank operators, compact operators. Because of it, compact operators has a lot of properties as similar as finite rank operators, such as the spectrum, the representations and so on. There are also some interesting classes contained in the compact operators, like the trace class. The importance of trace class is that it is the dual space of the operator algebra, and thus it can provide an extra topology on the operator algebra. This topology has some relations with the weak operator topology, and then it can provide a new method to research the von Neumann algebra. By the quotient map, there is a weak version compact operators, the Fredholm operators. So the Fredholm theory appeared. Finally, we have known that any normal operator can be diagonalizable in the finite dimensional case, but in the infinite dimensional case, we need the compact perturbation in order to get similar result. 

For the general von Neumann algebra, combining the $WOT$ and the ultraweak topology, we get more properties than a general $\st{C}$-algebra has, like the structure of the ideals. Moreover, it provides the equivalent condition the simple von Neumann algebra has, which is called factor. We have known that the von Neumann algebra is generated by all of its projections, thus these projections play an important role. By researching the relations of projections and the properties they have, it can classify von Neumann algebras into corresponding classes. In fact, these projections can be classified as abelian ones, non-abelian ones and pure infinite ones, and the corresponding von Neumann algebras are Type \RNum{1}, Type \RNum{2} and \RNum{3}. Type \RNum{1} is easier, but Type \RNum{2} and \RNum{2} do not have trivial example.

\chapter{Topological Vector Spaces and Banach Spaces}

\section{Topological Vector Spaces}
Linear operations, i.e addition and scalar multiplication, provide an algebraic structure on a set, therefore constructing a vector space. In the course, linear algebra, we have learn the algebraic structure of finite dimensional vector spaces. But how to deal with infinite dimensional vector spaces? By learning the topological spaces, we know that the topological structure can give us a method to research properties of infinity. Thus, we need to equip a vector space with an additional topological structure, which should coincide with the algebraic structure. This is the reason why we define the topological vector space.

\subsection{Topological Spaces}
\rule{1mm}{1mm} \textbf{Definition:} First, we define the topological structure on a general set.
\begin{defn}
A topological space $X$~=~($X$, $\mathscr{T}_X$) consists of a set $X$, called the underlying space of $X$, and a family $\mathscr{T}_X$ of subsets of $X$ s.t.
	\begin{enumerate}[label=\arabic*)]
		\item $X, \varnothing \in \mathscr{T}_X$.
		\item if $U_\alpha \in \mathscr{T}_X \ \text{for} \ \alpha \in A$, then $\bigcup_{\alpha \in A}U_\alpha \in \mathscr{T}_X$.
		\item if $U_1, U_2 \in \mathscr{T}_X$, then $U_1 \bigcap U_2 \in \mathscr{T}_X$.
	\end{enumerate}
And, $\mathscr{T}_X$ is called a topology on $X$. The element in $\mathscr{T}_X$ is called open set.
\end{defn}

Thus, the topological structure on a set $X$ is totally determined by the family $\mathscr{T}_X$. In particular, from $2)$, we can simplify $\mathscr{T}_X$. In other words, like the basis of a vector space, there is a "basis" of $\mathscr{T}_X$.

\begin{defn}
If $X$ is a set, a basis for a topology on $X$ is a family $\mathscr{B}$ of subsets of $X$, s.t.
	\begin{enumerate}[label=\arabic*)]
		\item $\forall ~ x \in X,~ \exists ~ B \in \mathscr{B},~\text{s.t.}~ x \in B$.
		\item if $x \in B_1 \bigcap B_2$, where $B_1,~B_2 \in \mathscr{B}$, then there is a $B_3 \in \mathscr{B}$, s.t. $B_3 \subset B_1 \bigcap B_2$.
	\end{enumerate}
\end{defn}

$\mathscr{B}$ can generate a topology $\mathscr{T}_X$ on $X$ by doing infinite times union of elements in $\mathscr{B}$. In fact,
\begin{equation*}
	\mathscr{T}_X~ = ~\{~U \subset X \colon U = \bigcup_{~\alpha \in A}U_\alpha,~U_\alpha \in \mathscr{B}~\},~ \text{where A is any index set.}
\end{equation*}

We can do more on the basis by $3)$.
\begin{defn}
A subbasis of a topology on $X$ is a collection $\mathscr{S}$ of subsets of $X$, whose union is $X$. The topology generated by $\mathscr{S}$ is noted by $\mathscr{T}(\mathscr{S})$.
\end{defn}
In fact, we can generate the basis of $\mathscr{T}(\mathscr{S})$ by $\mathscr{S}$, that is,
\begin{equation*}
	\mathscr{B}~ = ~\{~U \subset X \colon U = \bigcap_{\alpha=1}^{n}U_\alpha,~U_\alpha \in \mathscr{S},~n \in \N~\}
\end{equation*}
Therefore, this basis can generate the conincided topology on $X$.\vspace{0.2in}

\rule{1mm}{1mm} \textbf{Continuous maps:} Next, we need to endow the general maps with the topological structure.
\begin{defn}
Let $X$, $Y$ be topological spaces and $f \colon X \sto Y$ be a map. We say $f$ is continous if
	\begin{equation*}
		\forall ~V \in \mathscr{T}_Y,~f^{-1}(V) \in \mathscr{T}_X.
	\end{equation*}
\end{defn} 
In other words, if $f \colon X \sto Y$ is a continuous map, $\mathscr{T}_X$ has "more" elements than $\mathscr{T}_Y$ has. To get more rigorous discription, we define the following concept.
\begin{defn}
	Let $X$ be a set and $\mathscr{T}$, $\mathscr{T}^{'}$ be two topologies on $X$ we say that $\mathscr{T}$ is coaser than $mathscr{T}^{'}$ if $\mathscr{T} \subset \mathscr{T}^{'}$.
\end{defn}
Therefore, if $f \colon X \sto Y$ is a continuous map, the topology $\mathscr{T}(f^{-1}(\mathscr{T}_Y))$ is coaser than $\mathscr{T}_X$. \vspace{0.1in}

\rule{1mm}{1mm} \textbf{Generating topologies:} We use above methods to generate some interested topologies on a set.
\begin{enumerate}[label=\arabic*)]
	\item Inital topology: Given maps $f_\alpha \colon X \sto Y_\alpha ~( \alpha \in A )$ from a set $X$ to a family of topological spaces $\{Y_\alpha \colon \alpha \in A \}$. Let
	\begin{equation*}
		\mathscr{S}~=~\{~f_{\alpha}^{-1}(V) \colon V \in \mathscr{T}_{Y_\alpha},~ \alpha \in A ~\}
	\end{equation*}
	Then $\mathscr{T}(\mathscr{S})$ is the coarsest topology on $X$ such that each $f_\alpha$ is continuous, called the initial topology induced by the family of maps $\{ f_\alpha\ \colon \alpha \in  A \}$.

	\item Final topology: Given maps $f_\alpha \colon X_\alpha \sto Y ~ (\alpha \in A)$ from a family of topological spaces $\{X_\alpha \colon \alpha \in A\}$ to a set $Y$. Let
	\begin{equation*}
		\mathscr{S}~=~\{~ V \colon f_{\alpha}^{-1}(V) \in \mathscr{T}_{X_\alpha},~ \alpha \in A~\}
	\end{equation*}
	Then $\mathscr{T}(\mathscr{S})$ is the finest topology on $Y$ such that each $f_\alpha$ is continuous, called the final topology induced by the family of maps $\{f_\alpha \colon \alpha \in A \}$.
\end{enumerate}
Here is some important examples using above way to generate topologies.
\begin{exam}
	(Initial topology)
	\begin{enumerate}[label=\arabic*)]
		\item Subspace topology: Let $Y$ be a topological space and $X \subset Y$ be a subset of $Y$. The inclusion map $i \colon X \sto Y$ can generate the initial topology $\mathscr{T}_X$ on $X$, then $X$ become a subspace of $Y$. In fact,
		\begin{equation*}
			\mathscr{T}_X ~=~ \{~X \bigcap U \colon U \in \mathscr{T}_Y~\}
		\end{equation*}
		\item Product topology: Let $\{Y_\alpha \colon \alpha \in A\}$ be a family of topological spaces. The product set is 
		\begin{equation*}
			\prod_{\alpha \in A} Y_\alpha ~=~ \{~A \stackrel{f}{\sto} \bigcup_{\alpha \in A} Y_\alpha \colon \forall \alpha \in A,~ f(\alpha) \in Y_\alpha ~\}
		\end{equation*}
		There is a family of maps $\{ p_\beta \colon \prod_{\alpha \in A} Y_\alpha \sto Y_\beta (\beta \in A) \}$. Therefore, these maps can generate the initial topology $\mathscr{T}$ on $\prod_{\alpha \in A} Y_\alpha$ and let $\prod_{\alpha \in A} Y_\alpha$ be the product topological space. In fact,
		\begin{equation*}
			\mathscr{T} ~=~ \{~\prod_{\alpha \in A} V_\alpha \colon V_\alpha \in \mathscr{T}_{Y_\alpha} ~ \& ~ \#\{\alpha \in A \colon V_\alpha \neq Y_\alpha \} < \infty ~\}
		\end{equation*}
		\begin{rem}
			The condition, $\#\{ \alpha \in A \colon V_\alpha \neq Y_\alpha \} < \infty$, is because that when the subbasis generates the basis, only finite many elements can do intersection.
		\end{rem}
	\end{enumerate}
\end{exam}
\begin{exam}
	(Final topology)\\
	Quotient topology: For a topological space $X$ on which an equivalent relation R is fixed, $\pi \colon X \sto X/R$ is the quotient map, then the quotient set can be equiped with the final topology $\mathscr{T}$ generated by the quotient map. Therefore, $X/R$ become a quotient topological space. In fact,
	\begin{equation*}
		\mathscr{T} ~=~ \{~ U \subset X/R \colon \pi^{-1}(U) \in \mathscr{T}_X ~\}
	\end{equation*}
\end{exam}

\rule{1mm}{1mm} \textbf{Countability and metrizability:} When learning the analysis of real functions, we usually use the sequence to discribe the topological properties. But in some general topology, we cannot just use sequence since some properties of "uncountabibily". In this case, the concept of net can be applied to some "uncountable" topologies. Furthermore, there is a class of more special topology, metrizable topology, which has some better properties.

\begin{defn}
	(Net)
	\begin{enumerate}[label=\arabic*)]
		\item Direct set: A direct set $(D,~\geqslant)$ consists of a nonempty set $D$ and a relation $\geqslant$ on D, satisfies:
		\begin{enumerate}[label=\roman*)]
			\item $\forall ~ d \in D,~ d \geqslant d$
			\item $\forall ~ d_1,~d_2,~d_3 \in D, if ~ d_3 \geqslant d_2 ~ \& ~ d_2 \geqslant d_1,~ then ~ d_3 \geqslant d_1$
			\item $\forall ~ d,~ d^{'} \in D,~ \exists ~ d^{''}  ~s.t.~ d^{''} \geqslant d ~ \& ~ d^{''} \geqslant d^{'}$.
		\end{enumerate}
		\item if $X$ is a set, a net is a map $x_. \colon D \sto X$ from a direct set $D$ to $X$
	\end{enumerate}
\end{defn}
\begin{exam}
	If $X$ is a topological space and $x \in X$, then let 
	\begin{equation*}
		D ~=~ \{~ \text{all open neighbourhoods of x} ~\},~ U \geqslant V \Leftrightarrow U \subset V
	\end{equation*}
	Then $D$ is a direct set and $x_\alpha(\alpha \in D)$ is a net.
	And we say $ x_\alpha \sto x$ if and only if \\
	$\forall$ open neighbourhood $U$ of $x$ in $X$, $\exists  \delta \in D,~ \forall ~ \alpha \in D \text{ with } \alpha \geqslant \delta \Rightarrow x_\alpha \in U$
\end{exam}
Nets can be used as sequences in topological spaces. Like, 
\begin{prop}
	If $X$ is a topological space and the net $x_\alpha(\alpha \in D)$ defined above and $A \subset X$, then
	\begin{enumerate}[label=\arabic*)]
		\item $\clo{A} ~=~ \{~ x \in X \colon \exists ~ x_\alpha \text{ in } A,~ x_\alpha \sto x ~\}$
		\item $f \colon X \sto Y$ is continuous between two topological spaces, $x_0 \in X$, $f$ is continuous at $x_0$, if and only if\\
		$\forall$ net $x_\alpha(\alpha \in D)$, s.t. $x_\alpha \sto x_0 \Rightarrow f(x_\alpha) \sto f(x_0)$
	\end{enumerate}
\end{prop}

\begin{defn}
	(Countability)
	\begin{enumerate}[label=\arabic*)]
		\item First countability: For a topological space $X$, $X$ is called first countable if for each point $x \in X$, $x$ has a countable neighbourhood basis.
		\item Second countability: A topological space $X$ is second countable if it has the countable topological basis. 
	\end{enumerate}
\end{defn}
\begin{rem}
	Clearly, the second countable topological space is first countable, but the converse is not true.
\end{rem}
In particular, if $X$ is first countable, sequences can be used to illuminate tpological properties rather than nets. Like,
\begin{prop}
	If $X$ is first countable, then
	\begin{enumerate}[label=\arabic*)]
		\item $U \subset X$ is closed $\Leftrightarrow$ $\forall ~ x \in U,~ \exists ~\text{a sequence} \{x_n\} \subset U,~ s.t.~ x_n \sto x$.
		\item sequential compactness is equivalent to compactness.
	\end{enumerate}
\end{prop}

And for the second countability, it is about the separability.
\begin{defn}
	(Separability)
	\begin{enumerate}[label=\arabic*)]
		\item A subset $A$ of a topological space $X$ is called dense if $\clo{A} ~=~ X$.
		\item A topological space is called separable if it has a countable dense subset.
	\end{enumerate}
\end{defn}

By the definition, we can clearly know that:
\begin{prop}
	If $X$ is a second countable topological space, then it is separable and every open covering of $X$ has a finite subcollection covering $X$.
\end{prop}

We can classify topological spaces into some classes.
\begin{defn}
$X$ is a topological space, then we call $X$ is:
\begin{enumerate}
	\item [($T_0$)] $\forall ~ x,~y \in X,~ \exists ~ \text{open } U \subset X,~ s.t.~ x \in U \text{ but } y \notin U \text{ or } y \in U \text{ but } x \notin U$ (Kolmogorov space)
	\item [($T_1$)] $\forall ~ x,~y \in X,~ \exists ~ \text{open } U,~ V \subset X, ~s.t.~ x \in U \text{ but } y \notin U \text{ and } y \in V \text{ but } x \notin V$\\
	($\Leftrightarrow \forall~ x \in X,~ \{x\} \text{ is closed} $)
	\item [($T_2$)] $\forall ~ x,~y \in X,~ \exists ~ \text{open } U,~ V \subset X, ~s.t.~ x \in U ~\&~ y \in V \text { and } U \bigcap V = \varnothing$ (Hausdorff space)
	\item [($T_3$)] $T_1$ holds and $\forall ~ x \in X$ and closed $C \subset X$, if $x \notin C$, then $\exists ~ \text{open } U,~ V \subset X, ~s.t.~ x \in U ~\&~ C \subset V \text{ and } U \bigcap V = \varnothing$ (regular space)
	\item [($T_4$)] $T_1$ holds and $\forall ~ \text{closed } C_1,~ C_2 \subset X$, if $C_1 \bigcap C_2 = \varnothing$, \\ then $\exists ~ \text{open } U,~ V \subset X, ~s.t.~ C_1 \subset U ~\&~ C_2 \subset V \text{ and } U \bigcap V = \varnothing$ (normal space)
\end{enumerate}
\end{defn}

Then we can specify a class of more powerful topological space.
\begin{defn}
	If $X$ is a topological space, then $X$ is said to be metrizable if there exists a metric $d$ on the set $X$ that induces the topology of $X$.
\end{defn}
\begin{rem}
	Clearly, if $X$ is metrizable, $X$ is second countable and normal.
\end{rem}

Here is two metrization theorems provides the essence of metric spaces.
\begin{thm}
(Metrization theorems)
	\begin{enumerate}
		\item[Urysohn] A topological space is separable and metrizable if and only if it is regular, Hausdorff and second countable.
		\item[Nagata–Smirnov] A topological space is metrizable if and only if regular, Hausdorff and has a $\sigma$-locally finite basis.
	\end{enumerate}
\end{thm}
\vspace{0.2in}
\rule{1mm}{1mm} \textbf{Complete metic space:} For a metric space, we know it is first countable, so the concept of net is unnecessary. And thus sequences are enough to determine the topological structures, like that sequential compactness is equvilent to compactness. 

\begin{prop}
	A compact subset of a metric space is closed, bounded and separable.
\end{prop}
\begin{rem}
	it is clearly, since compactness is also about finity.
\end{rem}

For any metric space, we can use the following theorem to get a completion of that and this completion is unique. Thus, we can always assume a metric space is complete.
\begin{thm}
	Let ($X,~ d$) be a metric space. Then, there exists a metric space ($\hat{X},~ \hat{d}$) with the following properties:
	\begin{enumerate}[label=\arabic*)]
		\item ($\hat{X},~ \hat{d}$) is complete.
		\item There is an embedding $\sigma$ from $X$ to $\hat{X}$.
		\item $\sigma(X)$ is dense in $\hat{X}$.
	\end{enumerate}
	And this ($\hat{X},~ \hat{d}$) is unique with respect to isomorphism.
\end{thm}

Complete metric space is imporatant since it is "sufficiently large". Rigorously, we can the following definition to describe it.

\begin{defn}
	(Baire Category)
	A metric space is said to be of the first category if it can be written as a countable union of sets that are nowhere dense. Otherwise, it is of the second category.
\end{defn}

\begin{prop}
	A complete metric space is a space of the second category.
\end{prop}

\vspace{0.2in}
\rule{1mm}{1mm} \textbf{Filters:} For convenience, we define some terminologies.
\begin{defn}
	A filter on a set $X$ is a family $\mathscr{F} $ of subsets of $X$ satisfying the following conditions:
	\begin{enumerate}[label=\arabic*)]
		\item $\varnothing \notin \mathscr{F}$
		\item $\mathscr{F}$ is closed under finite many intersections
		\item Any subset of $X$ containing a set in $\mathscr{F}$ belongs to $\mathscr{F}$.
	\end{enumerate}
\end{defn}
\begin{exam}\label{exam1}
	For a topological space $X$ and $x \in X$, and let
	\begin{equation*}
		\mathscr{F}(x) ~=~ \{~\text{all neighbourhoods of x}~\}	
	\end{equation*}
	Then $\mathscr{F}(x)$ is a filter and $\mathscr{F}(x)$ satisfies the following properties:
	\begin{enumerate}[label=\arabic*)]
		\item $\forall~ U \in \mathscr{F}(x),~ x \in U$
		\item $\forall~ U \in \mathscr{F}(x),~ \exists ~ V \in \mathscr{F}(x),~ s.t.~ \forall~ y \in V,~ U \in \mathscr{F}(y)$
	\end{enumerate}
	And conversely, if we can find $\mathscr{F}(x)$ for any $x \in X$ with above two properties, these can define a unique topology $\mathscr{T}$ s.t. $\mathscr{F}(x)$ is the filter of neighbourhoods of $x$ for any $x \in X$. In fact,
	\begin{equation*}
		\mathscr{T} = \{~ U \subset X \colon x \in U \Rightarrow U \in \mathscr{F}(x) ~\}
	\end{equation*}
	Also, we can define the basis of $\mathscr{F}(x)$, noted by $\mathscr{B}(x)$. That is $\mathscr{B}(x) \subset \mathscr{F}(x)$ with the following properties:
	\begin{enumerate}[label=\arabic*)]
		\item $\forall~ U \in \mathscr{B}(x),~ x \in U$
		\item $\forall~ U_1 ~\&~ U_2 \in \mathscr{B}(x),~ \exists ~ U_3 \in \mathscr{B}(x),~ s.t.~ U_3 \subset U_1 \bigcap U_2$
		\item If $y \in U \in \mathscr{B}(x),~ \exists ~ W \in \mathscr{B}(y),~ W \subset U$
	\end{enumerate}
\end{exam}

\subsection{Definition and Properties}

\rule{1mm}{1mm} \textbf{Definition:} Now, we need to endow the topological structure on a vector spaces. And the most important thing is that the topological structure should coincide with the algebraic structure.
\begin{defn}
	A vector space $X$ over a field $\K$ (where $\K = \C or \R$) is called a topological vector space if $X$ is equiped with a topology $\mathscr{T}$ s.t. the addition and the scalar multiplication, i.e. 
	\begin{center}
		\begin{tabular}{r @{$\mapsto$} l}
			$(x,~y)~$ & $~x+y$ \\
			$(\lambda,~ x)~$ & $~ \lambda x$
		\end{tabular}
	\end{center}
	are continuous with respect to the topology $\mathscr{T}$.
\end{defn}

In this definition, the most important part is that the addition and the scalar multiplication are continuous. This condition provides some additional properties for the topology and also for the linear operations. First, it can simply the topology.

\begin{prop}
	Given a t.v.s. $X$, 
	\begin{enumerate}[label=\arabic*)]
		\item For any $x_0 \in X$, the map $x \mapsto x+x_0$ is a homeomorphism.
		\item For any $\lambda \in \K$, then map $x \mapsto \lambda x$ is a homeomorphism.
	\end{enumerate}
\end{prop}
\begin{proof}
	It is clearly, since by the definition, $x \mapsto x-x_0$ and $x \mapsto \frac{1}{\lambda}x$ are continuous.
\end{proof}

Therefore, the topology of a t.v.s is completely determined by the filter of neighbourhoods of any point. Or, more rigorously,
\begin{cor}
	For a t.v.s $X$, the filter $\mathscr{F}(x)$ of neighbourhoods of $x \in X$ is as same as $\{~ U+x \colon U \in \mathscr{F}(e) ~\}$, where $e$ is the unit element in $X$.
\end{cor}

Thus, to research the topology of a t.v.s. $X$, we just need to research the filter $\mathscr{F}(e)$ of neighbourhoods of $e$. First, there are two special properties of some subsets of a t.v.s. $X$.
\begin{defn}
	For a subset $U$ of a t.v.s. $X$, 
	\begin{enumerate}[label=\arabic*)]
		\item $U$ is absorbing if $\forall ~ x \in X,~ \exists ~ \rho > 0 ~s.t.~ \forall~ \lambda \in \K$ with $ \abs{\lambda} \leqslant \rho$, we have $\lambda x \in U$.
		\item $U$ is balanced if $\forall ~ x \in U,~ \forall \lambda \in \K$ with $\abs{\lambda} \leqslant 1$, we have $\lambda x \in U$.
	\end{enumerate}
\end{defn}

Then, the following theorem reveals the essence of $\mathscr{F}(e)$.
\begin{thm}
	A filter $\mathscr{F}$ of a vector space $X$ over $\K$ is the filter of neighbourhoods of the unit element $e$ w.r.t. some topology compatible with the algebraic structure of $X$ if and only if 
	\begin{enumerate}[label=\arabic*)]
		\item $\forall ~ U \in \mathscr{F},~ e \in U$
		\item $\forall ~ U \in \mathscr{F},~ \exists ~ V \in \mathscr{F} ~s.t.~ V+V \subset U$
		\item $\forall ~ U \in \mathscr{F},~ \forall ~ \lambda \in \K$ with $\lambda \neq 0$, $\lambda U \in \mathscr{F}$
		\item $\forall ~ U \in \mathscr{F},~ U$ is absorbing
		\item $\forall ~ U \in \mathscr{F},~ \exists ~ V \in \mathscr{F} ~s.t.~ V \subset U$ is balanced
	\end{enumerate}
\end{thm}
\begin{proof}
	If $\mathscr{F} = \mathscr{F}(e)$, these statements clearly hold.\\
	$1)$ is trivial.\\
	$2)$ is true since the addition is continuous.\\
	$3)$ and $4)$ hold since the scalar multiplication is continuous.\\
	For $5)$, because the scalar multiplication is continuous, we can find a $W \in \mathscr{F} ~s.t.~ \lambda W \subset U$ for any $\abs{\lambda} \leqslant \rho$, then let $V = \bigcup_{\abs{\lambda} \leqslant \rho} \lambda W$. Clearly, $V \in \mathscr{F}$ and $V$ is balanced.\\
	Conversely, We can define
	\begin{equation*}
		\mathscr{F}(x) = \{~ U+x \colon U \in \mathscr{F} ~\}
	\end{equation*}
	for any $x \in X$. It can be easily checked that $\mathscr{F}(x)$ satisfies the conditions in Example \ref{exam1} in last subsection. Therefore, these $\mathscr{F}(x)$ can determine a unique topology $\mathscr{T}$ on $X$.\\
	Now, we just need to check the continuity of the addition and the scalar multiplication. The addition is continuous, since $\mathscr{F}$ satisfies $2)$.  Using conditions $2)$ and $4)$ and $5)$ to get a balanced absorbing open neighbourhood in $\mathscr{F}$, and this neighbourhood prove the continuity of the scalar multiplication.
\end{proof}

Here is some simple properties of a t.v.s. $X$. These properties are directly obtained by definition and above theorem.
\begin{prop}
	For a t.v.s. $X$,
	\begin{enumerate}[label=\arabic*)]
		\item proper subspaces of $X$ are never absorbing. In particular, if $M \subset X$ is a open subspace, then $M = X$.
		\item each linear subspace of $X$, endowed with subspace topology, is also a t.v.s.
		\item if $H$ is a linear subspace of $X$, then $\clo{H}$ is also a linear subspace of $X$.
		\item if $Y$ is also a t.v.s. and $f \colon X \sto Y$ is a linear map, then $f$ is continuous if and only if $f$ is continuous at the unit element $e$.
	\end{enumerate}
\end{prop}

\vspace{0.2in}
\rule{1mm}{1mm} \textbf{Hausdorff t.v.s.~:} The Hausdorff Space is important since it can let the concept of limit make sense. And the topology of a t.v.s. can be simplified and has some additional properties, we can get a easier condition that make a t.v.s. become Hausdorff.

\begin{prop}
	A t.v.s $X$ is a Hausdorff space if and only if for any $x \in X$ with $x \neq e$ there exists a $U \in \mathscr{F}(e)$ s.t. $x \notin U$.
\end{prop}
\begin{proof}
	Since the open neighbourhoods of any point in $X$ is completely determined by the open neighbourhoods of $e$, this proposition is equivalent to the statement that ($T_1$) implies Hausdorff.\\
	The proof can be accomplished by obtaining a contradiction to the given condition that $x \neq e$, $\exists ~U \in \mathscr{F}(e)$ s.t. $x \notin U$. For that $U$, there is a balanced $V \in \mathscr{F}(e) ~s.t.~ V+V \subset U$ and the balance implies that $V-V \subset U$. Therefore, $(x+V) \bigcap V = \varnothing$. If not, $x+v_1 = v_2$ for $v_1,~ v_2 \in V$. This implies that $x = v_1 - v_2 \in V-V \subset U$. Thus it is a contradiction.
\end{proof}
The following theorem is more explicit.
\begin{thm} \label{thm1}
	For t.v.s. $X$ the following statements are equivalent.
	\begin{enumerate}[label=\arabic*)]
		\item $X$ is Hausdorff.
		\item the intersection of all neighbourhoods of the unit element $e$ is \{e\}.
		\item \{e\} is closed.
	\end{enumerate}
\end{thm}
\begin{proof}
	Before the rigorously proving, the intuition is clearly. Since in a t.v.s. ($T_1$) is equivalent to Hausdorff, the equivalence of $1)$ and $3)$ is clearly true.
	\begin{enumerate}
		\item[$1) \Rightarrow 2)$] It is because that elements in $\mathscr{F}(e)$ can separate $e$ and other points.
		\item[$2) \Rightarrow 3)$] If $x \in \clo{\{e\}}$, i.e. $\forall V_x \in \mathscr{F}(x),~ V_x \bigcap \clo{\{e\}} \neq \varnothing \Rightarrow e \in V_x$, and $V_x = U + x$ for some $U \in \mathscr{F}(e)$, then $u + x = e$ for some $u \in U$. Thus, $x = -u \in -U$ for all $U \in \mathscr{F}(e)$. That implies $x = e$.
		\item[$3) \Rightarrow 1)$] By above mentioned, it just needs to check that if for any topology space $Y$, $\{y\}$ is closed $\forall y \in Y$, $Y$ is ($T_1$). \\
		Since $\{y_1\}$ is closed, $Y \backslash \{y_1\}$ is open. That means if $y_2 \neq y_1$, there exists a open neighbourhood $U$ of $y_2$ s.t. $y_1 \notin U$. Similarly, we can find a open neighbourhood $V$ of $y_1$ s.t. $y_2 \notin V$. Therefore, $Y$ is ($T_1$). \qedhere
	\end{enumerate}	
\end{proof}

\vspace{0.2in}
\rule{1mm}{1mm} \textbf{Quotient t.v.s.~:} For a linear subspace $M$ of a t.v.s. $X$, the quotient topology on $X/M$ can be obtained by the quotient map $\pi \colon X \sto X/M$. But because of the algebraic structure, it has more properties.
\begin{prop}
	For a linear subspace $M$ of a t.v.s. $X$, the quotient map $\pi \colon X \sto X/M$ is open.
\end{prop}
\begin{proof}
	Let $V \subset X$ be open, then we have
	\begin{equation*}
		\pi^{-1}(\pi(V)) = V + M = \bigcup_{m \in M}(V+m)
	\end{equation*}
	Since $V$ is open, $V+m$ is open. Thus $\pi^{-1}(\pi(V))$ is open. And by the definition of the topology on $X/M$, $\pi(V)$ is open.
\end{proof}
\begin{cor}
	For a linear subspace $M$ of a t.v.s. $X$, the quotient space $X/M$ endowed with the quotient topology is a t.v.s..
\end{cor}
\begin{proof}
	We have the following commutative graph, where $f$ and $g$ are corresponding addition maps or scalar multiplication maps on $X$ and $X/M$.
	\begin{center}
		\begin{tikzcd}
			X \times X \arrow[r, "f"] \arrow[d, "\pi \times \pi"]
				& X \arrow[d, "\pi"] \\
			X/M \times X/M \arrow[r, "g"]
				& X/M
		\end{tikzcd}
	\end{center}
	Then for an open set $V \subset X/M$, since $f$ and $\pi$ are continuous, and $\pi$ is open, $(\pi \times \pi) \circ f^{-1} \circ \pi^{-1}(V)$ is open. By above commutative graph, we have $g \circ (\pi \times \pi) = \pi \circ f$. Therefore, $g^{-1}(V)$ is open, i.e. $g$ is continuous.
\end{proof}

Also, we can find the condition that lets the quotient topological vector space be Hausdorff.
\begin{prop}
	Let $X$ be a t.v.s..
	\begin{enumerate}[label=\arabic*)]
		\item $M$ be a linear subspace of $X$. Then $X/M$ is Hausdorff if and only if $M$ is closed.
		\item $X/\clo{\{e\}}$ is Hausdorff.
	\end{enumerate}	 
\end{prop}
\begin{proof}
	$2)$ is true because $1)$. And $1)$ clearly holds since $M$ is the unit element in $X/M$ and Theorem \ref{thm1} in this subsection.
\end{proof}
\begin{rem}
	By this method, for any t.v.s., we can find a Hausdorff space w.r.t it.
\end{rem}

\subsection{Continuous Linear Maps}

The interesting maps between two topological vector spaces not only preserve the algebraic structure, but also the topological structure, thus these are continuous linear maps.\\
First, for a linear map $f \colon X \sto Y$ between vector spaces $X$ and $Y$, we have the commutative graph, where $\tilde{f}(x+\ker{f}) = f(x)$ is well-defined.
\begin{center}
	\begin{tikzcd}
		X \arrow[r, "f"] \arrow[d, "\pi"]
			& \Img{f} \arrow[r, "i"]
			& Y \\
		X/\ker{f} \arrow[ru, "\tilde{f}"]
	\end{tikzcd}
\end{center}

\begin{prop} \label{prop3}
	Let $f \colon X \sto Y$ be a linear map between two t.v.s.'s $X$ and $Y$.
	\begin{enumerate}[label=\arabic*)]
		\item If $Y$ is Hausdorff and $f$ is continuous, then $\ker{f}$ is closed.
		\item By above notation, $f$ is continuous if and only if $\tilde{f}$ is continous.
	\end{enumerate}
\end{prop}
\begin{proof} 
	$1)$ is because that $\ker{f} = f^{-1}(\{e\})$ and $Y$ is Hausdorff.\\
	For $2)$, if $\tilde{f}$ is continuous, it is clearly that $f = i \circ \tilde{f} \circ \pi$ is continuous. Conversely, it is because of the universal property of quotient maps. And in this case, let $U \subset \Img{f}$ be open, then $f^{-1}(U)$ is open and $\tilde{f}^{-1}(U) = \pi(f^{-1}(U))$. Since $\pi$ is open, $\tilde{f}^{-1}(U)$ is open. Thus, $\tilde{f}$ is continuous.
\end{proof}

\subsection{Complete Topological Vector Spaces}

We have just defined the completeness on a metric space by using sequence, but in metric spaces, we know the topology is so powerful that sequences can do any thing, but in general topology, or the topology in a t.v.s., we need an equivalent concept to describe the completeness.

\begin{defn}
	(Completeness)
	\begin{enumerate}[label=\arabic*)]
		\item A filter $\mathscr{F}$ on a subset $A$ of a t.v.s. $X$ is said to be a Cauchy filter if
			\begin{equation*}
				\forall~ U \in \mathscr{F}(0) \textbf{ in } X,~ \exists ~ M \subset A ~s.t.~ M \in \mathscr{F} ~\&~ M-M \subset U
			\end{equation*}
		\item A subset A of a t.v.s. X is said to be complete if every Cauchy filter on A converges to a point $x \in A$.
	\end{enumerate}
\end{defn}
\begin{rem}
	Said "the filter converges to a point" means that we can define a net on this filter, and this net converge a point. And this definition is also valid without the algebraic structure.
\end{rem}

By this definition, and using the factor that Hausdorff spaces let the limit point of a net uniquely exist, we have similar results comparing with the metric spaces.
\begin{prop}
	Let $X$ be a t.v.s..
	\begin{enumerate}[label=\arabic*)]
		\item If $X$ is Hausdorff, any complete set is closed.
		\item If $X$ is complete, any closed set is complete.
	\end{enumerate}
\end{prop}

We known any metric space can be completion. Similarly, the same result can obtained in any t.v.s..
\begin{thm}
	Let $X$ be a Hausdorff t.v.s., then there exists a complete Hausdorff t.v.s. $\hat{X}$ and a map $i \colon X \sto \hat{X}$ with the following properties.
	\begin{enumerate}[label=\arabic*)]
		\item $i$ is a topological monomorphism.
		\item $\clo{i(X)} = \hat{X}$.
		\item For any complete Hausdorff t.v.s. $Y$ and for every continuous linear map $f \colon X \sto Y$, there exists a continuous map $\hat{f} \colon \hat{X} \sto Y$, s.t. the following graph is commutative
		\begin{center}
			\begin{tikzcd}
				X \arrow[r, "f"] \arrow[d, "i"]
					& Y \\
				\hat{X} \arrow[ru, "\hat{f}"]
			\end{tikzcd}
		\end{center}
	\end{enumerate}
	And ($\hat{X}$, $\hat{f}$) is unique with respect to the isomorphism
\end{thm}
\begin{proof}
	The proof is similar as the proof of the completion of metric spaces, which contructs the $\hat{X}$ as a set of equivalent classes of Cauchy sequences. In a t.v.s., we just need to replace Cauchy sequences by Cauchy filters (in fact, Cauchy nets). Let 
	\begin{center}
		\begin{tabular}{r c l}
			$\tilde{X}$ & $=$ & $\{~ \text{all Cauchy filters in } X ~\}$\\
			$R $ & $\colon$ & $ \mathscr{F} ~R~ \mathscr{G} \Leftrightarrow \forall ~ U \in \mathscr{F}(e),~ \exists ~ A \in \mathscr{F} ~\&~ B \in \mathscr{G} ~s.t.~ A-B \subset U$\\
			$\hat{X}$& $=$ & $\tilde{X} / R$
		\end{tabular}
	\end{center}
	We can easily define linear operations and topology, s.t. $\hat{X}$ become a complete t.v.s.. Then we just need to check the statements in above theorem hold.
\end{proof}

\subsection{Finite Dimensional Topological Vector Spaces}

For a finite dimensional topological vector space, the topology compatible with the algebraic structure has some properties coincided with the "finity". First, continuous linear functionals on a t.v.s. have some properties.

\begin{lem}
	Let $X$ be a t.v.s. over $\K$. Fixed $v \in X$, then the $\phi_{v} \colon \K \sto X$ by $\xi \mapsto \xi v$ is continuous,
\end{lem}
\begin{proof}
	It is because that $\phi_{v} = f \circ \psi_{v}$ where $f$ is the multiplication map.
	\begin{center}
		\begin{tabular}{r l c l r}
			$\K$ & $\stackrel{\psi_{v}}{\rightarrow}$ & $\K \times X$ & $\stackrel{f}{\rightarrow}$ & $X$ \\
			$\xi$ & $\mapsto$ & ($\xi$, $v$) & $\mapsto$ & $\xi v$ 
		\end{tabular} 
	\end{center}
\end{proof}

\begin{lem}
	For a non-zero linear functional $L \colon X \sto \K$, where $X$ is a t.v.s. over $\K$, the following statements are equivalent.
	\begin{enumerate}[label=\arabic*)]
		\item $L$ is continuous,
		\item $\ker{L}$ is closed,
		\item $\ker{L}$ is not dense in $X$,
		\item $L$ is bounded in some neighbourhood of the origin in $X$.
	\end{enumerate}
\end{lem}
\begin{proof}
	The equivalence of $1)$ and $2)$ and $4)$ is clearly.
	\begin{enumerate}
		\item[$1) \Rightarrow 2)$] It is because that $\ker{L} = L^{-1}(\{0\})$.
		\item[$2) \Rightarrow 3)$] Since $L$ is non-zero, it clearly holds.
		\item[$3) \Rightarrow 4)$] By the assumption, there exists a balanced set $V \in \mathscr{F}(e)$ and a point $x \notin \clo{\ker{L}}$ s.t. $(x+V) \bigcap \ker{L} = \varnothing$. $L(V)$ is balanced on $\K$, therefore $L(V)$ is bounded or $L(V) = \K$. But since $(x+V) \bigcap \ker{L} = \varnothing$, $L(V) \neq \K$.
		\item[$4) \Rightarrow 1)$] This implies that $L$ is continuous at $e$. But since $X$ is a t.v.s., $L$ is continuous at every point. \qedhere
	\end{enumerate}
\end{proof}

\begin{thm}
	Let $X$ be a finite dimensional Hausdorff t.v.s. over $\K$ (endowed with the standard topology), and $\dim{X}$ = $d$. Then we have: 
	\begin{enumerate}[label=\arabic*)]
		\item $X$ is topologically isomorphic to $\K^{d}$,
		\item every linear  functional on $X$ is continuous,
		\item every linear map from $X$ to any t.v.s. $Y$ is continuous
	\end{enumerate}
\end{thm}
\begin{proof}
	For $1)$, we just need to find a homeomorphic isomorphism from $\K^{d}$ to $X$, like the following map, where $\{e_i\}_{i=1}^{d}$ is the basis of $X$.
	\begin{center}
		\begin{tabular}{c c c}
			$\K^{d}$ & $\stackrel{\phi}{\longrightarrow}$ & $X$ \\
			$(\lambda_1,~ \lambda_2,~ \cdots,~ \lambda_d)$  & $\longmapsto$ & $\lambda_1 e_1 + \lambda_2 e_2 + \cdots + \lambda_d e_d$
		\end{tabular} 
	\end{center}
	$\phi$ is clearly an algebraic isomorphism. Thus we just need to check $\phi$ is both continuous and open.\\
	Check: $\phi$ is continuous.\\
	When $d = 1$, it is continuous by above lemma. For the general case, since $d$ is finite, $\phi$ is continuous.\\
	Check: $2)$ holds and $\phi$ is open.\\
	When $d = 1$, it is clearly $1)$ and $2)$ are trued. And suppose $1)$ and $2)$ hold for $\dim{X} \leqslant d-1$, then when $\dim{X} = d$, let $L$ be a non-zero linear function on $X$. Then since $\iso{X/\ker{L}}{\Img{L}} \subset \K$, $\dim{\ker{L}} = d-1$. Therefore, $\iso{\ker{L}}{\K^{d-1}} \Rightarrow \ker{L}$ is complete $\Rightarrow \ker{L}$ is closed $\Rightarrow L$ is continuous by above lemma. And,  
	\begin{center}
		\begin{tabular}{c c c}
			$X$ & $\stackrel{\phi^{-1}}{\longrightarrow}$ & $\K^{d}$ \\
			$\lambda_1 e_1 + \lambda_2 e_2 + \cdots + \lambda_d e_d$  & $\longmapsto$ & $(\lambda_1,~ \lambda_2,~ \cdots,~ \lambda_d)$
		\end{tabular} 
	\end{center}
	is continuous since each 
	\begin{equation*}	
			\lambda_1 e_1 + \lambda_2 e_2 + \cdots + \lambda_d e_d \longmapsto \lambda_i
	\end{equation*}
	is continuous.\\
	Then for $3)$, it is clealy since $\dim{\Img{L}} < \infty$. 
\end{proof}
 
\begin{cor}
	~
	\begin{enumerate}[label=\arabic*)]
		\item Every finite dimensional Hausdorff t.v.s. is complete.
		\item Every finite dimensional subspace of a Hausdorff t.v.s. is closed.
		\item For a finite dimensional vector space, there is only one topology w.r.t. homeomorphism that can make it be a Hausdorff t.v.s..
		\item Every bounded subset on a finite dimensional Hausdorff t.v.s. is compact.
	\end{enumerate}
\end{cor}
\begin{proof}
	These properties can be easily obtained by regarding the t.v.s. as $\K^{d}$ endowed with the standard topology.
\end{proof}

Finally, the most important theorem in this subsection is that the converse of $4)$ in above corollary is also true.
\begin{thm}
	A Hausforff t.v.s. is locally compact if and only if it is finite dimensional.
\end{thm}
\begin{proof}
	Let $X$ be a locally compact Hausdorff t.v.s. and K be a compact heighbourhood of $e$ in $X$, i.e.
	\begin{equation*}
		\exists ~ x_1,~ \cdots,~ x_r \in X ~s.t.~ K \subset \bigcup_{i=1}^{r}(x_i+\frac{1}{2}K)
	\end{equation*}
	Let $M = \spn{\{x_1,~ \cdots,~ x_r\}}$, and $M$ is closed. Therefore, $X/M$ is a Hausdorff t.v.s.. Let $\pi \colon X \sto X/M$ be the quotient map.\\
	Since $K \subset M+\frac{1}{2}K$, $\pi(K) \subset \pi(\frac{1}{2}K)$. Thus, by iterating $\pi(2^{n}K) \subset \pi(K)$.\\
	As $K$ is absorbing, $X = \bigcup_{n=1}^{\infty}2^{n}K$,
	\begin{equation*}
		X/M = \pi(X) = \bigcup_{n=1}^{\infty}\pi(2^{n}K) \subset \pi(K) \subset X/M
	\end{equation*}
	And since $\pi$ is continuous, $\pi(K)$ is compact, i.e. $X/M$ is compact.\\
	claim: $\dim{X/M} = 0$ \\
	Suppose $\dim{X/M} > 0$, then for some $\clo{x_0} \in X$ with $\clo{x_0} \neq \clo{e}$, $\R \clo{x_0} \subset X/M$. And since $X/M$ is Hausdorff compact and $\R \clo{x_0}$ is closed, $\R \clo{x_0}$ is compact, which is a contradiction.
\end{proof}

\section{Locally Convex Topological Vector Spaces}

The locally convex topological vector space is a topological vector spaces whose topology is generated by a family of seminorms, thus it can provide more properties.

\subsection{Definition by Convex Sets}

Firstly, the conception of locally convex space can be obtained by convex sets. So, we need to research some elementary traits of convex sets.

\begin{defn}
	~
	\begin{enumerate}[label=\arabic*)]
		\item Let $S$ be any subset of a vector space $X$ over $\K$. The convex hull of $S$, $conv(S)$, is the smallest convex subset containing $S$. In fact, 
		\begin{equation*}
			conv(S) = \{~ \sum_{i=1}^{n}\lambda_i x_i \colon x_i \in S,~ \lambda_i \in [0,1],~ \sum_{i=1}^{n}\lambda_i = 1,~ n \in \N ~\}
		\end{equation*}
		\item A subset $S$ of a vector space $X$ over $\K$ is absolutely convex, if $S$ is convex and balanced
		\item A subset $S$ of a vector space $X$ over $\K$ is called a barrel if $S$ is closed, absorbing and absolutely convex.
	\end{enumerate}
\end{defn}

\begin{prop}
	~
	\begin{enumerate}[label=\arabic*)]
		\item Arbitrary intersections of convex sets are convex sets, and the sum of two convex sets is convex, and linear maps preserve convex.
		\item The convex hull of a balanced set is balanced.
		\item The closure and the interior of a convex set in a t.v.s. is convex.
		\item Every neighbourhood of the origin of a t.v.s. is contained in a neighbourhood of the origin which is a barrel.
	\end{enumerate}
\end{prop}
\begin{proof}
	$1)$ and $2)$ are easily obtained by the definition. \\
	To prove $3)$, for any $\lambda \in [0,1]$, we define the map
	\begin{center}
		\begin{tabular}{l c c l}
			$\phi ~ \colon$ & $X \times X$ & $\longrightarrow$ & $X$ \\
			~ & $(x,y)$ & $\mapsto$ & $\lambda x + (1-\lambda) y$
		\end{tabular}
	\end{center}
	Using the fact that $\phi(S \times S) \subset S$, $S \times S \subset \phi^{-1}(S) \phi^{-1}(\clo{S})$. And since $X$ is a t.v.s., $\phi$ is continuous. Thus $\phi^{-1}(\clo{S})$ is closed, i.e. $\clo{S} \times \clo{S} \subset \phi^{-1}(\clo{S}) \Rightarrow \phi(\clo{S} \times \clo{S}) \subset \clo{S}$. $\clo{S}$ is convex.\\
	Since $z+u = \lambda x + (1-\lambda) y + \lambda u + (1-\lambda) u$ if $z = \lambda x + (1-\lambda) y$, $x + U ~\&~ y + U \subset S \Rightarrow z + U \subset S$. That means $\inte{S}$ is convex.\\
	For $4)$, $\forall ~ U \in \mathscr{F}(e)$, the set
	\begin{equation*}
		\clo{conv\left(\bigcup_{\abs{\lambda} \leqslant 1}\lambda U\right)}
	\end{equation*}
	is a barrel.
\end{proof}
\begin{cor}
	Every neighbourhood of the origin in a t.v.s. $X$ is contained in a neighbourhood of the origin which is absolutely convex.
\end{cor}

Now, we can get the definition of a locally convex t.v.s..
\begin{defn}
	A t.v.s. $X$ is said to be locally convex if there is a basis of neighbourhoods of the origin in $X$ consisting of convex sets.
\end{defn}

By this definition, the structure of the neighbourhoods of the origin in a locally convex t.v.s. can be more explicit by using above proposition.

\begin{prop}
	Let $X$ be a locally convex t.v.s..
	\begin{enumerate}[label=\arabic*)]
		\item $X$ has a basis of neighbourhoods of origin consisting with oepn absorbing absolutely convex sets.
		\item  $X$ has a basis of neighbourhoods of origin consisting with barrels.
	\end{enumerate}
\end{prop}

\begin{thm}
	If $X$ is a locally convex t.v.s., then there exists a basis $\mathscr{B}$ of neighbourhoods of origin consisting of absorbing absolutely convex set s.t.
	\begin{equation*}
		\forall ~ U \in \mathscr{B},~ \forall ~ \rho > 0,~ \exists ~ W \in \mathscr{B} ~s.t.~ W \subset \rho U
	\end{equation*}
	Conversely, if $\mathscr{B}$ is a collection of absorbing absolutely convex subsets of a vector space satisfying above condition, it can generate a unique locally convex t.v.s..
\end{thm}

\subsection{Definition by Seminorms}

\begin{defn}
	Let $X$ be a vector space over $\K$. A map $p \colon X \sto \R^{+}$ is called a seminorm if it satisfies:
	\begin{enumerate}[label=\arabic*)]
		\item $p(x+y) \leqslant p(x)+p(y),~ \forall ~ x,~ y \in X$,
		\item $p(\lambda x) = \abs{\lambda} p(x),~ \forall ~ x \in X,~ \forall ~ \lambda \in \K$.
	\end{enumerate}
\end{defn}
\begin{rem}
	In fact, $\ker{p}$ is a linear sbuspace and if $\ker{p} = \{0\}$, $p$ is called a norm.
\end{rem}

By the intuition, the seminorm could construct the continuity of the addition and multiplication since it satisfies above properties. Now, we can build this rigorously.

\begin{defn}
	Let $X$ be a vector space and $A \subset X$ be a nonempty subset. The Minkowski functional of $A$ is the map
	\begin{center}
		\begin{tabular}{l c c l}
			$p_A ~ \colon$ & $X$ & $\longrightarrow$ & $\R$ \\
			~ & $x$ & $\mapsto$ & $\inff\{~ \lambda > 0 \colon x \in \lambda A ~\}$
		\end{tabular}
	\end{center}
\end{defn}

Let $X$ be a vector space and $p$ is a seminorm on $X$, then let $\inte{U}_p = \{~ x \in X \colon p(x) < 1 ~\}$, $U_p = \{~ x \in X \colon p(x) \leqslant 1 ~\}$. Thus, $U$ may be the basis generating the topology. To see it, the following proposition is helpful.

\begin{prop}
	Let $A \subset X$ be a nonempty subset of a vector space, which is absorbing and absolutely convex, then $p_A$ is a seminorm and $\inte{U}_{p_A} \subset A \subset U_{p_A}$. Conversely, if $q$ is a norm on $X$ then $\inte{U}_q$ is an absorbing absolutely convex set and $q = p_{\inte{U}_q}$.
\end{prop}
\begin{proof}
	Since $A$ is balanced, $\xi A \in \lambda A \Leftrightarrow x \in \frac{\lambda}{\abs{\xi}} A$. Thus,
	\begin{equation*}
		p_A(x) = \abs{\xi} \inff{\{~ \frac{\lambda}{\abs{\xi}} \colon x \in \frac{\lambda}{\abs{\xi}} A~\}} = \abs{\xi} p_A(x)
	\end{equation*}
	And $p_A(x) < \infty  ~( \forall ~ x \in X)$ since $A$ is absorbing.\\
	Fixed $x,~ y \in X$, $\forall \varepsilon > 0,~ \exists ~ \lambda,~ \mu > 0$, s.t. $x \in \lambda A ~\&~ y \in \mu A$ and
	\begin{equation*}
		\lambda \leqslant p_A(x) + \varepsilon ~,~ \mu \leqslant p_A(y) + \varepsilon,
	\end{equation*}
	By convexity of $A$, $\lambda A + \mu A \subset (\lambda + \mu) A$. Thus,
	\begin{equation*}
		p_A(x) = \inff{\{~ \delta > 0 \colon x+y \in \delta A ~\}} \leqslant \lambda + \mu \leqslant p_A(x) + p_A(y) + 2\varepsilon
	\end{equation*}
	$\Rightarrow ~ p_A(x)$ is a seminorm.
	\begin{center}
		\begin{tabular}{r c l}
			$x \in \inte{U}_{p_A}$ & $\Rightarrow$ & $\exists ~ \lambda \in [0,1] ~s.t.~ x \in \lambda A \subset A$ \\
			$x \in A$ &  $\Rightarrow$  & $1 \in \inff\{~ \lambda > 0 \colon x \in \lambda A ~\} ~ \Rightarrow ~ p_A(x) \leqslant 1 \Rightarrow x \in U_{p_A}$
		\end{tabular}
	\end{center}
	That means $\inte{U}_{p_A} \subset A \subset U_{p_A}$.\\
	Finally, the statements for $q$ can be obtained easily by the definition.
\end{proof}

Now, we can give the definition of a locally convex t.v.s. by seminorms coinciding with the definition by convex sets.

\begin{thm}
	Let $X$ be a vector space and $\mathscr{P} = \{p_i\}_{i \in I}$ be a family of seminorms. Then the initial topology $\mathscr{T}_P$ generated by $\mathscr{P}$ makes $X$ be a locally convex t.v.s. In fact, the basis of neighbouhoods of the origin in $X$ is like
	\begin{equation*}
		\mathscr{B} = \left\{~ \{x \in X \colon p_{i_1}(x)<\varepsilon,\cdots,p_{i_n}(x)<\varepsilon\} \colon i_1,\cdots,i_n \in I,n \in \N, \varepsilon > 0 ~\right\}
	\end{equation*}
	Conversely, the topology of any locally convex t.v.s. can be generated by a family of seminorms.
\end{thm}
\begin{proof}
	Each element in the subbasis of $\mathscr{T}_P$ is like $\{ x \in X \colon p_i(x) < \varepsilon \} = \varepsilon \inte{U}_{p_i}$, which is clearly absorbing and absolutely convex. Therefore, every element in $\mathscr{B}$ is convex. $(X,\mathscr{T}_P)$ is a locally convex t.v.s..\\
	Convesrly, if $(X, \mathscr{T})$ is a locally convex t.v.s., the basis of neighbourhoods of the origin in $X$ consists of absorbing and absolutely convex stes, which can generate a family of seminorms by above proposition. Therefore, these seminorms can generate a locolly convex topology $\mathscr{T}_P$. In fact, $\mathscr{T}_P = \mathscr{T}$, since $\inte{U}_{p_A} \subset A \subset U_{p_A}$.
\end{proof}
\begin{rem}
	By this theorem, in a vector space $X$, the seminorms on $X$ can coincide with a locally convex topology making $X$ be a t.v.s..
\end{rem}

There some extra properties for the seminorms on a vector space.
\begin{prop} \label{prop1}
	Let $X$ be a vector space and $p$ be a seminorm on $X$. Then,
	\begin{enumerate}[label=\arabic*)]
		\item $\forall~ r>0,~ r \inte{U}_p=\{x \in X \colon p(x) <r\} = \inte{U}_{\frac{1}{r}p}$.
		\item $\forall x \in X,~ x+\inte{U}_p = \{y \in X \colon p(y-x) < 1\}$.
		\item if $q$ is a seminorm on $X$, $p \leqslant q \Leftrightarrow \inte{U}_q \subset \inte{U}_p$.
		\item if $\{s_i\}_{i=1}^{n}$ are seminorms on $X$, then $s(x) = \max_{i=1,\cdots,n}{s_i(x)}$ is also a seminorm and $\inte{U}_s = \bigcap_{i=1}^{n} \inte{U}_{s_i}$
	\end{enumerate}
\end{prop}

\begin{thm}
	Let $\mathscr{P} = \{p_i\}_{i \in I}$ and $\mathscr{Q} = \{q_j\}_{j \in J}$ be two families of seminorms on a vector space $X$ inducing $\mathscr{T}_P$ and $\mathscr{T}_Q$, then
	\begin{equation*}
		\mathscr{T}_Q \subset \mathscr{T}_P \Leftrightarrow \forall~ q \in \mathscr{Q},~ \exists~ \{i_k\}_{k=1}^{n} \subset I,~ \exists~ C>0,~s.t.~ Cq(x) \leqslant \max_{k=1,\cdots,n}{p_{i_k}(x)}
	\end{equation*}
\end{thm}
\begin{proof}
	This right side of above statement is equivalent to that
	\begin{equation*}
		\forall~ q \in \mathscr{Q},~ \exists~ \{i_k\}_{k=1}^{n} \subset I,~ \exists~ C>0,~s.t.~ C \bigcap_{k=1}^{n} \inte{U}_{p_{i_k}} \subset \inte{U}_q
	\end{equation*}
	So, it is clearly equivalent to $\mathscr{T}_Q \subset \mathscr{T}_P$.
\end{proof}
\begin{rem}
	Because of this, we have the definition of equivalent norms. In fact, two norms $p$ and $q$ are said to be equivalent if and only if there exists $C_1,~ C_2 > 0$, s.t. $C_1p(x) \leqslant q(x) \leqslant C_2 p(x)$, for all $x \in X$. This definition means that two equivalent norms can generate one same topology. 
\end{rem}
\begin{cor} \label{cor1}
	The family $\mathscr{P} = \{p_i\}_{i \in I}$ of seminorms and \\$\mathscr{Q} = \{~ \max_{i \in B} p_i \colon \varnothing \neq B \subset I \text{ with } B \text{ finite} ~\}$ can generate one same topology on $X$
\end{cor}

\subsection{Separability and Metrizability}

For a t.v.s., $(T_1)$ is equivalent to Hausdorff and $(T_1)$ is associated with the ability of a topology separating points. Therefore, wheather a t.v.s. is a Hausdorff space or not is completely determined by wheather the topology of it can separate points or not. Then for a locally convex t.v.s., whose topology is induced by a family of seminorms, this separability is related to these seminorms.

\begin{defn}
	A family of seminorms $\mathscr{P} = \{~p_i~\}_{i \in I}$ on a vector space $X$ is said to be speparating, if
	\begin{equation*}
		\forall~ x \in X \backslash \{0\},~ \exists~ i \in I ~s.t.~ p_i(x) \neq 0
	\end{equation*}
\end{defn}
\begin{rem}
	In fact, above condition is equivalent to 
	\begin{equation*}
		\text{if } p_i(x) = 0, ~\forall~ i \in I \Rightarrow x = 0
	\end{equation*}
\end{rem}	

Now, we can give the condition that makes a locally convex t.v.s. be Hausdorff.

\begin{thm} 
	A locally convex t.v.s. $X$ is Hausdorff if and only if its topology can be induced by a separating family of seminorms $\mathscr{P} = \{~p_i~\}_{i \in I}$ .
\end{thm}
\begin{proof}
	If $\mathscr{P} = \{~p_i~\}_{i \in I}$ is separating, the fact that $\mathscr{T}_P$ is Hausdorff can be obtained easily by the definition.\\
	Conversely, if $X$ is Hausdorff, for $x \neq 0$, we can find a $U \in \mathscr{F}(0)$, s.t. $U$ can separate $x$ and $0$. But since $X$ is locally convex, $U$ can be chosen as $\inte{U}_p$ for a seminorm $p$. Thus, for this $p$, $p(x) \neq 0$.
\end{proof}

For the metrizability of a locally convex t.v.s., the consequece is also easier than general case.
\begin{thm} \label{thm4}
	A locally convex t.v.s. $X$ is metrizable if and only if its topology is determined by a countable separating family of seminorms.
\end{thm}
\begin{proof}
	It can be directly obtained by the Nagata–Smirnov's Metrization Theorem. Also, there is a more explicit proof. If the topology of $X$ is generated by a countable separating family of seminorms $\mathscr{P} = \{~p_n~\}_{n=1}^{\infty}$, we can define the metric $d$ on $X$ by
	\begin{equation*}
		d(x,y) = \sum_{n=1}^{\infty} 2^{-n} \frac{p_n(x-y)}{1+p_n(x-y)}
	\end{equation*} 
	Conversely, if $(X,d)$ is the metric space, the subbasis of the topology generated by this metric is like $U_n = \{x \colon d(x,0) < 1/n\}$. And these $U_n$ can provide a countable separating family of seminorms. In fact, if $\mathscr{Q} = \{~q_i~\}_{i \in I}$ generates the topology of $X$, for each $U_n$, there are $q_1,\cdots,q_k \in \mathscr{Q}$ and $\varepsilon_1,\cdots,\varepsilon_k > 0$, s.t. $\bigcap_{i=1}^{k} \{x \colon q_i(x) < \varepsilon_i\} \subset U_n$. Then let $p_n = \sum_{i=1}^{k} \varepsilon_i^{-1}q_i$. It can check that the family $\{p_n\}_{n=1}^{\infty}$ generate the coincided topology on $X$.
\end{proof}

\subsection{Continuous Linear Maps on LCTVS}

To give the special property of continuous linear maps on LCTVS, we need firstly refine the family of seminorms.
\begin{defn}
	A family $\mathscr{Q} = \{~q_j~\}_{j \in J}$ of seminorms on a vector space $X$ is said to be directed if
	\begin{equation*}
		\forall ~ j_1, \cdots, j_n \in \mathscr{Q},~ \exists ~ j \in J ~\&~ C>0,~ s.t.~ C q_j(x) \geqslant \max_{k=1,\cdots,n} q_{j_k}(x),~ \forall~ x \in X
	\end{equation*}
\end{defn}
\begin{rem}
	By \textbf{Proposition} \ref{prop1} in \textbf{1.2.2}, this definition is equivalent to that
	\begin{equation*}
		\forall~ \inte{U}_{q_{j_1}}, \cdots, \inte{U}_{q_{j_n}},~ \exists~ \inte{U}_{q_j} ~s.t.~ \inte{U}_{q_j} \subset \bigcap_{k=1}^{n} \inte{U}_{j_i}
	\end{equation*}
	And thus the basis of this directed family of seminorms should be like
	\begin{equation*}
		\mathscr{B}_d = \{~ r\inte{U}_q \colon q \in \mathscr{Q},r>0 ~\}
	\end{equation*}
\end{rem}

By this special topology, we can find the condition making linear functional continuous.

\begin{prop}
	Let $\mathscr{T}$ be a locally convex topology on a vector space $X$ generated by a directed family $\mathscr{Q}$ of seminorms on $X$. Then
	\begin{equation*}
		L \colon ~ X \longrightarrow \K
	\end{equation*}
	is a $\mathscr{T}$-continuous linear functional if and only if $\exists ~ q \in \mathscr{Q}$ s.t. $L$ is $q$-continuous, i.e. $\abs{L(x)} \leqslant Cq(x)$ for some $C > 0$.
\end{prop}
\begin{proof}
	In fact, this property of continuous linear functional is because the element in a directed locally convex topology is like $r\inte{U}_q$. In fact, we just need to check the origin point.\\
	If $L$ is continuous, there exists a $r\inte{U}_q$ s.t. $r\inte{U}_q \subset L^{-1}(B_1(0))$, where $B_1(0)$ is the unit ball centered at $0$. This is equivalent to the $q$-continuity of $L$.\\
	Conversely, it is clearly by the fact $\mathscr{T}_q \subset \mathscr{T}$.
\end{proof}

We can easily see that the topology of a locally convex t.v.s. can be always induced by a directed family of seminorms by the \textbf{Corollary} \ref{cor1} in \textbf{1.2.2}. Thus, we have the corollary.

\begin{cor} \label{cor3}
	$(X,\mathscr{T})$ is a locally convex t.v.s. and $\mathscr{T}$ is generated by the family $\mathscr{P} = \{p_i\}_{i \in I}$. Then $L \colon ~ X \longrightarrow \K$ is a continuous linear functional if and only if 
	\begin{equation*}
		\exists ~ i_1,\cdots,i_n \in I,~ \exists ~ C>0 ~s.t.~ \abs{L(x)} \leqslant C \max_{k=1,\cdots,n} p_{i_k}(x),~ \forall ~ x \in X
	\end{equation*}
\end{cor}

And this corollary can be easily extended to linear maps. And the proof is similar as above statement In fact, we just need to replace $B_1(0)$ by $\inte{U}_q$
\begin{thm} \label{thm2}
	Let $X$ and $Y$ be two locally convex t.v.s.'s generated by $\mathscr{P}$ and $\mathscr{Q}$. Then linear map $f \colon X \sto Y$ is continuous if and only if 
	\begin{equation*}
		\forall ~ q \in \mathscr{Q},~ \exists ~ p_1,\cdots,p_n \in \mathscr{P},~ \exists ~ C>0 ~s.t.~ q(f(x)) \leqslant C \max_{i=1,\cdots,n} p_i(x)
	\end{equation*}
\end{thm}

\section{The Hahn-Banach Theorem}

\subsection{Two Forms of Hahn-Banach Theorem}

\begin{thm}[Geometric form]
	Let $X$ be a t.v.s. over $\K$, $N$ be a linear subspace of $X$ and $\Omega$ be a convex open subset of $X$ with $N \bigcap \Omega = \varnothing$. Then there is a closed hyperplane $H$ of $X$ s.t.
	\begin{equation*}
		N \subset H ~~\&~~ H \bigcap \Omega = \varnothing
	\end{equation*}
\end{thm}
\begin{proof}
	Assume that $\Omega \neq \varnothing$.\\
    Let $\mathscr{F} = \{~ \text{all linear subspace } L \text{ of } X \text{ s.t. } N \subset L \text{ and } L \bigcap \Omega = \varnothing ~\}$. \\
	Since $N \in \mathscr{F}$, $\mathscr{F} \neq \varnothing$. And $\mathscr{F}$ can be ordered by "$\subset$". Clearly, for every chain $\mathscr{C} = \{C_i\}_{i \in I} \in \mathscr{F}$, it has a maximal element $C = \bigcup_{i \in I} C_i \in \mathscr{F}$. Then by Zorn's Lemma, there exists a maximal $H \in \mathscr{F}$. And this $H$ is closed because the maximality of $H$.\\
	In fact, we just need to check $\dim{X/H} = 1$. In the case $\K = \R$, if $\dim{X/H} \geqslant 2$, then we can find one dimensional subspace $L$ in $X$ s.t. $L \oplus H$ satisfies above condition. Then it is a contradiction to the maximality of $H$. And for $\K = \C$, using above process to get a real hyperplane $H_0$ and then $H = H_0 \bigcap iH_0$ is the hyperplane we need.\\
	The main difficulty of this proof is to construct $L$. In fact, we just need to find a line $\tilde{L}$ in $X/H$ s.t. $\tilde{L} \bigcap A = \varnothing$, where$A = \bigcup_{\lambda > 0} \lambda \pi(\Omega)$ is a cone. This $\tilde{L}$ can easily be found because we can find $\clo{x}, -\clo{x} \in X/H \backslash A$ with $\clo{x} \neq \clo{0}$ by using the fact that $\dim{X/H} \geqslant 2$.
\end{proof}
\begin{rem}
	In this theorem, if $N$ is an affine linear subspace, then the $H$ can be chosen as a affine hyperplane satisfying above condition. It is clear by using translation.
\end{rem}

\begin{thm}[Analitic form]
	Let $p$ be a seminorm on a vector space $X$ over $\K$, $M$ is a linear space of $X$ and f is a linear functional on $M$ s.t. $\abs{f(x)} \leqslant p(x),~ \forall~ x \in M$. Then there is a linear function $\tilde{f}$ on $X$ s.t. $\tilde{f}(x) = f(x),~ \forall~ x \in M$ and $\abs{\tilde{f}(x)} \leqslant p(x),~ \forall~ x \in X$.
\end{thm}
\begin{proof}
	Let $N = \{x \in M \colon f(x) = 1\}$(affine hyperplane) and $\Omega = \{x \in X \colon  p(x) < 1\}$(open convex set). Then since $N \bigcap \Omega$, we can find a closed affine hyperplane $H$ of $X$, s.t. $N \subset H$ and $H \bigcap \Omega = \varnothing$. Fixed $x_0 \in N \subset H$, $H-x_0$ is a hyperplane, thus it can generate a functional $\tilde{f}$ on $X$. Set $\tilde{f}(x_0) = 1$, then define
	\begin{center}
		\begin{tabular}{l c c l}
			$\tilde{f}~\colon$ & $X=(H-x_0) \oplus \K x_0$ & $\longrightarrow$ & $\K$ \\
			$~$ & $(h-x_0)+\lambda x_0$ & $\longmapsto$ & $\lambda$
		\end{tabular}
	\end{center}
	Since $M = (N-x_0) \oplus \K x_0$ and $f(x_0) = 1$ and $H \bigcap \Omega = \varnothing$, we can easily check that $\tilde{f}(x) = f(x),~ \forall~ x \in M$ and $\abs{\tilde{f}(x)} \leqslant p(x),~ \forall~ x \in X$.
\end{proof}

\subsection{Applications}
By the geometric form of the Hahn-Banach Theorem, it says about hyperplanes can separate some non-intersecting subsets. And moreover, by the analytic form of the Hahn-Banach Theorem, since hyperplanes are linked with functionals, functionals can also separate some some non-intersecting subsets in a t.v.s. First, we can define this association more explicit.

\begin{defn}
	Let $X$ be a t.v.s. over $\R$ and $H$ is a closed affine hyperplane. For $A,~B \subset X$ and $A \bigcap B = \varnothing$, we say $A$ and $B$ separated by $H$, if
	\begin{equation*}
		\exists~ a \in \R,~ s.t.~ H = f^{-1}(\{a\}) \text{ for some } f \colon X \sto \R ~\&~ f(A) \geqslant a,~ f(B) \leqslant  a.
	\end{equation*}
\end{defn}
 
\begin{thm}
	Let $X$ be a t.v.s. over $\R$ and $A,~ B$ be two disjoint convex non-empty subsets of $X$, then we have:
	\begin{enumerate}[label=\arabic*)]
		\item if $A$ is open, then there exists a closed affine hyperplane $H$ of $X$ separating $A$ and $B$.
		\item if $A, B$ are open, $H$ can strictly separate $A$ and $B$.
		\item if $A$ is a cone and $B$ is open, then $H$ can be chosen as a hyperplane.
	\end{enumerate}
\end{thm}
\begin{proof}
	Let $U=A-B$. Clearly, U is open and convex and $N=\{0\} \bigcap H = \varnothing$. Therefore, there exists a continuous functional $f$ on $X$, s.t. $f(U) > 0$ i.e. $f(x) > f(y),~ \forall~ x \in A ~\&~ y \in B$. Since $B \neq \varnothing$, let $a = \inff_{x \in A} f(x) > -\infty$. And thus $1)$ and $2)$ can be obtained. \\
	For $3)$, if $A$ is a cone, then $tf(x) = f(tx) \geqslant a,~ \forall~ t > 0 \Rightarrow f(x) \geqslant \frac{a}{t}$. Thus, $f(A) \geqslant 0$. $H$ can be chosen as a hyperplane. 
\end{proof}

For a locally convex t.v.s $X$, each point in $X$ has some convex heighbourhoods. Therefore, we have following corollaries.

\begin{cor} \label{cor2}
	Let $X$ be a locally convex t.v.s over $\R$.
	\begin{enumerate}[label=\arabic*)]
		\item If $A$ and $B$ are two disjoint closed subsets and $B$ is compact, then $A$ and $B$ are strictly separated.
		\item If A is a closed convex subset of $X$ and $x \notin A$, then x is strictly separated from $A$.
		\item If $A$ is a subset of $X$, then $\clo{\spn{\{A\}}}$ is the intersection of all closed hyperplanes containing $A$.
	\end{enumerate}
\end{cor}

And these consequenses can be extended to $\C$.

\begin{thm} \label{thm3}
	Let $X$ be a locally convex t.v.s over $\C$ and $A,B$ be two disjoint closed convex subsets of $X$. If $B$ is compact, then there is a continuous linear functional $f \colon X \sto \C$, and $\alpha \in \R$, and $\varepsilon > 0$ s.t.
	\begin{equation*}
		\Rea{f(x)} \leqslant \alpha < \alpha +\varepsilon \leqslant \Rea{f(y)},~ \forall~ x \in A,~ \forall~ y \in B
	\end{equation*} 
\end{thm}

\section{Banach Spaces}

The Banach space is a very special locally convex topological space, whose topology is generated by only one seminorm. To make this space be a Hausdorff space, this seminorm is actually a norm. And more, we need it become complete. So, a Banach space is a complete normed space. Because it is definitely a locally convex Hausdorff t.v.s., all results mentioned above can be apllied on it. And we can have more interesting results of the Banach space because of its simple structure.

\subsection{Elementary Properties}

\begin{defn}
	A normed space is a vector space $X$ with a compatible norm $\norm{\cdot}$, which makes it be a locally convex Hausdorff topological vector space. A Banach space is a complete normed space.
\end{defn}
\begin{rem}
	By this definition, we know that any result mentioned above can be also true for the Banach space $(X,\norm{\cdot})$ by replacing the family of seminorms by the $\norm{\cdot}$. Moreover, two equivalent norms on $X$ provide same topology.
\end{rem}

The properties of finite dimensional Banach spaces is in the subsection \textbf{1.1.5}. And for the quotient space of a Banach space, we can get a more explicit expression of the induced quotient norm.

\begin{thm}
	Let $(X, \norm{\cdot})$ be a Banach space and $M$ be a closed linear subspace of $X$ and $\pi \colon X \sto X/M$, then the induced quotient norm on $X/M$ is defined as $\norm{x+M} = \inff{\{\norm{x+y} \colon y \in M\}}$. Thus, using the consequences of the quotient t.v.s., we have following results.
	\begin{enumerate}[label=\arabic*)]
		\item $\pi$ is continuous and $\norm{\pi(x)} \leqslant \norm{x}$.
		\item $X/M$ is a Banach space.
		\item $W \subset X/M$ is open if and only if $\pi^{-1}(W)$ is open.
		\item $\pi$ is open.
		\item if $N$ is a finite dimensional subspace of $X$, then $M+N$ is closed.
	\end{enumerate}
\end{thm}
\begin{proof}
	The element in the subbasis of the topology generated by $\norm{\cdot}$ at $0$ is like $U_\varepsilon=\{x \in X \colon \norm{x} < \varepsilon\}$ for a fixed $\varepsilon > 0$. Therefore, the element $V_\epsilon$ in the subbasis of the induced topology on $X/M$ at $0$ satisfies $\pi^{-1}(V_\epsilon)=\{x \colon \norm{x} < \epsilon\}$ for some $\epsilon > 0$, i.e. $V_\epsilon = \{x+M \colon \norm{x+y_0} < \epsilon, \exists y_0 \in M\}$ .Clearly, $V_\epsilon$ is an absorbing absolutely convex set. Then the Minkowski functional $p_\epsilon$ of $V_\epsilon$ is like
	\begin{eqnarray*}
		p_\epsilon(x+M) &=& \inff \{\lambda > 0 \colon x+M \in \lambda V_\epsilon\} \\
					 &=& \inff \{\lambda > 0 \colon \norm{x+y_0} < \lambda \epsilon,\exists y_0 \in M \} \\
					 &=& \frac{1}{\epsilon} \inff \{{\norm{x+y} \colon y \in M}\}
	\end{eqnarray*}
	Clearly, for any $\epsilon > 0$, $p_\epsilon$ is a norm and it is equivalent to the norm $\norm{x+M}$. Thus the quotient topology is definitely generated by $\norm{x+M}$.\\
	Then, $1)$ and $3)$ clearly hold by the definition. $2)$ is true since $H$ is a Banach space. $4)$ is true for any general t.v.s.. $5)$ holds since $N+M$ is a finite dimensional subspace of $X/M$. 
\end{proof}

Similarly, we can define the norm on the product space of some Banach spaces.
\begin{defn}
	Let $\{X_i\}_{i=1}^{p}$ is a family of Banach spaces with norm $\norm{\cdot}$. Then,
	\begin{enumerate}[label=\arabic*)]
		\item if $1 \leqslant p < \infty$, 
				\begin{equation*}
					\oplus_{i=1}^{p} X_i = \left\{~ x \in \prod_{i}^{p} X_i \colon \norm{x} = \left[ \sum_{i=1}^p \norm{x_i}^p\right]^{1/p} ~\right\}
				\end{equation*}
		\item if $p = \infty$,
				\begin{equation*}
					\oplus_{i=1}^{\infty} X_i = \left\{~ x \in \prod_{i}^{p} X_i \colon \norm{x} = \sup_i \{x(i)\} < \infty ~\right\}
				\end{equation*}
	\end{enumerate}
\end{defn}

\subsection{Linear Transformations and Linear Functionals}

By results in \textbf{Theorem} \ref{thm2} in the subsection \textbf{1.2.4} the linear transformation $T \colon X \sto Y$ between two Banach spaces is continuous if and only if $\exists~ C > 0$, s.t. $\norm{Tx} \leqslant \norm{x}$, $\forall~ x \in X$. Because of this property, we can define the norm of continuous linear transformation.

\begin{defn}
	Let $T \colon X \sto Y$ between two Banach spaces be a linear transformation. Then the norm of $T$ is defined as
	\begin{equation*}
		\norm{T} = \sup_{x \in X,x \neq 0} \frac{\norm{Tx}}{\norm{x}}
	\end{equation*}
\end{defn}
\begin{rem}
	By this definition, we know $T$ is continuous if and only if $\norm{T} < \infty$, and we call $T$ is bounded. Also, the formula of the norm can be
	\begin{equation*}
		\norm{T} = \sup_{\norm{x} = 1} \frac{\norm{Tx}}{\norm{x}}
	\end{equation*}
\end{rem}

Let $\fml{B}(X,Y)=$\{all bounded linear transformations between $X$ and $Y$\}. $\fml{B}(X,Y)$ is a Banach space with this norm. Then in the space $\fml{B}(X,Y)$, there are two topologies. The first one is generated by a family of seminorms $\{p_x\}_{x \in X}$, where $p_x(T) = \norm{Tx}$. And the second one is generated by the norm $\norm{\cdot}$. In fact, the convergence of a sequense in $\fml{B}(X,Y)$ with respect to the first one is about pointwise convergence, and with respect to the second one is about uniform convergence. Clearly, the second one is stronger. But in some case the first one can give some information of the first one.

\begin{thm}[The Principle of Uniform Boundedness]
	Let $X$ be a Banach space and $Y$ be a normed space, and $\{T_i\}_{i \in I}$ be a subset of $\fml{B}(X,Y)$. If for any $x \in X$ $\{\norm{T_i x}\}_{i \in I}$ is bounded, then $\{\norm{T_i}\}_{i \in I}$ is bounded.
\end{thm}
\begin{proof}
	Firstly, there is a open ball $B(x_0, \varepsilon)$ such that for any $x \in B(x_0, \varepsilon)$, $\norm{T_i}x \leqslant K$ for some constant $K$. Asssume it is not true. We can find a family of open balls $B(x_n, \varepsilon_n)$ s.t. $B(x_n, \varepsilon_n) \subset B(x_{n-1}, \varepsilon_{n-1})$, $\varepsilon_n < 1/n$, and a sequence ${i_n} \subset I$, satisfying $\norm{T_{i_n}x} > n$. And since each $\clo{B(x_n, \varepsilon_n)}$ is compact, there is a $z \in \bigcap_{n=1}^{\infty} \clo{B(x_n, \varepsilon_n)}$. This contradicts to the boundedness of $\{T_i z\}_{i \in I}$.\\
	Next, with this $B(x_0, \varepsilon)$, if $y \in X$ and $y \neq 0$, then $z = \frac{\varepsilon}{\norm{y}}y + x_0 \in B(x_0, \varepsilon)$. Therefore,
	\begin{equation*}
		\frac{\varepsilon}{\norm{y}} \norm{T_i y} - \norm{T_i x_0} \leqslant \norm{\frac{\varepsilon}{\norm{y}} \norm{T_i y} + \norm{T_i x_0}} = \norm{T_i z} \leqslant K
	\end{equation*}
	Then since $K^{'} = \sup_{i \in I}{\norm{T_i x_0}} < \infty$, 
	\begin{equation*}
		\norm{T_i y} \leqslant \frac{K+K^{'}}{\varepsilon} \norm{y} < \infty
	\end{equation*}
	Thus ${\norm{T_i}}_{i \in I}$ is bounded.
\end{proof}
\begin{rem}
	Let $X^{*} = \fml{B}(X,\K)$ be the continuous linear functional space. Above theorem can easily apply to it.
\end{rem}
\begin{cor}
	For a Banach space $X$ and $S \subset X^{*}$ a subset, $S$ is norme bounded if and only if for every $x \in X$, $\sup\{\abs{f(x)} \colon f \in S\}$.
\end{cor}

Another important property of the linear transformation betweeen two Banach spaces is that any continuous linear surjective transformation is open.

\begin{thm}[Open Mapping Theorem]
	Let $X$ and $Y$ be two Banach spaces and $T \colon X \sto Y$ be a continuous linear surjection. Then $T$ is open.
\end{thm}
\begin{proof}
	Let $X_\varepsilon$ and $Y_\varepsilon$ be two open balls in $X$ and $Y$ with centering at 0 and and radius $\varepsilon$.
	\begin{enumerate}[label=\arabic*)]
		\item For any $\varepsilon > 0$, there is a $\delta > 0$, s.t. $Y_{\delta} \subset \clo{T(X_{\varepsilon})}$. \\
		By $X = \bigcup_{n=1}^{\infty} n X_{\varepsilon}$, $Y=\bigcup_{n=1}^{\infty} T(nX_{\varepsilon})$. Then since $Y$ is the second Baire category, there exists $n_0$ and a ball $B_r(z) \subset Y$ s.t. $B_r(z) \subset \clo{T(n_0X_{\varepsilon})}$ i.e. $B_{\delta}(y_0) \subset \clo{T(X_{\varepsilon})}$ with $\delta = r/n$ and $y_0 = z/n$. Then since for any $y \in Y_{\delta}$, $y = (y+y_0) - y_0$
		\begin{equation*}
			Y_{\delta} \subset \{y_1-y_2 \colon y_1,y_2 \in B_{\delta}(y_0)\} \subset \clo{T(\{x_1-x_2 \colon x_1,x_2 \in X_{\varepsilon}\})} \subset \clo{T(X_{2\varepsilon})}
		\end{equation*}
		\item For any $\varepsilon_0 > 0$, there is a $\delta_0 > 0$, s.t. $Y_{\delta_0} \subset T(X_{2\varepsilon_0})$. \\
		Choose a positive sequence $\{\varepsilon_n\}$ with $\sum_{n=1}^{\infty} \varepsilon_n < \varepsilon_0$, then there exists a positive sequence $\delta_n$ with $\delta_n \sto 0$ s.t. $Y_{\delta_n} \subset \clo{T(X_{\varepsilon_n})}$\\
		For any $y \in Y_{\delta_0}$, there is a $x_0 \in X_{\varepsilon_0}$, s.t. $\norm{y-Tx_0} < \delta_1$. since $y-Tx_0 \in Y_{\delta_0}$, there is a $x_1 \in X_{\varepsilon_1}$ s.t. $norm{y-Tx_0-Tx_1} < \delta_2$. Thus by induction, we can find a sequence $\{x_n\}$ s.t. $x_n \in X_{\varepsilon_n}$ and
		\begin{equation*}
			 \norm{y-T\left(\sum_{k=0}^{n}x_k\right)} < \delta_{n+1}
		\end{equation*}
		And since $\sum_{n=1}^{\infty} \varepsilon_n < \varepsilon_0$, the sequence $\sum_{k=0}^{n}x_k$ absolutely converges to $x$ in $X$. And
		\begin{equation*}
			\norm{x} \leqslant \sum_{n=1}^{\infty} \norm{x_n} \leqslant \sum_{n=1}^{\infty} \varepsilon_n < 2 \varepsilon_0
		\end{equation*}
		By the continuity of $T$ and $\delta_n \sto 0$, $y=Tx$. Therefore, $Y_{\delta_0} \subset T(X_{2\varepsilon_0})$.
		\item For any open set $G \subset X$ and $y_0 = Tx_0$ with $x_0 \in G$, there is a open ball $Y_\delta$ s.t. $y_0 + Y_\delta \subset T(G)$.\\
		Since $G$ is open, there is a open ball $X_\varepsilon$ with $x_0+X_\varepsilon \subset G$. Then there is a $\delta > 0$ s.t. $Y_{\delta} \subset T(X_\varepsilon)$. Thus
		\begin{equation*}
			y_0+Y_{\delta} \subset Tx_0 + T(X_{\varepsilon}) = T(x_0 + X_{\varepsilon}) \subset T(G)  \qedhere
		\end{equation*}
	\end{enumerate}
\end{proof}

Then there is a directed corollary from the Open Mapping Theorem.
\begin{cor}[The Inverse Mapping Theorem]
	Let $X$ and $Y$ be two Banach spaces and $T \colon X \sto Y$ be a continuous linear isomorphism, then $T^{-1}$ is also bounded.
\end{cor}

\begin{cor}[The Closed Graph Theorem]
	Let $X$ and $Y$ be two Banach spaces and $T \colon X \sto Y$ be a linear transformation. If the graph of $T$, $G = \{x \oplus Tx \colon x \in X\}$ is closed, then $T$ is continuous.
\end{cor}
\begin{proof}
	Since $X$ and $Y$ are two Banach spaces and $G$ is closed, $G$ is also a Banach space. Let $P_1 \colon G \sto X$ be $P_1(x \oplus Tx)=x$ and $P_2 \colon G \sto Y$ be $P_2(x \oplus Tx)=Tx$. Then $P_1$ is bounded and bijective. Therefore, by the Inverse Mapping Theorem, $P_1^{-1} \colon X \sto G$ is continuous. Since $P_2$ is also continuous, $A=P_2 \circ P_1^{-1}$ is continuous.
\end{proof}

The next important theorem is Hahn-Banach Theorem. We have known the Hahn-Banach Theorem holds in any general t.v.s.. But for the Banach space, it can induce some interesting corollaries of the bounded linear functional space. 

\begin{cor}
	Let $X$ be a Banach space. Then, 
	\begin{enumerate}[label=\arabic*)]
		\item if $\{x_i\}_{i=1}^{d}$ is a linearly independent in $X$, and $\{\alpha_i\}_{i=1}^{d}$ are arbitrary scalars, then there is a $f \in X^{*}$ s.t. $f(x_i) = \alpha_i$ for $i=1,\cdots,d$.
		\item if $Y$ is a linear subspace of $X$ and $x_0 \in X$ with $\inff\{\norm{x_0-y} \colon y \in Y \} = d > 0$, then there is a $f \in X^{*}$ s.t. $f(x_0) = 1$ and $f(y) = 0 ~\forall~ y \in Y$ and $\norm{f}=d^{-1}$.
		\item if $x \in X$, then
			\begin{equation*}
				\norm{x} = \sup_{\norm{f} \neq 0} \frac{\abs{f(x)}}{\norm{f}} = \sup \{\abs{f(x)} \colon f \in X^{*},~ \norm{f} \leqslant 1 \}
			\end{equation*}
		\item if $x \neq y$ in $X$, then there is a $f \in X^{*}$ s.t. $f(x) \neq f(y)$.
		\item if $Y$ is a linear subspace of $X$ and $Y$ is not dense, then there is $f \in X^{*}$ with $f \neq 0$ s.t. $f(y) = 0 ~\forall~ y \in Y$.
		\item if $Y$ is a linear subspace of $X$, then
			\begin{equation*}
				\clo{Y} = \bigcap\{\ker{f} \colon f \in X^{*},~ Y \subset \ker{f}\}
			\end{equation*}
	\end{enumerate}
\end{cor}
\begin{proof}
	For $1)$, let $Y= \spn{\{x_i\}_{i=1}^{d}}$ and $g$ be a linear functional on $Y$ with $g(x_i) = \alpha_i$, then $g$ can extend to $f$.\\
	For $2)$, let $Y_1 = \spn{\{Y,\{x_0\}\}}$ and $g$ be a linear functional on $Y_1$ with $g(y+\lambda x_0) = \lambda$. \\Then since $\norm{y+\lambda x_0} = \abs{\lambda}\norm{\frac{1}{\lambda}y+x_0} \geqslant \abs{\lambda} d$, $\norm{g} \leqslant d^{-1}$. Let $\{y_n\} \in Y$ s.t.\\ $\norm{x_0-y_n} \sto d$, then $1 = g(x_0 - y_n) \leqslant \norm{g} \norm{x_0-y_n} \sto \norm{g} d$. \\Thus $\norm{g} = d^{-1}$. $g$ can extend to $f$ on $X$.\\
	For $3)$, clearly, $\norm{x} \geqslant \sup \{\abs{f(x)} \colon f \in X^{*},~ \norm{f} \leqslant 1 \}$. But by above proof, there is a $f(x) = \norm{x}$ with $\norm{f} = 1$.\\
	$4)$ and $5)$ can be easily obtained by the separability of continuous linear fuctionals and the fact that $X$ is locally convex.\\
	$6)$ is a special case of \textbf{Corollary} \ref{cor2} in the subsection \textbf{1.3.2}.
\end{proof}

For linear functionals on a general vector space, there is a interesting result.
\begin{prop} \label{prop2}
	Let $f$, $\{f_k\}_{k=1}^{n}$ be linear functionals on a vector space $X$. If $\bigcap_{k=1}^{n}\ker{f_k} \subset \ker{f}$, then there are scalars $\alpha_1,\cdots,\alpha_n$ such that $f = \sum_{k=1}^{n} f_k$.
\end{prop}
\begin{proof}
	Assume for $1 \leqslant k \leqslant n$, $\bigcap_{j \neq k} \ker{f_j} \neq \bigcap_{j=1}^{n} \ker{f_j}$.\\ Therefore, there is a $y_k \in \bigcap_{j \neq k} \ker{f_j}$ s.t. $y_k \notin \bigcap_{j=1}^{n} \ker{f_j}$, i.e. $f_j(y_k) = 0$ for $j \neq k$ and $f_k(y_k) \neq 0$. \\Thus we can find ${x_k}_{k=1}^{n}$, s.t. $f_k(x_k) = 1$ and $f_j(x_k)=0$ for $j \neq k$. \\Let $\alpha_k = f(x_k)$. For $x \in X$, let $y=x-\sum_{k=1}^{n} f_k(x)x_k$. \\Then $f_j(y)=f_j(x) - \sum_{k=1}^{n} f_k(x)f_j(x_k)=0$. Thus $f(y) = 0$, \\i.e. $f(x) = \sum_{k=1}^{n} \alpha_k f_k(x)$.
\end{proof}

\subsection{Weak Topologies}

In a Banach space $X$, $X^{*}$ denoted the set of all bounded linear functionals is also a Banach space with the induced norm. Then we can also find all bounded linear functionals on the space ($X^{*}$,$\norm{\cdot}$), denoted by $X^{**}$. By the Hahn-Banach Theorem, we can easily know the following proposition.

\begin{prop}
	Let $X$ be a Banach space. Then $X$ can be isometrically embeded in $X^{**}$.
\end{prop}
\begin{proof}
	Define the map $\phi$, where $\hat{x}(f) = f(x)$,
	\begin{center}
		\begin{tabular}{l r c l}
			$\phi \colon$ & $X$ & $\longrightarrow$ & $X^{**}$ \\
			~ & $x$ & $\longmapsto$ & $\hat{x} = \phi(x)$
		\end{tabular}
	\end{center}
	Then by the corollary of Hahn-Banach Theorem, $\norm{\hat{x}}=\norm{x}$.
\end{proof}
\begin{rem}
	In a special case, if $X^{**} = \hat{X}$, where $\hat{X} = \pi(X)$, then $X$ is called a reflexive space.
\end{rem}

For a Banach space $X$ and $X^{*}$, we can define different topologies.

\begin{defn}
	Let $X$ be a Banach space.
	\begin{enumerate}[label=\arabic*)]
		\item The weak topology on $X$, denoted by $wk$, is generated by the family of seminorms $\{p_f \colon f \in X^{*}\}$, where $p_f(x) = \abs{f(x)}$.
		\item The weak$^{*}$ topology on $X^{*}$, denoted by $wk^{*}$, is generated by the family of seminorms $\{p_x \colon x \in X\}$, where $p_x(f) = \abs{f(x)}$.
	\end{enumerate}
\end{defn}
\begin{rem}
	Since the $\abs{f(x)} \leqslant \norm{f}\norm{x}$, we can easily know $wk$ on $X$ and $wk^{*}$ on $X^{*}$ are weaker than the norm topology respectively. 
	\begin{enumerate}[label=\arabic*)]
		\item The subbasis of the weak topology at $x_0$ is like 
			\begin{equation*}
				U_\varepsilon(x_0) = \{x \in X \colon \abs{f(x-x_0)} < \varepsilon\}
			\end{equation*}
		Therefore, a net $\{x_\alpha\}$ in $X$ converges weakly to $x_0$ if and only if $f(x_\alpha) \sto f(x)$ for all $f \in X^{*}$.
		\item The subbasis of the weak$^{*}$ topology at $f_0$ is like
			\begin{equation*}
				V_\varepsilon(f_0) = \{f \in X^{*} \colon \abs{(f-f_0)(x)} < \varepsilon\}
			\end{equation*}
		Therefore, a net $\{f_\alpha\}$ in $X^{*}$ converges weakly to $f_0$ if and only if $f_\alpha(x) \sto f(x)$ for all $x \in X$.
	\end{enumerate}
\end{rem}

There are some easy properties between these two topologies and the respective norm topology.
\begin{prop}
	Let $X$ be a Banach space. Then we have
	\begin{enumerate}[label=\arabic*)]
		\item $(X,wk)^{*} = X^{*}$
		\item $(X^{*},wk^{*})^{*} = X$
		\item if $A \subset X$ is convex, then $\clo{A}=\clo{A}^{wk}$
	\end{enumerate}
\end{prop}
\begin{proof}
	$1)$ can be obtained easily by the fact that $wk$ is weaker than the norm topology and by the definition of continuous functionals.\\
	For $2)$, because of the \textbf{Corollary} \ref{cor3} in the subsction \textbf{1.2.4} and the \textbf{Propostion} \ref{prop1} in the subsection \textbf{1.2.2} and the \textbf{Propostion} \ref{prop2}. 
	\begin{eqnarray*}
		F \in (X^{*},wk^{*})^{*} &\Rightarrow& \abs{F(f)} \leqslant \sum_{i=1}^{n} \abs{\hat{x}_k} \text{ for some } \{\hat{x}_k\}_{k=1}^{n} \subset \hat{X} \\
		&\Rightarrow& \bigcap_{k=1}^{n}\ker{\hat{x}_k} \subset \ker{F} \Rightarrow F = \sum_{k=1}^{n} \alpha_k \hat{x}_k \in \hat{X} \cong X
	\end{eqnarray*}
	And the converse is because $wk^{*}$ is weaker than norm topology.\\
	For $3)$, because $wk$ is weaker than the norm topology, $\clo{A} \subset \clo{A}^{wk}$ . By the separability of continuous functionals in \textbf{Theorem} \ref{thm3} in the \textbf{1.3.2}, we can fine a $f \in X^{*}$ s.t. $f$ separates $\clo{A}$ and any $x \in X \backslash \clo{A}$ in using a positive real number $\alpha$. But $\clo{A} \subset B=\{y \in X \colon \Rea{f(y)} \leqslant \alpha\}$ and $B$ is clearly $wk$-closed. Therefore, $\clo{A}^{wk} \subset B$. $x \notin \clo{A}$ implies $x \notin B$, thus $x \notin \clo{A}^{wk}$, i.e. $\clo{A}^{wk} \subset \clo{A}$.
\end{proof}

Also, by the Hahn-Banach Theorem and the \textbf{Theorem} \ref{thm2} in the \textbf{1.2.4}, the bounded linear map can be charasterized as the following statement.
\begin{prop}
	Let $T \colon X \sto Y$ be a linear map between two Banach spaces. Then $T$ is bounded if and only if $T \colon (X,wk) \sto (Y,wk)$ is continuous.
\end{prop}
 
By the \textbf{Theorem} \ref{thm4} in the \textbf{1.2.3}, we can easily see how to make $X^{*}$ be $wk^{*}$-metrizable.

\begin{thm}
	If $X$ is a Banach space, then $X^{*}$ is $wk^{*}$-metrizable if and only if $X$ is separable.
\end{thm}
\begin{proof}
	It is because that $wk^{*}$ is generated by $\{p_x \colon x \in X\}$.
\end{proof}

Let $Y$ be a closed subspace a Banach space $X$. We can define the orthogonal complement of $Y$, $Y^{\bot} = \{f \in X^{*} \colon Y \subset \ker{f}\}$ (similar definition in $X^{*}$). Then we have the following theorem.

\begin{thm}
	If $Y$ is a closed subspace a Banach space $X$ and $\pi \colon X \sto X/Y$ is the quotient map, then
	\begin{enumerate}[label=\arabic*)]
		\item the following map is an isometric isomorphism, i.e. $X^{*}/Y^{\bot} \cong Y^{*}$.
			\begin{center}
				\begin{tabular}{l r c l}
					$\rho \colon$ & $X^{*}/Y^{\bot}$ & $\longrightarrow$ & $Y^{*}$ \\
					~ & $f+Y^{\bot}$ & $\longmapsto$ & $f|_Y$
				\end{tabular}
			\end{center}
		\item the the following map is an isometric isomorphism, i.e. $(X/Y)^{*} \cong Y^{\bot}$.
			\begin{center}
				\begin{tabular}{l c c l}
					$\kappa \colon$ & $(X/Y)^{*}$ & $\longrightarrow$ & $Y^{\bot}$ \\
					~ & $f$ & $\longmapsto$ & $f \circ \pi$
				\end{tabular}
			\end{center}
	\end{enumerate}
\end{thm}
\begin{proof}
	For $1)$, clearly, $\rho$ is linear and injective. Since for any $f \in X^{*}$ and $g \in Y^{\bot}$, 
	\begin{equation*}
		\norm{f|_Y} = \norm{(f+g)|_Y} \leqslant \norm{(f+g)}
	\end{equation*}
	we have $\norm{f|_Y} \leqslant \norm{f+Y^{\bot}}$. By the Hahn-Banach Theorem, for any $\phi \in Y^{*}$, there is a $f \in X^{*}$ with $f|_Y = \phi$ and $\norm{\phi} = \norm{f} \geqslant \norm{f+Y^{\bot}}$.\\
	For $2)$, clearly $\norm{\kappa(f)} \leqslant \norm{f}$. We can find a sequence ${x_n+y_n}$ with $x_n \in X$ and $y_n \in Y$ and $\norm{x_n+y_n}<1$ s.t. 
	\begin{equation*}
		\norm{\kappa(f)} \geqslant \abs{\kappa(f)(x_n+y_n)}=f(x_n+Y) \sto \norm{f} 
	\end{equation*}
	thus $\kappa$ is an isometry. And by the universal property of quotient map, in the \textbf{Propostion} \ref{prop3} in the subsection \textbf{1.1.3}, we can prove that $\kappa$ is surjective.
	\begin{center}
	\begin{tikzcd}
		X \arrow[r, "f"] \arrow[d, "\pi"]
			& \K\\
		X/\ker{f} \arrow[ru, "\tilde{f}"] \arrow[r,"i"]
			& X/Y \arrow[u,"f^{'}"]
	\end{tikzcd}
\end{center}
\end{proof}

We have an imprtant theorem to discribe the $wk^{*}$-compactness in dual space.

\begin{thm}[Alaoglu's Theorem]
	Let $X$ be a normed space, then the unit ball in $X^{*}$ is $wk^{*}$-compact.
\end{thm} 
\begin{proof}
	Let $D_x=\{\alpha \in \K \colon \abs{\alpha} \leqslant 1\}$ for any $x \in X$, then put $D=\prod_{x \in X} D_x$. By Tychonoff's Theorem, $D$ is compact. Let the unit ball in $X^{*}$ be denoted by $B$ and $\tau$ be defined as
	\begin{center}
		\begin{tabular}{l c c l}
			$\tau \colon$ & $B$ & $\longrightarrow$ & $D$ \\
			~ & $f$ & $\longmapsto$ & $\tau(f)$
		\end{tabular}
	\end{center}
	where $\tau(f)(x) = f(x)$. Then we can prove that $B$ is homeomorphic to $\tau(B)$ with respect to the induced topology of $D$ and $\tau(B)$ is closed in $D$. Thus $B$ is compact.
	\begin{enumerate}[label=\arabic*)]
		\item Injection: $\tau(f) = \tau(g) \Rightarrow f(x) = g(x) ~\forall~ x \in B \Rightarrow f = g$.
		\item Continuity: $f_i \sto f ~wk^{*} \Rightarrow \tau(f_i)(x) \sto \tau(f)(x) ~\forall~ x \in B \Rightarrow \tau(f_i) \sto \tau(f)$.
		\item Closedness: $\tau(f_i) \sto f \in D \Rightarrow f_i(x) \sto f(x) ~\forall~ x \in B$, then we extend $f$ by defining $\tilde{f}(x) = \alpha^{-1}f(\alpha x)$ for any $x \in X$ and $\alpha > 0$ with $\norm{\alpha x} \leqslant 1$. It is well-defined by the linearity. Then $\tilde{f} \in B$. $\tau(B)$ is closed, and $\tau(B)$ is complete.
		\item Homeorphism: $\tau \colon B \sto \tau(B)$ is continuous linear map between two Banach spaces. Thus it is a homeomorphism.
	\end{enumerate}
\end{proof}

\begin{cor}
	Let $X$ be a Banach space and $Y$ is a closed linear subspace of $X$.
	\begin{enumerate}[label=\arabic*)]
		\item $X$ is reflexive if and only if the unit ball in $X$ is weakly compact.
		\item If $X$ is reflexive and $x_0 \in X \backslash Y$, then there is a point $y_0 \in Y$ s.t. $\norm{x_0-y_0} = \inff{y-x_0 \colon y \in Y}$.
	\end{enumerate}
\end{cor}
\begin{proof}
	For $1)$, by above theorem, the unit ball in $X^{**}$ is $wk^{*}$-compact. Since $X=X^{**}$, the unit ball in $X$ is $wk$-compact. The converse is similar as above proof.\\
	For $2)$, $Y$ is $wk$-compact by above corollary. Since by the Hahn-Bnanch Theorem, for each $x$, we can find a $f \in X^{*}$ with $\norm{f}=1$ and $f(x)=x$. The map $x \mapsto \norm{x-x_0}$ is weakly lower semicontinuous. Therefore, there is a $y_0 \in Y$ s.t. $\norm{x_0-y_0} = \inff\{y-x_0 \colon y \in Y\}$.
\end{proof}

\subsection{Adjoint Operators} \label{sec1}

\begin{defn}
	Let $T \colon X \sto Y$ be a bounded linear map between two Banach spaces. Then the adjoint of operator of $T$ is defined as
		\begin{center}
			\begin{tabular}{l r c l}
				$T^{*} \colon$ & $Y^{*}$ & $\longrightarrow$ & $X^{*}$ \\
				~ & $f$ & $\longmapsto$ & $f \circ T$
			\end{tabular}
		\end{center}	
\end{defn}

There are some easy properties of the adjoint operator, which can be obtained by the definition.
\begin{prop} \label{prop4}
	Let $X$, $Y$ and $Z$ be three Banach spaces and\\ $T \in \fml{B}(X,Y), S \in \fml{B}(Y,Z)$. Then, we have
	\begin{enumerate}[label=\arabic*)]
		\item $T^{**}|_X = T$
		\item the map $T \sto T^{*}$ is an isometric isomorphism.
		\item $(ST)^{*} = T^{*}S^{*}$.
		\item $\ker{T^{*}} = (\ran{T})^{\bot}$ and $\ker{T}=(\ran{T^{*}})^{\bot}$.
	\end{enumerate}
\end{prop}

Then for the $4)$ in above theorem, we can find dual consequences. Firstly, there is a useful lemma.

\begin{lem} \label{lem1}
	Let $T \colon X \sto Y$ be a bounded linear map between two Banach spaces. Then $\ran{T}$ is closed if and only if there exists a constant $C>0$, for any $y \in \ran{T}$ there is a point $x \in X$ s.t. $\norm{y} \geqslant C \norm{x}$.
\end{lem}
\begin{proof}
	By the Open Mapping Theorem, for the unit open ball $B \subset X$ and some $\delta > 0$, s.t.
	\begin{equation*}
		\{y \in \ran{T} \colon \norm{y} < \delta\} \subset T(B)
	\end{equation*}
	Thus for any nonzero $y \in \ran{T}$,
	\begin{equation*}
		\exists~ z \in B ~s.t.~ Tz = \frac{\delta}{2\norm{y}}y \Rightarrow \norm{y} \geqslant \frac{2}{\delta}\norm{x} \text{~where~} x = \frac{2\norm{y}}{\delta} z \text{~with~} Tx = y
	\end{equation*}
	Conversely, if $y \in \clo{\ran{T}}$, there is $\{y_n\} \subset \ran{T}$ with $y_n \sto y$. By the assumption, there is a constant $C>0$ and a sequence $\{x_n\} \subset X$ s.t. $\norm{x_n-x_m} \leqslant C\norm{Tx_n-Tx_m}$. Since $\{y_n\}$ is Cauchy, $\norm{x_n-x_m}$ is Cauchy. Thus there exists a $x \in X$ s.t. $x_n \sto x$ and $Tx=y$.
\end{proof}
\begin{rem}
	There is a more special case for this lemma. $\ker{T}=\{0\}$ and $\ran{T}$ is closed if and ony if there exists a constant $C>0$ s.t. $\norm{Tx} \geqslant C\norm{x}$ for any $x \in X$.
\end{rem}

\begin{thm}
	Let $T \colon X \sto Y$ be a bounded linear map between two Banach spaces.
	\begin{enumerate}[label=\arabic*)]
		\item $\clo{\ran{T}} = (\ker{T^{*}})^{\bot}$.
		\item If $\ran{T}$ is closed, then $\ran{T^{*}}$ is closed and $\ran{T^{*}} = (\ker{T})^{\bot}$.
	\end{enumerate}
\end{thm}
\begin{proof}
	For $1)$, let $y \in \clo{\ran{T}}$ and ${y_n} \subset \ran{T}$ with $y_n \sto y$. If $g \in \ker{T^{*}}$, then 
	\begin{equation*}
		g(y_n) = g(Tx_n) = T^{*}g(x_n) = 0 \sto g(y) \text{ i.e. } y \in (\ker{T^{*}})^{\bot}
	\end{equation*}
	Conversely, if $y_0 \notin \clo{\ran{T}}$, then by the Hahn-Banach Theorem, there is a $g \in Y^{*}$ s.t. 
	\begin{equation*}
		\ran{T} \subset \ker{g} \text{ i.e. } g \in \ker{T^{*}} ~\&~ g(y_0) \neq 0 \Rightarrow y_0 \notin (\ker{T^{*}})^{\bot}
	\end{equation*}
	For $2)$, if $f \in (\ker{T})^{\bot}$ i.e $\ker{T} \subset \ker{f}$, then there is a $\tilde{g} \in (\ran{T})^{*}$ s.t. $\tilde{g}(Tx) = f(x)$ since $\ran{T} \cong X/\ker{T}$. By above lemma, there exists a constant $C>0$ s.t. for any $y \in \ran{T}$ there is a $x \in X$ with $Tx=y$ and $\norm{x} \leqslant C\norm{y}$. Therefore,
	\begin{equation*}
		\abs{\tilde{g}(y)} = \abs{f(x)} \leqslant C\norm{f}\norm{x}
	\end{equation*}
	Thus $\tilde{g}$ can extends to $g$ defining on $Y^{*}$ s.t.
	\begin{equation*}
		T^{*}g(x) = g(Tx) = f(x) ~\text{ i.e. }~ T^{*}g = f
	\end{equation*}
	Therefore, $(\ker{T})^{\bot} \subset \ran{T^{*}}$. \\
	Coversely, if $f \in \ran{T^{*}}$, i.e. there is a $g \in Y^{*}$ with $T^{*}g =f$, then for any $x \in \ker{T}$, $f(x) = T^{*}g(x) = g(Tx) = 0$. Therefore, $f \in (\ker{T})^{\bot}$.
\end{proof}
\begin{cor}
	Let $T \colon X \sto Y$ be a bounded linear map between two Banach spaces. Then $T$ is invertible if and only if $T^{*}$ is invertible. In this case, $(T^{*})^{-1} = (T^{-1})^{*}$.
\end{cor}

%\begin{thm}
% 	Let $T \colon X \sto Y$ be a bounded linear map between two Banach spaces. Then the following statements are equivalent.
% 	\begin{enumerate}[label=\arabic*)]
% 		\item $\ran{T}$ is closed.
% 		\item $\ran{T^{*}}$ is norm closed.
% 		\item $\ran{T^{*}}$ is $wk^{*}$-closed.
% 	\end{enumerate}
%\end{thm}
%\begin{proof}
%	By above theorem, $1)$ implies $2)$. If $T$ is injective and $\clo{\ran{T}} = Y$,then we can get these results.
%	\item $2) \Rightarrow 3)$: 
%\end{proof}

\section{Hilbert Spaces}

A Hilber space is a special Banach space, which is endowed with a inner product. And the structure of inner product can provide better properties of Hilbert spaces.

\subsection{Projection Theorem and Riesz Theorem}

\begin{defn}
	On a vector space $\fml{H}$ over $\C$, an inner product is a map $ \langle \cdot, \cdot \rangle \colon \fml{H} \times \fml{H} \sto \K$ satisfies that for any $\alpha, \beta \in \K$ and $x,y,z \in \fml{H}$,
	\begin{enumerate}[label=\arabic*)]
	 	\item $ \langle \alpha x + \beta y,z \rangle = \alpha  \langle x,z \rangle + \beta  \langle y,z \rangle$
	 	\item $ \langle x,y \rangle = \clo{ \langle y,x \rangle}$
	 	\item $ \langle x,x \rangle \geqslant 0$ and $ \langle x,x \rangle = 0 \Leftrightarrow x = 0$
	\end{enumerate} 
\end{defn}
\begin{rem}
	The vector space $\fml{H}$ with the inner product $ \langle \cdot,\cdot \rangle$ is called an inner product space. And the inner product can induce the CBS-Inequality, 
	\begin{equation*}
		\abs{ \langle x,y \rangle}^{2} \leqslant  \langle x,x \rangle \langle y,y \rangle
	\end{equation*}
	by using the positivity of the inner product, $ \langle x-\alpha y,x-\alpha y \rangle \geqslant$0.
\end{rem}

Then on the $\fml{H}$, a nature norm can be induced by the inner product, defined as $\norm{x}^{2}= \langle x,x \rangle$ for any $x \in \fml{H}$. This definition is valid since the linearity, positivity and CBS-Inequality of the inner product. And there are two forms of the norm.

\begin{prop}
	Let $(\fml{H}, \langle \cdot,\cdot \rangle)$ be an inner product space, and $\norm{\cdot}$ be the coincided with this inner product. Then, we have the following identities.
	\item Polarization identity: 
	\begin{equation*}
		 \langle x,y \rangle = \frac{1}{4}(\norm{x+y}^{2}-\norm{x-y}^{2}+i\norm{x-iy}^{2}-i\norm{x+iy}^{2})
	\end{equation*}
	\item Parallelogram law:
	\begin{equation*}
		\norm{x+y}^{2}+\norm{x-y}^{2} = 2(\norm{x}^{2}+\norm{y}^{2})
	\end{equation*}
\end{prop}
\begin{rem}
	The first identity can be used to construct an inner product, but not all norm can do this successfully. So, the second identity can be used to check whether a norm can construct an inner product on a normed space.
\end{rem}

\begin{defn}
	A Hilbert space is an inner product space, which is complete with respect to the induced norm.
\end{defn}

Therefore, a Hilbert space is indeed a Banach space, whose norm can construct an inner product. Now, we can find the extra properties provided by the inner product. The following theorem is the most important property the Hilbert space has.

\begin{thm}
	If $\fml{H}$ is a Hilbert space and $K$ is a closed convex nonempty subset of $\fml{H}$ and $x \in \fml{H} \backslash K$, then there exists a unique $k_0 \in K$ s.t.
	\begin{equation*}
		\norm{x-k_0} = \inff{\norm{x-k} \colon k \in K}
	\end{equation*}
\end{thm}
\begin{proof}
	Let $d=\inff{\norm{x-k} \colon k \in K}$, then there is a sequence $\{k_n\} \subset K$ s.t. $\norm{x-k_n} \sto d$. By the parallelogram law,
	\begin{equation*}
		4\norm{x-\frac{1}{2}(k_m+k_n)}^{2}+\norm{k_m-k_n}^{2} = 2(\norm{x-k_m}^{2}+\norm{x-k_n}^{2}) \sto 4d^{2}
	\end{equation*}
	Since $\frac{1}{2}(k_m+k_n) \in K$, 
	\begin{equation*}
		4\norm{x-\frac{1}{2}(k_m+k_n)}^{2} \geqslant 4d^{2}
	\end{equation*}
	Thus $\norm{k_m-k_n} \sto 0$. By the facts that $\fml{H}$ is complete and $K$ is closed, there exists $k_0 \in K$ s.t. $k_n \sto k_0$. Then $\norm{x-k_0} = \lim_{n \sto \infty}\norm{x-k_n} = d$.\\
	If there is another $k_1 \in K$, $\norm{x-k_0} = \norm{x-k_1}$.
	\begin{equation*}
		d \leqslant \norm{x-\frac{1}{2}(k_0+k_1)} \leqslant \frac{1}{2}(\norm{x-k_0}+\norm{x-k_1}) = 2d
	\end{equation*}
	Then
	\begin{equation*}
		\norm{x-\frac{1}{2}(k_0+k_1)} = \frac{1}{2}(\norm{x-k_0}+\norm{x-k_1})
	\end{equation*}
	Thus by the parallelogram law, $k_0 = k_1$.
\end{proof}	
\begin{rem}
	The main method of above proof is the parallelogram law, which is the most eesential property of the norm induced by the inner product.
\end{rem}

For $x,y \in \fml{H}$, if $ \langle x,y \rangle=0$, we say $x$ is orthogonal to $y$. Similarly, if $W$ is a subset of $\fml{H}$, we define $W^{\bot} = \{y \in \fml{H} \colon  \langle x,y \rangle=0 ~\forall~ x \in W\}$. Then we can use above theorem to obtain a important structure of a Hilbert space.

\begin{thm}[Projection Theorem]
	Let $\fml{M}$ be a closed subspace of a Hilbert space $H$. Then $\fml{H} = \fml{M} \oplus \fml{M}^{\bot}$.
\end{thm}
\begin{proof}
	Clearly, $\fml{M} \bigcap \fml{M}^{\bot} = \{0\}$. We just need to prove that for any $x \in \fml{H}$, there exist a unique $x_1 \in \fml{M}$ and $x_2 \in \fml{M}^{\bot}$, s.t. $x=x_1+x_2$. If $x \in \fml{M}$, let $x_1=0$ and $x_2=0$.\\
	Assume $x \notin \fml{H}$, then by above theorem, we can find a unique $m_0 \in \fml{M}$ s.t. $\norm{x-m_0}=\inff{\{\norm{x-m} \colon m \in \fml{M}\}}$. Let $x_1 = m_0$. Then $x=x_1 + (x-m_0)$. Therefore, it is sufficient to prove that $x-m_0 \in \fml{M}^{\bot}$.\\
	For any $m \in \fml{M}$ and any $\lambda \in \C$, since $m_0+\lambda m \in \fml{M}$, we have
	\begin{eqnarray*}
		\norm{x-m_0}^{2} &\leqslant& \norm{x-m_0-\lambda m}^{2} \\
		&=& \norm{x-m_0}^{2} -2\Rea{\lambda \langle m,x-m_0 \rangle} + \abs{\lambda}^{2}\norm{m}^{2}
	\end{eqnarray*}
	Thus $-2\Rea{\lambda \langle m,x-m_0 \rangle} + \abs{\lambda}^{2}\norm{m}^{2} \geqslant 0$. Then taking the $\lambda = \varepsilon  > 0$ and let $\varepsilon \sto 0$, therefore
	\begin{equation*}
		\Rea{ \langle m,x-m_0 \rangle} \leqslant 0
	\end{equation*}
	Similarly, taking $\lambda = -i \varepsilon$ and let $\varepsilon \sto 0$,
	\begin{equation*}
		\Img{ \langle m,x-m_0 \rangle} \leqslant 0
	\end{equation*}
	Also, these are true for $-m$. Therefore, $ \langle m,x-m_0 \rangle = 0$ for any $m \in \fml{M}$, i.e. $x-m_0 \in \fml{M}^{\bot}$.
\end{proof}
By the Projection Theorem, we can directly obtained the following corrolary.
\begin{cor} \label{cor4}
	Let $\fml{H}$ be a Hilbert space.
	\begin{enumerate}[label=\arabic*)]
		\item If $\fml{M}$ is a closed subsapce of $\fml{H}$, then $(\fml{M}^{\bot})^{\bot} = \fml{M}$.
		\item If $A \subset \fml{H}$ is a subset, then $(A^{\bot})^{\bot} = \clo{\spn{A}}$.
	\end{enumerate}
\end{cor}

Using the Projection Theorem, the dual space of a Hilbert space can be more explicit.
\begin{thm}[Riesz Theorem]
	Let $\fml{H}$ be a Hilbert space. Then the map $\sigma$ is defined as
	\begin{center}
		\begin{tabular}{l r c l}
			$\sigma \colon$ & $\fml{H}$ & $\longrightarrow$ & $\fml{H}^{*}$ \\
			~ & $x$ & $\longmapsto$ & $L_x$
		\end{tabular}
	\end{center}
	where $L_x(y)= \langle y,x \rangle$. Then $\sigma$ is an isometric antilinear bijection, i.e. $\fml{H} \cong \fml{H}^{*}$.
\end{thm}
\begin{proof}
	Clearly, $L_x$ is antilinear. And by the CBS-Inequality, $\norm{L_x} = \norm{x}$, thus $\sigma$ is definitely an isometry. Then we just need to prove $\sigma$ is surjective. If $L \in \fml{H}^{*}$ is nonzero, then there is a $x_0 \in (\ker{L})^{\bot}$. Thus we can assume $L(x_0) = 1$. If $y \in \fml{H}$, then $y-L(y)x_0 \in \ker{L}$. Therefore,
	\begin{equation*}
		0= \langle y-L(y)x_0,x_0 \rangle= \langle y,x_0 \rangle-L(y)\norm{x_0}^{2}
	\end{equation*}
	Then let $x = \norm{x_0}^{-2} x_0$, $L_x=L$.
\end{proof}
\begin{cor}
	A Hilbert space $\fml{H}$ is relexive. Thus, $\fml{H}$ is weakly complete and a subset in $\fml{H}$ is weakly compact if and only if it is bounded and weakly closed.
\end{cor}

And the Riesz Theorem can extend to bounded sesquilinear forms.
\begin{defn}
	Let $\fml{H}_1$ and $\fml{H}_2$ be two Hilbert spaces. The map 
	\begin{equation*}
		f \colon \fml{H}_1 \times \fml{H}_2 \sto \C
	\end{equation*}
	is called a sesquilinear form, if it satisfies
	\begin{enumerate}[label=\arabic*)]
	 	\item $f(\alpha x + \beta y,z) = \alpha f(x,z) + \beta (y,z)$
	 	\item $f(x,\alpha y + \beta z) = \clo{\alpha} f(x,y) + \clo{\beta} (x,z)$
	\end{enumerate}
\end{defn}
\begin{rem}
	If $f$ is continuous, then we know $\abs{f(x,y)} \leqslant C\norm{x}\norm{y}$ for some $C < 0$. Also, the converse is ture. Then we can define the norm of $f$ as
	\begin{equation*}
		\norm{f} =\sup_{x \in \fml{H}_1, y \in \fml{H}_2} \frac{\abs{f(x,y)}}{\norm{x}\norm{y}}
	\end{equation*} 
\end{rem}

\begin{thm} \label{thm7}
	Let $f \colon \fml{H}_1 \times \fml{H}_2 \sto \C$ be a bounded sesquilinear form of two Hilbert spaces $\fml{H}_1$ and $\fml{H}_2$. Then there is a unique bounded linear map with $\norm{S} = \norm{f}$
	\begin{equation*}
		S \colon \fml{H}_1 \sto \fml{H}_2 \text{ s.t. } f(x,y)= \langle Sx,y \rangle ~\forall~ x \in \fml{H}_1 ~\forall~ y \in \fml{H}_2
	\end{equation*}
\end{thm}

\subsection{Adjoint Operators}

Let $T \colon \fml{H} \sto \fml{H}$ be a bounded linear operator on a Hilbert space $\fml{H}$. Since $\fml{H}$ is also a Banach space, we can define the adjoint operator of $T$ as 
\begin{center}
	\begin{tabular}{l r c l}
		$T^{*} \colon$ & $\fml{H}^{*}$ & $\longrightarrow$ & $\fml{H}^{*}$ \\			~ & $f$ & $\longmapsto$ & $T^{*}f$
	\end{tabular}
\end{center}
By the Riesz Theorem, each $f \in \fml{H}^{*}$ can be expressed as $f = \langle \cdot, x \rangle$ for some $x \in \fml{H}$. Then for any $y \in \fml{H}$ we have
\begin{equation*}
	T^{*}(\langle \cdot, x \rangle)(y) = (\langle \cdot, x \rangle)(Ty) =\langle Ty, x \rangle 
\end{equation*}
Clearly, $f(y) = \langle Ty, x \rangle  \in \fml{H}^{*}$, thus there is a unique $\tilde{x} \in \fml{H}$ s.t. $f(y) = \langle y, \tilde{x} \rangle$. Then, we have 
\begin{equation*}
	T^{*}(\langle \cdot, x \rangle)(y) = \langle Ty, x \rangle = \langle y, \tilde{x} \rangle = (\langle \cdot, \tilde{x} \rangle)(y)
\end{equation*}
Thus, we have 
\begin{equation*}
	T^{*}(\langle \cdot, x \rangle) = \langle \cdot, \tilde{x} \rangle
\end{equation*}
Since $\fml{H} \cong \fml{H}^{*}$, in fact $T^{*} \colon \fml{H} \sto \fml{H}$, and by above mention, $T^{*}(x) = \tilde{x}$, where $\tilde{x}$ is determined by the equation
\begin{equation*}
	\langle y, \tilde{x} \rangle = \langle Ty, x \rangle,~~ \forall~ y \in \fml{H}
\end{equation*}

Therefore, we can give the definition of the adjoint operator on a Hilbert space.
\begin{defn}
	Let $T \colon \fml{H} \sto \fml{H}$ be a bounded linear operator on a Hilbert space $\fml{H}$. Then the adjoint operator $T^{*} \colon \fml{H} \sto \fml{H}$ is defined as
	\begin{equation*}
		\langle y, T^{*}x \rangle = \langle Ty, x \rangle ~~ \forall~ y \in \fml{H}
	\end{equation*}
\end{defn}
\begin{rem}
	Equivalently, $\langle T^{*}x, y \rangle = \langle x, Ty \rangle ~ \forall~ y \in \fml{H}$. By above mention, this definition is well-defined and nature.
\end{rem}

Since this definition is induced by the definition of a Banach space, thus all results in the subsection \ref{sec1} also hold for the adjoint operators 0n a Hilbert space, except the $T \sto T^{*}$ is linear. In fact, on a Hilbert space, this map $T \sto T^{*}$ is antilinear, i.e. $((\alpha + \beta)T)^{*} = \clo{\alpha}T^{*}T^{*} + \clo{\beta}T^{*}$. Moreover, Since any Hilbert space is reflexive, the first result in \textbf{Proposition} \ref{prop4} in the subsection \textbf{1.4.4} can be $T^{**} = T$.\\
And by the \textbf{Corollary} \ref{cor4} of the Projection Theorem and the last result in \textbf{Proposition} \ref{prop4} in the subsection \textbf{1.4.4}, we have the following proposition.
\begin{prop}
	Let $T \colon \fml{H} \sto \fml{H}$ be a bounded linear operator on a Hilbert space $\fml{H}$. Then, we have
	\begin{eqnarray*}
		\ker{T^{*}} = (\ran{T})^{\bot} &,& \ker{T}=(\ran{T^{*}})^{\bot} \\
		\clo{\ran{T}} = (\ker{T^{*}})^{\bot} &,& \clo{\ran{T^{*}}} = (\ker{T})^{\bot}
	\end{eqnarray*}
\end{prop}

And there is a result, which provide another important information of operators on a Hilbert space and make it more interesting than the operators defined on a Banach space.

\begin{thm} \label{thm0}
	Let $T \in \oper$ for a Hilbert space. Then
	\begin{equation*}
		\norm{T} = \norm{\st{T}} = \norm{\st{T}T}^{\frac{1}{2}}
	\end{equation*}
\end{thm}  
\begin{proof}
	Firstly, for any $h \in \Hs$ with $\norm{h} \leqslant 1$
	\begin{equation*}
		\norm{Ah}^2 = \langle Ah,Ah \rangle = \langle \st{A}Ah,h \rangle \leqslant \norm{\st{A}Ah}\norm{h} \leqslant \norm{\st{A}A} \leqslant \norm{\st{A}}\norm{A}
	\end{equation*}
	Therefore, $\norm{A}^2  \leqslant \norm{\st{A}A} \leqslant \norm{\st{A}}\norm{A}$. and $\norm{A} \leqslant \norm{\st{A}}$. But $\st{(\st{A})} = A$, thus this identity can hold.
\end{proof}

\subsection{Orthonormal Sets and Schauder Basis}

For a Hilbert space $\fml{H}$, subset $W \subset \fml{H}$ is called orthonormal if  elements in $W$ are pariwise orthogonal and each element has norm $1$. Then we can find a maximal orthonormal set, which is called a Schauder basis. Since the argebraic basis, Hamel basis, of a Hilbert space may be uncountable, we firstly need to define the uncountable summation.

\begin{defn}
	Let $\{h_i \colon i \in I\}$ be family of elements in $\fml{H}$ and $\fml{F}$ be a collection of all finite subsets of $I$. $\fml{F}$ can be endowded with the orter by $\subset$, then $\fml{F}$ is a directed set. Define the net, where $F \in \fml{F}$
	\begin{equation*}
		h_F = \sum \{h_i \colon i \in F\}
	\end{equation*}
	Therefore, we can define sum of $\{h_i \colon i \in I\}$ as
	\begin{equation*}
		\sum \{h_i \colon i \in I\} = \lim h_F
	\end{equation*}
	where the limit is with respect to the norm topology on $H$.
\end{defn}

For finite orthonormal set, the results can be obtained by the algebraic structure. And if the orthonormal set is infinite, we have similar results.
\begin{thm}[Bessel's Inequality]
	If $\{e_n\}_{n=1}^{\infty}$ is an orthonormal set of a Hilbert space and $h \in \fml{H}$, then
	\begin{equation*}
		\sum_{n=1}^{\infty} \abs{ \langle h,e_n \rangle}^{2} \leqslant \norm{h}^{2}
	\end{equation*}
\end{thm}
\begin{proof}
	Let $h_n=h-\sum_{k=1}^{n}  \langle h,e_k \rangle e_k$. Then $h_n$ is clearly orthogonal to $\{e_k\}_{k=1}^{n}$.
	\begin{eqnarray*}
		\norm{h}^{2} &=& \norm{h_n}^{2} + \norm{\sum_{k=1}^{n}  \langle h,e_k \rangle e_k}^{2} \\
		&=& \norm{h_n}^{2} + \sum_{k=1}^{n} \abs{ \langle h,e_k \rangle }^{2} \\
		&\geqslant& \sum_{k=1}^{n} \abs{ \langle h,e_k \rangle }^{2}
	\end{eqnarray*}	
\end{proof}
\begin{cor}
	Let $\fml{H}$ be a Hilbert space and $\fml{E}$ be an orthonormal subset. 
	\begin{enumerate}[label=\arabic*)]
		\item For any $h \in \fml{H}$, $\abs{ \langle h,e \rangle } \neq 0$ for at most a countable many $e \in \fml{E}$.
		\item $\sum_{e \in \fml{E}} \abs{ \langle h,e \rangle }^{2} \leqslant \norm{h}^{2}$.
		\item $\sum \{ \langle h,e \rangle e \colon e \in \fml{E}\}$ is converges.
	\end{enumerate}
\end{cor}
\begin{proof}
	For $1)$, let $\fml{E}_n=\{e \in \fml{E} \colon \abs{ \langle h,e \rangle } \geqslant \frac{1}{n}\}$, then $\fml{E}_n$ has to be finite. But 
	\begin{equation*}
		\bigcup_{n=1}^{\infty} \fml{E}_n = \{e \in \fml{E} \colon \abs{ \langle h,e \rangle } \neq 0\}
	\end{equation*}
	For $2)$, it is clearly by the Bessel's Inequality and above corollary.\\
	For $3)$, it is because the net $h_F = \sum \{h_i \colon i \in F\}$, where $F \subset \fml{E}$ is finite, is Cauchy by using the fact that for any $\varepsilon  >  0$ there is a $N \in \N$ s.t. 
	\begin{equation*}
		\sum_{n=N}^{\infty} \abs{ \langle h,e_n \rangle }  <  \varepsilon
	\end{equation*}
\end{proof}

\begin{defn}[Schauder basis]
	A orthonormal set $\fml{E}$ of a Hilbert space $\fml{H}$ is called a Schauder basis if for any $h \in \fml{H}$,
	\begin{equation*}
		h = \sum \{ \langle h,e \rangle e \colon e \in \fml{E}\}
	\end{equation*}
\end{defn}
\begin{rem}
	By above corollary, this definition is equivalent to that for any $h \in \fml{H}$, there exists $\{e_n\}_{n=1}^{\infty} \subset \fml{E}$, s.t.
	\begin{equation*}
		h = \sum_{n=1}^{\infty}  \langle h,e_n \rangle e_n
	\end{equation*}
	Moreover, by the Zorn's Lemma, every Hilbert space has a Schauder basis.
\end{rem}

By the definition, and above theorem and corollaries, we can find the properties of the Schauder basis.
\begin{thm}
	Let $\fml{H}$ be a Hilbert space and $\fml{E}$ be an orthonormal subset. Then the following statements are equivalent.
	\begin{enumerate}[label=\arabic*)]
		\item $\fml{E}$ is a Schauder basis.
		\item $h \in \fml{H}$ with $h \bot \fml{E}$, then $h=0$.
		\item $g,h \in \fml{H}$, then
			\begin{equation*}
				 \langle g,h \rangle  = \sum \{ \langle g,e \rangle  \langle e,h \rangle  \colon e \in \fml{E}\}
			\end{equation*}
		\item (Parseval's Identity)$h \in \fml{H}$, then
			\begin{equation*}
				\norm{h}^{2} = \sum \{\abs{ \langle h,e \rangle }^{2} \colon e \in \fml{E}\}
			\end{equation*}
	\end{enumerate}
\end{thm}

\begin{prop}
	Let $\fml{H}$ be a Hilbert space and $\fml{E}$ be an orthonormal subset.
	\begin{enumerate}[label=\arabic*)]
		\item $\fml{H}$ is separable if and only if $\fml{E}$ is countable.
		\item Any separable Hilbert space is isometrically isomorphic to $l^{2}(\C)$.
	\end{enumerate}
\end{prop}

\subsection{Unitaries and Projections}

If we can find a bijection, which is continuous and the inverse of which is also continuous, between two topological spaces, these two topological spaces are regarded as same. Also, if there is a bijection, which is linear between two linear spaces, then we say these two linear spaces are same. Now, we also want to use a special map to classify Hilbert spaces. We know the Hilbert space has two structures, linear structure and the inner product structure. So following definition is nature.

\begin{defn}
	Let $\Hs$ and $\fml{K}$ be two Hilbert spaces. If there is a linear isomorphism $U$ from $\Hs$ to $\fml{K}$, s.t $\langle Ux,Uy \rangle = \langle x,y \rangle$, then $U$ is called a unitary.
\end{defn}
\begin{rem}
	In fact, if there exists a unitary $U$ between $\Hs$ and $\fml{K}$, $U$ preserves not only the linear structure, but also the inner product structure of Hilbert spaces. Therefore, these two Hilbert spaces are regarded as same. Moreover, if the $U$ is not assumed bijection, then $U$ is called an isometry.
\end{rem}

As above definition, the following proposition is clearly.

\begin{prop}
	If $U \in \oper$, then the following statements are equivalent.
	\begin{enumerate}[label=\arabic*)]
		\item $U$ is a unitary.
		\item $\st{U}U = U\st{U} = I$.
		\item $U$ is a normal isometry.
	\end{enumerate}
\end{prop}
\begin{rem}
	$A \in \oper$ is called normal, if $\st{A}A=A\st{A}$.
\end{rem}

Now, the another important operator is projection. Like its name showing, the projection can project the elements in a Hilbert space to a corresponding subspace, and because of the Projection Theorem, we can make the definition be well-defined.

\begin{defn}
	Let $\M$ be a any closed subspace of $\Hs$. Then by the Projection Theorem, $\Hs = \M \oplus \M^{\bot}$, i.e. for any $x \in \Hs$, there exist un $x_{//} \in \M$ and $x_{\bot} \in \M^{\bot}$ s.t.$x = x_{\shortparallel} + x_{\bot}$. Therefor we can define a map $P \colon \Hs \sto \M$ as $Px=x_{\shortparallel}$. $P$ is called a projection.
\end{defn}
\begin{rem}
	$P$ is a linear operator can be easily proved.
\end{rem}

There is an equivalent definition of the projection. Firstly, $A \in \oper$ is called self-adjoint if $\st{A} = A$.

\begin{thm}
	Let $\Hs$ be a Hilbert space. $P \in \oper$ is a projection if and only if $P$ is self-adjoint and $P^2=P$.
\end{thm}
\begin{proof}
	Let $\Hs = \M \oplus \M^{\bot}$. If $P$ is a projection to $\M$, $P^2=P$ is clearly true. 
	\begin{eqnarray*}
		\langle P(x = x_{\shortparallel} + x_{\bot}), y = y_{\shortparallel} + y_{\bot} \rangle &=& \langle x_{\shortparallel}, y_{\shortparallel} \rangle \\
		\langle \st{P}(x = x_{\shortparallel} + x_{\bot}), y = y_{\shortparallel} + y_{\bot} \rangle &=& \langle x = x_{\shortparallel} + x_{\bot}, P(y = y_{\shortparallel} + y_{\bot}) \\
		&=& \langle x_{\shortparallel}, y_{\shortparallel} \rangle
	\end{eqnarray*}
	Therefore, $P$ is self-adjoint. \\
	Conversely, $\M=P(\Hs)$ is clearly a subspace. And for any $y \in \M$, let $x=y$, we have $Px = y$. Thus by the \textbf{Lemma} \ref{lem1} in the subsection \textbf{1.4.4}, $\M$ is closed. Since $P$ is sefl-adjoint, 
	\begin{equation*}
		\langle x-Px,Px \rangle = \langle Px-P^2x,x \rangle = 0
	\end{equation*}
	That means $x-Px \in \M^{\bot}$. Therefore, $x=Px+(x-Px)$ is the unique decomposition of $x$ with respect to $\M$. $P$ is a projection. 
\end{proof}
\begin{rem}
	By the fact that $P^2 =P$ and the \textbf{Theorem} \ref{thm0} in the subsection \textbf{1.5.2}, $\norm{P} = 1$. Therefore, $P$ is bounded.
\end{rem}

The one of the importance of projections is that any closed subspace of a Hilbert space can be regarded as a operator on the Hilbert space. And then this can provide us an effective method to research the invariant space.

\begin{defn}
	For $T \in \oper$ and a closed subspace $\M$ of $\Hs$, if $T(\M) \subset \M$, $\M$ is called an invariant space for $T$. If $T(\M) \subset \M$ and $T(\M^{\bot}) \subset \M^{\bot}$, then $\M$ is called a reducing space for $T$.
\end{defn}

\begin{prop}
	Let $\M$ be a closed subspace of a Hilbert space $\Hs$ and $P$ be the projection to $\M$ and $T \in \oper$. $T$ acts on $\Hs=\M \oplus \M^{\bot}$ can be expressed as
	\begin{equation*}
		T = \left(
			\begin{array}{cc}
				W & X \\
				Y & Z
			\end{array}
		\right)
	\end{equation*}
 	Then the following statements are equivalent.
	\begin{enumerate}[label=\arabic*)]
		\item $\M$ is invariant for $T$.
		\item $PTP=TP$.
		\item $Y=0$.
	\end{enumerate}
\end{prop}
\begin{proof}
	$1) \Rightarrow 2)$ is clearly.
	\item $2) \Rightarrow 3)$: The $P$ can be expressed as
	\begin{equation*}
		P = \left(
			\begin{array}{cc}
				I & 0 \\
				0 & 0
			\end{array}
		\right)
	\end{equation*}
	Then by $PTP=TP$, we can find $Y=0$.
	\item $3) \Rightarrow 1)$ is also clearly.
\end{proof}

\begin{prop}
	Let $\M,\Hs$ and $T,P$ be defined as above proposition. Then the following statements are equivalent.
	\begin{enumerate}[label=\arabic*)]
		\item $\M$ reduces $\Hs$.
		\item $PT=TP$.
		\item $X$ and $Y$ are $0$.
		\item $\M$ is invariant for $T$ and $\st{T}$.
	\end{enumerate}
\end{prop}
\begin{proof}
	$1) \Rightarrow 2)$: By above proposition, $PTP=TP$ and $(I-P)T(I-P)=T(I-P)$, thus we have $PT=TP$.
	\item $2) \Rightarrow 3)$: Expressing $P$ as above proposition, then by $PT=TP$, we find $X$ and $Y$ are $0$.
	\item $3) \Rightarrow 4)$: Since $X$ and $Y$ are $0$, then
	\begin{equation*}
		\st{T} = \left(
			\begin{array}{cc}
				\st{W} & 0 \\
				0 & \st{Z}
			\end{array}
		\right)
	\end{equation*}
	Clearly, $\M$ is invariant for $T$ and $\st{T}$.
	\item $4) \Rightarrow 1)$: If $h \in \M^{\bot}$ and $g \in \M$, $\langle g,Ah \rangle = \langle \st{A}g,h \rangle = 0$ since $\st{A}g \in \M$. Therefore, $T(\M^{\bot}) \subset \M^{\bot}$.
\end{proof}

\chapter{Banach Algebras and \texorpdfstring{$C^{*}$-Algebras}{C*-Algebras}}
\section{Banach Algebras}

Let $\fml{H}$ be a Hilbert space. Then $\oper$ is indeed a Banach space. But we have more sructure on it. Any two element $S,T \in \oper$ can do multiplication, defined as $ST = S \circ T$, then $ST \in \oper$ by the definition of norm, and moreover $\norm{ST} \leqslant \norm{S}\norm{T}$. Therefore, $\oper$ is an algebra with the extra property of the multiplication, called a Banach algebra.

\subsection{Elementary Properties}

\begin{defn}
	A Banach algebra $\alg{A}$ is an algebra over $\C$ with a norm $\norm{\cdot}$ relative to which $\alg{A}$ is a Banach space and s.t. for all $a,b \in \alg{A}$,
	\begin{equation*}
		\norm{ab} \leqslant \norm{a}\norm{b}.
	\end{equation*}
\end{defn}
\begin{rem}
	The extra condition guarantees the multiplication is norm continuous. In fact, $\alg{A}$ with the multiplication and the norm is a topological semigroup.
\end{rem}

If $\alg{A}$ has an identity $1$, it assumes $\norm{1}=1$. But if $\alg{A}$ does not have an identity, we can add an identity to it.

\begin{prop}
	If $\alg{A}$ is a Banach algebra without the identity. The let $\tilde{\alg{A}}= \alg{A} \oplus \C$ be an induced vector space. Then we define a norm on $\tilde{\alg{A}}$ as
	\begin{equation*}
		\norm{(a,\lambda)} = \norm{a} + \abs{\lambda}
	\end{equation*}
	and define a multiplication on $\tilde{\alg{A}}$ as
	\begin{equation*}
		(a,\alpha)(b,\beta) = (ab+\alpha b + \beta a, \alpha \beta)
	\end{equation*}
	Then $\alg{A}$ is a Banach algebra with the identity $(0,1)$.
\end{prop}

Then $\alg{A}$ can be isometrically imbedded into $\tilde{\alg{A}}$. Therefore, we can always assume $\alg{A}$ has an identity. For a unit algebra, the invertibility of a element is important. 

\begin{thm}
	Let $\alg{A}$ be a Banach algebra and $a \in \alg{A}$. If $\norm{a-1} < 1$, then $a$ is invertible.
\end{thm}
\begin{proof}
	For a nonzero real number $\lambda \in \R$ with $\abs{\lambda} < 1$, we know 
	\begin{equation*}
		(1-\lambda)^{-1} = \sum_{n=0}^{\infty} \lambda^{n}
	\end{equation*}
	Similar, for $a \in \alg{A}$ with $\norm{a-1} < 1$, set
	\begin{equation*}
		b= \sum_{n=0}^{\infty} (1-a)^{n}
	\end{equation*}
	Firstly, since $\norm{(1-a)^{n}} \leqslant \norm{(1-a)}^{n}$, $b$ is well-defined. Then we can prove $b = (1-(1-a))^{-1} = a^{-1}$.
\end{proof}
\begin{rem}
	This result is important. It says a small perturbation of an invertible element is also invertible. It is because that the multiplication is norm continuous. And by the continuity of multiplication, this result can be true at any point other than 1.
\end{rem}

\begin{cor}
	Let $\alg{A}$ be a Banach algebra and 
	\begin{eqnarray*}
		G_l &=& \{~a \in \alg{A} \colon a \text{ is left invertible}~\}\\
		G_r &=& \{~a \in \alg{A} \colon a \text{ is right invertible}~\}\\
		G &=& G_l \bigcap G_r = \{~a \in \alg{A} \colon a \text{ is invertible}~\}
	\end{eqnarray*}
	Then $G_l$ and $G_r$ and $G$ are open. Moreover, the map $a \sto a^{-1}$ from $G$ to $G$ is continuous.
\end{cor}
\begin{proof}
	$G_l$ and $G_r$ and $G$ are open by above theorem. \\
	We just need to check this map is continuous at $1$ because of the continuity of multiplication. For $\{a_n\} \subset G$ with $a_n \sto 1$, thus $\norm{1-a_n}<\delta<1$. Since
	\begin{equation*}
		a_n^{-1} = (1-(1-a_n))^{-1} = \sum_{k=0}^{\infty} (1-a_n)^{k} = 1+ \sum_{k=1}^{\infty} (1-a_n)^{k}
	\end{equation*}
	Therefore,we have
	\begin{eqnarray*}
		\norm{1-a_n^{-1}} &=& \norm{\sum_{k=1}^{\infty} (1-a_n)^{k}}\\
		&\leqslant&  \sum_{k=1}^{\infty} \norm{1-a_n}^{k}\\
		&<& \frac{\delta}{1+\delta} < \delta = \norm{1-a_n}
	\end{eqnarray*}
	i.e. $\lim a_n = 1$.
\end{proof}

\begin{cor}
	Let $\alg{A}$ be a Banach algebra.
	\begin{enumerate}[label=\arabic*)]
		\item The closure of a proper ideal is a proper ideal.
		\item A maximal ideal is closed.
		\item every ideal contained in a maximal ideal.
	\end{enumerate}
\end{cor}

If $\alg{B}$ is a closed ideal of a Banach algebra $\alg{A}$, then then quotient algbra $\alg{A}/\alg{B}$ with the induced norm is also a Banach algebra since 
\begin{equation*}
	\norm{(a+\alg{B})(b+\alg{B})} = \norm{ab+\alg{B}} \leqslant \norm{(a+b_1)(b+b_2)} \leqslant \norm{(a+b_1)}\norm{(b+b_2)}
\end{equation*}
for any $b_1, b_2 \in \alg{B}$.

\subsection{Spectrum}


\begin{defn}
	Let $\alg{A}$ be a Banach algebra and $a \in \alg{A}$. The spectrum of $a$, denoted by $\sigma(a)$ defined as
	\begin{equation*}
		\sigma(a) = \{~ \lambda \in \C \colon a-\lambda \text{ is invertible}~\}
	\end{equation*}	
	And the resolvents of $a$, $\rho(a) = \C \backslash \sigma(a)$.\\
	Moreover, we can define the spectral radius of $a$ as
	\begin{equation*}
		r(a) = \sup{\{~\abs{\lambda} \colon \lambda \in \sigma(a)~\}}
	\end{equation*}
\end{defn}

Firstly, there are some elementary properties of the spectrum.

\begin{thm}
	Let $\alg{A}$ be a Banach algebra and $a \in \alg{A}$.
	\begin{enumerate}[label=\arabic*)]
		\item If $\abs{\lambda} > \norm{a}$, then $\lambda \notin \sigma(a)$.
		\item $\sigma(a)$ is a compact subset of $\C$.
		\item the map $\lambda \mapsto (a-\lambda)^{-1}$ from $\rho(a)$ to $\alg{A}$ is analytic and $\sigma(a)$ is nonempty.
		\item $r(a)=\lim_{n \sto \infty} \norm{a^{n}}^{\frac{1}{n}}$.
	\end{enumerate}
\end{thm}
\begin{proof}
	$1)$ holds by above theorem. \\
	For $2)$, since $\lambda \sto a-\lambda$ is continuous from $\C$ to $\alg{A}$ and $G$ is open, $\rho(a)$ is open i.e. $\sigma(a)=\C \backslash \rho(a)$ is closed. Then by $1)$, $\sigma(a)$ is compact.\\
	For $3)$, by the identity $a^{-1} - b^{-1} = a^{-1}(b-a)b^{-1}$ and the continuity of $a \sto a^{-1}$, we can compute the derivative of $F(\lambda) = (a-\lambda)^{-1}$,
	\begin{equation*}
		F^{'}(\lambda) = (a-\lambda)^{-2}
	\end{equation*}
	And clearly, $F^{'}(\lambda)$ is continuous. Thus it is analytic and it vanishes at $\infty$. By the Liouville's Theorem, if $\rho(a) = \C$, $F$ is constant. Therefore, $\rho(a) \neq \C$ i.e. $\sigma(a) \neq \varnothing$.\\
	For $4)$, let $U=\{\lambda \in \C \colon \lambda = 0 \text{ or } \lambda^{-1} \in \rho(a)\}$ and 
	\begin{equation*}
		f(\lambda) = 
		\begin{cases}
			(\lambda^{-1}-a)^{-1} & x \neq 0,\\
			0,& x = 0
		\end{cases}
	\end{equation*}
	Then $f$ is analytic on $U$, i.e $f(\lambda)=\lambda\sum_{n=0}^{\infty} \lambda^{n} a^{n}$ is well-defined. Therefore, the convergent radius $R = r(a)^{-1}$
	\begin{equation*}
		R^{-1} = \limsup_{n \sto \infty} \norm{a^{n}}^{\frac{1}{n}} = r(a)
	\end{equation*}
	Conversely, by the identity $(a^{n}-\lambda^{n}) = (a-\lambda)(a^{n-1}+\lambda a^{n-2}+\lambda^{2} a^{n-3} + \cdots + \lambda^{n-1})$. Then, if $(a^{n}-\lambda^{n})$ is invertible, then $(a-\lambda)$ is invertible, i.e. $\sigma(a) \subset \sigma(a^{n})$. Thus $\abs{\lambda}^{n} \leqslant \norm{a^{n}}$ for any $\lambda \in \sigma{a}$. $r(a)=\liminf_{n \sto \infty}\norm{a^{n}}^{\frac{1}{n}}$. Therefore, $r(a)=\lim_{n \sto \infty} \norm{a^{n}}^{\frac{1}{n}}$.
\end{proof}

If $\alg{B} \subset \alg{A}$ is a subalgebra with the same identity of a Banach algebra $\alg{A}$, then we know for any element $b \in \alg{B}$, $\sigma_{\alg{A}}(b) \subset \sigma_{\alg{B}}(b)$. Then we can have more results other than it. Since the spectrum is a subset of $\C$, we need some topological properties results of $\C$.

\begin{lem}
	If $K$ is any compact subset of $\C$, then $\C \backslash K$ has a countable components, only one of which is unbounded. And the boundary of each component is in $K$.
\end{lem}
\begin{proof}
	Let $\tilde{K} = \C \backslash K$, then $\tilde{K}$ is open.
	\item Firstly, the connected component of open set in $\C$ is open. \\
		  Let $U$ be an connected component in $\tilde{K}$ and $x \in U$. For any point $x \in U$, Since any open neighbourhood of $x$ is connected, and $K$ is open, there is a open neighbourhood $V$ of $x$ s.t. $V \subset U$.
	\item Secondly, $\C$ has just at most countable many open sets, which are pairwise disjoint.\\
		  This result is because any open set in $\C$ contains a rational point.
	\item For any two disjoint open sets $A$ and $B$ in $\C$, $\partial A \bigcap B = \varnothing$. Thus the boundary of some compoment of $\tilde{K}$ can not be contained in any component of $\tilde{K}$, i.e. it is contained $K$.
	\item Finally, since $K$ is bounded, there is a closed ball $B$ containing $K$. But the complement of $B$ is connected, thus there is only one component of $\tilde{K}$ containing $B$. Thus the other components of $\tilde{K}$ are bounded.
\end{proof}
\begin{rem}
	The bounded component of $\C \backslash K$ is called a hole of $K$.
\end{rem}

\begin{defn}
	If $f \colon A \sto \C$, where $A$ is a set, then the norm of $f$ on $A$ is defined as
	\begin{equation*}
		\norm{f}_A = \sup{\{\abs{f(x)} \colon x \in A\}}
	\end{equation*}
	For a compact set $K \in \C$, the polynomially convex hull of $K$ is defined as
	\begin{equation*}
		\hat{K} = \{~z \in \C \colon \abs{p(z)} \leqslant \norm{p}_K \text{ for any polynomial } p ~\}
	\end{equation*}
	If $K = \hat{K}$, $K$ is called polynomially convex.
\end{defn}

\begin{prop}
	Let $K$ be a compact subset of $\C$. Then $\C \backslash \hat{K}$ is the unbounded component of $\C \backslash K$. Therefore, $K$ is polynomially convex if and only if $\C \backslash K$ is connected.
\end{prop}
\begin{proof}
	Let $L$ be the set containing $K$ and all bounded component of $\C \backslash K$. Then by the Maximal Principle, $L \subset \hat{K}$. Conversely, if $\alpha \notin L$, then $(z-\alpha)^{-1}$ is analytic in a neighbourhood of $L$. Therefore, there is a sequence of polynomials $\{p_n\}$ s.t. $p_n \sto (z-\alpha)^{-1}$. Let $q_n=(z-\alpha)p_n$. Then $q_n \sto 1$, i.e. $\norm{q_n-1} < \frac{1}{2}$ for some $n$. But $\abs{q_n(\alpha)-1}=1$, this implies $\alpha \notin \hat{K}$, i.e. $\hat{K} \subset L$.
\end{proof}

By above results, now we can provide the relationships betweem $\sigma_{\alg{A}}(b)$ and $\sigma_{\alg{B}}(b)$.

\begin{thm}
	If $\alg{A}$ and $\alg{B}$ are Banach algebras with same identity s.t. $\alg{B} \subset \alg{A}$ and $b \in \alg{B}$, then
	\begin{enumerate}[label=\arabic*)]
		\item $\sigma_{\alg{A}}(b) \subset \sigma_{\alg{B}}(b)$ and $\partial\sigma_{\alg{B}}(b) \subset \partial\sigma_{\alg{A}}(b)$
		\item $\hat{\sigma_{\alg{A}}(b)} = \hat{\sigma_{\alg{B}}(b)}$
		\item if $G$ is a hole of $\sigma_{\alg{A}}(b)$, then $G \subset \sigma_{\alg{B}}(b)$ or $G \bigcap \sigma_{\alg{B}}(b) = \varnothing$
	\end{enumerate}
\end{thm}
\begin{proof}
	\item For $1)$, let $\lambda \in \partial\sigma_{\alg{B}}(b)$. Since $\inte{\sigma_{\alg{A}}(b)} \subset \inte{\sigma_{\alg{B}}(b)}$, it is sufficient to show $\lambda \in \sigma_{\alg{A}}(b)$. Suppose $\lambda \notin \sigma_{\alg{A}}(b)$, i.e. $(b-\lambda)$ is invertible in $\alg{A}$. But since $\lambda \in \partial\sigma_{\alg{B}}(b)$, there are $\lambda_n \in \C \backslash \alg{B}$ with $\lambda_n \sto \lambda$. Thus $(b-\lambda_n)^{-1} \in \alg{B}$. But $(b-\lambda_n)^{-1} \sto (b-\lambda)^{-1} \in \sigma_{\alg{B}}(b)$, contradicting to $\lambda \in \sigma_{\alg{A}}(b)$.
	\item $2)$ holds because of the result of $1)$ and the Maxiamal Principle.
	\item For $3)$, let $G_1 = G \bigcap \sigma_{\alg{B}}(b)$ and $G_2 = G \backslash \sigma_{\alg{B}}(b)$. Since $\partial\sigma_{\alg{B}}(b) \subset \sigma_{\alg{A}}(b)$ and $G \bigcap \sigma_{\alg{A}}(b) = \varnothing$, $G_1 = G \bigcap \inte{\sigma_{\alg{B}}(b)}$ is open. By the facts that $G_2$ is clearly open and $G = G_1 \bigcup G_2$ and $G_1 \bigcap G_2 = \varnothing$, either $G_1$ or $G_2$ is empty.
\end{proof}

Then we can have some useful corollaries.

\begin{cor} \label{cor5}
	Let $\alg{A}$ and $\alg{B}$ be Banach algebras with same identity s.t. $\alg{B} \subset \alg{A}$ and $b \in \alg{B}$.
	\begin{enumerate}[label=\arabic*)]
		\item If $\sigma_{\alg{A}}(b)$ has no holes, then $\sigma_{\alg{A}}(b)=\sigma_{\alg{B}}(b)$.
		\item If $\sigma_{\alg{B}}(b) \subset \R$, then $\sigma_{\alg{A}}(b)=\sigma_{\alg{B}}(b)$.
		\item $\sigma_{\alg{A}}(b)=\sigma_{\alg{B}}(b)$ if and only if $\rho_{\alg{A}}(b)$ is connected.
	\end{enumerate}
\end{cor}
\begin{proof}
	$1)$ is clearly true since ubbouded component does not intersect $\sigma_{\alg{B}}(b)$. $2)$ is because $\C \backslash \sigma_{\alg{A}}(b)$ has no holes. $3)$ is similar as $2)$.
\end{proof}

\subsection{Riesz Functional Calculus}

For any polynomial $p$ with complex coefficients,  
\begin{equation*}
	p(z) = \sum_{k=0}^{n} \alpha_k z^{k}
\end{equation*}
we can define $p(a)$ for some $a \in \alg{A}$, where $\alg{A}$ is a Banach algebra
\begin{equation*}
	p(a) = \sum_{k=0}^{n} \alpha_k a^{k}
\end{equation*}
Clearly, $p(a)$ is well-defined. But we can do more. If $f$ is an analytic funcion on $A \subset \C$, then $f$ can be approximated by a sequence of polynomials
\begin{equation*}
	f(z) = \sum_{n=0}^{\infty} \alpha_n z^{n}
\end{equation*}
Similarly, we can define $f(a)$ for $a \in \alg{A}$ as
\begin{equation*}
	f(a) = \sum_{n=0}^{\infty} \alpha_n a^{n}
\end{equation*}
If the radius of convergence of this sequence is $R$, then it can be well-defined for $\norm{a} \leqslant R$. By the fact that $r(a) \leqslant \norm{a}$, for the analytic function $f$, if $\sigma(a) \subset A$, $f(a)$ can be well-defined.\\
Let $\hol{(a)}$ denote all functions that are analytic in a neighbourhood of $\sigma(a)$. Then there is a map from $\hol{(a)}$ to $\alg{A}$ defined as $f \mapsto f(a)$. Now, we can find more properties of this map. Firstly, we can give another formula of $f(a)$.\\
If $f \in \hol{(a)}$, then for any closed curve $\gamma$ which encloses $\hol{(a)}$ and any point $z_0 \in \hol{(a)}$, 
\begin{equation*}
	f(z_0) = \frac{1}{2 \pi i}\int_{\gamma} f(z) (z-z_0)^{-1} dz
\end{equation*}
Therefore, replacing $z_0$ by $a \in \alg{A}$, then we have 
\begin{equation*}
	f(a) = \frac{1}{2 \pi i}\int_{\gamma} f(z) (z-a)^{-1} dz
\end{equation*}
Clearly, by the Cauchy's Integral Formula, this definition is well-defined and is coincided with above definition. But this definition can provide us a conivient method to research the map $f \mapsto f(a)$.

\begin{thm}[Riesz Functional Calculus]
	Let $\alg{A}$ be a Banach algebra and $a \in \alg{A}$ and the map
	\begin{center}
		\begin{tabular}{l c c l}
			$\rho \colon$ & $\hol{(a)}$ & $\longrightarrow$ & $\alg{A}$ \\
			~ & $f$ & $\longmapsto$ & $f(a)=\frac{1}{2 \pi i}\int_{\gamma} f(z) (z-a)^{-1} dz$
		\end{tabular}
	\end{center}
	has the following properties.
	\begin{enumerate}[label=\arabic*)]
		\item $\rho$ is an algebra homomorphism.
		\item $\rho(1) = 1$ and $\rho(z)=a$.
		\item If $\{f_n\} \subset \hol{(a)}$ and $f \in \alg{A}$ with $f_n \sto f$ uniformly on a compact set of $\hol{(a)}$, then $\rho(f_n) \sto \rho(f)$ in norm.
	\end{enumerate}
	Moreover, if any map $\tau \colon \hol{(a)} \sto \alg{A}$ satifies above conditions, then $\tau = \rho$. 
\end{thm}
\begin{proof}
	For $1)$, $\rho$ is clearly linear. And
		\begin{eqnarray*}
			f(a)g(a)&=& -\frac{1}{4 \pi^{2}}\int_{\gamma_1} f(z) (z-a)^{-1} dz\int_{\gamma_2} g(\zeta) (\zeta-a)^{-1} d\zeta \\
			&=& -\frac{1}{4 \pi^{2}}\int_{\gamma_1}\int_{\gamma_2} f(z)g(\zeta) \frac{(z-a)^{-1}-(\zeta-a)^{-1}}{\zeta-z} d\zeta dz \\
			&=& -\frac{1}{4 \pi^{2}}\int_{\gamma_1}f(z) \int_{\gamma_2} \frac{g(\zeta)}{\zeta-z} d\zeta (z-a)^{-1} dz \\
		    && \negmedspace{} + \frac{1}{4 \pi^{2}}\int_{\gamma_2}g(\zeta) \int_{\gamma_1} \frac{f(z)}{\zeta-z} dz (\zeta-a)^{-1} d\zeta
		\end{eqnarray*}
		We can choose $\gamma_2$ to enclose $\gamma_1$, thus 
		\begin{equation*}
			\int_{\gamma_1} \frac{f(z)}{\zeta-z} dz =0,~ \int_{\gamma_2} \frac{g(\zeta)}{\zeta-z} d\zeta] = 2\pi i g(z)
		\end{equation*}
		Therefore, 
		\begin{equation*}
			f(a)g(a) = {2 \pi i}\int_{\gamma_1} f(z)g(z)(z-a)^{-1} dz = (fg)(a)
		\end{equation*}
	\item For $2)$, let $f(z) = z^k$ and $\gamma = R e^{2 \pi i t}$, where $R>\norm{a}$ and $t \in [0,1]$, then
	\begin{eqnarray*}
		f(a) &=& \frac{1}{2 \pi i}\int_{\gamma} z^k (z-a)^{-1} dz \\
		&=& \frac{1}{2 \pi i}\int_{\gamma} z^{k-1} (1-\frac{a}{z})^{-1} dz \\
		&=& \frac{1}{2 \pi i}\int_{\gamma} z^{k-1} \sum_{n=0}^{\infty} \frac{a^{n}}{z^{n}}dz \\
		&=& \sum_{n=0}^{\infty} (\frac{1}{2 \pi i}\int_{\gamma} \frac{1}{z^{n-k+1}}) a^{n} \\
		&=& a^{k}
	\end{eqnarray*}
	\item For $3)$, 
	\begin{eqnarray*}
		\lefteqn { \norm{\int_{\gamma} f_n(z) (z-a)^{-1} dz - \int_{\gamma} f(z) (z-a)^{-1} dz} }\\
		&=& \norm{\int_{0}^{1}(f_n(\gamma(t))-f(\gamma(t)))(\gamma(t)-a)^{-1}d\gamma(t)}\\
		&\leqslant& \int_{0}^{1} \abs{f_n(\gamma(t))-f(\gamma(t))}\norm{(\gamma(t)-a)^{-1}}d\abs{\gamma}(t) \\
		&\leqslant& M \norm{\gamma} \sup{\{\abs{f_n(z)-f(z)} \colon z \in \gamma(t)\}}
	\end{eqnarray*}
	where $M$ is the bound of $\norm{(\gamma(t)-a)^{-1}}$ since $t \mapsto \norm{(\gamma(t)-a)^{-1}}$ is continuous on $\gamma(t)$. Therefore, by the fact that $f_n \sto f$ uniformly,
	\begin{equation*}
		\norm{f_n(a)-f(a)} \sto 0
	\end{equation*}
	\item Finally, the uniquness is because any $f \in \hol{(a)}$ can be approximated uniformly by a sequence of polynomials. Thus, $1)$ and $2)$ means $\tau(p) = \rho(p)$ for any polynomial $p$, and $3)$ provides the fact that $\tau(f) = \rho(f)$ for any $f \in \hol{(a)}$.
\end{proof}
\begin{rem}
	we have mentioned that the integral definition is coincided with the convergent difinition. In fact, by $2)$, this statement can be proved rigorously.
\end{rem}

\begin{thm}[Spectral Mapping Theorem]
	If $a \in \alg{A}$ and $f \in \hol{(a)}$, then
	\begin{equation*}
		\sigma(f(a)) = f(\sigma(a))
	\end{equation*}
\end{thm}
\begin{proof}
	Firstly, there is a $g \in \hol{(a)}$ s.t. for $\alpha \in \sigma(a)$, $f(z)-f(\alpha) = (z-\alpha)g(z)$, that means $f(\sigma(a)) \subset \sigma(f(a))$.
	\item Conversely, if $\alpha \notin f(\sigma(a))$, $g(z)=(f(z)-\alpha)^{-1} \in \hol{(a)}$. Thus, $g(a)(f(a)-\alpha) = 1$. Therefore, $\alpha \notin \sigma(f(a))$.
\end{proof}

\begin{prop} \label{prop10}
	Let $\alg{A}$ be a Banach algebra and $a \in \alg{A}$. $\sigma(a) = F_1 \bigcup F_2$, where $F_1$ and $F_2$ are disjoint nonempty closed sets. Then there is a nontrial idempotent $e$, i.e. $e^{2}=e$, s.t.
	\begin{enumerate}[label=\arabic*)]
		\item if $ab=ba$, then $eb=be$.
		\item if $a_1=ae$ and $a_2=a(1-e)$, then $a_1a_2=a_2a_1=0$.
		\item $\sigma(a_1)=F_1 \bigcup \{0\}$ and $\sigma(a_2)=F_2 \bigcup \{0\}$.
	\end{enumerate}
\end{prop}
\begin{proof}
	Since $F_1$ and $F_2$ are disjoint closed set, there are two disjoint open sets $G_1$ and $G_2$ separating $F_1$ and $F_2$. Let $f$ be the characteristic function of $G_1$ and $e=f(a)$. Thus $e^{2}=e$ by $f^{2}=f$.
	\item For $1)$, there is a more genera result, $f(a)b=bf(a)$ for any $f \in \hol{(a)}$. It is because by extending the fact $p(a)b=bp(a)$ for any polynomial $p$.
	\item $2)$ is clearly true.
	\item Let $f_1(z)=zf(z)$ and $f_2(z)=z(1-f(z))$. Then $a_j = f_j(a)$ for $j=1,2$. Then by the Spectral Mapping Theorem $\sigma(a_j) = f_j(\sigma(a_j)) = F_j \bigcup \{0\}$.
\end{proof}

\begin{cor}
	Let $\Hs$ be a Hilbert space and $T \in \oper$. If $\sigma(T) = F_1 \cup F_2$, where $F_1$ and $F_2$ are disjoint nonempty closed sets, then there are closed subspaces $\Hs_1$ and $\Hs_2$ with $\Hs = \Hs_1 \oplus \Hs_2$, s.t.
	\begin{enumerate}[label=\arabic*)]
		\item $B\Hs_j \subset \Hs_j$ for $j=1,2$, whenever $BT=TB$.
		\item If $T_j = T|_{\Hs_j} \colon \Hs_j \sto \Hs_j$, then $\sigma(T_j) = F_j$, for $j=1,2$.
	\end{enumerate}
\end{cor}
\begin{proof}
	From above proposition, $e$ is actually the propjection from $\Hs$ to $\Hs_1$. Therefore by the result in above proposition, $1)$ clearly holds.\\
	For $2)$, since $e$ is in fact the indentity from $\Hs_1$ to $\Hs_1$, similarly, by the Spectral Mapping Theorem, $\sigma(T_j) = F_j$.
\end{proof}

\subsection{Abelian Banach Algebras} \label{sec2}
 
 \begin{thm}[Gelfand-Mazur Theorem]
	If $\alg{A}$ is a Banach algebra and a division ring, then $\alg{A} = \C$.
\end{thm}
\begin{proof}
	It is because that for any $a \in \alg{A}$, $\sigma(a) \neq \varnothing$.
\end{proof}

Next, we reach the structure of an abelian Banach algebra. The structure of abelian Banach algebras can be explicit by constructing a map from an abelian Banach algebra to a continuous function space on a compact space. Firstly, we can find this compact space. Let 
\begin{eqnarray*}
	\Sigma(\alg{A}) &=& \{ \text{all algebra homomorphism } h \colon \alg{A} \sto \C\}\\
	\fml{M} &=& \{\text{all maximal ideals of } \alg{A}\}
\end{eqnarray*}
for an abelian Banach algebra $\alg{A}$. Then we can find the relationship between $\Sigma(\alg{A})$ and $\fml{M}$.

\begin{thm}
	Let $\alg{A}$ be an abelian Banach algebra. Define a map
	\begin{center}
		\begin{tabular}{l c c l}
			$\gamma \colon$ & $\Sigma(\alg{A})$ & $\longrightarrow$ & $\fml{M}$ \\
			~ & $h$ & $\longmapsto$ & $\ker{h}$
		\end{tabular}
	\end{center}
	Then $\gamma$ is a bijection.
\end{thm}
\begin{proof}
	Since $\alg{A} / \ker{h} \cong \C$, $\ker{h} \in \fml{M}$, i.e. $\gamma$ is well-defined.
	\item Check: $\alg{A} / M \cong \C$ for any $M \in \fml{M}$\\
		Let $\pi \colon \alg{A} \sto \alg{A} / M$. If $\pi(a)$ is not invertible, then $\pi(a\alg{A})$ is a proper ideal in $\alg{A} / M$. Thus $I = \pi^{-1}(\pi(a\alg{A}))$ is a proper ideal in $\alg{A}$ and $M \subset I$. Then by the maximality of $M$, $I=M$, i.e. $\pi(a)=0$. In fact, for any commutative ring, this result is true. Therefore, by Gelfand-Mazur Theorem, $\alg{A} / M \cong \C$.
	\item Check: $\gamma$ is surjective.
		Let $M \in \fml{M}$. Define $\tilde{h} \colon \alg{A} / M \sto \C$ as the algebraic isomorphism. Then $h=\pi \circ \tilde{h} \in \Sigma(\alg{A})$ with $\ker{h} = M$.
	\item Check: $\gamma$ is injective.
		If $\ker{h} = \ker{h^{'}}$ for $h,h^{'} \in \Sigma(\alg{A})$, then by the \textbf{Propostion} \ref{prop2} in the subsection \textbf{1.4.2}, $h = \alpha h^{'}$. And since $h(1) = h^{'}(1)=1$, $h=h^{'}$.
\end{proof}

Then we have some properties of $h \in \Sigma(\alg{A})$.

\begin{prop} \label{prop5}
	Let $\alg{A}$ be an abelian Banach algebra and $h \in \Sigma(\alg{A})$.
	\begin{enumerate}[label=\arabic*)]
		\item $h$ is continuous.
		\item $\norm{h}=1$ for $h \neq 0$.
	\end{enumerate}
\end{prop}
\begin{proof}
	$1)$ holds since $\ker{h}$ is maximal, thus it is closed.
	\item Let $\lambda = h(a)$. Suppose $\abs{\lambda} > \norm{a}$. Then $1-\frac{1}{\lambda}$ is invertible. Set $b = (1-\frac{1}{\lambda})^{-1}$, then 
	\begin{equation*}
		1=h(b(1-\frac{1}{\lambda})) = h(b) - \frac{h(b)h(a)}{\lambda} =0
	\end{equation*}
	Therefore, $\abs{h(a)} \leqslant \norm{a}$ i.e $\norm{n} \leqslant 1$. Since $h(1) = 1$, $\norm{h}=1$.
\end{proof}

\begin{defn}
	Let $\alg{A}$ be an abelian Banach algebra. Then $\Sigma(\alg{A}) \subset \alg{A}^{*}$ endowed with the induced $wk^{*}$-topology, is called the maximal ideal space of $\alg{A}$.
\end{defn}

\begin{prop} \label{prop6}
	If $\alg{A}$ is an abelian Banach algebra, then $\Sigma(\alg{A})$ is a compact Hausdorff space. Moreover, if $a \in \alg{A}$, then
	\begin{equation*}
		\sigma(a) = \Sigma(a) = \{~ h(a) \colon h \in \Sigma(\alg{A}) ~\}
	\end{equation*}
\end{prop}
\begin{proof}
	Since $\Sigma(\alg{A}) \subset \alg{A}^{*}$, we just need to show $\Sigma(\alg{A})$ is $wk^{*}$-closed. Let $\{h_i\}$ be a net in $\Sigma(\alg{A})$ s.t. $h_i \sto h$ $wk^{*}$ for some $h$ in the unit closed ball of $\alg{A}^{*}$. Then for $a,b \in \alg{A}$,
	\begin{equation*}
		h(ab) = \lim_{i} h_i(ab) = \lim_{i} h_i(a)h_i(b) = h(a)h(b)
	\end{equation*}
	and $h(1)=\lim_{i}h_i(1)=1$, thus $h \in \Sigma(\alg{A})$. $\Sigma(\alg{A})$ is compact.
	\item If $h\in \Sigma(\alg{A})$ and $h-h(a) \in \ker{h} \in \fml{M}$, then $h-h(a)$ is not invertible, i.e. $\Sigma(a) \subset \sigma(a)$. Conversely, if $a-\lambda$ is not invertible, $(a-\lambda)\alg{A}$ is a proper ideal, which can be contained in a maximal ideal. Then $(a-\lambda) \in \ker{h}$ with some $h \in \Sigma(\alg{A})$, $\lambda = h(a) \in \Sigma(a)$.
\end{proof}

Therefore, $\Sigma(\alg{A})$ is the compact space we need. Then we define the map from $\alg{A}$ to $C(\Sigma(\alg{A}))$.

\begin{thm} \label{thm5}
	If $\alg{A}$ is an abelian Banach algebra, the Gelfand transform is defined as
	\begin{center}
		\begin{tabular}{l c c l}
			$\Gamma \colon$ & $\alg{A}$ & $\longrightarrow$ & $C(\Sigma(\alg{A}))$ \\
			~ & $a$ & $\longmapsto$ & $\hat{a} = \Gamma(a)$
		\end{tabular}
	\end{center}
	where $\hat{a}(h)=h(a)$.
	\begin{enumerate}[label=\arabic*)]
		\item $\Gamma$ is a continuous homomorphsim.
		\item $\norm{\Gamma}=1$.
		\item $\ker{\Gamma}=\bigcap\{M \colon M \in \fml{M}\}$.
		\item $\norm{\hat{a}}_{\infty}=r(a)$.
	\end{enumerate}
\end{thm}
\begin{proof}
	Firstly, for $1)$ if $h_i \sto h$ in $wk^{*}$, $\hat{a}(h_i) = h_i(a) \sto h(a) = \hat{a}(h)$. Thus $\Gamma$ is well-defined. And
	\begin{equation*}
		\Gamma(ab)(h) = h(ab) = h(a)h(b) = \Gamma(a)(h)\Gamma(b)(h)
	\end{equation*}
	Thus $\Gamma$ is a homormophsim.
	\item For $2)$, since $\abs{\hat{a}(h)} = \abs{h(a)} \leqslant \norm{a}$, $\norm{\hat{a}}_{\infty} \leqslant \norm{a}$. Then $\norm{\Gamma} \leqslant 1$. By $\Gamma(1) = 1$, $\norm{\Gamma} = 1$.
	\item For $3)$, $a \in \ker{\Gamma}$ if and only if $h(a) = 0$ for any $h \in \Sigma(\alg{A})$, i.e. $a \in \bigcap\{M \colon M \in \fml{M}\}$. 
	\item For $4)$, it holds since $\sigma(a) = \{~ h(a) \colon h \in \Sigma(\alg{A}) ~\}$.
\end{proof}

If $a \in \alg{A}$ s.t. $\clo{\{p(a) \colon p \text{ is any polynomial}\}} = \alg{A}$, then $a$ is called a generator of $\alg{A}$. Clearly, this $\alg{A}$ is commutative. Then we can find an extral property of this special algebra.

\begin{prop} \label{prop7}
	If $\alg{A}$ is an abelian Banach algebra with a generator $a$, then there is a homeomorphism $\tau \colon \Sigma(\alg{A}) \sto \sigma(a)$ s.t. $\Gamma(p(a)) = p \circ \tau$.
\end{prop}
\begin{proof}
	In fact, $\tau$ can be defined as $\tau(h)=h(a)$. By above mention, $\tau$ is continuous and surjective. If $\tau{h_1}=\tau{h_2}$, then $ h_1(a) = h_2(a)$. By the fact that $h_1,h_2 \in \alg{A}$ and $a$ is a generator of $\alg{A}$, $h_1=h_2$. Thus $\tau$ is a bijection. And because $\Sigma(\alg{A})$ is compact, $f$ is a closed map, i.e. $f$ is a homeomorphism.
	\begin{equation*}
		\Gamma(p(a))(h) = p(\Gamma(a))(h) = p(\Gamma(a)(h)) = p(\tau(h))
	\end{equation*}
\end{proof}
\begin{rem}
	If $\alg{A}$ is generate by $a$, then $\Gamma \colon \alg{A} \sto C(\sigma(a))$ can be defined as $\Gamma(p(a)) = p$. 
\end{rem}

In fact, above proposition can extends to $n$ generators. If $\{a_i\}_{i=1}^{n}$ are generators of $\alg{A}$, i.e $\clo{\{p(a_1,\cdots,a_n) \colon p \text{ is any } n \text{ variables polynomial}\}} = \alg{A}$, then we have similar results as above proposition.


\section{\texorpdfstring{$C^{*}$-Algebras}{C*-Algebras}}

Now, we have known $\oper$ is a Banach algebra. But there is another algebraic operation on $\oper$, which let $\oper$ be more interesting than the general Banach algebra. This operation is a map $T \sto T^{*}$ on $\oper$, called an involution, and moreover, it satisfies the condition $\norm{T} = \norm{T^{*}} = \norm{\st{T}T}^{\frac{1}{2}}$. This identity provides a strong relation between the topological structure and the algebraic structure on $\oper$. In fact, the topology is completely determined by the algebraic structure on $\oper$. In order to research this structure, we firstly define an general algebra satisfying above condition, called a $C^{*}$-algebra. By digging its topological structures and algebraic structures, we can embed it into $\oper$ for some Hilbert space $\fml{H}$. Therefore, any $C^{*}$-algebra can be regarded as a subalgebra of $\oper$.

\subsection{Elementary Properties}
\begin{defn}
	If $\alg{A}$ is a Banach algebra, an involution is a map $a \sto a^{*}$ from $\alg{A}$ to $\alg{A}$ satisfying for any $a,b \in \alg{A}$ and any $\alpha \in \C$, 
	\begin{enumerate}[label=\arabic*)]
		\item $(a^{*})^{*}=a$,
		\item $(ab)^{*}=b^{*}a^{*}$,
		\item $(\alpha a+b)^{*} = \clo{\alpha} a^{*}+b^{*}$.
	\end{enumerate}
\end{defn}

\begin{defn}
	A $C^{*}$-algebra is a Banach algebra $\alg{A}$ with an involution s.t. for every $a \in \alg{A}$,
	\begin{equation*}
		\norm{\st{a}a} = \norm{a}^{2}
	\end{equation*}
\end{defn}

Then we can get some easy properties for the norm and the involution.

\begin{prop} \label{prop14}
	Let $\A$ be a \Cs and $a \in \A$.
	\begin{enumerate}[label=\arabic*)]
		\item $\norm{\st{a}} = \norm{a}$.
		\item $\norm{a\st{a}}=\norm{a}^{2}$.
		\item $\norm{a}=\sup{\{\norm{ax} \colon \norm{x} \leqslant 1\}} = \sup{\{\norm{xa} \colon \norm{x} \leqslant 1\}}$.
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, $\norm{a}^{2} = \norm{\st{a}a} \leqslant \norm{\st{a}}\norm{a}$, thus $\norm{a} \leqslant \norm{\st{a}}$. Taking the involution, $\norm{\st{a}} \leqslant \norm{a}$.
	\item $2)$, $\norm{a\st{a}} = \norm{\st{(\st{a})}} = \norm{\st{a}}^{2} = \norm{a}^{2}$.
	\item For $3)$, let $\alpha$ be the supremum, then $\alpha \leqslant \norm{a}$. $a = 0$ is clearly true. For $a \neq 0$, let $x = \st{a} / \norm{a}$. Thus $\alpha \geqslant \norm{a}$.
\end{proof}

If a \Cs $\A$ is without the identity, we can use same method of the Banach algebra to extend it to a unit \Cs $\tilde{\A}$. The only thing we need to prove is the identity. And this can be obtained the result in above proposition. Therefore, we always assume a \Cs is with the identity.

\begin{defn}
	Let $\A$ be a \Cs and $a \in \A$.
	\begin{enumerate}[label=\arabic*)]
		\item $a$ is self-adjoint if $a = \st{a}$.
		\item $a$ is normal if $a\st{a} = \st{a}a$.
		\item $a$ is unitary if $a\st{a}=\st{a}a=1$.
		\item $a$ is a projection if $a$ is self-adjoint and $a=a^{2}$.
	\end{enumerate}
\end{defn}

Then we can see the algebraic strucuture on a \Cs completely determine its norm topology.

\begin{thm}
	Let $\A$ be a \Cs and $a \in \A$. If $a$ is self-adjoint, then
	\begin{equation*}
		r(a) = \norm{a}
	\end{equation*}
\end{thm}
\begin{proof}
	Since $a$ is sef-sdjoint,
	\begin{equation*}
		\norm{a}^{2} = \norm{\st{a}a} = \norm{a^{2}}
	\end{equation*}
	Thus by induction, we have $\norm{a}^{2n} = \norm{a^{2n}}$. Then
	\begin{equation*}
		r(a) = \lim_{n \sto \infty} \norm{a^{n}}^{\frac{1}{n}} = \lim_{n \sto \infty} \norm{a^{2n}}^{\frac{1}{2n}} = \norm{a} \qedhere
	\end{equation*}
\end{proof}
\begin{rem}
	For any $b \in \A$, we know $\st{b}b$ is self-adjoint,
	\begin{equation*}
		r(\st{b}b) = \norm{\st{b}b} = \norm{b}^{2}
	\end{equation*}
	Thus, the norm in a \Cs is completely determined by the spectral radius, which is totally an algebraic trait.
\end{rem}

Now, we can see how the algebraic property influences the topological structure.

\begin{prop} \label{prop8}
	Let $\rho \colon \A \sto \B$ be a $*$-homomorphsim between two $C^{*}$-algebras.
	\begin{enumerate}[label=\arabic*)]
		\item $\rho$ is continuous, and moreover $\norm{\rho(a)} \leqslant \norm{a}$.
		\item If $\rho$ is a $*$-isomorphism, then $\rho$ is an isometry.
	\end{enumerate}
\end{prop}
\begin{proof}
	$2)$ is the direct corollary from $1)$. For $1)$, clearly $\sigma(\rho(a)) \subset \sigma(a)$, thus
	\begin{equation*}
		\norm{\rho(a)}^{2} = r(\rho(\st{a}a)) \leqslant r(\st{a}a) = \norm{a}^{2} \qedhere
	\end{equation*}
\end{proof}

Let $\Rea{\A}$ denote the set of all self-adjoint elements in a \Cs $\A$. Then, for any $a \in \A$, there are $x,y \in \Rea{\A}$, s.t.
\begin{equation*}
	a = x + iy, \text{ where } x = \frac{a + \st{a}}{2}, y = \frac{a-\st{a}}{2i}
\end{equation*}
Therefore, any element in a \Cs $\A$ can be combined by two self-adjoint elements. And the self-adjoint element play a important role in the algebraic structure of a \Cs. 

\begin{prop}
	If $h \colon \A \sto \C$ is an algebraic homomorphis on a \Cs $\A$. 
	\begin{enumerate}[label=\arabic*)]
		\item If $a \in \Rea{\A}$, $h(a) \in \R$.
		\item For any $a \in \A$, $h(\st{a})=\clo{h(a)}$.
		\item $h(\st{a}a) \geqslant 0$ $\forall~ a \in \A$.
		\item If $u \in \A$ is a unitary, then $\abs{u} = 1$.
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, let $h(a) = \alpha +i \beta$ for $\alpha,\beta \in \R$ and $\Cg{a+it}$ be the \Cs generated by $a+it$ and $1$, which is abelian. Therefore, $\norm{h}_{\Cg{a+it}} = 1$ by \textbf{Proposition} \ref{prop5} in the subsection \textbf{2.1.4}. Then we have
	\begin{eqnarray*}
		\abs{h(a+it)} &\leqslant& \norm{a+it}^{2} \\
		&=& \norm{\st{(a+it)}(a+it)} \\
		&=& \norm{a^{2}+t^{2}} \\
		&\leqslant& \norm{a}^{2}+t^2
	\end{eqnarray*}
	i.e.
	\begin{eqnarray*}
		\norm{a}^{2}+t^2 &\geqslant& \abs{\alpha +i(t+\beta)}^2 \\
		&=& \alpha^2 + (\beta+t)^2 \\
		&=& \alpha^2 + \beta^2 +2 \beta t + t^2
	\end{eqnarray*}
	Therefore, for any $t \in \R$, $\norm{a}^2 \geqslant \alpha^2 + \beta^2 +2 \beta t$. Thus, $\beta = 0$. \\
	$2)$ and $3)$ and $4)$ is the direct results from $1)$.
\end{proof}

\begin{cor}
	If $a \in \Rea{A}$, then $\sigma(a) \subset \R$.
\end{cor}
\begin{proof}
	Let $\Cg{a}$ be the \Cs generated by $1$ and $a$. Thus $\Cg{a}$ is abelian. Then by \textbf{Proposition} \ref{prop6} in the subsection \textbf{2.1.4}, 
	\begin{equation*}
		\sigma_{\Cg{a}}(a) = \{~ h(a) \colon h \in \Sigma(\alg{A}) ~\} \subset \R
	\end{equation*} 
	And by the $Corollary$ \ref{cor5} in the subsection \textbf{2.1.2},
	\begin{equation*}
		\sigma(a) = \sigma_{\Cg{a}}(a) \subset \R
	\end{equation*}
\end{proof}

And the spectrum of a element in a \Cs has better property.

\begin{thm}
	If $\B$ is a $C^{*}$-subalgebra of a \Cs $\A$ and $b \in \B$, then
	\begin{equation*}
		\sigma_{\B}(b) = \sigma_{\A}(b)
	\end{equation*}
\end{thm} 
\begin{proof}
	It suffices to show that if $b$ is invertible in $\A$ with the inverse $x$, then $x \in \B$. Then $(a^{*}a)(xx^{*})=1$. Since $a^{*}a \in \B$ and by above corollary, we know $xx^{*} \in \B$. But $x = (x\st{x})\st{a}$, thus $x \in \B$.
\end{proof}

\subsection{Abelian \texorpdfstring{$C^{*}$-Algebras}{C*-Algebras}}

The abelian \Cs is firstly an ablian Banach algebra, thus all results in the subsection \ref{sec2} can be applied to it. But since the involution and the related norm provide more information, we can have better results than the general abelian Banach algebra has. Firsly, we strengthen the \textbf{Theorem} \ref{thm5} in subsection \textbf{2.1.4}.

\begin{thm}
	If $\A$ is an abelian \Cs, then the Gelfand transform $\Gamma \colon \A \sto C(\Sigma(\A))$ is an isometric $*$-isomorphism.
\end{thm}
\begin{proof}
	Firstly, $\Gamma$ is a $*$-homormophism, since the result in \textbf{Theorem} \ref{thm5} and
	\begin{equation*}
		\Gamma(\st{a})(h) = h(\st{a}) = \clo{h(a)} = \clo{\Gamma(a)}(h)
	\end{equation*}
	Now, we can easily see $\Gamma$ is an isometry by $4)$ in the \textbf{Theorem} \ref{thm5},
	\begin{equation*}
		\norm{\hat{a}}_{\infty}^{2} = \norm{\hat{\st{a}a}}_{\infty} = r(\st{a}a) = \norm{a}^2
	\end{equation*}
	Finally, we need to check $\Gamma$ is surjective. It is because $\Gamma(\A)$ is a closed subalgebra of $C(\Sigma(\A))$, which is closed under the complex conjugate and separates points in $\Sigma(\A)$. Then by the Stone-Weierstrass Theorem $\Gamma(\A)=C(\Sigma(\A))$
\end{proof}

We know if $\A = \Cg{a}$ for some normal element $a$, then $\A$ is an abelian \Cs. In fact, 
\begin{equation*}
	\A = \clo{\{~p(a,\st{a}) \colon p(z,\clo{z}) \text{ is a polynomial} ~\}}
\end{equation*}

Then, we can modify the result in the \textbf{Propostion} \ref{prop7} in subsection \textbf{2.1.4}.

\begin{thm}
	Let $\A = \Cg{a}$ for some normal element $a$. Then there is a unique isometric $*$-isomorphism $\rho \colon \A \sto C(\sigma(a))$.
\end{thm}
\begin{proof}
	Firstly, we have a similar homeomorphism
	\begin{center}
		\begin{tabular}{l c c l}
			$\tau \colon$ & $\Sigma(\A)$ & $\longrightarrow$ & $\sigma(a)$ \\
			~ & $h$ & $\longmapsto$ & $h(a)$
		\end{tabular}
	\end{center}
	Then $\rho(x) = \Gamma(x) \circ \tau^{-1}$ is indeed an isometric $*$-isomorphism by the property of Gelfand transform. And moreover, by the result of \textbf{Propostion} \ref{prop7}, for any $z \in \sigma(a)$, $z = h(a)$ for some $h \in \Sigma(\A)$
	\begin{eqnarray*}
		\rho(p(a,\st{a}))(z) &=& \rho(p(a,\st{a}))(h(a)) = \Gamma(p(a,\st{a})) \circ \tau^{-1} (h(a)) \\
		&=& \Gamma(p(a,\st{a}))(h) = h(p(a,\st{a})) \\
		&=& p(h(a), h(\st{a})) = p(h(a), \clo{h(a)}) \\
		&=& p(z,\clo(z))
	\end{eqnarray*}
	That means that $\rho$ maps the polynomials in $\A$ to polynomails in $\sigma(a)$. Therefore, $\rho$ is unique.
\end{proof}

By the Riesz Functional Calculus, we have the map $f \mapsto f(a)$ from $\hol{(a)}$ to $\A$ for a \Cs $\A$ and any element $a \in \A$. Now, we can extend this definition a $C(\sigma(a))$ by above $\rho$, but we need $a$ is normal, then
\begin{center}
	\begin{tabular}{l c c l}
		$\rho^{-1} \colon$ & $C(\sigma(a))$ & $\longrightarrow$ & $\Cg{a}$ \\
		~ & $f$ & $\longmapsto$ & $f(a)$
	\end{tabular}
\end{center}
defined above is an isometric isomorphism and $\rho^{-1}$ maps
\begin{center}
	\begin{tabular}{r @{$~\longmapsto$~} l}
		$1$ & $1$ \\
		$z$ & $a$ \\
		$\clo{z}$ & $\st{a}$ \\
		$z^{-1}$ & $a^{-1}$\\
		$p(z,\clo{z})$ & $p(a,\st{a})$ 
	\end{tabular}
\end{center}

Therefore, this map is unique and it is clearly the extension of the Riesz Functional Calculus, called Continuous Functional Calculus. Like the Riesz Functional Calculus, there is also a Spectral Theorem.
\begin{thm}[Spectral Theorem]
	Let $\A$ be a \Cs and $a \in \A$ be a normal element, then for $f \in C(\sigma(a))$, 
	\begin{equation*}
		\sigma(f(a)) = f(\sigma(a))
	\end{equation*}
\end{thm}
\begin{proof}
	For some compact space $X$ and $f \in C(X)$, then $C(X)$ with the supremum norm is a \Cs and $\sigma(f) = \ran{f}$. Then since $f \mapsto f(a)$ is a $*$-isomorphism, 
	\begin{equation*}
		\sigma(f(a)) = \sigma_{C(\sigma(a))}(f) = \ran{f} = f(\sigma(a)) \qedhere
	\end{equation*}
\end{proof}


There is an important example.
\begin{exam} \label{exam2}
	Let $\mu$ be a compactly supported, regular Borel measure on $\C$ and ($X,\Omega,\mu$) be the measure space. For each $\pi \in \lfs{\infty}(\mu)$, we define the map
	\begin{center}
		\begin{tabular}{l c c l}
			$M_{\phi} \colon$ & $\lfs{2}(\mu)$ & $\longrightarrow$ & $\lfs{2}(\mu)$ \\
			~ & $f(z)$ & $\longmapsto$ & $\phi(z)f(z)$
		\end{tabular} 
	\end{center}
	Then clearly $M_{\phi}$ is in $\fml{B}(\lfs{2}(\mu))$.
	\begin{enumerate}[label=\arabic*)]
		\item $\st{(M_{\phi})} = M_{\clo{\phi}}$ and $M_{\phi}$ is a normal element in $\fml{B}(\lfs{2}(\mu))$.
		\item $\phi \mapsto M_{\phi}$ is a $*$-homomorphism from $\lfs{\infty}(\mu)$ to $\lfs{2}(\mu)$.
		\item $\norm{M_{\phi}} = \norm{\phi}_{\infty}$.
		\item $\sigma(M_{\phi})= \bigcap\{\clo{\phi(U)} \colon U \in \Omega ~\&~ \mu(X \backslash U) = 0\}$.
		\item If $f \in C(\sigma(M_{\phi}))$, then $f(M_{\phi}) = M_{f \circ \phi}$.
	\end{enumerate}
	If $\phi(z) = z$, we set denote $N_{\mu} = M_{\phi}$ and in fact, $\sigma(N_{\mu}) = \supp{\mu}$.
\end{exam}


\subsection{Positive Elements}

We have known that self-adjoint elements play a important role in a \Cs $\A$. The self-adjoint element $a$ in $\A$ is like the real number in $\C$, and the relationship between them can be revealed by the fact $a \in \Rea{\A}$ if and only if $\sigma(a) \subset \R$. The converse is obtained by the Continuous Functional Calculus. In fact, Continuous functional calculus can provide more relation between the element in $\A$ and the elment in $\C$, like positivity.

\begin{defn}
	Let $\A$ be a \Cs and $a \in \Rea{\A}$. Then $a$ is called a positive element if and only if $\sigma(a) \subset \R^{+}$, denoted by $a \geqslant 0$. And let $\A_{+}$ be the set of all positive elements.
\end{defn}

This definition is nature by above mention, but it may not be very explicit. So we need to show more direct equivalent definitions of positive elements.

\begin{thm}
	Let $\A$ be a \Cs. Then the following statements are equivalent.
	\begin{enumerate}[label=\arabic*)]
		\item $a \geqslant 0$.
		\item $a = b^2$ for some $b \geqslant 0$.
		\item $a \in \Rea{\A}$ and $\norm{t - a} \leqslant 0$ for all $t \geqslant \norm{a}$.
		\item $a \in \Rea{\A}$ and $\norm{t - a} \leqslant 0$ for some $t \geqslant \norm{a}$
	\end{enumerate}
\end{thm}
\begin{proof}
	All of these can be done by the functional calculus. And our goal is to find some vilid functions in $C(\sigma(a))$ to complete these.
	\item $1) \Rightarrow 2)$ Let $f(x) = \sqrt{x}$ in $C(\sigma(a))$ and since $\sigma(a) \subset \R^{+}$, $f$ is well-defined. Let $b = f(a)$. Then, we have $a = b^{2}$. And by Spectral Theorem, $\sigma(b) = \sigma(f(a)) \subset \R{+}$.
	\item $2) \Rightarrow 3)$ Let $f(x) = x^2$ defined on $\sigma(b)$, then $a = f(b)$ and $\norm{a} = \norm{f}_{\infty}$. By this condition, $f(x) \geqslant 0$. Thus $\sigma(a) = f(\sigma(b)) \subset \R^{+}$.
	\item $3) \Rightarrow 4)$ It is trivial.
	\item $4) \Rightarrow 1)$ Let $f(x) = x$ defined on $\sigma(a) \subset \R$. Then this condition means 
	\begin{equation*}
		\norm{t-f}_{\infty} = \norm{t-f(a)} =\norm{t-a} \leqslant t
	\end{equation*}
	for some $t \geqslant \norm{a} = \norm{f}_{\infty}$. Therefore, $f(x) \geqslant 0$ for all $x \in \sigma(a)$. Thus $\sigma(a) = f(\sigma(a)) \subset \R^{+}$.
\end{proof}

Like the fact that any element in a \Cs can be combined by two self-ajoint elements, any self-adjoint element can be combined by two positive elements.

\begin{prop}
	Let $\A$ be a \Cs. If $a \in \Rea{\A}$, then there are unique $u,v \in \R^{+}$, s.t.
	\begin{equation*}
		a = u - v ~~\&~~ uv = vu = 0
	\end{equation*}
\end{prop}
\begin{proof}
	Let $f(x) = \max{x,0}$ and $g(x) = - \min{x,0}$. Then $f,g \in C(\sigma(a))$ and $f(x)-g(x)=x$ and $f(x)g(x)=0$. Then $u = f(a)$ and $v = g(a)$ satisfy above conditions.\\
	If $a=u_1-v_1$, then we can know $\Cg{a,u,v,u_1,v_1}$ is an abelian \Cs, thus for some compact space $X$, $\Cg{a,u,v,u_1,v_1} \cong C(X)$. And this uniqueness can be proved in a continuous function space.
\end{proof}

\begin{cor}
	Let $\A$ be a \Cs. Then $\A_{+}$ is a cone.
\end{cor}
\begin{proof}
	Let $\{a_n\} \subset \A_{+}$ be a sequence s.t. $a_n \sto a$. Then by above proposition, $\norm{a_n-\norm{a_n}} \leqslant \norm{a_n}$. Taking norm limit, 
	$\norm{a-\norm{a}} \leqslant \norm{a}$, thus $a \in \A_{+}$.\\
	Clearly, $\alpha \A_{+} \subset \A_{+}$ for any $\alpha >0$. For $a, b \in \A$, we can assume that $\norm{a} \leqslant 1$ and $\norm{b} \leqslant 1$, then
	\begin{equation*}
		\norm{1-\frac{1}{2}(a+b)} = \frac{1}{2}\norm{(1-a)+(1-b)} \leqslant 1
	\end{equation*}
	Thus $\frac{1}{2}(a+b) \in \A_{+}$, i.e. $a+b \in \A_{+}$.
\end{proof}

Then, we can build an order on $\Rea{\A}$ by defining $a \leqslant b \Leftrightarrow b-a \in \A_{+}$. And moreover, let $\A_{-} = - \A_{+}$, then $\A_{-} \bigcap \A_{+} = \{0\}$. There are other properties of positivity.

\begin{prop}
	Let $\A$ be a \Cs.
	\begin{enumerate}[label=\arabic*)]
		\item If $a \geqslant 0$, then there is a unique $b \geqslant 0$ s.t. $a = b^n$.
		\item If $a \in \A$, then $\st{a}a \in \A_{+}$.
		\item If $a \leqslant b$ in $\Rea{\A}$, then $\st{c}ac \leqslant \st{c}bc$ for any $c \in \A$.
		\item For any $a \in \Rea{\A}$, $-\norm{a} \leqslant a \leqslant \norm{a}$ and if $a \in \A$, $0 \leqslant \st{a}a \leqslant \norm{a}^2$.
		\item If $0 \leqslant a \leqslant b$, then $b^{-1} \leqslant a^{-1}$.
		\item For any $a \in \A$, we define $\abs{a} = \sqrt{\st{a}a}$, then $\abs{a} = a_{+}+a_{-}$.
		\item If $0 \leqslant a \leqslant b \in \A$, then $\norm{a} \leqslant \norm{b}$.
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, let $f(x)= \sqrt[n]{x}$ defined on $\sigma(a) \subset \R$, then $b=f(a)$ sastisfying $ a = b^{n}$.
	\item For $2)$, let $b = \st{a}a = b_{+} - b_{-}$ and $c = \sqrt{b_{+}}$  and $d=ac$. Since $\st{d}d = b_{-}^2 \in \A_{+}$, $\st{d}d \in \A_{-}$. Let $d = x + iy$, then $d\st{d} + \st{d}d = 2(x^2+y^2) \in \A_{+}$. Thus
	\begin{equation*}
		d\st{d} = d\st{d} + \st{d}d -\st{d}d \in \A_{+}
	\end{equation*}
	By the fact that $\sigma(d\st{d})\bigcup\{0\} = \sigma(\st{d}d)\bigcup\{0\}$, $b_{-}^2 = -\st{d}d =0$. Therefore, $b = \st{a}a \in \A_{+}$.
	\item For $3)$, let $d = \sqrt{b-a}$, then 
	\begin{equation*}
		\st{c}bc - \st{c}ac = \st{c}(b-a)c = \st{c}\st{d}dc = \st{(dc)}dc \in \A_{+}
 	\end{equation*}
 	\item For $4)$, if $x \in \sigma(a)$, $\abs{x} \leqslant \norm{a}$. Therefore, $f(x) = \norm{a}-x$ and $g(x) = \norm{a}+x$ are positive on $\sigma(a)$.
 	\item For $5)$, since $0 \leqslant a \leqslant b$,
 	\begin{equation*}
 		1-b^{-\frac{1}{2}}ab^{-\frac{1}{2}} = b^{-\frac{1}{2}}(b-a)b^{-\frac{1}{2}} \geqslant 0
 	\end{equation*}
 	i.e. $\st{(a^{\frac{1}{2}} b^{-\frac{1}{2}})}(a^{\frac{1}{2}} b^{-\frac{1}{2}}) \leqslant 1$, therefore $\norm{a^{\frac{1}{2}} b^{-\frac{1}{2}}} \leqslant 1$ by functional calculus as similar as $4)$. And thus $1 \geqslant (a^{\frac{1}{2}} b^{-\frac{1}{2}})\st{(a^{\frac{1}{2}} b^{-\frac{1}{2}})} = a^{\frac{1}{2}}b^{-1}a^{\frac{1}{2}}$. Therefore, $a^{-1}=a^{-\frac{1}{2}}1a^{-\frac{1}{2}} \geqslant b^{-1}$.
 	\item $6)$ holds by the functional calculus and the uniqueness is by $1)$.
 	\item For $7)$, $\sigma(a) = \{h(a) \colon h \in \Sigma(\A)\} \subset \R^{+}$ and $\sigma(b) = \{h(b) \colon h \in \Sigma(\A)\} \subset \R^{+}$ and $\sigma(b-a) = \{h(b-a) \colon h \in \Sigma(\A)\} \subset \R^{+}$, therefore $h(b) \geqslant h(a) \geqslant 0$ for any $h \in \Sigma(\A)$. That means $r(b) \geqslant r(a)$, i.e. $\norm{b} \geqslant \norm{a}$.
\end{proof}

By using $2)$ on above proposition, we can easily see that
\begin{cor} \label{cor7}
	Let $\Hs$ be a Hilbert space and $T \in \oper$. If $T$ is positive, then for any $h \in \Hs$
	\begin{equation*}
		\langle Th,h \rangle \geqslant 0
	\end{equation*}
\end{cor}
\begin{rem}
	There is a $A \in \oper$ s.t. $T=\st{A}A$, thus above statement is true. In fact, the converse is also true.
\end{rem}

\subsection{Approximate Identities}

When we research the proper ideal of an algebra, this ideal does not contain the identity. So for the ideal of a $\st{C}$-algebra, we want to find some element has similar property as the identity has in the ideal.

\begin{defn}
	Let $\A$ be a \Cs and $\{e_i\}$ be a net in $\A$ s.t.
	\begin{enumerate}[label=\arabic*)]
		\item $0 \leqslant e_i \leqslant 1$ for all $i$,
		\item $e_i \leqslant e_j$ for $i \leqslant j$,
		\item $\lim_{i} ae_i = \lim_{i} e_ia = a$ for any $a \in \A$,
	\end{enumerate}
	Then $\{e_i\}$ is called an approximate identity for $\A$.
\end{defn}

\begin{thm}
	Every \Cs $\A$ has an approximate identity.
\end{thm}
\begin{proof}
	Firstly, let $\Lambda = \{e \in \A_{+} \colon e < 1\}$. We can check $\Lambda$ is indeed a direct set with respect to $\leqslant$. Define two functions as
	\begin{eqnarray*}
		f(t) &=& \frac{t}{1-t},~ \forall~ t \in [0,1),\\
		g(t) &=& \frac{t}{1+t} = 1 - \frac{1}{1+t},~ \forall~ t \in [0,\infty).
	\end{eqnarray*}
	In fact, $g(f(t))=t$. Then for any $a,b \in \Lambda$, let $y=f(a)+f(b)$ and $c = g(y)$. And since $\norm{g}_{\infty} < 1$, $c \in \Lambda$. The fact that $x=f(a) \leqslant y$ implies $1+x \leqslant 1+y$. Then $(1+x)^{-1} \geqslant (1+y)^{-1}$.
	\begin{equation*}
		a = g(f(a)) = g(x) = 1 - (1+x)^{-1} \leqslant 1-(1+y)^{-1} =c
	\end{equation*}
	Similarly, $b \leqslant c$. Therefore, $\Lambda$ is direct.
	\item If $a \in \A_{+}$, let $e_n=g(na) \in \Lambda$. Define
	\begin{equation*}
		h(t) = t^2(1-g(nt)) = \frac{t^2}{1+nt} \leqslant \frac{t}{n}
	\end{equation*}
	Thus $h(a)= a^2(1-g(na)) = a(1-e_n)a$, that means
	\begin{equation*}
		\norm{a(1-e_n)a} = \norm{h}_{\infty} \leqslant \frac{\norm{a}}{n}
	\end{equation*}
	For any $\varepsilon > 0$, we can choose a $N$, s.t. for $n > N$, $\norm{a(1-e_n)a} < \varepsilon$. Moreover, since for $0 \leqslant d \leqslant b \leqslant 1 \in \A$, $\st{c}(1-b)c \leqslant \st{c}(1-d)c$ for any $c \in \A$. Therefore, 
	\begin{equation*}
		\norm{\st{c}(1-b)c} \leqslant \norm{\st{c}(1-d)c}
	\end{equation*}
	And combining above mention and the fact for $0 \leqslant d \leqslant b \leqslant 1 \in \A$,
	\begin{eqnarray*}
		\norm{c-dc}^2 &\leqslant& \norm{\st{c}(1-d)c} \\
		\norm{c-cd}^2 &\leqslant& \norm{\st{c}(1-d)c}
	\end{eqnarray*}
	implies for $e \geqslant e_N$, 
	\begin{eqnarray*}
		\norm{a-ea}^2 &<& \varepsilon \\
		\norm{a-ae}^2 &<& \varepsilon
	\end{eqnarray*}
	Therefore, 
	\begin{equation*}
		\lim_{i} ae_i = \lim_{i} e_ia = a,~~\forall~~a \in \A 
	\end{equation*}
	For arbitrary $a \in \A$, $a$ can be write as the linear combination of four positive elements.
\end{proof}
\begin{rem}
	The result that $\Lambda$ is direct is also true for $\A$ without the identity, since $g(0)=f(0)=0$, which means $x, y, c \in \A$. And if $\A$ is separable, we can find a sequential approximate identity in its countable dense subset. Moreover, this sequential approximate identity can apply in whole $\A$.
\end{rem}

Then we can use the approximate identity to get some interesting results. First, we need a lemma.

\begin{lem}
	If $\A$ is a \Cs and $x,y \in \A$, $a \in \A_{+}$ s.t. $\st{x}x \leqslant a^{\alpha}$ and $\st{y}y \leqslant a^{\beta}$ for some positive scalars $\alpha$ and $\beta$ with $\alpha + \beta > 1$, then the sequence $u_n = x(n^{-1}+a)^{-\frac{1}{2}}$y converges to a $u \in \A$ with $\norm{u} \leqslant \norm{a^{\frac{1}{2}(\alpha+\beta-1)}}$.
\end{lem}
\begin{proof}
	Let $d_nm = (n^{-1}+a)^{-\frac{1}{2}}-(m^{-1}+a)^{-\frac{1}{2}}$.
	\begin{eqnarray*}
		\norm{u_n-u_m}^2 &=& \norm{xd_nmy}^2 = \norm{\st{y}d_nm\st{x}xd_nmy} \\
		&\leqslant& \norm{a^{\frac{\alpha}{2}}d_nmy}^2 = \norm{a^{\frac{\alpha}{2}}d_nm\st{y}yd_nma^{\frac{\alpha}{2}}} \\
		&\leqslant& \norm{a^{\frac{\alpha}{2}}d_nm a^{\beta} d_nma^{\frac{\alpha}{2}}} \\
		&=& \norm{d_nm a^{\frac{\alpha+\beta}{2}}}^2
	\end{eqnarray*}
	Since $f_n(t) = (n^{-1}+t)t^{\frac{\alpha+\beta}{2}}$ is an increasing positive sequence, $d_n=(n^{-1}+a)a^{\frac{\alpha+\beta}{2}}$ is an increasing positive sequence in $\A_{+}$. By Dini's Theorem, since $\sigma(a)$ is compact, there is a continuous fuction $f$ s.t. $f_n \sto f$ uniformly. Let $d = f(a)$, thus $d_n \sto d$ in norm. Thus $\{u_n\}$ is Cauchy and there exists $u = \lim_{n \sto \infty} u_n$.
	\begin{equation*}
		\norm{u_n} = \norm{x(n^{-1}+a)^{-\frac{1}{2}}} \leqslant \norm{(n^{-1}+a)a^{\frac{\alpha+\beta}{2}}} \leqslant \norm{a^{\frac{1}{2}(\alpha+\beta-1)}} \qedhere
	\end{equation*}
\end{proof}

\begin{prop}
	If $\A$ is a \Cs and $a \in \A{+}$ and $x \in \A$ with $\st{x}x \leqslant a$, and $0<\alpha<\frac{1}{2}$, then there exists $u \in \A$ with $\norm{u} \leqslant \norm{a^{\frac{1}{2}-\alpha}}$ and $x=ua^{\alpha}$.
\end{prop}
\begin{proof}
	Let $u_n=x(n^{-1}+a)^{-\frac{1}{2}}a^{\frac{1}{2}-\alpha}$. By above lemma, $u_n \sto u$ with $\norm{u} \leqslant \norm{a^{\frac{1}{2}-\alpha}}$. We use similar prove as above lemma, 
	\begin{eqnarray*}
		\norm{x-u_na^{\alpha}}^2 &=& \norm{x(1-(n^{-1}+a)^{-\frac{1}{2}}a^{\frac{1}{2}})}^2 \\
		&\leqslant& \norm{(1-(n^{-1}+a)^{-\frac{1}{2}}a^{\frac{1}{2}})a(1-(n^{-1}+a)^{-\frac{1}{2}}a^{\frac{1}{2}})} \\ 
		&=& \norm{a^{\frac{1}{2}}(1-(n^{-1}+a)^{-\frac{1}{2}}a^{\frac{1}{2}})}^2 \\
		&=& \norm{a^{\frac{1}{2}}-(n^{-1}+a)^{-\frac{1}{2}}a}
	\end{eqnarray*}
	By the Dini's Theorem, $(n^{-1}+a)^{-\frac{1}{2}}a \sto a$ in norm. Therefore, $u_na^{\alpha} \sto a$ i.e. $a = ua^{\alpha}$.
\end{proof}
\begin{cor}
	If $\A$ is a \Cs and $x \in \A$ and $0 < \beta <1$, then there is a $u \in \A$ s.t.
	\begin{equation*}
		x = u\abs{x}^{\beta}	
	\end{equation*}
\end{cor}

\subsection{Ideals and Quotients}

Firstly, there are two easy results of closed ideal in a $\st{C}$-algebra.

\begin{prop} \label{prop12}
	Let $\A$ be a $\st{C}$-algebra.
	\begin{enumerate}[label=\arabic*)]
		\item If $\I$ is a closed left or right ideal of $\A$, $a \in \I$ with $a=\st{a}$, then for $f \in C(\sigma(a))$ with $f(0)=0$, $f(a) \in \A$.
		\item If $\I$ is a closed ideal, then $a \in \I$ implies $\st{a} \in \A$.
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, if $\I$ is proper, $0 \in \sigma(a)$. Then $f(0) = 0 and \sigma(a) \subset \R$, $f$ can be approximated by a sequence of polynomials $p_n$ with $p_n(0) = 0$. Therefore, $p_n(a) \in \I$ and by the fact that $\I$ is closed, $f(a) \in \I$.
	\item For $a \in \I$, by the corollary in above subsection, we know there is a $u \in \A$ s.t. $a=u\abs{a}^{\frac{1}{2}}$. By $1)$, $\abs{a}^{\frac{1}{2}} \in \I$. Therefor,
	\begin{equation*}
		\st{a} = \abs{a}^{\frac{1}{2}} u \in \I \qedhere
	\end{equation*}
\end{proof}

\begin{defn}
	If $\A$ is a \Cs and $\B$ is a $*$-subalgebra of $\A$, then $\B$ is called hereditary if for any $b \in \B_{+}$ and $x \in \A$ with $0 \leqslant x \leqslant b$, $x \in \B$.
\end{defn}

Now, we can give more profound properties of the closed left ideals.

\begin{thm} \label{thm6}
	Let $\A$ be a $\st{C}$-algebra.
	\begin{enumerate}[label=\arabic*)]
		\item If $\I$ is a closed left ideal of $\A$ and $\B = \I \bigcap \st{\I}$, then $\B$ is a hereditary subalgebra of $\A$.
		\item If $\B$ is a hereditary subalgebra of $\A$ and $\I = \{x\in \A \colon \st{x}x \in \B\}$, then $\I$ is a closed left ideal of $\A$.
		\item If $\I$ is a closed left ideal of $\A$ and $\B = \I \bigcap \st{\I}$, then $\I = \{x\in \A \colon \st{x}x \in \B\}$.
		\item If $\B$ is a hereditary subalgebra of $\A$ and $\I = \{x\in \A \colon \st{x}x \in \B\}$, then $\B = \I \bigcap \st{\I}$.
	\end{enumerate}
\end{thm}
\begin{proof}
	For $1)$, clearly, $\B$ is a $\st{C}$-algebra. Let $0 \leqslant x \leqslant b$ for some $b \in \B_{+}$. Since $x^{\frac{1}{2}}x^{\frac{1}{2}} \leqslant b$ there is a $u \in \A$, s.t. $x^{\frac{1}{2}} = u b^{\frac{1}{3}}$. But $b^{\frac{1}{3}} \in \B_{+} \subset \I$. Therefore, $x^{\frac{1}{2}} \in \I$ and thus $x \in \I$. Since $x$ is self-adjoint, $x \in \B$.
	\item For $2)$, if $x \in \I$ and $a \in \A$, then 
	\begin{equation*}
		\st{(ax)}ax = \st{x}\st{a}ax \leqslant \norm{a}^2 \st{x}x \in \B.
	\end{equation*}
	Therefore, $\st{(ax)}ax \in \B$, i.e. $ax \in \I$. If $x,y \in I$, then 
	\begin{equation*}
		\st{(x+y)}x+y \leqslant \st{(x+y)}(x+y)+\st{(x-y)}(x-y) = 2 (\st{x}x+\st{y}y) \in \B
	\end{equation*}
	Thus, $\I$ is a closed left ideal.
	\item For $3)$, if $x \in \A$ and $\st{x}x \in \B$, $\st{x}x \in \I$. Thus $\abs{x}^{\frac{1}{2}} \in \I$ since $\I$ is a closed left ideal. Therefore, $x = u \abs{x}^{\frac{1}{2}} \in \I$. The converse is clearly true.
	\item For $4)$, if $x \in \I_{+}$, then $x^2 \in \B$. So $x = \sqrt{x^2} \in \B_{+}$. Conversely, $x \in \B_{+}$ means $\st{(x^{\frac{1}{2}})}(x^{\frac{1}{2}}) = x \in \B$, $x^{\frac{1}{2}} \in \I_{+}$. Therefore, $\B_{+} = \I_{+}$. Thus, $\B = \I \bigcap \st{\I}$. 
\end{proof}

\begin{thm}
	If $\I$ is a closed ideal of a \Cs $\A$, then the quotient algebra $\A / \I$ with the induced norm and the induced involution, i.e. $\st{a+\I} = \st{a}+\I$ is also a \Cs and the norm can be
	\begin{equation*}
		\norm{a+\I} = \inf{\{~\norm{a-ax} \colon x \in \I_{+}, \norm{x} \leqslant 1~\}}
	\end{equation*}
\end{thm}
\begin{proof}
	Firstly, let $\{e_i\}$ be an approximate identity for $\I$. Since $0 \leqslant e_i \leqslant 1$, if $a \in \A$ and $y \in \I$, $\norm{(a+y)(1-e_i)} \leqslant \norm{a+y}$.
	\begin{eqnarray*}
		\norm{a+y} &\geqslant& \liminf_{i} \norm{(a+y)(1-e_i)} \\
		&=& \liminf_{i} \norm{(a-ae_i)+(y-ye_i)} \\
		&=& \liminf_{i} \norm{(a-ae_i)}
	\end{eqnarray*}
	The converse is clearly true.
	\item The involution defined on the quotient algebra is well-defined and satifies the conditions since $\I$ is self-adjoint. We just need to show the induced norm satisfies the $\st{C}$-identity. For $a \in \A$, we have $\norm{\st{a}+\I} = \norm{a+\I}$, and 
	\begin{eqnarray*}
		\norm{a+\I}^2 &=& \norm{(\st{a}+\I)(a+\I)} \\
		&\leqslant& \norm{\st{a}+\I}\norm{a+\I} \\
		&=& \norm{a+\I}^2
	\end{eqnarray*}
	Conversely,
	\begin{eqnarray*}
		\norm{a+\I}^2 &=& \inf{\{~\norm{a-ax}^2 \colon x \in \I_{+}, \norm{x} \leqslant 1~\}}\\
		&=& \inf{\{~\norm{(1-x)\st{a}a(1-x)} \colon x \in \I_{+}, \norm{x} \leqslant 1~\}}\\
		&\leqslant& \inf{\{~\norm{\st{a}a(1-x)} \colon x \in \I_{+}, \norm{x} \leqslant 1~\}}\\
		&=& \norm{\st{a}a+\I}
	\end{eqnarray*}
	Therefore, $\A / \I$ is indeed a $\st{C}$-algebra.
\end{proof}

Then it can provide a \Cs with some similar results as general rings have. These results can also show us how the algebraic structure in a \Cs affect the topological structure. In my oppion, for researching a \Cs, researching the algebraic structure may be more important.

\begin{cor}
	Let $\A$ and $\mathfrak{C}$ be two $\st{C}$-algebras.
	\begin{enumerate}[label=\arabic*)]
		\item If $\rho \colon \A \sto \mathfrak{C}$ is a $*$-homomorphism, then $\ran{\rho}$ is a \Cs and the induced map $\tilde{\rho} \colon \A / \ker{\rho} \sto \ran{\rho}$ is an $*$-isomorphism.
		\item If $\I$ is a closed ideal of $\A$ and $\B$ is a subalgebra of $\A$, then there is a $*$-isomorphism
		\begin{equation*}
			 \B / (\B \cap \I) \cong (\B+\I) / \I
		\end{equation*}
	\end{enumerate}
\end{cor}
\begin{proof}
	For $1)$, we just need to show $\ran{\rho}$ is closed.\\ Since $\tilde{\rho}$ is a $*$-monomorphism from $\A / \ker{\rho}$ to $\C$, by the result in \textbf{Proposition} \ref{prop8} in the subsection \textbf{2.1.1}, $\rho$ is an isometry. Thus $\ran{\rho}=\rho(\A)$ is closed.
	\item For $2)$, there is a commutative graph like
	\begin{center}
		\begin{tikzcd}
			\B \arrow[r, "i"] \arrow[d, "Q"]
				& \A \arrow[ld, "\pi"] \\
			\A / \I
		\end{tikzcd}
	\end{center}
	$Q=\pi \circ i \colon \B \sto \B / \I$ and thus $\pi^{-1}(Q(\B)) = \B + \I$. By restricting $\pi$ on $\B + \I$, then we have
	\begin{equation*}
		(\B+\I) / \I \cong Q(\B) \cong \B / (\B \cap \I) \qedhere
	\end{equation*}
\end{proof}

\subsection{Positive Functionals and GNS Construction}

We have known that $\oper$ is a $\st{C}$-algebra. In fact, defining the general \Cs is to research the operator algebra. Moreover, by the properties, we can see any \Cs is a $*$-subalgebra of $\oper$ for some $\Hs$. To prove that, we just need to find a faithful representation of the fixed $\st{C}$-algebra. Therefore, the main idea is to construct a representation $(\pi,\Hs)$. How to construct it is a question. But, fortunately, some special functionals can provide us a method.

\begin{defn}
	Let $\A$ be \Cs and $\phi$ is a linear functional on $\A$. $\phi$ is called positive if for any $a \in \A_{+}$, $\phi(a) \leqslant 0$. A positive linear functional $\phi$ is called a state if $\phi(1) = 1$.
\end{defn}
\begin{rem}
	Let $\St_{\A}$ denote the set of all states on $\A$.
\end{rem}

Then there are some properties of positive functionals.

\begin{prop}
	Let $\A$ be a \Cs and $\phi$ be a positive functional.
	\begin{enumerate}[label=\arabic*)]
		\item For any $x,y \in \A$, then
		\begin{equation*}
			\abs{\phi(\st{y}x)} \leqslant \phi(\st{x}x)\phi(\st{y}y)
		\end{equation*}
		\item $\phi$ is bounded and if $\{e_i\}$ is an approximate identity of $\A$, then
		\begin{equation*}
			\norm{\phi} = \lim_{i} \phi(e_i)
		\end{equation*}
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, it can easily check that $<x,y> = \phi(\st{y}x)$ is a semi-inner product, thus by the CBS inequality, above inequality is true.
	\item Assume $\A$ without identity.  If $\phi$ is unbounded, then there is a sequence $\{a_k\} \in \A_{+}$ with $\norm{a_k} \leqslant 1$ s.t. $\phi(a_k) > 2^k$. Let $a = \sum_{k=1}^{\infty} 2^{-k} a_k$. Then
	\begin{equation*}
		\phi(a) \geqslant \phi(\sum_{k=1}^{n} 2^{-k} a_k) > n
	\end{equation*}
	which is a contradiction.
	\begin{equation*}
		\alpha = \sup{\{~\phi(a) \colon a \in \A_{+}, \norm{a} \leqslant 1~\}} < \infty
	\end{equation*} 
	Since any element in $\A$ can be a linear combination of four positive elements, $\norm{\phi} \leqslant 4\alpha$. Therefore, $\phi$ is bounded.\\
	Let $\beta = \lim_{i}\phi(e_i)$. Clearly, $\beta \leqslant \norm{\phi}$. And since for $a \in \A$ with $\norm{a} \leqslant 1$ then $0 \leqslant \st{a}a \leqslant 1$
	\begin{equation*}
		\abs{\phi(a)}^2 = \lim_{i} \abs{\phi(e_ia)}^2 \leqslant \lim_{i}\phi(e_i)\phi(\st{a}a) \leqslant \beta \norm{\phi}
	\end{equation*}	
	\begin{equation*}
		\norm{\phi}^2 \leqslant \beta \norm{\phi}
	\end{equation*}
	i.e. $\norm{\phi} \leqslant \beta$.
\end{proof}
\begin{rem}
	For $2)$, if $\A$ has an identity, then $\norm{\phi} = \phi(1)$. It is because for $a \in \A$ with $\norm{a} \leqslant 1$
	\begin{equation*}
		\abs{\phi(a)}^2 \leqslant \phi(\st{a}a)\phi(1) \leqslant \phi(1)^2
	\end{equation*}
	i.e. $\abs{\phi(a)} \leqslant \phi(1)$.
\end{rem}

In fact, the converse of $2)$ in above proposition is also true.
\begin{prop}
	Let $\A$ be \Cs and $\phi$ is a bounded linear functional with $\norm{\phi} = \phi(1)$, then $\phi \leqslant 0$.
\end{prop}
\begin{proof}
	If $\A=C(X)$ for some compact space $X$, $\phi$ is a measure $\mu$ with $\mu(X)=\norm{\mu}$, then $\mu \geqslant 0$, i.e. $\phi$ is positive. Then for any $\A$, if $a \in \A_{+}$, $\B=\Cg{a} \cong C(\sigma(a))$. Then $\phi|_\B(1) \leqslant \norm{\phi} = \phi(1) = \phi|_\B(1)$, thus $\phi|_\B(a) = \phi(a) \geqslant 0$.
\end{proof}
Using above proposition and the Hahn-Banach Theorem, we can get the corollary.
\begin{cor} \label{cor6}
	If $\A$ is a \Cs and $\B$ is a $\st{C}$-subalgebra of $\A$, then every state on $\B$ can extend to $\A$.
\end{cor}	

Now, we can construct the a representation of a $\st{C}$-algebra. A representation $(\pi,\Hs)$ of a \Cs $\A$ is called cyclic if there is a unit cyclic vector $e$ s.t. $\clo{\pi(\A)e} = \Hs$.

\begin{thm}[Gelfand-Naimark-Segal Construction]
	Let $\A$ be a \Cs and $\St_{\A}$ be the coincided state space.
	\begin{enumerate}[label=\arabic*)]
		\item If $\phi \in \St_{\A}$, then there is a cyclic representation $(\pi_{\phi},\Hs_{\phi})$ with the unit cyclic vector $e_{\phi}$ s.t.
		\begin{equation*}
			\phi(a) = \langle \pi_{\phi}(a)e_{\phi},e_{\phi} \rangle ,~~\forall~ a \in \A
		\end{equation*}
		\item If $(\pi,\Hs)$ is a cyclic representation with the unit cyclic vector $e$, then there is a $\phi \in \St_{\A}$ defined as 
		\begin{equation*}
			\phi(a) = \langle \pi(a)e, e \rangle,~~ \text{for}~ a \in \A
		\end{equation*}
		And for the $(\pi_{\phi},\Hs_{\phi})$ defined as above mention, $\pi_{\phi} \cong \pi$.
	\end{enumerate}
\end{thm}
\begin{proof}
	For $1)$, the prove can be completed by several nature steps.
	\begin{enumerate}[label=\arabic*)]
		\item Constructing semi-inner product: Define a semi-inner product $\langle \cdot, \cdot \rangle$ on $\A$ like
		\begin{equation*}
			\langle x,y \rangle = \phi(\st{y}x),~~ \text{for}~ x,y \in \A
		\end{equation*}
		\item Constructing $\Hs_{\phi}$: $\langle \cdot, \cdot \rangle$ is just a semi-inner product on $\A$, thus we need to make it be nondegenerate. The nature method is constructing a equilaten relation or a closed ideal, and then inducing a quotient space. Naturally, we define
		\begin{equation*}
			\B = \{~x \in \A \colon \phi(x) = 0~\}
		\end{equation*}
		Clearly, $\B$ is a hereditary subalgebra. Then by the \textbf{Theorem} \ref{thm6} in the subsection \textbf{2.2.5}, $\B$ can induced a closed left ideal
		\begin{equation*}
			\I = \{~x \in \A \colon \st{x}x \in \B~\} = \{~x \in \A \colon \phi(\st{x}x) = 0~\}
		\end{equation*}
		And define the inner product on $\A / \I$ as
		\begin{equation*}
			\langle x+\I,y+\I \rangle = \phi(\st{y}x)
		\end{equation*}
		Therefore, we can easily check that $\A / \I$ is a inner product space. Then let $\Hs_{\phi}$ be the completion of $\A / \I$.
		\item Constructing $\pi_{\phi}$: Firstly, let $\pi_{\phi}(a)$ be defined on $\A / \I$ for $a \in \A$.
		\begin{center}
		\begin{tabular}{l c c l}
			$\pi_{\phi}(a) \colon$ & $\A / \I$ & $\longrightarrow$ & $\A / \I$ \\
			~ & $x+\I$ & $\longmapsto$ & $ax+\I$
		\end{tabular}
		\end{center}
		But since
		\begin{eqnarray*}
			\norm{ax+\I}^2 &=& \langle ax+\I,ax+\I \rangle = \phi(\st{ax}ax) \\
		 	&\leqslant& \norm{a}^2 \phi(\st{x}x) = \norm{a}^2\norm{x+\I}^2
		\end{eqnarray*}
		$\norm{\pi_{\phi}(a)} \leqslant \norm{a}$. Therefore, $\pi_{\phi}(a)$ can extend to $\Hs_{\phi}$ for any $a \in \A$. $\pi_{\phi} \colon \A \sto \fml{B}(\Hs_{\phi})$ is a representation.
		\item Check the conditions: Let $e_{\phi} = 1+\I$. Then
		\begin{equation*}
			\pi_{\phi}(\A)e_{\phi} = \{~a+\I \colon a \in \A~\} = \A / \I
		\end{equation*}
		Therefore, $\pi_{\phi}$ with $e_{\phi}$ is indeed a cyclic representation of $\A$. And clearly,
		\begin{equation*}
			\langle \pi_{\phi}(a)e_{\phi}, e_{\phi} \rangle = \phi(a)
		\end{equation*}
	\end{enumerate}
	For $2)$, we just need to construct a unitary from $\Hs_{\phi}$ to $\Hs$. By observation, 
	\begin{equation*}
		\langle \pi_{\phi}(a)e_{\phi}, e_{\phi} \rangle =\langle \pi(a)e, e \rangle
	\end{equation*}
	and the facts that $\Hs_{\phi}=\clo{\pi_{\phi}(\A)e_{\phi}}$ and $\Hs=\clo{\pi(\A)e}$, we can find the unitary $U$. Firstly, let $U$ be defined on $\pi_{\phi}(\A)e_{\phi}$ 
	\begin{center}
		\begin{tabular}{l c c l}
			$U \colon$ & $\pi_{\phi}(\A)e_{\phi}$ & $\longrightarrow$ & $\pi(\A)e$ \\
			~ & $\pi_{\phi}(a)e_{\phi}$ & $\longmapsto$ & $\pi(a)e$
		\end{tabular}
	\end{center}
	Since
	\begin{equation*}
		\norm{\pi(a)e}^2 = \langle \pi(a)e, \pi(a)e \rangle = \phi(\st{a}a) = \norm{\pi_{\phi}(a)e_{\phi}}^2
	\end{equation*}
	$U$ can extend to an unitary from $\Hs_{\phi}$ to $\Hs$. And
	\begin{equation*}
		U\pi_{\phi}(a)(\pi_{\phi}(x)e_{\phi}) = U\pi_{\phi}(ax)e_{\phi}=\pi(ax)e = \pi(a)(\pi(x)e) = \pi(a)U(\pi_{\phi}(x)e_{\phi})
	\end{equation*}
	Then $U\pi_{\phi}\st{U} = \pi$, $\pi_{\phi} \cong \pi$.
\end{proof}
\begin{rem}
	In fact, in above theorem, if $\phi$ is a positive functional, the results is also true.
\end{rem}

By above theorem, our faithful representation of a \Cs can not be constructed by a state, since $\pi_{\phi}$ is not injective. But we may choose enough many states to construct a faithful representation. Therefore, we need more properties of states.

\begin{prop}
	If $\A$ is \Cs and $a \in \A$ is self-adjoint, let $\alpha = \min{\sigma(a)}$ and $\alpha = \max{\sigma(a)}$, then
	\begin{equation*}
		[\alpha,\beta]= \{~\phi(a) \colon \phi \in \St_{\A}~\}
	\end{equation*}
\end{prop}
\begin{proof}
	Let $\B = \Cg{a}$. Then $\B = \{f(a) \colon f \in C(\sigma(a))\}$. For $\phi \in \St_{\A}$ and $\phi_0 =\phi|_{\B}$, then there is a measure $\mu$ s.t.
	\begin{equation*}
		\phi(f(a))=\phi_0(f(a)) = \int_{\sigma(a)} f d \mu,~~ \forall~ f \in C(\sigma)
	\end{equation*}
	In particular, $\phi(a) = \int_{\sigma(a)} t d \mu \in [\alpha, \beta]$.\\
	Conversely, if $\alpha \leqslant t_0 \leqslant \beta$, define $\phi_0 \in \St_{\B}$ as
	\begin{equation*}
		\phi_0(f(a)) = \frac{t_0 - \alpha}{\beta-\alpha}f(\alpha)+\frac{\beta - t_0}{\beta-\alpha}f(\alpha)
	\end{equation*}
	Then $\phi_0$ can extend to $\A$, and $t_0 = \phi(\alpha)$.
\end{proof}

By this proposition, we can get an important corollary.

\begin{cor}
	If $\A$ is a \Cs and $a \in \A$ and $\St_{}$ is $wk^{*}$-dense subset of $\St_{\A}$, then
	\begin{equation*}
		\norm{a}^2 = \sup{\{~\phi(\st{a}a) \colon \phi \in \St_{}~\}}
	\end{equation*}
\end{cor}
\begin{rem}
	In fact, we can easily check that $\St_{\A} \subset \st{\A}$ is a $wk^{*}$-compact convex subset. And this corollary is equivalent to saying that $\St_{}$ can seperate the points in $\A_{+}$.
\end{rem}

Now, using this corollary, we can finally construct a faithful representation.

\begin{thm}[Gelfand-Naimark Theorem]
	Every \Cs $\A$ has a faithful representation $(\pi,\Hs)$. Moreover, $\Hs$ is separable if and only if there are countable number of states on $\A$ that can separates points in $\A_{+}$, each of which defines a separable representation. In particular, each separable \Cs has a faithful, separable representation.
\end{thm}
\begin{proof}
	Let $\St_{}$ be $wk^{*}$-dense subset of $\St_{\A}$. Define
	\begin{equation*}
		\Hs = \oplus \{~\Hs_{\phi} \colon \phi \in \St_{}~\}
	\end{equation*} 
	\begin{equation*}
		\pi = \oplus \{~\pi_{\phi} \colon \phi \in \St_{}~\}
	\end{equation*}
	Then we can see
	\begin{eqnarray*}
		\norm{a}^2 &=& \sup \{~\phi(\st{a}a) \colon \phi \in \St_{}~\}\\ 
		&=& \sup \{~\langle \pi_{\phi}(a)e_{\phi},\pi_{\phi}(a)e_{\phi} \rangle \colon \phi \in \St_{}~\} \\
		&=& \sup \{~\norm{\pi_{\phi}(a)e_{\phi}}^2 \colon \phi \in \St_{}~\} \\
		&=&	\norm{\pi(a)e}^2\\
		&\leqslant& \norm{\pi(a)}^2
	\end{eqnarray*}
	And in the GNS Construction, we have seen $\norm{\pi_{\phi}(a)} \leqslant \norm{a}$ for any $\phi \in \St_{\A}$. Therefore,
	\begin{equation*}
		\norm{a} \geqslant \norm{\pi(a)}
	\end{equation*}
	Thus $\norm{\pi(a)} = \norm{a}$ i.e. $(\pi,\Hs)$ is indeed a faithful representation.
	\item If $\Hs$ is separable, let $\{e_n\}$ be the dense subset of $\{h \in \Hs \colon \norm{h} =1\}$. Define $\Hs_n = \clo{\pi(\A)e_n}$ and $\pi_n = \pi|_{\Hs_n}$. Therefore, in above construction,
	\begin{equation*}
		\{(\pi_{\phi},\Hs_{\phi},e_{\phi}) \colon \phi \in \St_{}\}
	\end{equation*}
	can be replaced by
	\begin{equation*}
		\{(\pi_n,\Hs_n,e_n) \colon n \in \N\}
	\end{equation*}
	Then for $a \in \A_{+}$, there exists $b \in \A$ s.t. $a = \st{b}b$, if for $n \in \N$
	\begin{equation}
		0=\phi_n(a) = \langle \pi_n(\st{b}b)e_n,e_n \rangle = \norm{\pi(b)e_n}^2 \tag{$*$}
	\end{equation}
	But $\norm{b} = \sup_{n} \norm{\pi(b)e_n}$, that implies $a = 0$.\\
	Conversely, if $\{\phi_n\}$ is these states, we can use the GNS Construction to get $\{(\pi_n,\Hs_n,e_n) \colon n \in \N\}$. Similarly, we can use direct sum to get the representation $(\pi,\Hs)$. Then by using the $(*)$, we can know this representation is definitely faithful.
	\item Finally, if $\A$ is separable, then the closed unit ball in $\A^{*}$ is $wk^{*}$-compactly metrizable. Therefore, there is a countable $wk^{*}$-dense subset of $\St_{\A}$. Thus by above corollary, this subset can separate the points in $\A_{+}$
\end{proof}
\begin{rem}
	Therefore, any \Cs can be isometrically imbedded in a operator algebra on some Hilbert space. Researching a abstract \Cs is actually researching the $\st{C}$-subalgebra of an operator algebra on some Hilbert space.
\end{rem}

Now, we can see the importance of states or positive funtionals. Thus, we want to find the relation between general linear functionals and the positive linear functionals. Firstly, we observe that for a positive functional $\phi$, $\phi(\st{a})=\clo{\phi(a)}$ for all $a$. 
\begin{defn}
	If $\A$ is a \Cs and $L$ is a linear functional, $L$ is called self-adjoint if 
	\begin{equation*}
		L(\st{a})=\clo{L(a)},~~ \forall~ a \in \A
	\end{equation*}
	Or equivalently, $L(a) \in \R$ for all $a \in \Rea{\A}$.
\end{defn}

The bounded self-adjoint linear functional in $\st{\A}$ is like the self-adjoint element in $\A$. So by the fact that any self-adjoint element can be a linear combination of two positive element, we want to find similar result of bounded linear functionals. There is a clearly lemma of bounded self-adjoint linear functional.

\begin{lem}
	If $\A$ is a \Cs and $L$ is a bounded self-adjoint linear functional, then
	\begin{equation*}
		\norm{L} = \sup{\{~L(a) \colon a \in \Rea{\A},~\norm{a} \leqslant 1~\}}
	\end{equation*}
\end{lem}

\begin{thm} [Jordan Decomposition]
	If $\A$ is a \Cs and $L$ is a bounded self-adjoint linear functional, then there are positive linear functionals $\phi_{+}$ and $\phi_{-}$ s.t. 
	\begin{equation*}
		L = \phi_{+} - \phi_{-} ~~\text{and}~~ \norm{L} = \norm{\phi_{+}}+\norm{\phi_{-}}
	\end{equation*}
\end{thm}
\begin{proof}
	Let $\Omega$ be the set of all bounded self-adjoint linear functional in the unit ball of $\st{\A}$ and $\tilde{\Omega}$ be the $wk^{*}$-closed convex hull of $\St_{\A}\cup (-\St_{\A})$.
	\begin{enumerate}[label=\arabic*)]
		\item Claim: $\Omega = \tilde{\Omega}$ \\
		Clearly, $\tilde{\Omega} \subset \Omega$. If there is a $L_0 \in \Omega \backslash \tilde{\Omega}$, then there exists a $x_0 \in \A$ separating $L_0$ and $\tilde{\Omega}$, and let $a_0 = \Rea{x_0}$, we have
		\begin{equation*}
			L(a_0) \leqslant \alpha < L_0(a_0),~~\forall~L \in \tilde{\Omega}
		\end{equation*}
		That means 
		\begin{equation*}
			\norm{a_0}=\sup{\{\abs{\phi(a_0)} \colon \phi \in \St_{\A}\}} \leqslant \alpha < L_0(a_0)
		\end{equation*}
		but $\norm{L_0} \leqslant 1$, which is a contradiction.
		\item Claim: $\Omega = \{ s\phi-t\psi \colon \phi,\psi \in \St_{\A},~s+t = 1 ~\&~ s,t \geqslant 0\}$ \\
		By the fact that $(s,t,\phi,\psi) \sto s\phi-t\psi$ is continuous and $\St_{\A}$ is $\st{wk}$-compact, above claim is clearly true.
		\item Existence: Therefore, for any self-adjoint linear functional $L$ with $\norm{L} = 1$, there are two $\phi,\psi \in \St_{\A}$, and positive real numbers $s,t$ with $s+t=1$ s.t. $L=s\phi-t\psi$. Then let $\phi_{+} = s\phi$ and $\phi_{-}=t\phi$, then $L = \phi_{+} - \phi_{-}$ and
		\begin{equation*}
			\norm{\phi_{+}}+\norm{\phi_{-}}= s+t = 1 = \norm{L}
		\end{equation*}
		For general $L$, just let $L / \norm{L}$ for $L \neq 0$, the statements are true. \qedhere
	\end{enumerate}
\end{proof}

In fact, for any $f \in \st{\A}$, $f = \phi + i \psi$ for some self-adjoint linear funtional $\phi, \psi$, where
\begin{equation*}
	\phi(a) = \frac{f(a) + \clo{f(\st{a})}}{2} ~\&~ \psi(a) =\frac{f(a) - \clo{f(\st{a})}}{2i}
\end{equation*}
By combining this and the Jordan Decomposition Theorem, we can have the following corollaries.

\begin{cor}
	Let $\A$ be a \Cs and $\pi \colon \A \sto \oper$ be the faithful representation constructed in the Gelfand-Naimark Theorem.
	\begin{enumerate}[label=\arabic*)]
		\item Any bounded linear functional can be a linear combination of four positive linear functionals.
		\item If $L \in \st{\A}$, then there are $g,h \in \Hs$, s.t. for any $a \in \A$
		\begin{equation*}
			L(a) = \langle \pi(a)g,h \rangle
		\end{equation*}
	\end{enumerate}
\end{cor}

\subsection{Representations}

\begin{defn}
	Let $\pi \colon \A \sto \oper$ be a representation of a \Cs $\A$.
	\begin{enumerate}[label=\arabic*)]
		\item If there is no invariant subspace for $\pi(\A)$, $\pi$ is called algebraically irreducible. If there is no invariant closed subspace, $\pi$ is called topologically irreducible.
		\item If $\clo{\pi(\A)e} = \Hs$ for some $e \in \Hs$, $\pi$ is called cyclic and $e$ is called a cyclic vector for $\pi$.
		\item If $\clo{\pi(\A)\Hs} = \Hs$, $\pi$ is called non-degenerate.
	\end{enumerate}
\end{defn}
\begin{rem}
	Since $\pi$ is $*$-homomorphism and $\A$ is $*$-closed, the definition of irreducibily of $\pi$ is valid. In fact, if $\pi$ is algebraically irreducible, then $\pi$ is clearly topologically irreducible. But the converse is also true. Then we have,
	\begin{center}
		$\pi$ irreducible $\Rightarrow$ $\pi$ cyclic $\Rightarrow$ $\pi$ is non-degenerate
	\end{center}
\end{rem}

\begin{thm}
	Every representation of a \Cs is equivalent to the direct sum of cyclic representations.
\end{thm}
\begin{proof}
	Let $\pi \colon \A \sto \oper$ be a representation and $e \in \Hs$ be any unit element. Then $\M = \clo{\pi(\A)e}$ is clearly a invariant space for $\pi$. If $\M \neq \Hs$, then $\Hs = \M \oplus \M^{\bot}$. We have another unit vector $e^{'} \in \M^{\bot}$, then let $\M^{'} = \clo{\pi(\A)e^{'}}$ and $\M^{'} \bot \M$. If $\M^{'} \neq \M^{\bot}$, we can continue above process again. By induction and the Zorn's Lemma, the theorem can be obtained.
\end{proof}

\begin{thm} \label{thm8}
	If $\A$ is a \Cs and $\I$ is an ideal of $\A$, then every representation $\rho \colon \I \sto \oper$ can be extended to a representation $\tilde{\rho} \colon \A \sto \oper$. Moreover, if $\rho$ is non-degenerate, then $\tilde{\rho}$ is unique.
\end{thm}
\begin{proof}
	Firstly, assume $\rho$ is non-degenerate and by above theorem we can also assume $\rho$ is cyclic with the cyclic vector $e$. Then for any $a \in \A$, we define
	\begin{center}
		\begin{tabular}{l c c l}
			$\tilde{\rho(a)} \colon$ & $\rho(\I)e$ & $\longrightarrow$ & $\Hs$ \\
			~ & $\rho(x)e$ & $\longmapsto$ & $\rho(ax)e$
		\end{tabular}
	\end{center}
	And since for an approximate identity $\{e_i\}$ for $\I$, we have
	\begin{eqnarray*}
		\norm{\rho(ax)e} &=& \lim_{i} \norm{\rho(ae_ix)e} \\
		&\leqslant& \lim_{i} \norm{\rho(ae_i)\rho(x)e} \\
		&\leqslant& \sup_{i} \norm{ae_i} \norm{\rho(x)e} \\
		&\leqslant& \norm{a} \norm{\rho(x)e}
	\end{eqnarray*}
	i.e. $\norm{\tilde{\rho}(a)} \leqslant \norm{a}$, $\tilde{\rho}(a)$ can extend to $\Hs$. Then, we can check that $\tilde{\rho} \colon \A \sto \oper$ is indeed a representation. \\
	If $T \in \oper$ s.t. for any $x \in \I$, $T\rho(x) = \rho(ax)$, then
	\begin{equation*}
		T\rho(x)h = \tilde{\rho}\rho(x)h,~~ \forall~ x \in \I ~\&~ \forall~ h \in \Hs
	\end{equation*}
	Since $\rho$ is non-degenerate, $T=\tilde{\rho}(a)$.\\
	Now, if $\rho$ is degenerate, let $\Hs_0 = \clo{\rho{\I}}$, and $\rho_0(x) = \rho(x)|_{\Hs_0}$, then $\rho_0 \colon \I \sto \fml{B}(\Hs_0)$ is a non-degenerate representation. Therefore, it can extend to $\tilde{\rho_0} \colon \A \sto \fml{B}(\Hs_0)$. Let $\kappa \colon \A \sto \fml{B}(\Hs_0^{\bot})$ be any representation. Then $\tilde{\rho} = \tilde{\rho_0} \oplus \kappa$ is the extension.
\end{proof}

\begin{cor}
	If $\A$ is a \Cs and $\I$ is an ideal of $\A$, and $(\rho,\Hs)$ and $(\kappa,\fml{K})$ are two representations of $\A$ s.t.
	\begin{enumerate}[label=\arabic*)]
		\item $\rho|_{\I}$ is a non-degenerate representation of $\I$.
		\item $\rho|_{\I} \cong \kappa|_{\I}$.
	\end{enumerate}
	then $\rho \cong \kappa$
\end{cor}


We know the irreducible representation play a important role in the representation theory. Therefore, we want to find the necessary and sufficient conditions make a representation be irreducible.

\begin{defn}
	If $\A \subset \oper$ is a $\st{C}$-subalgebra, the commutant of $\A$
	\begin{equation*}
		\Ac = \{~T \in \oper \colon TS=ST,~\forall~S \in \A~\}
	\end{equation*}
\end{defn}
\begin{rem}
	Clearly, $\Ac$ is a $\st{C}$-algebra.
\end{rem}

\begin{thm}
	Let $\A$ be a \Cs and $(\rho,\Hs)$ be a representation, the following statements are equivalent. Then $\rho$ is irreducible if and only if ${\rho(\A)}^{'} = \C$
\end{thm}
\begin{proof}
	If $\rho$ is irreducible and $\C \neq {\rho(\A)}^{'}$, then there is a $T \in {\rho(\A)}^{'} \backslash \C$. Therefore, there is a proper projection $P \in {\rho(\A)}^{'} \backslash \C$. Then $P\Hs$ is a proper invariant space for $\rho$, which is a contradiction. The converse is clearly true by using similar prove as above.
\end{proof}
\begin{rem}
	The existence of $P$ is because that ${\rho(\A)}^{'}$ is a von Neumann algebra.
\end{rem}

Firstly, by the GNS construction, the representations generated by positive linear functionals are important. So we need more properties of these representations.

\begin{prop} \label{prop17}
	Let $\A$ be a \Cs and $\psi$ and $\phi$ be two positive linear functionals on $\A$ and $(\pi,\Hs,e)$ be the representation generated by $\phi$. Then $\psi \leqslant \phi$ if and only if there is unique a $T \in {\pi(\A)}^{'}$ with $0 \leqslant T \leqslant 1$, s.t. $\psi(a) = \langle \pi(a)Te, e \rangle$ for all $a \in \A$. 
\end{prop}
\begin{proof}
	Assume there is a $T \in {\pi(\A)}^{'}$ with $0 \leqslant T \leqslant 1$. If $a \in \A_{+}$, then
	\begin{equation*}
		0 \leqslant T^{\frac{1}{2}}\pi(a)T^{\frac{1}{2}} = \pi(a)T = \pi(a)^{\frac{1}{2}}T\pi(a)^{\frac{1}{2}} \leqslant \pi(a)
	\end{equation*}
	Therefore, $\psi(a) \leqslant \phi(a)$. 
	\item Conversely, we define a sesquilinear form on $\pi(\A)e$,
	\begin{equation*}
		f(\pi(a)e, \pi(b)e) = \psi(\st{b}a)
	\end{equation*}
	And since $\psi \leqslant \phi$, by CBS Inequality, we have
	\begin{eqnarray*}
		\abs{f(\pi(a)e, \pi(b)e)} &=& \abs{\psi(\st{b}a)}^2 \\
		&\leqslant& \psi(\st{a}a)\psi(\st{b}b) \leqslant \phi(\st{a}a)\phi(\st{b}b) \\
		&=& \norm{\pi(a)e}^2\norm{\pi(b)e}^2
	\end{eqnarray*}
	Therefore, $f$ is bounded and can be extended to $\Hs = \clo{\pi(\A)e}$. By \textbf{Theorem} \ref{thm7} in the subsection \textbf{1.5.1}, we have $T \in \oper$, s.t.
	\begin{equation*}
		\psi(\st{b}a) = \langle T\pi(a)e, \pi(b)e \rangle
	\end{equation*}
	In particular, $\psi(a) = \langle T\pi(a)e, e \rangle$.
	For $a,b,c \in \A$,
	\begin{eqnarray*}
		\langle T\pi(a)\pi(b)e, \pi(c)e \rangle &=& \langle T\pi(ab)e, \pi(c)e \rangle = \psi(\st{c}(ab)) \\
		&=& \psi(\st{(\st{a}c)}b) = \langle T\pi(b)e, \pi(\st{a}c)e \rangle \\
		&=& \langle \pi(a)T\pi(b)e, \pi(c)e \rangle
	\end{eqnarray*}
	And by the fact that $\Hs = \clo{\pi(\A)e}$, $T\pi(a)=\pi(a)T$ i.e. $T \in {\pi(\A)}^{'}$. And the uniqueness of $T$ can be easily checked.
\end{proof}

\begin{prop}
	Let $(\pi_j,\Hs_j,e_j)$ for $j=1,2$ be two cyclic representations of a \Cs $\A$. Then $\pi_1 \cong \pi_2$ by a unitary $U \colon \Hs_1 \sto \Hs_2$ satisfying $Ue_1=e_2$ if and only if for any $a \in \A$
	\begin{equation*}
		\langle \pi_1(a)e_1, e_1 \rangle = \langle \pi_2(a)e_2, e_2 \rangle
	\end{equation*}
\end{prop}
\begin{proof}
	We define for any $a \in \A$
	\begin{center}
		\begin{tabular}{l c c l}
			$U \colon$ & $\pi_1(\A)e_1$ & $\longrightarrow$ & $\pi_2(\A)e_2$ \\
			~ & $\pi_1(a)e_1$ & $\longmapsto$ & $\pi_2(a)e_2$
		\end{tabular}
	\end{center}
	If $\langle \pi_1(a)e_1, e_1 \rangle = \langle \pi_2(a)e_2, e_2 \rangle$, 
	\begin{equation*}
		\norm{\pi_2(a)e_2}^2 = \langle \pi_2(a)e_2, \pi_2(a)e_2 \rangle = \langle \pi_1(a)e_1, \pi_1(a)e_1 \rangle = \norm{\pi_1(a)e_1}^2
	\end{equation*}
	$U$ is a unitary on $\pi_1(\A)e_1$ and $U$ can extend to $\Hs_1$. And since
	\begin{equation*}
		U(\pi_1(a)\pi_1(b)e_1) = \pi_2(ab)e_2 = \pi_2(a)\pi_2(b)e_2=\pi_2(a)U(\pi_1(b)e_1)
	\end{equation*}
	$U$ is the unitary make $\pi_1 \cong \pi_2$. The converse is trivial.
\end{proof}
\begin{rem}
	Using this proposition, we can strengthen the result of the \textbf{Corollary} \ref{cor6} in the subsection \textbf{2.2.6}. In fact, every state on an closed ideal $\I$ of a \Cs $\A$ can extend to a unique state on $\A$. 
	If there are two extensions, they can generate two cyclic representations. And these two representations are equivalent on the ideal, thus these two representations are equivalent. And by above proposition, these two extensions are equal.
\end{rem}

By above two propositions, we can get the relationship between positive functionals and the generated representations.

\begin{cor}
	Let $\A$ be a \Cs and $\psi$ and $\phi$ be two positive linear functionals on $\A$ with $\psi \leqslant \phi$. Then $\pi_{\psi}$ is equivalent to a subrepresentation of $\pi_{\phi}$.
\end{cor}
\begin{proof}
	By above proposition, there is a $T \in {\pi(\A)}^{'}$ s.t. 
	\begin{equation*}
		\psi(a) = \langle \pi_{\phi}(a)Te_{\phi}, e_{\phi} \rangle
	\end{equation*}
	Put $\M = \clo{\pi_{\phi}(\A)T^{\frac{1}{2}}e_{\phi}}$. Clearly, $\M$ reduces $\pi_{\phi}(\A)$. Since
	\begin{equation*}
		\langle \pi_{\psi}(a)e_{\psi}, e_{\psi} \rangle = \psi(a) = \langle \pi_{\phi}(a)T^{\frac{1}{2}}e_{\phi}, T^{\frac{1}{2}}e_{\phi} \rangle
	\end{equation*}
	by above proposition $\pi_{\psi} \cong \pi_{\phi}|_{\M}$
\end{proof}

\begin{defn}
	A state $\phi \in \St_{\A}$ on some \Cs $\A$ is called pure if for any positive linear functional $\psi$ on $\A$ with $\psi \leqslant \phi$, there is a sclalar $\lambda \in [0,1]$ s.t. $\psi = \lambda \phi$.
\end{defn}

\begin{thm}
	Let $\A$ be a \Cs and $(\rho,\Hs)$ be a representation, the following statements are equivalent. Then $\rho$ is irreducible if and only if $\rho$ is equivalent to some cyclic representation generated by a pure state.
\end{thm}
\begin{proof}
	Suppose $\rho$ is irreducible. Then for any nonzero unit vector $h \in \Hs$, $\clo{\rho(\A)h} = \Hs$. Define 
	\begin{center}
		\begin{tabular}{l c c l}
			$\phi \colon$ & $\A$ & $\longrightarrow$ & $\C$ \\
			~ & $a$ & $\longmapsto$ & $\langle \rho(a)h,h \rangle$
		\end{tabular}
	\end{center}
	Then $\phi$ is clearly a state. If $(\pi,\fml{K},e)$ is the representation generated by $\phi$, then
	\begin{equation*}
		\langle \pi(a)e,e \rangle = \langle \rho(a)h,h \rangle
	\end{equation*}
	Thus, by above proposition, $\pi \cong \rho$. \\
	If there is a positive linear functional $\psi \leqslant \phi$, then
	\begin{equation*}
		\exists~ T \in {\pi(\A)}^{'},\text{ s.t. } \psi(a) = \langle \pi(a)Te,e \rangle
	\end{equation*}
	But by above theorem, ${\pi(\A)}^{'} = \C$, therefore $T = \lambda \in \C$, $\psi = \lambda \phi$.
	\item Conversely, if $(\rho,\Hs,e) \cong (\pi_{\phi}, \Hs_{\phi},e_{\phi})$ for some pure state $\phi$, 
	\begin{equation*}
		\phi(a) = \langle \rho(a)e, e \rangle =\langle \pi_{\phi}e_{\phi}, e_{\phi} \rangle
	\end{equation*}
	Then if a projection $P \in {\rho(\A)}^{'}$, then
	\begin{equation*}
		\psi(a) = \langle \rho(a)Pe, Pe \rangle = \langle \rho(a)Pe, e \rangle
	\end{equation*}
	is a positive linear functional and $\psi \leqslant \phi$, therefore $\psi = \lambda \phi$ for some $\lambda \in [0,1]$, i.e.
	\begin{equation*}
		\langle \rho(a)Pe, e \rangle = \langle Pe, \rho(\st{a})e \rangle =\lambda\langle \rho(a)e, e \rangle = \langle \lambda e, \rho(\st{a})e \rangle
	\end{equation*}
	Since $\Hs = \clo{\rho(\A)e}$, $P = \lambda$, thus $P=1$ or $0$. Therefore $\rho$ has no proper invariant space.
\end{proof} 

\begin{prop}
	Let $\A$ be a \Cs and $\phi \in \St_{\A}$. Then $\phi$ is pure if and only if $\phi$ is the extreme point of  $\St_{\A}$.
\end{prop}
\begin{rem}
	This proposition can be obtained by definition. In fact, we usually use the extreme point to define the pure state.
\end{rem}

We have similar results for pure states as general states. Firstly, we need a lemma.

\begin{prop}
	Let $\A$ be a \Cs and $\I$ be a closed ideal of $\A$. 
	\begin{enumerate}[label=\arabic*)]
		\item If $(\rho, \Hs)$ is an irreducible representation of $\I$, then it can extend to a unique irreducible representation $(\tilde{\rho},\Hs)$ on $\A$.
		\item If $(\rho, \Hs)$ is an irreducible representation of $\A$, then $(\rho|_{\I},\Hs)$ is an irreducible representation of $\I$.
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, since $\rho$ is irreducible, $\rho$ is non-degenerate. By the \textbf{Theorem} \ref{thm8} in this subsection, there is a unique extension $\tilde{\rho}$ of $\A$. And clearly, 
	\begin{equation*}
		\C \subset {\tilde{\rho}(\A)}^{'} \subset {\rho(\I)}^{'} = \C
	\end{equation*} 
	${\tilde{\rho}(\A)}^{'} = \C$, i.e. $\tilde{\rho}$ is irreducible.
	\item For $2)$, $\rho$ can be generated by a pure state $\phi$ on $\A$. Then $\phi|_{\I}$ is a pure state on $\I$ since if $\phi|_{\I} = s\psi_1 + (1-s)\psi_2$ for some $\psi_1 ,\psi_2 \in \St_{\I}$ and $s \in (0,1)$, then $\psi_1, \psi_2$ have extension $\psi_1^{'}, \psi_2^{'}$ on $\A$, $\phi = s\psi_1^{'} + (1-s)\psi_2^{'}$ by the uniqueness of extensions, which is a contradiction. Therefore, $\phi|_{\I}$ can generate an irreducible representation $\kappa$ on $\I$ and $\kappa \cong \rho|_{\I}$.
\end{proof}

\begin{prop}
	Let $\B$ be a $\st{C}$-subalgebra of $\A$. Then every pure state on $\B$ can extend to a pure state on $\A$.
\end{prop}
\begin{proof}
	Define $T \colon \St_{\A} \sto \St_{\B}$ by $\phi \sto \phi|_{\B}$. Then $T$ is surjective, affine and $\st{wk}$-continuous. Therefore, $T$ maps extreme points to extreme points. Thus the proposition holds.
\end{proof}

\begin{cor}
	Let $\A$ be a \Cs and $a \in \A$. Then
	\begin{equation*}
		\norm{a}^2 = \sup{\{~\phi(\st{a}a) \colon \phi \text{ is a pure state on } \A~\}}
	\end{equation*}
\end{cor}
\begin{proof}
	If $\A=C(X)$ for some compact space $X$, this corollary is true. And then by above proposition, any pure state on $\Cg{\st{a}a}$ can extend to a pure state on $\A$. Therefore, this corollary holds.
\end{proof}

\begin{thm}
	If $\A$ is a $\st{C}$-algebra, then there is a family of irreducible representations $\{\pi_i\}_{i\in I}$ s.t. $\oplus_{i \in I} \pi_{i}$ is a faithful representation of $\A$.
\end{thm}
\begin{proof}
	Let $\{\pi_i\}_{i\in I}$ be generated by all pure state. Then by above corollary, $\oplus_{i \in I} \pi_{i}$ is faithful.
\end{proof}

\section{Operators on Hilbert Spaces}

We have known that each $\st{C}$-algebra can be isometrically imbedded a $\oper$ for some Hilbert space $\Hs$. Therefore, we just research operator algebras other than $\st{C}$-algebras. Firstly, we need some general theories of operators on a Hilbert space.

\subsection{Spectrums for Operators}

By using the fact that $T \sto \st{T}$ in $\oper$ is bijective and isometrically antilinear, we have the following proposition.
\begin{prop}
	Let $\Hs$ be a Hilbert space and $T \in \oper$. Then
	\begin{equation*}
		\sigma(\st{T}) = \st{\sigma(T)} 
	\end{equation*}
\end{prop}

For self-adjoint operators in $\oper$, we have some extral properties related to the inner product.

\begin{prop}
	Let $\Hs$ be a Hilbert space and $T \in \oper$. Then $T$ is self-adjoint if and only if $\langle Th,h \rangle \in \R$ for any $h \in \Hs$.
\end{prop}
\begin{proof}
	If $\langle Th,h \rangle \in \R$ for any $h \in \Hs$, then for any $h,g \in \Hs$ and $\alpha \in \C$,
	\begin{eqnarray*}
		\langle T(h+\alpha g),h+\alpha g \rangle = \langle Th,h \rangle + \clo{\alpha}\langle Th,g \rangle + \alpha \langle Tg,h \rangle + \abs{\alpha}^2 \langle Tg,g \rangle \in \R
	\end{eqnarray*}
	Then by taking its conjugate,
	\begin{eqnarray*}
		\clo{\alpha}\langle Th,g \rangle + \alpha \langle Tg,h \rangle &=& \clo{\alpha} \langle h,Tg \rangle + \alpha \langle g,Th \rangle \\
		&=& \clo{\alpha} \langle \st{T}h,g \rangle + \alpha \langle \st{T}g,h \rangle
	\end{eqnarray*}
	Taking $\alpha = 1$ and $i$, we have
	\begin{eqnarray*}
		\langle Th,g \rangle + \langle Tg,h \rangle &=& \langle \st{T}h,g \rangle + \langle \st{T}g,h \rangle \\
		i\langle Th,g \rangle - i\langle Tg,h \rangle &=& -i\langle \st{T}h,g \rangle + i\langle \st{T}g,h \rangle
	\end{eqnarray*}
	Therfore, $\langle Th,g \rangle=\langle \st{T}g,h \rangle$ for any $h,g \in \Hs$.\\
	The converse is clearly true by definition.
\end{proof}

\begin{prop} \label{prop9}
	Let $\Hs$ be a Hilbert space and $T \in \oper$ be self-adjoint. Then
	\begin{equation*}
		\sigma(T) \subset \{~\langle Th,h \rangle \colon \norm{h} = 1~\}
	\end{equation*}
\end{prop}
\begin{proof}
	If $\lambda \notin \{~\langle Th,h \rangle \colon \norm{h} = 1~\}$, then there is a $\varepsilon > 0$, s.t.
	\begin{equation*}
		\varepsilon < \abs{\lambda - \langle Th,h \rangle} \leqslant \norm{Th},~~\forall~ h \in \Hs,~\norm{h}=1
	\end{equation*}
	Therefore, by the \textbf{Lemma} \ref{lem1} in the subsection \textbf{1.4.4},
	\begin{equation*}
		\ker{(T - \lambda)}=\{0\} ~\&~ \ran{(T - \lambda)} \text{ is closed}
	\end{equation*}
	Since $T$ is self-adjoint, $\clo{\lambda} \notin \sigma(T)$, so $\ker{(\clo{\lambda} - T)} = \{0\}$. Thus 
	\begin{equation*}
		\ran{(T - \lambda)}^{\bot} = \ker{(T - \clo{\lambda})} = \{0\}
	\end{equation*}
	i.e. $\ran{(T - \lambda)} = \Hs$. Then by the Inverse Mapping Theorem, $(T - \lambda)^{-1} \in \oper$, i.e. $\lambda \notin \sigma(a)$.
\end{proof}

\begin{cor} \label{cor8}
	Let $\Hs$ be a Hilbert space and $T \in \oper$ be self-adjoint.
	\begin{enumerate}[label=\arabic*)]
		\item $\norm{T} = \sup{\{\langle Th,h \rangle \colon \norm{h} = 1\}}$.
		\item If $\langle Th,h \rangle = 0$ for any $h \in \Hs$, then $T=0$.
	\end{enumerate}
\end{cor}
\begin{proof}
	For $1)$, 
	\begin{equation*}
		\norm{T} = r(T) \leqslant \sup{\{\langle Th,h \rangle \colon \norm{h} = 1\}} \leqslant \norm{T}
	\end{equation*}
	$2)$ is the direct result of $1)$.
\end{proof}
\begin{rem}
	In fact, for any $T \in \oper$ with $\langle Th,h \rangle = 0$ for any $h \in \Hs$, then $T = 0$ since any $T$ can be the linear combination of two self-adjoint operators.
\end{rem}

By above proposition, we see the spectrum of operators can be described by using another method. Firstly, we can generize the consequence in \textbf{Proposition} \ref{prop9}.
\begin{prop} \label{prop15}
	Let $\Hs$ be a Hilbert space and $T \in \oper$. Then let 
	\begin{equation*}
		\chi(\lambda) = \inf{\{~\norm{(T-\lambda)h} \colon \norm{h} = 1~\}}
	\end{equation*}
	\begin{equation*}
		\sigma_l(T) =\{~\lambda \in \C \colon \chi(\lambda) = 0~\}
	\end{equation*}
\end{prop}
\begin{proof}
	By above proposition, we have seen if $\chi(\lambda) > 0$, 
	\begin{equation*}
		\ker{(T - \lambda)}=\{0\} ~\&~ \ran{(T - \lambda)} \text{ is closed}
	\end{equation*}
	Then let $\fml{K} = \ran{(T - \lambda)}$, then $T - \lambda \colon \Hs \sto \fml{K}$ is a bijection and\\ $(T-\lambda)^{-1} \colon \fml{K} \sto \Hs$ is bounded. Let
	\begin{equation*}
		B = (T-\lambda)^{-1}P \colon \Hs \sto \Hs
	\end{equation*}
	where $P$ is a projection to $\fml{K}$. Then $B \in \oper$ and $B(T - \lambda) = 1$. Therefore, $\sigma_l(T) \subset \{~\lambda \in \C \colon \chi(\lambda) = 0~\}$.
	\item Conversely, if there is a $B \in \oper$ s.t. $B(T-\lambda)=1$, then
	for $h \in \Hs$ with $\norm{h} = 1$
	\begin{equation*}
		1 = \norm{h} = \norm{B(T-\lambda)h} \leqslant \norm{B}\norm{(T-\lambda)h}
	\end{equation*}
	Therefore, $\norm{(T-\lambda)h} \geqslant \norm{B}^{-1}$, i.e. $\chi(\lambda) > 0$.
\end{proof}

\begin{cor} \label{cor11}
	If $N \in \oper$ is a normal operator, then
	\begin{equation*}
		\sigma_l(N) = \sigma_r(N) = \sigma(N)
	\end{equation*}
	In particular, if a normal operator is left (or right) invertible, then it is invertible.
\end{cor}
\begin{proof}
	If $N$ is normal, then $N-\lambda$ is normal. Therefore,
	\begin{equation*}
		\norm{(N-\lambda)h} = \norm{(\st{N}-\clo{\lambda})h},~ \forall h \in \Hs
	\end{equation*}
	By above theorem, $\sigma_l(\st{N}) = \clo{\sigma_l(N)}$. Thus,
	\begin{equation*}
		\sigma_r(N) = \clo{\sigma_l(\st{N})} = \sigma_l(N) \qedhere
	\end{equation*}
\end{proof}

\begin{defn}
	Let $\Hs$ be a Hilbert space and $T \in \oper$.
	\begin{enumerate}[label=\arabic*)]
		\item The point spectrum of $T$ is defined as
		\begin{equation*}
			\sigma_p(T) = \{~ \lambda \in \C \colon \ker{(T-\lambda)} \neq \{0\}~\}
		\end{equation*}
		\item The approximate point spectrum of $T$ is defined as 
		\begin{equation*}
			\sigma_{ap}(T) =\{~\lambda \in \C \colon \exists~\text{units }{x_n} \subset \oper ~\text{s.t.}~ \norm{(T-\lambda)x_n} \sto 0~\}
		\end{equation*}
	\end{enumerate}
\end{defn}

\begin{prop} \label{prop16}
	Let $\Hs$ be a Hilbert space and $T \in \oper$.
	\begin{enumerate}
		\item $\lambda \notin \sigma_{ap}(T)$ if and only if $\ker{(T - \lambda)}=\{0\}$ and $\ran{(T - \lambda)}$ is closed.
		\item $\partial \sigma(T) \subset \sigma_{ap}(T)$.
		\item $\partial \sigma(T) \subset \sigma_l(T) \cap \sigma_r(T) = \sigma_{ap}(T) \cap \sigma_{ap}(\st{T})$.
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, if $\lambda \notin \sigma_{ap}(T)$, then there is a constant $C > 0$ s.t.
	\begin{equation*}
		\norm{(T-\lambda)x} \geqslant C\norm{x},~~\forall~x \in \Hs
	\end{equation*}
	Thus by above proposition, $\ker{(T - \lambda)}=\{0\}$ and $\ran{(T - \lambda)}$ is closed. Conversely, the condition that means $(T-\lambda)$ is left invertible, thus 
	\begin{equation*}
		\norm{(T-\lambda)x} \geqslant \norm{B}^{-1}\norm{x},~~\forall~ x \in \Hs,~\norm{x}=1
	\end{equation*}
	where $B$ is the left inverse of $T$. Therefore, $\lambda \notin \sigma_{ap}(T)$.
	\item For $2)$, let $\lambda \in \partial \sigma(T)$ and $\{\lambda_n\} \subset \rho(T)$ s.t. $\lambda_n \sto \lambda$. Then we know $\norm{(T-\lambda_n)^{-1}} \sto \infty$. Otherwise, if $\norm{(T-\lambda_n)^{-1}} < M$ and $\abs{\lambda_n-\lambda} < M^{-1}$ for sufficiently large $n$,
	\begin{equation*}
		\norm{(T-\lambda_n)-(T-\lambda)} < \norm{(T-\lambda_n)^{-1}}^{-1}
	\end{equation*}
	by the perturbation of inverse, $T-\lambda$ is also invertible. Let $\{x_n\}$ by any sequence of unit vectors in $\Hs$. Define
	\begin{equation}
		y_n = \frac{(T-\lambda_n)^{-1}x_n}{\norm{(T-\lambda_n)^{-1}x_n}}
	\end{equation}
	Then $\norm{(T-\lambda)y_n} \sto 0$, i.e. $\lambda \in \sigma_{ap}(T)$.
	\item For $3)$, by $1)$ we have known $\sigma_l(T)=\sigma_{ap}(T)$ and by taking the complex conjugate, $\sigma_r(\st{T})=\sigma_{ap}(\st{T})$. Therefore, $3)$ holds.
\end{proof}

Now, we can prove the inverse of the \textbf{Corollary} \ref{cor7} in the subsection \textbf{2.2.3}.

\begin{thm}
	Let $\Hs$ be a Hilbert space and $T \in \oper$. If for any $h \in \Hs$, 
	\begin{equation*}
		\langle Th, h \rangle \geqslant 0
	\end{equation*}
	then $T$ is positive.
\end{thm}
\begin{proof}
	Firstly, $T$ is self-adjoint by above proposition. And for $\lambda < 0$ and $\norm{h} =1$
	\begin{eqnarray*}
		\norm{(T-\lambda)h} &=& \norm{Th}^2 - 2\lambda \langle Th,h \rangle + \lambda^2\norm{h}^2 \\
		&\geqslant& - 2\lambda \langle Th,h \rangle + \lambda^2\norm{h}^2 \\
		&\geqslant& \lambda^2\norm{h}^2
	\end{eqnarray*}
	Therefore, $\lambda \notin \sigma_l(T)$. Since $T$ is self-adjoint, $\lambda \notin \sigma_r(T)$. Thus  $\lambda \notin \sigma(T)$, i.e. $\sigma(T) \subset [0,\infty)$.
\end{proof}

\subsection{Polar Decomposition}

For a $z \in \C$, it can be decomposed as $z = \abs{z}e^{i\theta}$. Similarly, a operator in $\oper$ can also be decomposed as a complex number does. Firstly, we need to find the element playing same role as $e^{i\theta}$.

\begin{defn}
	Let $\Hs$ be a Hilbert space and $U \in \oper$ and $\M$ be a closed subspace of $\Hs$. If $U|_{\M}$ is an isometry and $U|_{\M^{\bot}} = 0$, then $U$ is called a partial isometry. $\M$ is called the initial space and $\fml{N}=U(\M)$ is called the final space.
\end{defn}

\begin{prop}
	If $U$ is a partial isometry, then $\st{U}U$ is the projection on the initial space $\M$ and $U\st{U}$ is the projection on the final space $\fml{N}$. Moreover, $\st{U}$ is the partial isometry with the initial space $\fml{N}$ and final space $\M$.
\end{prop}
\begin{proof}
	For any $g,h \in \Hs$, then $g = g_{\shortparallel} + g_{\bot}$ and $h = h_{\shortparallel} + h_{\bot}$, where $g_{\shortparallel},h_{\shortparallel} \in \M$ and $g_{\bot},h_{\bot} \in \M^{\bot}$
	\begin{eqnarray*}
		\langle \st{U}U(g_{\shortparallel} + g_{\bot}), h_{\shortparallel} + h_{\bot} \rangle &=& \langle Ug_{\shortparallel},Uh_{\shortparallel} \rangle = \langle g_{\shortparallel},h_{\shortparallel} \rangle \\
		&=& \langle P_{\M}(g_{\shortparallel} + g_{\bot}),h_{\shortparallel} + h_{\bot} \rangle
	\end{eqnarray*}
	Then $\st{U}U = P_{\M}$. $P_{\M^{\bot}} = 1-\st{U}U$ implies $U(1-\st{U}U) = 0$, i.e. $U = U\st{U}U$ and $\ker{\st{U}} = (\ran{U})^{\bot} = \fml{N}^{\bot}$, therefore, $U\st{U}$ is the projection on $\fml{N}$. For $x \in \fml{N}$.
	\begin{equation}
		\langle \st{U}x, \st{U}x \rangle = \langle U\st{U}x, x \rangle = \langle x, x \rangle
	\end{equation}
	And $\ran{\st{U}} = (\ker{U})^{\bot} = \M$, thus $\st{U}$ is a partial isometry with the initial space $\fml{N}$ and the final space $\M$.
\end{proof}

\begin{cor}
	If $U \in \oper$, then the following statements are equivalent.
	\begin{enumerate}[label=\arabic*)]
		\item $U$ is a partial isometry.
		\item $\st{U}U$ is a projection.
		\item $U = U\st{U}U$.
		\item $\st{U}$ is a partial isometry.
		\item $U\st{U}$ is a projection.
		\item $\st{U} = \st{U}U\st{U}$.
	\end{enumerate}
\end{cor}

\begin{thm}[Polar Decomposition]
	Let $\Hs$ be a Hile]bert space and $T \in \oper$. Then there is a partial isometry $U \in \oper$ with the initial space $(\ker{T})^{\bot}$ and the final space $\clo{\ran{T}}$, s.t. $T = U\abs{T}$. Moreover, if $T=WS$, where $S \geqslant 0$ and $W$ is a partial isometry with $\ker{W}=\ker{S}$, then $S = \abs{T}$ and $W=U$.
\end{thm}
\begin{proof}
	Define 
	\begin{center}
		\begin{tabular}{l c c l}
			$U \colon$ & $\ran{\abs{T}}$ & $\longrightarrow$ & $\ran{T}$ \\
			~ & $\abs{T}h$ & $\longmapsto$ & $Th$
		\end{tabular}
	\end{center}
	Since 
	\begin{equation*}
		\norm{Th}^2=\langle Th,Th \rangle = \langle \st{T}Th,h \rangle = \langle \abs{T}h,\abs{T}h \rangle = \norm{\abs{T}h}^2
	\end{equation*}
	$U$ is a isometry. And thus $U$ can extend to $\clo{\ran{\abs{T}}}$ and onto $\clo{\ran{T}}$. Then extending $U$ to $\Hs$ by setting $U|_{\clo{\ran{\abs{T}}}^{\bot}} = 0$. $U$ is a partial isometry with the initial space $\ker{\abs{T}}^{\bot}$ and the final space $\clo{\ran{T}}$. Clearly, $\ker{\abs{T}} = \ker{T}$ and $T=U\abs{T}$.\\
	If $T=WS$, then $\st{T}T=S\st{W}WS = SP_{\ker{S}^{\bot}}S = S^2$. Therefore, $S = \abs{T}$. And $W\abs{T}=U\abs{T}$, thus $W$ ans $U$ has same initial space, then $W=U$.
\end{proof}

\subsection{Topologies on \texorpdfstring{$\oper$}{Operator}}

In $\oper$, the norm topology may be too stronger, which means norm closed subalgebras in $\oper$ do not contain "enough" elements. Therefore, we need some weaker topologies

\begin{defn}
	Let $\Hs$ be a Hilbert space. 
	\begin{enumerate}[label=\arabic*)]
		\item The strong operator topology on $\oper$, denoted by $SOT$, is generated by a family of seminorms $\{p_x\}_{x \in \Hs}$, where $p_x(T) = \norm{Tx}$.
		\item The weak operator topology on $\oper$, denoted by $WOT$, is denerated by a fanmily of seminorms $\{p_{gh}\}_{g,h \in \Hs}$, where $p_{gh}(T) = \abs{\langle Tg,h \rangle}$.
	\end{enumerate}
\end{defn}
\begin{rem}
	Firstly, by definition and the \textbf{Corollary} \ref{cor8} in the subsection \textbf{2.3.1}, we can see 
	\begin{equation*}
		\bigcap_{x \in \Hs} \ker{p_x}=\{0\} ~\&~ \bigcap_{g,h \in \Hs} \ker{p_{gh}}=\{0\}
	\end{equation*}
	Therefore, both $SOT$ and $WOT$ can let $\oper$ be a Hausdorff locally convex t.v.s.. And by the CBS Inequatlity, $SOT$ is stronger than $WOT$. Moreover,
	\begin{enumerate}[label=\arabic*)]
		\item the subbasis of the $WOT$ at $T_0$ is like 
			\begin{equation*}
				U_{gh\varepsilon}(T_0) = \{T \in \oper \colon \abs{\langle (T-T_0)g,h \rangle} < \varepsilon\}
			\end{equation*}
		Therefore, a net $\{T_\alpha\}$ in $\oper$ converges in $WOT$ to $T_0$ if and only if $\langle T_{\alpha}g,h \rangle \sto \langle T_0g,h \rangle $ for all $g,h \in \Hs$.
		\item the subbasis of the $SOT$ at $T_0$ is like 
			\begin{equation*}
				V_{x\varepsilon}(T_0) = \{T \in \oper \colon \norm{(T-T_0)x} < \varepsilon\}
			\end{equation*}
		Therefore, a net $\{T_\alpha\}$ in $\oper$ converges in $TOT$ to $T_0$ if and only if $\norm{T_{\alpha}x} \sto \norm{T_0x}$ for all $x \in \Hs$.
	\end{enumerate}
	Comparing with the norm topology, the $SOT$ is related to the pointwise convergence, where the norm topology is related to the uniform convergence.
\end{rem}

\begin{prop} \label{prop13}
	Let $\Hs$ be a Hilbert space and $L$ is a linear functional on $\oper$. Then the following statements are equivalent.
	\begin{enumerate}[label=\arabic*)]
		\item $L$ is $SOT$-continuous.
		\item $L$ is $WOT$-continuous.
		\item There are vectors $f_1,\cdots,f_n,g_1,\cdots,g_n \in \Hs$ s.t.
		\begin{equation*}
			L(T) = \sum_{i=1}^{n} \langle Tg_i,f_i \rangle,~~\forall~T \in \oper
		\end{equation*}
	\end{enumerate}
\end{prop}
\begin{proof}
	Clearly, $3) \Rightarrow 2) \Rightarrow 1)$, thus assume $1)$, then by the \textbf{Theorem} \ref{thm2} in the subsection \textbf{1.2.4}, there are $g_1,\cdots,g_n \in \Hs$ and $\alpha_1,\cdots,\alpha_n > 0$ s.t.
	\begin{equation*}
		\norm{L(T)} \leqslant \sum_{i=1}^{n} \alpha_i \norm{Tg_i}
	\end{equation*}
	Replacing $g_i$ by $\alpha_i g_i$ and $g_i$ by $\sqrt{n} g_i$ then
	\begin{equation*}
		\norm{L(T)} \leqslant \sum_{i=1}^{n} \norm{Tg_i} \leqslant \sqrt{n}(\sum_{i=1}^{n} \norm{Tg_i}^2)^{\frac{1}{2}} = (\sum_{i=1}^{n} \norm{Tg_i}^2)^{\frac{1}{2}}
	\end{equation*}
	Let $\fml{K} = \clo{\{\oplus_{i=1}^{n}Tg_i \colon T \in \oper\}}$ be a closed subspace of $\Hs^{(n)}$. 
	Define a linear functional $F$ on $\fml{K}$ by $F(\oplus_{i=1}^{n}Tg_i) = L(T)$, since
	\begin{equation*}
		\abs{F(\oplus_{i=1}^{n}Tg_i)} = \norm{L(T)} \leqslant (\sum_{i=1}^{n} \norm{Tg_i}^2)^{\frac{1}{2}}
	\end{equation*}
	Therefore, $F$ can extends to $\Hs^{(n)}$ with the conincided inner product and norm. By the Riesz Theorem, there is a $f_1, \cdots, f_n \in \Hs$ s.t.
	\begin{equation*}
		F(\oplus_{i=1}^{n}h_i) = \langle \oplus_{i=1}^{n}h_i, \oplus_{i=1}^{n}f_i \rangle,~~\forall~\oplus_{i=1}^{n}h_i \in \Hs^{(n)}
	\end{equation*}
	In particular, restricting $F$ to $\fml{K}$
	\begin{equation*}
		L(T) = F(\oplus_{i=1}^{n}Tg_i) = \langle \oplus_{i=1}^{n}Tg_i, \oplus_{i=1}^{n}f_i \rangle = \sum_{i=1}^{n} \langle Tg_i,f_i \rangle \qedhere
	\end{equation*}

\end{proof}

\begin{prop}
	If $S$ is a convex subset of $\oper$, then
	\begin{equation*}
		\clo{S}^{WOT} = \clo{S}^{SOT} 
	\end{equation*}
\end{prop}
\begin{proof}
	Clearly, 
	\begin{equation*}
		\fml{T}_{WOT} \subset \fml{T}_{SOT}
	\end{equation*}
	Therefore,
	\begin{equation*}
		\clo{S}^{SOT} \subset \clo{S}^{WOT}
	\end{equation*}
	Since for linear functionals, $SOT$-continuity implies $WOT$-continuity, 
	\begin{equation*}
		\clo{(S,WOT)}^{wk} \subset \clo{(S,SOT)}^{wk}
	\end{equation*}
	And we have known $\clo{(S,WOT)}^{wk} = \clo{(S,WOT)} = \clo{S}^{WOT}$ and $\clo{(S,SOT)}^{wk} = \clo{(S,SOT)} = \clo{S}^{SOT}$, therefore
	\begin{equation*}
		\clo{S}^{SOT} \subset \clo{S}^{WOT} \subset \clo{S}^{SOT} \qedhere
	\end{equation*}
\end{proof}

$WOT$ also have a similar property to $wk$-topology, the Alaoglu's Theorem.
\begin{thm}
	The closed unit ball in $\oper$ is $WOT$-compact.
\end{thm}
\begin{proof}
	Let $X_h$ be closed unit ball in $\Hs$ with the $wk$-topology and indexed with $h \in \Hs$ and $B$ be the closed unit ball in $\Hs$ with the $WOT$. Define
	\begin{center}
		\begin{tabular}{l c c l}
			$\tau \colon$ & $B$ & $\longrightarrow$ & $\prod\{X_h \colon \norm{h} \leqslant 1\}$ \\
			~ & $T$ & $\longmapsto$ & $\tau(T)$
		\end{tabular}
	\end{center}
	where $\tau(T)_h = Th$. Then using similarl method, we can prove $B$ is compact.
\end{proof}


\chapter{Normal Operators and Abelian Von Neumann Algebras}

For a normal operator $N$, it can generate an abelian norm closed $\st{C}$-subalgebra of $\oper$, which is isometrically $*$-isomorphic to $C(\sigma(N))$. But the norm closed $\st{C}$-subalgebra may be too "small" to get more interesting results. Therefore, we want to see the $WOT$-closed $\st{C}$-subalgebra $\st{W}(N)$ generated by a normal operator $N$. This extension can be naturally done by following processes. Firstly, we will extend $C(X)$ to $B(X,\Omega)$, where $B(X,\Omega)$ denotes all $\Omega$-measurable functions on $X$, and find the map from $B(X,\Omega)$ to $\oper$. Then using these method, we can extend the Continuous Functional Calculus to the Borel Functional Calculus. In order to illuminate the structure of $\st{W}(N)$, we need more properties of $WOT$-closed $\st{C}$-subalgebras, i.e. von Neumann algebras, and abelian von Neumann algebras. After that, we can build the isomorphism from $\st{W}(N)$ to $\lfs{\infty}(\sigma(N))$. Finally, by above methods, we can get the multiplicity theory of normal operators.

\section{Spectral Theorem}

\subsection{Spectral Measures}

Firstly, we want to construct the map from $B(X,\Omega)$ to $\oper$. Thus we need to define the operator-valued measure.

\begin{defn}
	If $X$ is a set and $\Omega$ is a $\sigma$-algebra of subsets of $X$, and $\Hs$ is a Hilbert space, then a spectral measure for $(X,\Omega,\Hs)$ is a function $E \colon \Omega \sto \oper$ satisfying the following properties.
	\begin{enumerate}[label=\arabic*)]
		\item $E(\Delta)$ is a projection for any $\Delta \in \Omega$.
		\item $E(\varnothing) = 0$ and $E(X) = 1$.
		\item $E(\Delta_1\cap\Delta_1)=E(\Delta_1)E(\Delta_2)$ for any $\Delta_1, \Delta_2 \in \Omega$.
		\item If $\{\Delta_n\}_{n=1}^{\infty}$ is a sequence of pairwise disjoint sets in $\Omega$,
		\begin{equation*}
			E(\bigcup_{n=1}^{\infty}\Delta_n) = \sum_{n=1}^{\infty} E(\Delta_n)
		\end{equation*}
	\end{enumerate}
\end{defn}
\begin{rem}
	In $4)$, this convergence is about $SOT$, and since $E(\Delta)$ is a projection, it is also about $WOT$.
\end{rem}

Then we can see the relation between the spectral measure and the complex measure.
\begin{prop}
	If $E$ is a spectral measure for $(X,\Omega,\Hs)$ and $g,h \in \Hs$, then
	\begin{equation*}
		E_{gh}(\Delta) = \langle E(\Delta)g, h \rangle
	\end{equation*}
	is a complex measure of $(X,\Omega)$. Moreover, $\norm{E_{gh}} \leqslant \norm{g}\norm{h}$.
\end{prop}
\begin{proof}
	$\mu=E_{gh}(\Delta)$ is a complex measure by definition.
	\begin{equation*}
		\abs{\mu}(\Delta) = \abs{\langle E(\Delta)g, h \rangle} \leqslant \norm{E(\Delta)g}\norm{h} \leqslant \norm{g}\norm{h} \qedhere
	\end{equation*}
\end{proof}

Using the spectral measure, we can define the operator-valued integral.

\begin{thm}
	If $E$ is a spectral measure for $(X,\Omega,\Hs)$ and $\phi \colon X \sto \C$ is a bounded $\Omega$-measurable function, then there is a unique operator $T \in \oper$ s.t. for any $\varepsilon > 0$, there is a $\Omega$-partition $\{\Delta_i\}_{i=1}^{n}$ of $X$ with
	\begin{equation*}
		 \sup{\{\abs{\phi(x)-\phi(y)} \colon x, y \in \Delta_k\}}
	\end{equation*}
	for $1 \leqslant k \leqslant n$ s.t. for any $x_k \in \Delta_k$
	\begin{equation*}
		\norm{T-\sum_{k=1}^{n}\phi(k)E(\Delta_k)} < \varepsilon
	\end{equation*}
\end{thm}
\begin{proof}
	Define
	\begin{center}
		\begin{tabular}{l c c l}
			$B \colon$ & $\Hs \times \Hs$ & $\longrightarrow$ & $\C$ \\
			~ & $(g,h)$ & $\longmapsto$ & $\int \phi dE_{gh}$
		\end{tabular}
	\end{center}
	Since $\norm{B(g,h)} \leqslant \norm{\phi}_{\infty} \norm{g} \norm{h}$, $B$ is a bounded sesquilinear form. Then by the Riesz Theorem, there is a $B \in \oper$ s.t. $B(g,h) = \langle Tg,h \rangle$ for all $g,h \in \Hs$ and $\norm{T} \leqslant \norm{\phi}_{\infty}$. Then for and $g,h \in \Hs$ and $x_k \in \Delta_k$ with the giving partition
	\begin{eqnarray*}
		\abs{\langle Tg,h \rangle - \sum_{k=1}^{n}\phi(x_k)\langle E(\Delta_k)g, h \rangle} &=& \abs{\sum_{k=1}^{n} \int_{\Delta_k} (\phi(x)-\phi(x_k))dE_{gh}(x)} \\
		&\leqslant& \sum_{k=1}^{n} \int_{\Delta_k} \abs{\phi(x)-\phi(x_k)} d\abs{E_{gh}}(x) \\
		&\leqslant& \varepsilon \int d\abs{E_{gh}}(x) \leqslant \varepsilon \norm{g}\norm{h}
	\end{eqnarray*}
	Therefore, by the Riezs Theorem, 
	\begin{equation*}
		\norm{T-\sum_{k=1}^{n}\phi(k)E(\Delta_k)} < \varepsilon  \qedhere
	\end{equation*}
\end{proof}
\begin{rem}
	We define $T = \int \phi dE$, and $\langle Tg,h \rangle = \int \phi dE_{gh}$.
\end{rem}

We have one more property on $B(X)$ for a compact space $X$. Let $B(X)$ denote all bounded Borel measurable functions on $X$ and $M(X)$ be all Borel measures.

\begin{lem}
	If $X$ is a compact space and $\phi \in B(X)$, then there is a net $\{u_i\} \subset C(X)$ with $\norm{u_i}_{\infty} \leqslant \norm{\phi}$ s.t. $\int u_i d\mu \sto \int \phi d\mu$ for any $\mu$ in $M(X)$.
\end{lem}
\begin{proof}
	$C(X)^{*} = M(X)$ and $C(X) \subset C(X)^{**} = \st{M(X)}$.  Therefore, the unit ball in $C(X)$ is $wk$-dense in the unit ball in $\st{M(X)}$ (by using Hahn-Banach Theorem). Identifying $B(X)$ be the subspace of $\st{M(X)}$, we have this lemma.
\end{proof}
\begin{rem}
	In fact, $C(X)$ is norm closed in $C(X)^{**} = \st{M(X)}$ like that the $\st{C}$-algebra is norm closed in $\oper$. But by above lemma, we see in $\st{M(X)}$
	\begin{equation*}
		\clo{C(X)}^{wk} = B(X)
	\end{equation*}
	Thus we may apply this to extending $\st{C}$-algebras.
\end{rem}

$B(X,\Omega)$ with the supremum norm and complex conjugate can become a $\st{C}$-algebra. Then by above theorem, we can provide the map from $B(X,\Omega)$ to operator algebras.

\begin{prop}
	If $E$ is a spectral measure for $(X,\Omega,\Hs)$, then
	\begin{center}
		\begin{tabular}{l c c l}
			$\rho \colon$ & $B(X,\Omega)$ & $\longrightarrow$ & $\oper$ \\
			~ & $\phi$ & $\longmapsto$ & $\int \phi dE$
		\end{tabular}
	\end{center}
	is a representation of $B(X,\Omega)$.
\end{prop}
\begin{proof}
	Firstly, we need check that $\rho$ preserves the involution. For $g,h \in \Hs$,
	\begin{equation*}
		E_{gh}(\Delta) = \langle E(\Delta)g, h \rangle = \langle g, E(\Delta)h \rangle = \clo{\langle E(\Delta)h, g \rangle} = \clo{E_{hg}(\Delta)}
	\end{equation*}
	Therefore, for any $g,h \in \Hs$
	\begin{eqnarray*}
		\langle \st{(\int \phi dE)}g,h \rangle &=& \langle g, (\int \phi dE)h \rangle \\
		&=& \clo{\langle (\int \phi dE)h, g \rangle} = \clo{\int \phi dE_{hg}} \\
		&=& \int \st{\phi} d \clo{E_{hg}} = \int \st{\phi} dE_{gh} \\ 
		&=& \langle (\int \st{\phi} dE)g,h \rangle
	\end{eqnarray*}
	\item Also, $\rho$ must be multiplicative. Fix $\phi,\psi \in B(X)$ and $\varepsilon >0$, let $\{\Delta_i\}_{i=1}^{n}$ be the $\Omega$-partition of $X$ s.t. the oscillations of $\phi,\psi,\phi\psi$ on each $\Delta_i$ are less than $\varepsilon$.
	By the fact $E(\Delta_i)E(\Delta_j) = 0$ for $i \neq j$, 
	\begin{eqnarray*}
		\lefteqn{\norm{\int \phi\psi dE - (\int \phi dE)(\int \psi dE)}} \\
		&\leqslant& \varepsilon+ \norm{\sum_{k=1}^{n}\phi(x_k)\psi(x_k)E(\Delta_k) - (\sum_{i=1}^{n}\phi(x_i)E(\Delta_i))(\sum_{j=1}^{n}\psi(x_j)E(\Delta_j))} \\
		&& \negmedspace{} + \norm{(\sum_{i=1}^{n}\phi(x_i)E(\Delta_i))(\sum_{j=1}^{n}\psi(x_j)E(\Delta_j))-(\int \phi dE)(\int \psi dE)} \\
		&\leqslant& \varepsilon + \norm{(\sum_{i=1}^{n}\phi(x_i)E(\Delta_i))(\sum_{j=1}^{n}\psi(x_j)E(\Delta_j)-\int \psi dE)} \\
		&& \negmedspace{} + \norm{(\sum_{i=1}^{n}\phi(x_i)E(\Delta_i)-\int \phi dE)(\sum_{j=1}^{n}\psi(x_j)E(\Delta_j))} \\
		&\leqslant& \varepsilon(1+\norm{\phi}_{\infty}+\norm{\psi}_{\infty})
	\end{eqnarray*} 
	Then $\rho$ is indeed multiplicative.
\end{proof}

We have already there is a map from $C(X)$ to $\oper$, then by combining this proposition and above lemma, if the map is $wk$-continuous on $C(X)$, we can extend it from $M(X)$ to $\oper$. 

\begin{thm}
	If $X$ is a compact space and $\rho \colon C(X) \sto \oper$ is a representation, then there is a unique spectral measure $E$ defined on the Borel sets of $X$ s.t. $\rho$ can be expressed as 
	\begin{equation*}
		\rho(\phi) = \int \phi dE ~~\forall~\phi \in C(X)
	\end{equation*}
	Moreover, $T \in \oper$ commutes with $\rho(\phi)$ for any $\phi \in C(X)$ if and only if $T$ commutes with $E(\Delta)$ for any Borel set $\Delta$.
\end{thm}
\begin{proof}
	Constructing $\tilde{\rho}$ from $\rho$: \\
	For any $g,h \in \Hs$, the map $u \sto \langle \rho(u)g,h \rangle$ from $C(X)$ to $\oper$ is bounded with $\norm{g}\norm{h}$. Therefore, by Riesz Theorem, there exists a unique $\mu_{gh} \in M(X)$ with $\norm{\mu_{gh}} \leqslant \norm{g}\norm{h}$
	\begin{equation*}
		\langle \rho(u)g,h \rangle = \int u d\mu_{gh},~~\forall~u \in C(X)
	\end{equation*}
	For any $\phi \in B(X)$, $(g,h) \sto \int \phi d\mu_{gh}$ is a bounded sesquilinear on $\Hs \times \Hs$. Therefore, there exsits a unique $T \in \oper$, s.t.
	\begin{equation*}
		\int \phi d\mu_{gh} = \langle Tg,h \rangle
	\end{equation*}
	Then we define $\tilde{\rho}(\phi) = T$ and it is well-defined. Clearly, $\tilde{\rho}(u) = \rho(u)$ for any $u$ in $C(X)$.
	\item Check: $\tilde{\rho} \colon B(X) \sto \oper$ is a representation \\
	By the definiation, $\tilde{\rho}$ is clearly linear and preserves the involution, thus we just need to prove the multiplication. Let $\phi$ and $\psi$ in $B(X)$. There is a sequence $\{u_i\} \subset C(X)$ s.t. $u_i \sto \phi$ in $wk$-topology. Then since $\int u_i\psi d\mu \sto \int \phi\psi$ for any $\mu \in M(X)$,  $\tilde{\rho(u_i\psi)} \sto \rho(\phi\psi)$ in $WOT$. For any $\psi \in C(X)$,
	\begin{equation*}
		\tilde{\rho}(\phi\psi) = \lim \tilde{\rho}(u_i\psi) = \lim \rho(u_i)\rho(\psi) = \tilde{\rho}(\phi)\rho(\psi)
	\end{equation*}
	Therefore, if $\phi,\psi \in B(X)$, $\tilde{\rho}(\phi\psi) = \tilde{\rho}(\phi)\tilde{\rho}(\psi)$.
	\item Contructing the spectral measure: \\
	Let $E(\Delta) = \rho(\chi_{\Delta}(x))$ for all Borel set $\Delta$. Clearly, $E(\Delta)$ is a projection for any $\Delta$. For disjoint Borel sets $\Delta_1, \Delta_2$,
	\begin{equation*}
		E(\Delta_1 \cap \Delta_2) = \tilde{\rho}(\chi_{\Delta_1 \cap \Delta_2}) = \tilde{\rho}(\chi(\Delta_1)\chi(\Delta_2)) =\tilde{\rho}(\chi(\Delta_1)) = E(\Delta_1)E(\Delta_2)
	\end{equation*}
	Let $\{\Delta_n\}_{n=1}^{\infty}$ be disjoint Borel sets and $\Delta = \cup_{n=1}^{\infty}\Delta_n$ and $\Lambda_n = \cup_{k=n+1}^{\infty}\Delta_k$. By the fact that $E$ is finitely additive, for any $h \in \Hs$
	\begin{eqnarray*}
	\norm{E(\Delta)h-\sum_{k=1}^{n}E(\Delta_k)h} &=& \langle E(\Lambda_n)h, E(\Lambda_n)h \rangle \\
	&=& \langle E(\Lambda_n)h, h \rangle = \langle \tilde{\rho}(\Lambda_n)h, h \rangle \\
	&=& \int \chi_{\Lambda_n} d\mu_{hh} \\
	&\leqslant& \mu_{hh}(\Lambda_n) \sto 0
	\end{eqnarray*}
	Then by above theorem, with respect to this spectral measure $E$, for any $\phi \in B(X)$,
	\begin{equation*}
		\tilde{\rho}(\phi) = \int \phi dE
	\end{equation*}
	In particular, for $u \in C(X)$, it is also true.
	\item Check: The uniqueness of $E$.
	If there is another $E^{'}$ satisfying above conditions, then for any $g,h \in \Hs$
	\begin{equation*}
		\int \phi dE^{'}_{gh} = \int \phi dE_{gh}
	\end{equation*}
	Therefore, $E^{'} = E$.
	\item Finally, if $T$ commutes with $\tilde{\rho}(\phi)$ for any $\phi \in C(X)$, we can use the $WOT$-convergence to get that $T$ commutes with $\tilde{\rho}(\phi)$ for any $\phi \in B(X)$. Therefore, clearly $T$ commutes with $E(\Delta)$ for any Borel set $\Delta$. Conversely, if $T$ commutes with $E(\Delta)$ for any Borel set $\Delta$, 
	\begin{equation*}
		\langle E(\Delta)Tg,h \rangle = \langle E(\Delta)g,\st{T}h \rangle
	\end{equation*}
	i.e. $\mu_{Tg,h} = \mu_{g, \st{T}h}$. Thus for any $\phi \in B(X)$,
	\begin{equation*}
		\int \phi d\mu_{Tg,h} = \int \phi d\mu_{g,\st{T}h},~\text{i.e.}~\langle \phi Tg,h \rangle = \langle \phi g,\st{T}h \rangle
	\end{equation*}
	Then $\langle \tilde{\rho}(\phi) Tg,h \rangle = \langle T \tilde{\rho}(\phi) g,h \rangle$ for any $g,h \in \Hs$.
\end{proof}
\begin{rem}
	Thus, we extend $\rho \colon C(X) \sto \oper$ to $\tilde{\rho}$ defined on $B(X)$ Moreover, by above proof we know the $*$-homomorphism
	\begin{center}
		\begin{tabular}{l c c l}
			$\tilde{\rho} \colon$ & $(B(X),wk)$ & $\longrightarrow$ & $(\oper,WOT)$ \\
			~ & $\phi$ & $\longmapsto$ & $\int \phi dE$
		\end{tabular}
	\end{center}
	is continuous and therefore $\tilde{\rho}(B(X))$ is $WOT$-closed in $\oper$.
\end{rem}

\subsection{Spectral Theorem for Normal Operators}

Now we can apply above theorem to a normal operator and extend the Continuous Functional Calculus to the Borel Functional Calculus. Moreover, it will promote us to consider the structure of the $WOT$-closed operator algebra generated by a normal operator.

\begin{thm}
	If $N$ is a normal operator, then there is a unique spectral measure $E$ s.t. 
	\begin{center}
		\begin{tabular}{l c c l}
			$\rho \colon$ & $B(\sigma(N))$ & $\longrightarrow$ & $\oper$ \\
			~ & $\phi$ & $\longmapsto$ & $\phi(N) = \int \phi dE$
		\end{tabular}
	\end{center}
	and $\rho|_{C(\sigma(N))}$ is the Continuous Functional Calculus. Moreover,
	\begin{enumerate}[label=\arabic*)]
		\item $\tilde{\rho} \colon (B(X),wk) \sto (\oper,WOT)$ is continuous.
		\item if $G$ is nonempty and relatively open subset in $\sigma(N)$, $E(G) \neq 0$.
		\item if $T \in \oper$, then $TN=NT$ and $T\st{N}=\st{N}T$ if and only if T commutes with $E(\Delta)$ for any Borel set $\Delta$.
	\end{enumerate}
\end{thm}
\begin{proof}
	By above theorem, this $\rho$ is in fact the extension of the Continuous Functional Calculus. And $\rho$ is $wk-WOT$ continuous. 
	\item For $2)$, it is because that $\rho|_{C(\sigma(N))}$ is an isometry. If $\chi_{G} > 0$, then there is a continuous function s.t. $0<f<\chi_{G}$. Therefore, $0 < \rho(f) \leqslant \rho(\chi_{G})$.
	\item Since the condition that $T$ commutes with $N$ and $\st{N}$ is equivalent to that $T$ commutes with $\phi(N)$ for any $\phi \in C(\sigma(N))$, by above theorem, $3)$ holds.
\end{proof}
\begin{rem}
	Now, for a normal operator $N$, we have
	\begin{equation*}
		N = \int_{\sigma(N)} z dE = z(N) = \int_{\Gamma} (z-N)^{-1} dz
	\end{equation*}
\end{rem}

There are some properties of the spectral measure of normal operator $N$.

\begin{prop} \label{prop11}
	Let $N$ be a normal operator with the spectral measure $E$.
	\begin{enumerate}[label=\arabic*)]
		\item $\lambda \in \sigma_p(N) \Leftrightarrow E(\{\lambda\}) \neq 0$.
		\item If $\lambda \in \sigma_p(N)$, then $\ran{E(\{\lambda\})}=\ker{(N-\lambda)}$.
		\item If $\lambda \in \sigma_p(N)$ and $\phi \in B(\sigma(N))$, then for any $h \in \Hs$,
		\begin{equation*}
			\phi(N)h = \phi(\lambda)h
		\end{equation*}
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, if $\lambda \in \sigma(N)$, then there is a nonzero vector $h \in \Hs$ s.t. $(N-\lambda)h=0$.
	\begin{equation*}
		0 = \norm{(N-\lambda)h}^2=\int_{\sigma(N)} \abs{z-\lambda}^2 d E_{hh} = \int_{\sigma(N) \backslash \{\lambda\}} \abs{z-\lambda}^2 d E_{hh}
	\end{equation*}
	Then since $E_{hh}$ is a positive measure,
	\begin{equation*}
		\int_{\sigma(N) \backslash \{\lambda\}} d E_{hh} = \norm{E(\sigma(N) \backslash \{\lambda\})h}^2 = 0
	\end{equation*} 
	And since $E(\sigma(N))=1$, 
	\begin{equation*}
		E(\{\lambda\})h = h,~\text{i.e } E(\{\lambda\}) \neq 0
	\end{equation*}
	Conversely, if $E(\{\lambda\}) \neq 0$, then for nonzero $h \in \ran{E(\{\lambda\})}$, $E(\{\lambda\})h = h$,
	\begin{eqnarray*}
		\int_{\sigma(N)} \abs{z-\lambda}^2 d \langle E(z)h,h \rangle &=&  \int_{\sigma(N)} \abs{z-\lambda}^2 d \langle E(z)E(\{\lambda\})h,h \rangle \\
		&=& \int_{\{\lambda\}} \abs{z-\lambda}^2 d \langle E(z)h,h \rangle =0
	\end{eqnarray*}
	That means
	\begin{equation*}
		\norm{(N-\lambda)h}^2 = \int_{\sigma(N)} \abs{z-\lambda}^2 d \langle E(z)h,h \rangle = 0
	\end{equation*}
	Then $h \in \ker{(T-\lambda)}$, i.e. $\lambda \in \sigma_p(N)$. \\
	$2)$ and $3)$ can be obtained directly by above proof.
\end{proof}
\begin{rem}
	This means that if $\lambda$ is an isolated point in $\sigma(N)$, then $\lambda \in \sigma_P(N)$.
\end{rem}

Now, we can extend the \textbf{Example} \ref{exam2} in the subsection \textbf{2.2.2}.

\begin{exam} \label{exam3}
	Let $\mu$ be a compactly supported, regular Borel measure on $\C$ and ($X,\Omega,\mu$) be the measure space. For each $\phi \in \lfs{\infty}(\mu)$, we define the map
	\begin{center}
		\begin{tabular}{l c c l}
			$M_{\phi} \colon$ & $\lfs{2}(\mu)$ & $\longrightarrow$ & $\lfs{2}(\mu)$ \\
			~ & $f(z)$ & $\longmapsto$ & $\phi(z)f(z)$
		\end{tabular} 
	\end{center}
	\begin{enumerate}[label=\arabic*)]
		\item the spectral measure for $M_{\phi}$ is $M_{\chi_{\phi^{-1}(\Delta)}}$.
		\item If $\psi \in B(\sigma(M_{\phi}))$, then $\psi(M_{\phi}) = M_{\psi \circ \phi}$.
	\end{enumerate}
\end{exam}

\section{Abelian Von Neumann Algebras}

In above section, we built the representation $\rho$ from $B(X)$ to $\oper$, and more over, $\rho$ is $wk-WOT$ continuous. Thus we want to prove $\rho(B(X))$ is indeed a $WOT$-closed $\st{C}$-subalgebra of $\oper$. If $X = \sigma(N)$, $\rho(B(\sigma(N)))$ is the $WOT$-closed $\st{C}$-subalgebra generated by $N$, denoted by $\st{W}(N)$. We will provide more rigorous proof of this statement. After that, we will make the structure of $\st{W}(N)$ more explicit. But before doing these, we some properties of $WOT$-closed subalgebra.

\subsection{Double Commutant Theorem}

\begin{defn}
	A von Neumann algebra is a weakly (or strongly) closed $\st{C}$-subalgebra of $\oper$ that contains the identity.
\end{defn}

\begin{defn}
	If $\mathcal{S} \subset \oper$ is a subset, then the commutant of $\mathcal{S}$, denoted by $\mathcal{S}^{'}$,
	\begin{equation*}
		\mathcal{S}^{'} = \{~ T\in \oper \colon TS=ST~\forall~S \in \mathcal{S} ~\}
	\end{equation*}
\end{defn}

There are some easy properties if the commutant.
\begin{prop}
	Let $\mathcal{S}$ be a subset of $\oper$.
	\begin{enumerate}[label=\arabic*)]
		\item $\mathcal{S}^{'}$ is a von Neumann algebra.
		\item If $A = \oplus_{i=1}^{n} A_i$ acts on $\Hs^{(n)}$ and $T=[T_{ij}] \in \fml{B}(\Hs^{(n)})$, then $T \in \{A\}^{'}$ if and only if $T_{ij}A_j=A_iT_{ij}$ for all $0 \leqslant i,j \leqslant n$.
		\item $[\mathcal{S}^{(n)}]^{''} = [\mathcal{S}^{''}]^{(n)}$.
	\end{enumerate}
\end{prop}

\begin{defn}
	Let $\mathcal{S}$ be a linear manifold of $\oper$.
	\begin{equation*}
		\Lat{\mathcal{S}} =\{~\M \colon \M \text{ is a invariant closed subspace for } S,~\forall S \in \mathcal{S}~\}
	\end{equation*}
\end{defn}

\begin{prop}
	If $\A$ is a $\st{C}$-subalgebra of $\oper$ containing the identity, then
	\begin{equation*}
		\clo{A}^{SOT} = \{~T \in \oper \colon \Lat{\A^n} \subset \Lat{T^n} ~\forall~ n \in \N~\}
	\end{equation*}
\end{prop}
\begin{proof}
	Assume $T \in \clo{A}^{SOT}$, there exist $T_k \in \A$ s.t. $T_kh \sto Th$ for all $h \in \Hs$. If $\M \in \Lat{\A^{(n)}}$, $T_{k}^{(n)}(\M) \subset \M$. Since $\M$ is closed, $T^{(n)}(\M) \subset \M$. \\
	Conversely, let $T$ satisfy the condition. Fix $h_1,\cdots,h_n \in \Hs$ and $\varepsilon > 0$. It suffices to show that there exists $A \in \A$ s.t. $\norm{(T-A)h_k} < \varepsilon$ for $1 \leqslant k \leqslant n$. \\
	Let $\M = \clo{\spn{\{(Ah_1,\cdots,Ah_n) \colon A \in \A\}}}$. Since $1 \in \A$, $(h_1,\cdots,h_n) \in \M$. Clearly, $\M \in \Lat{\A^{(n)}}$. Therefore $\M \in \Lat{T^{(n)}}$, i.e. $T^{(n)}(\M) \subset \M$
	\begin{equation*}
		T^{(n)}(h_1,\cdots,h_n) = (Th_1,\cdots,Th_n) \in \M
	\end{equation*}
	Thus, clearly for any given $\varepsilon > 0$, there exists $A \in \A$ s.t. 
	\begin{equation*}
		\norm{(Ah_1,\cdots,Ah_n)-(Th_1,\cdots,Th_n)} < \varepsilon
	\end{equation*}
	That means,
	\begin{equation*}
		\sum_{k=1}^{n} \norm{(A-T)h_k}^2 < \varepsilon^2
	\end{equation*}
	Therefore, $\norm{(T-A)h_k} < \varepsilon$ for $1 \leqslant k \leqslant n$.
\end{proof}

\begin{thm}[Double Commutant Theorem]
	If $\A$ is a $\st{C}$-subalgebra of $\oper$ containing the identity, then
	\begin{equation*}
		\clo{\A}^{SOT} = \clo{\A}^{WOT} = \A^{''}
	\end{equation*}
\end{thm}
\begin{proof}
	Firslty, by above proposition, $\A^{''}$ is $SOT$-closed and clearly $\A \subset \A^{''}$. Therefore, it is sufficient to show that $\A^{''} \subset \clo{\A}^{SOT}$. Let $T \in \A^{''}$. Then, by above proposition, we just to check that $\Lat{\A^{(n)}} \subset \Lat{T^{(n)}}$. \\
	Let $\M \in \Lat{\A^{(n)}}$. Thus, $\M$ reduces $\A^{(n)}$. That means the projection $P$ from $\Hs^{(n)}$ to $\M$ satisfies $P\A^{(n)} = \A^{(n)}P$, i.e. $P \in \{\A^{(n)}\}^{'}$. Since $T \in \{\A\}^{''}$, and by above proposition $T^{(n)} \in \{\A^{(n)}\}^{''}$, $PT^{(n)} = T^{(n)}P$. That means $\M \in \Lat{T^{(n)}}$
\end{proof}
\begin{rem}
	Therefore, if $\A$ is a von Neumann algebra, $\A = \A^{''}$. It supports the statement that the algebraic structure in a $\st{C}$-algebra can completely determine the topological structure.
\end{rem}

\subsection{Abelian Von Neumann Algebras}

\begin{prop}
	\begin{enumerate}[label=\arabic*)]
		\item If $\{\A_i\}_{i \in I}$ is a collection of von Neumann algebras, then $\cap_{i \in I} \A_i$ is a von Neumann algebra.
		\item If $\A$ is von Neumann algebra, then the center of $\A$, $Z_{\A} = \A \cap \A^{'}$ is a von Neumann algebra.
	\end{enumerate}
\end{prop}

We said that the norm closed $\st{C}$-subalgebras of $\oper$ not containing enough interesting elements. Now, we can see what are these "interesting elements" the $WOT$-closed $\st{C}$-subalgebras have.

\begin{thm}
	Let $\A$ be a von Neumann algebra, then $\A$ is the norm closed linear span of the projections in $\A$.
\end{thm}
\begin{proof}
	Since $\A$ is the linear span of $\Rea{\A}$, we just need to show $\Rea{\A}$ is the norm closed linear span of the projections in $\A$.\\
	Let $A \in \Rea{\A}$ with the spectral measure $E$. $E$ is defined on $\sigma(A)$. If $[a,b] \subset \sigma(A)$, then there exists a sequence $\{u_n(t)\}$ in $C(\sigma(A))$ s.t.
	\begin{equation*}
		u_n(t) = 1 \text{ for } a \leqslant t \leqslant b-n^{-1} \text{ and } u_n(t) = 0 \text{ for other} t
	\end{equation*}
	Then $u_n(t) \sto \chi_{[a,b)}(t)$. If $h \in \Hs$,
	\begin{equation*}
		\norm{(u_n(A)-E[a,b))h}^2 = \int_{\sigma(A)} \abs{u_n(t)-\chi_{[a,b)}(t)}^2 dE_{hh}(t)
	\end{equation*}
	Therefore, $u_n(A) \sto E[a,b)$ in $SOT$. And since $u_n(A) \in \A$ and $\A$ is $SOT$-closed, $E[a,b)$ is in $\A$. Thus, for any Borel subset $\Omega$ of $\sigma(A)$, $E(\Omega) \in \A$. Then $A = \int_{\sigma(A)} t dE$ is the norm closed of linear span of all $E(\Omega)$
\end{proof}
\begin{rem}
	In fact, for any normal operator $N$ in a von Neumann algebra $\A$ with the spectral measure $E$ and for any $\phi \in B(\sigma(N))$, $\phi(N)$ is in $\A$. It is because that $\clo{C(\sigma(N))}^{WOT} = B(\sigma(N))$, and the map from $B(\sigma(N))$ to $\oper$ is $wk-WOT$ continuous. That means $\phi(N)$ can be approximated by a sequence in $\A$ with respect to the $WOT$, thus $\phi(N)$ is in $\A$. In particular, for any Borel subset $\Omega$ of $\sigma(N)$, the projection $E(\Omega) \in \A$.
\end{rem}

So, these interesting elements are projections. We say the von Neumann algebra have enough projections wich can generate the von Neumann algebra. Projections play an important role in a von Neumann algebra. We will classify von Neumann algebras by classifying the containing projections.

\begin{prop}
	Let $\A$ be a von Neumann algebra and $A \in \A$.
	\begin{enumerate}[label=\arabic*)]
		\item If $E$ and $F$ are the projections onto $\clo{\ran{A}}$ and $\ker{A}$, then $E,F \in \A$.
		\item If $A = W\abs{A}$ is teh polar decomposition, then $\abs{A},W \in \A$.
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, if $h \in \ker{A}$ and $B \in \A^{'}$, then $BAh = ABh = 0$. That means $F$ is invariant for $\{\A\}^{'}$ and thus $F \in \{\A\}^{''}$. And $E = \ker{\st{A}} \in \{\A\}^{''}$.
	\item For $2)$, $\abs{A}$ is clearly in $\A$ by the Continuous Functional Calculus. For $W$, we just need to prove that $WT=TW$ for any $T \in \A^{'}$. Let $E = \ker{\abs{A}}$ . By $1)$, $E \in \A = \A^{''}$. For $x \in \ker{\abs{A}} = E$, $ET=TE$ implies $Tx \in \ker{\abs{A}}$. Since $\ker{\abs{A}} = \ker{A}$, $WTx =0 = TWx$. On the other hand, if $x \in \ran{\abs{A}}$, $x = \abs{A}y$ for some $y \in \Hs$.
	\begin{equation*}
		WTx = WT\abs{A}y = W\abs{A}Ty = ATy= TAy = TW\abs{A}y = TWx
	\end{equation*} 
	And this equation can be easily extended to $\clo{\ran{\abs{A}}}$. $\Hs = \ker{\abs{A}} \oplus \clo{\ran{\abs{A}}}$, thus $TW=WT$.
\end{proof}

Before researching the structure of abelian von Neumann algebras, there is a typical example.
\begin{exam}
	If $(X,\Omega,\mu)$ is a finite measure space, and $\A_{\mu} = \{M_{\phi} \colon \phi \in \lfs{\infty}(\mu)\}$, then
	\begin{equation*}
		\A_{\mu} = \A_{\mu}^{'} = \A_{\mu}^{''}
	\end{equation*}
\end{exam}
\begin{proof}
	It suffices to show $\A_{\mu} = \A_{\mu}^{'}$. And since $\A_{\mu}$ is abelian, $\A_{\mu} \subset \A_{\mu}^{'}$. Consider $T \in \A_{\mu}^{'}$, then $\mu(X) < \infty$ implies that $1 \in \lfs{2}(\mu)$. Let $\phi = T(1) \in \lfs{2}(\mu)$. 
	\item Check: $T=M_{\phi}$ \\
	Firstly, if $\psi \in \lfs{\infty}(\mu)$, 
	\begin{equation*}
		T(\psi) = T(M_{\psi}1) = M_{\psi}T(1) = \phi\psi
	\end{equation*}
	And also,
	\begin{equation*}
		\norm{T(\psi)} = \norm{\phi\psi} \leqslant \norm{T}\norm{\psi}_2
	\end{equation*}
	Using this we can show $\phi \in \lfs{\infty}(\mu)$. Let 
	\begin{equation*}
		\Delta_n = \{~ x \in X \colon \abs{\phi(x)} \leqslant n ~\},~ \psi = \chi_{\Delta_n}
	\end{equation*}
	Then we have 
	\begin{equation*}
		\norm{T}^2\mu(\Delta_n) = \norm{T}^2 \norm{\psi}^2 \geqslant \norm{\phi}^2\norm{\psi}^2 = \int_{\Delta_n}\abs{\phi}^2 d\mu = n^2\mu(\Delta_n)
	\end{equation*}
	Thus $\mu(\Delta_n)=0$. $\phi \in \lfs{\infty}(\mu)$. And since $\lfs{\infty}(\mu)$ is dense in $\lfs{2}(\infty)$, $T=M_{\phi}$ can be defined on $\lfs{2}(\infty)$.
\end{proof}
\begin{rem}
	In fact, this result can be also true for $(X,\Omega,\mu)$ $\sigma$-finite.
\end{rem}

\begin{defn}
	Let $\mathcal{S} \subset \oper$ and $e_0 \in \Hs$.
	\begin{enumerate}[label=\arabic*)]
		\item $e_0$ is said to be star-cyclic for $\mathcal{S}$ if $\clo{\Cg{\mathcal{S}}e_0} = \Hs$.
		\item $e_0$ is said to be separating for $\mathcal{S}$ there is no nonzero $S \in \mathcal{S}$ s.t. $Se_0=0$.
	\end{enumerate}
\end{defn}

\begin{prop}
	If $\A$ is a unital $\st{C}$-algebra of operators, a vector is cyclic if and only if it is separating for $\A^{'}$
\end{prop}
\begin{proof}
	For $T \in \A^{'}$, s.t. $Te_0 = 0$. Then $T \A e_0 = \A T e_0 =  0$. If $e_0$ is the cyclic vector for $\A$, then $\A e_0$ is dense in $\Hs$. Therefore, $T=0$.\\
	Conversely, if $e_0$ separates $\A^{'}$, let $P$ be the projection onto $\clo{(\A e_0)}^{\bot}$. Then $P \in \A^{'}$ and $P e_0 = 0$. Therefore, $P = 0$. $e_0$ is cyclic for $\A$. 
\end{proof}
\begin{cor}
	If $\A$ is an abelian operator algebra, then each cyclic vector for $\A$ is also a separating vector for $\A$.
\end{cor}

\begin{defn}
	An abelian subalgebra $\A \subset \oper$ is said to be a maximal abelian subalgebra if there is no abelian subalgebra in $\oper$ containing $\A$. In paticular, a maximal abelian von Neumann algebra is called a masa.
\end{defn}

\begin{thm}
	Let $\A$ be a subalgebra in $\oper$. Then the following statement are equivalent.
	\begin{enumerate}[label=\arabic*)]
		\item  $\A$ is a masa.
		\item $\A = \A^{'}$
	\end{enumerate}
\end{thm}
\begin{proof}
	Assume $\A$ is a masa. Then $\A \subset \A^{'}$. If there is a nonzero $A \in \A^{'} \backslash \A$, then $\C = \st{W}(\A,A)$ is an abelian von Neumann algebra containing $\A$, which is a contradiction. Thus $\A = \A^{'}$.\\
	Conversely, $\A$ is an abelian von Neumann algebra by above proposition. By Zorn's Lemma there is a maximal abelian von Neumann algebra $\B$ s.t. $\A \subset \B$. Then $\B^{'} \subset \A^{'}$. By above statement, $\B = \B^{'}$. Thus $\B \subset \A$.
\end{proof}

\begin{thm}
	If $\Hs$ is separable and $\A$ is an abelian $\st{C}$-algebra containing the identity, the following statements are equivalent.
	\begin{enumerate}[label=\arabic*)]
		\item $\A=\A^{'}$.
		\item $\A$ is strongly closed and has a cyclic vector.
		\item There is a compact metric space $X$, a regular Borel measure $\mu$ with support $X$, and a unitary $U \colon \lfs{2}(\mu) \sto \Hs$ s.t. $U\A_{\mu}U^{-1}=\A$.
	\end{enumerate}
\end{thm}
\begin{proof}
	$1) \Rightarrow 2)$ Let $\{e_n\}_{n=1}^{\infty}$ be a sequence of unit vectors s.t. 
	\begin{equation*}
		\clo{\A e_n} \bot \clo{\A e_m},\text{ for } n \neq m \text{ and } \Hs = \oplus_{n=1}^{\infty} \clo{\A e_n}
	\end{equation*}
	Set $e_0 = \sum_{n=1}^{\infty} 2^{-n} e_n$ and $P_n = \clo{\A e_n}$. Then $P_n \in \A^{'} = \A$. 
	\begin{equation*}
		e_n = 2^{n} P_n e_0 \in \clo{\A e_0} \Rightarrow \clo{\A e_n} \subset \clo{\A e_0}
	\end{equation*}
	Therefore, $\Hs = \clo{\A e_0}$.
	\item $2) \Rightarrow 3)$ Since $\Hs$ is separable, the unit ball in $\A$ is a $WOT$-closed  compact metric space, therefore there is a countable weakly dense set. Let $\A_1$ be the $\st{C}$-algebra generated by this set and $X$ be the maximal ideal space of $\A_1$. Clearly, $X$ is metrizable. Then the inverse of Gelfand transform
	\begin{equation*}
		\rho \colon C(X) \longrightarrow \A_1 \subset \A
	\end{equation*}
	And there is a spectral measure $E$, s.t. $\rho(f) = \int_{X} f dE$.
	Let $e_0$ be the cyclic vector of $\A$. Then we can define the $U$,
	\begin{center}
		\begin{tabular}{l c c l}
			$U \colon$ & $C(X)$ & $\longrightarrow$ & $\A_1 e_0$ \\
			~ & $\phi$ & $\longmapsto$ & $\rho(\phi)e_0$
		\end{tabular}
	\end{center}
	Let $\mu(\Delta) = \langle E(\Delta)e_0,e_0 \rangle$, then $C(X) \subset \lfs{2}(\mu)$ by the fact that $\mu$ is positive finite measure. For $\phi \in C(X)$,
	\begin{equation*}
		\norm{\rho(\phi)e_0}^2 = \langle \rho(\st{\phi})\rho(\phi)e_0,e_0 \rangle = \int \abs{\phi}^2 d \mu = \norm{\phi}^2
	\end{equation*}
	Therefore, $U$ is an isometry. Since $C(X)$ is norm densed in $\lfs{2}(\mu)$ and $\clo{\A_1 e_0} = \clo{\A e_0} = \Hs$, $U \colon \lfs{2}(\mu) \sto \Hs$ is a unitary. \\
	Let $\psi \in C(X)$ and $\phi \in C(X)$
	\begin{equation*}
		UM_{\psi}\phi = U(\psi\phi) = \rho(\psi\phi)e_0 = \rho(\psi) \rho(\phi)e_0 = \rho(\psi) U \phi  
	\end{equation*}
	Since $\rho(C(X)) = \A_1$, $\st{U} \A_1 U = \{M_{\phi} \colon \phi \in C(X)\}$.
	Define the map $\Gamma \colon \A \sto \A_{\mu}$ by $\Gamma(A) = \st{U} A U$. We have known that
	\begin{equation*}
		 \Gamma(\A_1) \subset \{M_{\phi} \colon \phi \in C(X)\} \subset \A_{\mu},
	\end{equation*}
	\begin{equation*}
		\clo{\{M_{\phi} \colon \phi \in C(X)\}}^{WOT} \subset \A_{\mu}
	\end{equation*}
	And $\Gamma$ is clearly $WOT$-closed, thus 
	\begin{equation*}
		\Gamma(\A) \subset \clo{\Gamma(\A_1)}^{WOT} \subset \A_{\mu}
	\end{equation*}
	$\Gamma$ is well-defined.
	In fact, by similar proof of $\A_{\mu}=\A_{\mu}^{'}$, ${\{M_{\phi} \colon \phi \in C(X)\}}^{'} = \A_{\mu}$, i.e. 
	\begin{equation*}
		\A_{\mu} = \clo{\{M_{\phi} \colon \phi \in C(X)\}}^{WOT}
	\end{equation*}
	Finally, it can easily check $\clo{\Gamma(\A_1)}^{WOT} \subset \Gamma(\A)$. Therefore, $\Gamma$ is an isomorphism.
	\item $3) \Rightarrow 1)$ It clearly holds by above example.
\end{proof}


This theorem gives an explicit structure of the maximal abelian von Neumann algebra, which is equivalent to $\lfs{\infty}(\mu)$. And for a general abelian von Neumann algebra, by Zorn's Lemma, it can embedded into a masa.

\begin{cor} \label{cor9}
	If $\Hs$ is separable, every abelian \Cs contained in $\oper$ has a separating vector.
\end{cor}
\begin{proof}
	By Zorn's Lemma, there is a masa containing the abelian \Cs and thus by above theorem it has a cyclic vector, which can separate the masa, in particular, this $\st{C}$-algebra.
\end{proof}

\subsection{Star-Cyclic Normal Operators}

In above subsection, we can see $\A_{\mu} = \{M_{\phi} \colon \phi \in \lfs{\infty}(\mu)\} \cong \lfs{\infty}(\mu)$ play an important role in the abelian von Neumann algebra. So we will see more properties of $\A_{\mu}$.

\begin{thm}[Fuglede-Putnam Theorem]
	Let $N$ and $M$ are normal operators and $A \in \oper$. If $NA = AM$, then $\st{N}A = A\st{M}$.
\end{thm}
\begin{proof}
	Since for any polynomial, $p(N)A=Ap(M)$, then for a fixed $\omega \in \C$, by taking limits
	\begin{equation*}
		e^{i\omega N}A = A e^{i\omega M}, \text{ or } A = e^{-i\omega N} A e^{i\omega M}
	\end{equation*}
	By the fact that $e^{X}e^{Y} = e^{X+Y}$ for commuting operators $X,Y$., therefore
	\begin{eqnarray*}
		f(\omega) &=& e^{-i\omega \st{N}} A e^{i\omega \st{M}} \\
		&=& e^{-i\omega \st{N}} e^{-i\clo{\omega} N} A e^{i\clo{\omega} M} e^{i\omega \st{M}} \\
		&=& e^{-i(\omega \st{N}+\clo{\omega} N)} A e^{i(\omega \st{M}+\clo{\omega} M)}
	\end{eqnarray*}
	Note that $f$ is a entire operator-valued function. Since $(\omega \st{N}+\clo{\omega} N)$ and $(\omega \st{M}+\clo{\omega} M)$ are self-adjoint, $e^{-i(\omega \st{N}+\clo{\omega} N)}$ and $e^{i(\omega \st{M}+\clo{\omega} M)}$ are unitaries. Then $f$ is bounded, thus $f$ is constant, i.e.
	\begin{equation*}
		0 = f^{'}(\omega) = -i\st{N}e^{-i\omega \st{N}} A e^{i\omega \st{M}} + ie^{-i\omega \st{N}} A \st{M} e^{i\omega \st{M}}
	\end{equation*}
	Let $\omega = 0$, then $0=-i\st{N}A + iA\st{M}$.
\end{proof}

\begin{cor}
	If $N$ is a normal operator with $N = \int z dE$, then $NA=AN$ if and only if $E(\Delta)N=NE(\Delta)$ for all Borel set $\Delta$.
\end{cor}

Then using this theorem we can find the generator of $\A_{\mu}$.
\begin{thm}
	If $\mu$ is any compactly supported measure on $\C$, then
	\begin{equation*}
		\{N_{\mu}\}^{'} = \A_{\mu}^{'}
	\end{equation*}
\end{thm}
\begin{proof}
	Clearly, $\A_{\mu}^{'} \subset N_{\mu}^{'}$. If $T \in N_{\mu}^{'}$, then $T\st{N_{\mu}} = \st{N_{\mu}}T$. Therefore, $T$ can commutes with any polynomials in $z$ and $\clo{z}$, and taking limits, $T \in \A_{\mu}^{'}$.
\end{proof}
\begin{rem}
	By this, we can also see the statement in above theorem
	\begin{equation*}
		{\{M_{\phi} \colon \phi \in C(X)\}}^{'} = \A_{\mu}
	\end{equation*}
	is true. Moreover, $\{N_{\mu}\}^{'} = \A_{\mu}^{'}$ implies that
	\begin{equation*}
		\st{W}(N_{\mu}) = \A_{\mu} \cong \lfs{\infty}(\mu)
	\end{equation*}
	Therefore, in order to research $\A_{\mu}$, we just research $N_{\mu}$.
\end{rem}

We have seen that if $\mu$ is finite then $N_{\mu}$ is indeed a cyclic normal operator on $\lfs{2}(\mu)$ as $\clo{\st{C}(\mu)1} = \lfs{2}(\mu)$ by the Stone-Weierstrass Theorem. Now, we can prove any cyclic normal operator is equivalent to a $N_{\mu}$ for some finite $\mu$.
\begin{thm}
	A normal operator $N$ is cyclic if and only if it is equivalent to $N_{\mu}$ for some compactly supported measure $\mu$ on $\C$. Moreover, if $e_0$ is the cyclic vector, then the unitary $U \colon \Hs \sto \lfs{2}(\mu)$ with $N_{\mu} = UN\st{U}$ can be chosen s.t. $Ue_0 = 1$.
\end{thm}
\begin{proof}
	If $E$ is the spectral measure s.t. $N = \int_{\sigma(N)} z dE$, for any Borel set $\Delta$ in $\sigma(N)$, then define
	\begin{equation*}
		\mu(\Delta) = \langle E(\Delta)e_0,e_0 \rangle = \norm{E(\Delta)e_0}^2
	\end{equation*}
	$\mu$ is finite, positive, and compactly supported on $\C$. Then $C(\sigma(N)) \subset \lfs{2}(\mu)$. We know that $\Cg{N} \cong C(\sigma(N))$. Define
	\begin{center}
		\begin{tabular}{l c c l}
			$U \colon$ & $\Cg{N}e_0$ & $\longrightarrow$ & $C(\sigma(N))$ \\
			~ & $\phi(N)e_0$ & $\longmapsto$ & $\phi$
		\end{tabular}
	\end{center}
	Then we have,
	\begin{equation*}
		\norm{\phi(N)e_0}^2 = \langle \phi(\st{N})\phi(N)e_0,e_0 \rangle = \int_{\sigma(N)} \abs{\phi}^2 d\mu = \norm{\phi}_2
	\end{equation*}
	$U$ is a unitary. By taking norm limits, $U \colon \Hs \sto \lfs{2}(\mu)$ is a unitary and $Ue_0 = 1$ and $UNe_0 = z$. If $\phi \in C(\sigma(N))$, then
	\begin{equation*}
		UN\st{U}(\phi) = UN\phi(N)e_0 = U(z\phi)(N)e_0 = z\phi = N_{\mu}(\phi)
	\end{equation*}
	Also, taking the norm limits, $UN\st{U}=N_{\mu}$.
\end{proof}

\begin{thm}
	Two normal operator $N_{\mu}$ and $N_{\nu}$ are equivalent if and only if $\mu$ and $\nu$ are mutually absolutely continuous.
\end{thm}
\begin{proof}
	If $\mu$ and $\nu$ are mutually absolutely continuous and $\phi = \frac{d\mu}{d\nu}$, then define
	\begin{center}
		\begin{tabular}{l c c l}
			$U \colon$ & $\lfs{2}(\mu)$ & $\longrightarrow$ & $\lfs{2}(\nu)$ \\
			~ & $f$ & $\longmapsto$ & $f\sqrt{\phi}$
		\end{tabular}
	\end{center}
	Then we have
	\begin{equation*}
		\norm{Uf}^2 = \int \abs{f}^2 \phi d\nu = \int \abs{f}^2 d \mu = \norm{f}^2
	\end{equation*}
	Thus $U$ is an isometry. Since $\frac{1}{\phi} = \frac{d\nu}{d \mu}$, the map $g \sto \sqrt{\frac{1}{\phi}}g$ is the inverse of $U$. Therefore, $U$ is unitary, and
	\begin{equation*}
		UN_{\mu}\st{U}g = UN_{\mu}(\sqrt{\frac{1}{\phi}}g) = U(z\sqrt{\frac{1}{\phi}}g) = zg = N_{\nu}g
	\end{equation*}
	Conversely, $N_{\mu} \cong N_{\nu}$ means $K=\sup{\mu} = \sigma(N_{\mu}) = \sigma(N_{\nu}) = \sup{N_{\nu}}$. Let $V \colon \lfs{2}(\mu) \sto \lfs{2}(\nu)$ be the unitary s.t. $VN_{\mu}\st{V}=N_{\nu}$. Then also $V\st{N_{\mu}}\st{V}=\st{N_{\nu}}$. Therefore, for any polynomial in $z$ and $\clo{z}$, let $V(1) = \psi$
	\begin{equation*}
		Vp(N_{\mu},\st{N_{\mu}})(1) = p(N_{\nu},\st{N_{\nu}})V(1)
	\end{equation*}
	That means
	\begin{equation*}
		\int_{K} \abs{p}^2 d\mu = \int_{K} \abs{p}^2 \abs{\psi}^2 d \nu
	\end{equation*}
	Taking limits, for any $f \in C(K)$, above identity is also true. Thus, $d \mu = \abs{\psi}^2 d \nu$, i.e. $\mu \ll \mu$. Similarly, by $V^{-1}$, we can get the converse.
\end{proof}

\section{The structure of \texorpdfstring{$W^{*}(N)$}{W*(N)}}

For a norm operator $N$, by above subsection, clearly
\begin{equation*}
	\{~M_{\phi} \colon \phi \in B~\} \subset \st{W}(N) = \{N\}^{'}
\end{equation*}
And we have seen, $\{N_{\mu}\}^{'} = \A_{\mu} \cong \lfs{\infty}(\mu)$. Firsty, we want to prove $\{M_{\phi} \colon \phi \in B\} = \st{W}(N)$. More, if we also can find some $\mu$ s.t. $\st{W}(N)=\st{W}(N_{\mu})$, then the structure of $\st{W}(N)$ is explicit, 
\begin{equation*}
	\st{W}(N) = \{~M_{\phi} \colon \phi \in B~\} \cong \lfs{\infty}(\mu)
\end{equation*}

Let $N$ be a normal operator acting on $\Hs$ with the spectral measure $E$. If $h \in \Hs$ is nonzero, then let 
\begin{equation*}
	\mu_h(\Delta) = E_{hh}(\Delta),~\Hs_h=\clo{\st{W}(N)h},~N_h = N|_{\Hs_h}
\end{equation*}
In fact, $\Hs_h$ is the smallest reducing space for $N$ containing $h$. And $N_h$ is a star-cyclic normal operator with the cyclic vector $h$. If $E_h$ is the spectral measure of $N_h$, then by the uniqueness of spectral measure
\begin{equation*}
	E_h(\Delta) = \chi_{\Delta}(N_h) = \chi_{\Delta}(N)|_{\Hs_h} = E(\Delta)|_{\Hs_h}
\end{equation*}
Therefore, there is a unique unitary $U_h \colon \Hs_h \sto \lfs{2}(\mu_h)$ s.t. $U_hh=1$ and $U_h N_h \st{U_h} = N_{\mu_h}$.

\begin{prop}
	Let $N$ be a normal operator acting on $\Hs$ and a nonzero $h \in \Hs$.
	\begin{center}
		\begin{tabular}{l c c l}
			$\rho_h \colon$ & $\st{W}(N)$ & $\longrightarrow$ & $\st{W}(N_h)$ \\
			~ & $A$ & $\longmapsto$ & $A|_{\Hs_h}$
		\end{tabular}
	\end{center}
	\begin{enumerate}[label=\arabic*)]
		\item $\rho_h$ is a $*$-homomorphism and $WOT$-continuous.
		\item If $\phi \in B(\sigma(N))$, then $\rho_h(\phi(N)) = \phi(N_h)$.
		\item If $h$ is separating for $\st{W}(N)$, then $\rho_h$ is injective.
		\item If $A \in \st{W}(N)$, then there exists a $\phi \in B(\sigma(N))$ s.t. $\rho_h(A) = \phi(N_h)$, and thus $\rho_h$ is surjective.
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, if $p(z,\clo{z})$ is any polynomial, then $\rho(p(N,\st{N})) = p(N_h,\st{N_h})$. For any $A \in \st{W}(N)$, there exists $p_n(N,\st{N})$ s.t. $p_n(N,\st{N}) \sto A$ in $WOT$. Then for any $g,h \in \Hs_h$
	\begin{equation*}
		\langle p_n(N,\st{N})g,h \rangle \sto \langle Ag,h \rangle
	\end{equation*}
	Therefore, $p_n(N_h,\st{N_h}) \sto A|_{\Hs_h}$ in $WOT$. And thus, $\rho_h$ is $WOT$-continuous and $\rho_h(A) \in \st{W}(N_h)$, well-defined. And clearly, $\rho_h$ is a $*$-homomorphism.

	\item For $2)$, if $\phi \in B(\sigma(N))$, then there exist polynomials $p_n(z,\clo{z})$ s.t. $p_n \sto \phi$ weakly in $M(\sigma(N))$ and $M(\sigma(N_h))$ as $\sigma(N_h) \subset \sigma(N)$. That means $p_n(N,\st{N}) \sto \phi(N)$ in $WOT$ and $p_n(N_h,\st{N_h}) \sto \phi(N_h)$. But $\rho_h(p_n(N,\st{N}) = p_n(N_h,\st{N_h})$ and $\rho$ is $WOT$-continuous, $\rho_h(\phi(N)) = \phi(N_h)$.

	\item For $3)$, if $h$ is separating for $\st{W}(N)$, $A_h = 0$ i.e $A\st{W}(N)h = 0$. That means $A\st{W}(N)=0$, then $A = 0$.

	\item For $4)$, if $A \in \st{W}(N)$ and $A_h = \rho_h(A)$, then $A_h \in \{N_h\}^{'} =\st{U_h}\{N_{\mu_h}\}^{'}U_h$. There is a $\psi \in \lfs{\infty}(\mu_h)$ s.t. $A_h = \st{U_h}M_{\psi} U_h$. Then there exist $\psi_n \in B(\sigma(N))$ s.t. $M_{\psi_n} \sto M_{\psi}$ in norm. Thus $\psi_n(N_h) \sto A_h$ in norm, there is a $\phi \in M(\sigma(N))$, s.t. $\phi(N_h) = A_h$. Moreover, this also implies $\rho_h$ is surjective.
\end{proof}
\begin{rem}
	The most important part in this proof is that for the $\mu_h$,
	\begin{equation*}
		\st{W}(N_{\mu_h}) = \A_{\mu_h} = \{~M_{\phi} \colon \phi \in \lfs{\infty}(\mu_h)~\} = \{~M_{\phi} \colon \phi \in B(\sigma(N_{\mu_h}))~\}
	\end{equation*}
\end{rem}

Using above proposition we get one of the main result of this subsection.
\begin{thm}
	If $N$ is a normal operator, then 
	\begin{equation*}
		\st{W}(N) = \{~\phi(N) \colon \phi \in B(\sigma(N))~\}
	\end{equation*}
\end{thm}
\begin{proof}
	It is sufficient to show that $\A = \{\phi(N) \colon \phi \in B(\sigma(N))\}$ is $WOT$-closed. Let $A \in \clo{\A}^{WOT} = \st{W}(N)$. Then there exists $\{\phi)n\} \subset B(\sigma(N))$ s.t. $\phi_n(N) \sto A$ in $WOT$. And for any $h \in \Hs$, there exists $\phi_h \in B(\sigma(N_h))$, s.t. $A_h = \phi_h(N_h)$, also $\phi_n(N_h) \sto A_h$ in $WOT$. That means 
	\begin{equation*}
		Ah = \phi_h(N_h)h = \phi_h(N)h,~~\forall~h \in \Hs
	\end{equation*}
	But $\phi_h$ is dependent with the chose of $h$. So we want to find a $e \in \Hs$ s.t. $\phi_h(N_h) = \phi_e(N_h)$ for any $h \in \Hs$. Fix a $e \in \Hs$ \\
	Check: $\phi_h(N_h)h = \phi_e(N_h)h$ \\
	By the definition, for any Borel subset $\Delta$ of $\sigma(N)$, since
	\begin{eqnarray*}
		\mu_e &=& \langle E(\Delta)e,e \rangle = \norm{E(\Delta)e}^2 \\
		\mu_h &=& \langle E(\Delta)h,h \rangle = \norm{E(\Delta)h}^2
	\end{eqnarray*}
	$mu_e$ and $\mu_h$ are mutually absolutely continuous. In fact, for any $g \in \Hs$, $\mu_h$ and $\mu_g$ are mutually absolutely continuous. Since $\phi_n(N_h) \sto A_h$ in $WOT$, $\phi_n \sto \phi_h$ weak$^{*}$ in $\lfs{\infty}(\mu_h)$. Also, $\phi_n \sto \phi_e$ weak$^{*}$ in $\lfs{\infty}(\mu_e)$. Then for any Borel subset $\Delta$
	\begin{equation*}
		\int_{\Delta} \phi_n d\mu_h = \int_{\Delta} \phi_n \frac{d\mu_h}{d\mu_e}d\mu_e \sto \int_{\Delta} \phi_e d\mu_h
	\end{equation*}
	and also $\int_{\Delta} \phi_n d\mu_h \sto \int_{\Delta} \phi d\mu_h$, therefore, $\phi_h = \phi_e$ a.e. with repect to $\mu_h$, in fact, it can be with respect to any $\mu_g$. Then for $g \in \Hs_h$,
	\begin{equation*}
		\langle \phi_h(N_h)g,g \rangle = \langle \phi_h(N)g,g \rangle = \int \phi_h d\mu_g = \int \phi_e d\mu_g = \langle \phi_e(N_h)g,g \rangle
	\end{equation*}
	Therefore, $\phi_h(N_h)h = \phi_e(N_h)h$. Then $A = \phi_e(N)$.
\end{proof} 

And also, by above proposition, the second result can also be proved.

\begin{thm}
	If $N$ is a normal operator on a separable Hilbert space, then there is a compactly supported, positive and finite measure $\mu$, s.t. there is a map $\rho \colon \lfs{\infty} \sto \st{W}(N)$, s.t.
	\begin{enumerate}[label=\arabic*)]
		\item $\rho$ is an isometrical $*$-isomorphism.
		\item $\rho \colon (\lfs{\infty}(\mu), \text{weak}^{*}) \sto (\st{W}(N), WOT)$ is a homeomorphism.
	\end{enumerate}
\end{thm}
\begin{proof}
	Since $\st{W}(N)$ is an abelian von Neumann algebra, it has a separating vector $e$ by the \textbf{Corollary} \ref{cor9} in the subsection \textbf{3.2.2}. Then let $\rho^{'} = \rho_e$ and $\mu = \mu_e$. By above proposition, $\rho^{'}$ is a $*$-isomorphism from $\st{W}(N_e)$ to $\st{W}(N)$. And since $\st{W}(N_e)$ is also $*$-isomorphic to $\lfs{\infty}(\mu)$. Thus there is a $*$-isomorphism $\rho$ from $\lfs{\infty}(\mu)$ to $\st{W}(N)$ s.t. for any $\phi \in B(\sigma(N))$, $\rho(\phi) = \phi(N)$. And thus $\rho$ is isometrical.\\
	For $2)$, since $\st{W}(N) = \{\phi(N) \colon \phi \in B(\sigma(N))\}$, if $\phi_n(N) \sto \phi(N)$ in $WOT$, then we can easily know $\phi_n \sto \phi$ in weak$^{*}$. And the converse is trivial. $\rho$ is weak$^{*}$-$WOT$ homeomorphism.
\end{proof}

Now, we can see the structure of any abelian von Neumann algebra on a separable Hilbert space.
\begin{thm} \label{thm13}
	If $\A$ is an abelian von Neumann algebra on a separable Hilbert space $\Hs$, then there is a compactly supported, positive and finite measure $\mu$ s.t. $\A \cong \lfs{\infty}(\mu)$, $*$-isomorphism.
\end{thm}
\begin{proof}
	Since $\Hs$ is separable, the closed unit ball in $\A$ is $WOT$-compactly metrizable, thus there is a countable $WOT$-dense set of $\A$. Since $\A$ can be generated by projections in $\A$, thus this $WOT$-dense set can be chosen as a set of projections $\{P_n\}$. Let $\alg{C} = \Cg{\{P_n\}}$, then $\alg{C}$ is ablelian. Thus there is a compact space $X$, which is totally disconnected, s.t. $\alg{C} \cong C(X)$. And let $\rho \colon C(X) \sto \alg{C}$ be the inverse of Gelfand Transform. Then $p_n = \rho^{-1}(P_n)$ is the characteristic function and continuous. Define
	\begin{equation*}
		f = \sum_{n=1}^{\infty} 3^{-n}(2p_n - 1)
	\end{equation*}
	Claim: $\Cg{f} = C(X)$ \\
	By the Stone-Weierstrass Theorem, we just need to show that $f$ can separate the points of $X$. Since $\{p_n\}$ generates $C(X)$, $\{p_n\}$ can separate the points in $X$. Thus, for $x \neq y \in X$, there is a $p_k$, s.t. $p_k(x) \neq p_k(y)$ and chosing the $k$ be the smallest one satifying this condition, then
	\begin{eqnarray*}
		\abs{f(x)-f(y)} &=& 2 \abs{\sum_{n=k}^{\infty} 3^{-n}(p_n(x) - p_n(y))} \\
		&\geqslant& 2 3^{-k} - 2 \sum_{n=k+1}^{\infty} 3^{-n} \\
		= 3^{-k}
	\end{eqnarray*}
	Therefore, let $A = \rho(f) = \sum_{n=1}^{\infty} 3^{-n}(2P_n - 1)$, $\Cg{A} = \alg{C}$. Moreover, $\st{W}(A) = \clo{\Cg{A}}^{WOT} = \A$. And since $A$ is self-adjoint, thus by above theorem, there exists $\mu$ on $\sigma(A)$, s.t.
	\begin{equation*}
		\A \cong \lfs{\infty}(\mu) \qedhere
	\end{equation*}
\end{proof}

\section{Multiplicity Theory}

Finally, we want find the necessary and sufficient condition making two normal operators be equivalent. We should assume the Hilbert space is always separable.

\begin{prop}
	If $N$ is a normal operator on $\Hs$ and $e \in \Hs$, then there is a separating vector $e_0$ for $\st{W}(N)$ s.t. $e \in \clo{\st{W}(N)}$.
\end{prop}
\begin{proof}
	Choosing any separating operator $f_0$ for $\clo{\st{W}(N)}$, let $\M = \clo{\st{W}(N)}f_0$, then $e = m_0 + g_0$ for $m_0 \in \M$ and $g_0 \in \M^{\bot}$. Now, let $\fml{G} = \clo{\st{W}(N)g_0}$ and $e_0 = f_0 +g_0$. Then $e \in \clo{\st{W}(N)e_0}$.\\
	Check: $e_0$ is separating for $\st{W}(N)$\\
	For any $A \in \st{W}(N)$, since both $\M$ and $\fml{G}$ reduce $\st{W}(N)$, if
	\begin{equation*}
		Ae_0 = Af_0 + Ag_0 = 0
	\end{equation*}
	then $Af_0=0$. Because $f_0$ is separating for $\st{W}(N)$, $A = 0$.
\end{proof}

\begin{prop}
	Let $\mu$ be a compactly supported measure on $\C$ and $\Delta$ be a Borel subset of $\sup{\mu}$ and $\nu = \mu|_{\Delta}$. If $N = N_{\mu} \oplus N_{\nu}$ on $\lfs{2}(\mu) \oplus \lfs{2}(\nu)$ and $g\oplus h \in \lfs{2}(\mu) \oplus \lfs{2}(\nu)$ with $h \neq 0$ a.e. $\nu$, then there is a $f \in \lfs{2}(\mu)$ s.t. $f \oplus h$ is a separating vector for $\st{W}(N)$ and $g\oplus h \in \clo{\st{W}(N)(f \oplus h)}$.
\end{prop}
\begin{proof}
	Let $f(z) = g(z)$ for $z \in \Delta$ and $f(z) = 1$ for $x \in \Delta^{'}$ where $\Delta^{'} = \sup{\mu} \backslash \Delta$. In fact,
	\begin{equation*}
		\Hs = \clo{\st{W}(N)(f \oplus h)} = \clo{\{~\phi f \oplus \phi h \colon \phi \in \lfs{\infty}(\mu)~\}}
	\end{equation*}
	Since $\phi \chi_{\Delta^{'}} \oplus 0 = \phi \chi_{\Delta^{'}}(f \oplus h)$,
	\begin{equation*}
		g \oplus h = f \oplus h - (1-g)\chi_{\Delta^{'}} \oplus 0 \in \Hs
	\end{equation*}
	If $\phi \in \lfs{\infty}(\mu)$ with $\phi f \oplus \phi h = 0$, then $\phi f = \phi h = 0$ a.e. $\mu$ and $\nu$ respectively. By definition, $\phi = 0$ a.e. $\mu$.
\end{proof}

Then we can decompose normal operators as a "decreasing" sequence of cyclic operators.

\begin{thm} \label{thm10}
	If $N$ is a normal operator, then there is a sequence of measures $\{\mu_n\}$ on $\C$ s.t. $\mu_{n+1} \ll \mu_{n}$ for all $n$ and 
	\begin{equation*}
		N \cong N_{\mu_1} \oplus N_{\mu_2} \oplus N_{\mu_3} \oplus \cdots
	\end{equation*}
\end{thm}
\begin{proof}
	Let $e_1$ be a separating vector for $\st{W}(N)$ and $\{f_n\}$ be the orthonormal basis of $\Hs$ s.t. $f_1 = e_1$. Put
	\begin{equation*}
		\Hs_1 = \clo{\st{W}(N)e_1},~~\mu_1(\Delta) = \norm{E(\Delta)}^2,~~ N_2 = N|_{\Hs_1}
	\end{equation*}
	Then for $f_2^{'} = $ the projection of $f_2$ to $\Hs_1^{\bot}$, there is a separating vector $e_2$ for $\st{W}(N_2)$ s.t. 
	\begin{equation*}
		f_2^{'} \in \Hs_2 = \clo{\st{W}(N_2)e_2}
	\end{equation*} 
	And clearly, if $\mu_2{\Delta} = \norm{E(\Delta)|_{\Hs_2}e_2}$, $\mu_2 \ll \mu_1$. By induction and the Zorn's Lemma, 
	\begin{equation*}
		N \cong N_{\mu_1} \oplus N_{\mu_2} \oplus N_{\mu_3} \oplus \cdots \qedhere
	\end{equation*}
\end{proof}

Therefore, if there is another normal operator $M \cong N_{\nu_1} \oplus N_{\nu_2} \oplus \cdots$, we want to find the relation between the equivalence of $N$ and $M$ and the equivalence of the coincided $\mu_n$ and $\nu_n$. But before that we need some lemmas.

\begin{prop}
	If $N_1$ and $N_2$ are normal operators on $\Hs_1$ and $\Hs_2$ respectively and $X \colon \Hs_1 \sto \Hs_2$ s.t. $XN_1 = N_2X$, then 
	\begin{enumerate}[label=\arabic*)]
		\item $\clo{\ran{X}}$ reduces $N_2$.
		\item $\ker{X}$ reduces $N_1$.
		\item If $M_1 = N_1|_{(\ker{X})^{\bot}}$ and $M_2 = N_2|_{\clo{\ran{X}}}$, then $M_1 \cong M_2$.
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, if $f_1 \in \Hs_1$, $XN_1f_1 = N_2Xf_1 \in \ran{X}$. Therefore, $\clo{\ran{X}}$ is invariant $N_2$. And also, by the Fuglede-Putnam Theorem, $X\st{N_1} = \st{N_2}X$, thus $\clo{\ran{X}}$ is invariant $\st{N_2}$.\\
	$2)$ is similar as $1)$.
	For $3)$, it is sufficent to show this when $\ker{X}=\{0\}$ and $\ran{X}$ is dense. By the Polar Decomposition, $X=UA$ for some unitary $U$. Since $\st{X}\st{N_2} = \st{N_1}\st{X}$, $\st{X}N_2 = N_1\st{X}$. Therefore $A^2 \in \{N_1\}^{'}$, so $A \in \{N_1\}^{'}$ by the functional calculus.
	\begin{equation*}
		N_2X = N_2UA= XN_1 = UAN_1 = UN_1A
	\end{equation*}
	That means $N_2U=UN_1$ on $\clo{\ran{A}} = \clo{\ran{X}} = \Hs_1$, therefore $N_1 \cong N_2$.
\end{proof}

\begin{prop}
	If $N,A$ and $B$ are normal operators on $\fml{K}$, $\Hs_A$ and $\Hs_B$ respectively and $N$ is $*$-cyclic and 
	\begin{equation*}
		N \oplus A \cong N \oplus B
	\end{equation*}
	then $A \cong B$.
\end{prop}
\begin{proof}
	Let $U \colon \fml{K} \oplus \Hs_A \sto \fml{K} \oplus \Hs_B$, and $U$ can be
	\begin{equation*}
		U = \left(
			\begin{array}{cc}
				U_{11} & U_{12} \\
				U_{21} & U_{22}
			\end{array}
		\right)
	\end{equation*}
	Then we have
	\begin{eqnarray*}
		\left(
			\begin{array}{cc}
				U_{11}N & U_{12}A \\
				U_{21}N & U_{22}A
			\end{array}
		\right)
		&=& \left(
			\begin{array}{cc}
				NU_{11} & NU_{12} \\
				BU_{21} & BU_{22}
			\end{array}
		\right) \\
		\left(
			\begin{array}{cc}
				U_{11}\st{N} & U_{12}\st{A} \\
				U_{21}\st{N} & U_{22}\st{N}
			\end{array}
		\right)
		&=&\left(
			\begin{array}{cc}
				\st{N}U_{11} & \st{N}U_{12} \\
				\st{B}U_{21} & \st{B}U_{22}
			\end{array}
		\right)
	\end{eqnarray*}
	Then by above proposition, 
	\begin{equation*}
		A|_{(\ker{U_{22}})^{\bot}} = B|_{(\ker{\st{U_{22}}})^{\bot}}
	\end{equation*}
	For $\ker{U_{22}}$ and $\ker{\st{U_{22}}}$, put $\M_1 = U_{12}(\ker{U_{22}})$, $\M_2= \st{U_{21}}(\ker{\st{U_{22}}})$, also by the identity, $\st{U}U = U\st{U} = 1$, 
	\begin{equation*}
		A|_{\ker{U_{22}}} \cong N|_{\M_1},~~B|_{\ker{\st{U_{22}}}} \cong N|_{\M_2}
	\end{equation*}
	And then it easily check that $\M_1 = \M_2$.
\end{proof}

\begin{thm}
	For two normal operators $N$ and $M$ and the two sequences of measures $\{\mu_n\}$ and $\{\nu_n\}$ on $\C$ s.t. $\mu_{n+1} \ll \mu_{n}$ and $\nu_{n+1} \ll \nu_{n}$ for all $n$ s.t.
	\begin{eqnarray*}
		N &\cong& N_{\mu_1} \oplus N_{\mu_2} \oplus \cdots \\
		M &\cong& N_{\nu_1} \oplus N_{\nu_2} \oplus \cdots
	\end{eqnarray*}
	then $N \cong M$ if and only if $\mu_n$ and $\nu_n$ are mutually absolutely continuous for all $n$.
\end{thm}
\begin{proof}
	Let $N \cong M$ with the unitary $U$. If $e_1$ is the separating vector for $\st{W}(N)$, then $f_1 = Ue_1$ is the separating vector for $\st{W}(M)$. If the $\mu_1$ and $\nu_1$ are the coincided measures, then $\mu_1$ and $\nu_1$ are mutually absolutely continuous, thus $N_{\mu_1} \cong N_{\nu_1}$. Let $\Hs_1 = \clo{\st{W}(N)e_1}$ and $\Hs_1^{'} = \clo{\st{W}(M)e_1}$. Then by above theorem,
	\begin{equation*}
		N = N_{\mu_1} \oplus N|_{\Hs_1^{\bot}} \cong M = N_{\nu_1} \oplus M|_{\Hs_1^{'\bot}}
	\end{equation*}
	we know that $N|_{\Hs_1^{\bot}} \cong M|_{\Hs_1^{'\bot}}$. Therefore, by induction, we can get the result.
\end{proof}

Then we can get another formula of above theorem to help us build the Multiplicity Theorem.
\begin{cor}
 	If $N$ is a normal operator with the coincided measure $\mu$, then there is a decreasing sequence $\{\Delta_n\}$ of Borel subsets of $\sigma(N)$ s.t. $\Delta_1 = \sigma(N)$ and 
 	\begin{equation*}
 		N \cong N_{\mu} \oplus N_{\mu|_{\Delta_2}} \oplus N_{\mu|_{\Delta_3}} \oplus \cdots
 	\end{equation*}
 	Also, if $M$ is another normal operator with similar formula
 	\begin{equation*}
 		M \cong N_{\nu} \oplus N_{\nu|_{\Sigma_2}} \oplus N_{\nu|_{\Sigma_3}} \oplus \cdots
 	\end{equation*}
 	then $N \cong M$ if and only if $\mu$ and $\nu$ are mutually absolutely continuous and $\mu(\Delta_n \backslash \Sigma_n) = 0 = \mu(\Sigma_n \backslash \Delta_n)$
\end{cor}

\begin{thm} \label{thm9}
	If $N$ is a normal operator, then there are mutually singular measures $\mu_{\infty}, \mu_1, \mu_2, \cdots$ s.t.
	\begin{equation*}
		N \cong N_{\infty}^{(\infty)} \oplus N_{\mu_1} \oplus N_{\mu_2}^{(2)} \oplus  N_{\mu_3}^{(3)} \oplus \cdots
	\end{equation*}
	If $M$ is another normal operator with the corresponding  measures $\nu_{\infty}, \nu_1, \cdots$, then $N \cong M$ if and only if $\mu_n$ and $\nu_n$ are mutually absolutely continuous for $1 \leqslant n \leqslant \infty$.
\end{thm}
\begin{proof}
	Let the $\mu$ and $\{\Delta_n\}$ be the sequence in above corollary. Put
	\begin{equation*}
		\Sigma_{\infty} = \bigcap_{n=1}^{\infty} \Delta_n \text{, } \Sigma_n = \Delta_n \backslash \Delta_{n+1} \text{ and } \mu_n = \mu|_{\Sigma_n}
	\end{equation*}
	for $1 \leqslant n \leqslant \infty$ and $\nu_n = \mu|_{\Delta_n}$ for $1 \leqslant n < \infty$. Now, 
	\begin{equation*}
		\Delta_n = \Sigma_{\infty} \bigcup (\Delta_n \backslash \Delta_{n+1}) \bigcup (\Delta_{n+1} \backslash \Delta_{n+2}) \bigcup (\Delta_{n+2} \backslash \Delta_{n+3}) \bigcup \cdots
	\end{equation*}
	Therefore, $\nu_n = \mu_{\infty} + \mu_n + \mu_{n+1} + \mu_{n+2} + \cdots$ and $\{\mu_n\}$ are pairwise singular.
	Thus,
	\begin{equation*}
		N_{\nu_n} = N_{\mu_{\infty}} \oplus N_{\mu_n} \oplus N_{\mu_{n+1}} \oplus \cdots
	\end{equation*}
	Then we have
	\begin{eqnarray*}
		N &=& N_{\nu_1} \oplus N_{\nu_2} \oplus \cdots \\
		&=& N_{\infty}^{(\infty)} \oplus N_{\mu_1} \oplus N_{\mu_2}^{(2)} \oplus  N_{\mu_3}^{(3)} \oplus \cdots
	\end{eqnarray*}
\end{proof}

Now, we can define the multiplicity function $m_N$ for a normal operator $N$ with the corresponding measure $\mu$. As above preceding theorem, 
\begin{equation*}
	N \cong N_{\infty}^{(\infty)} \oplus N_{\mu_1} \oplus N_{\mu_2}^{(2)} \oplus  N_{\mu_3}^{(3)} \oplus \cdots
\end{equation*}
If there are disjoint Borel sets $\Delta_{\infty},\Delta_1,\Delta_2,\cdots$ of $\C$ s.t. $\mu_n$ and $mu|_{\Delta_n}$ are mutually absolutely continuous for all $n$, then define
$m_N \colon \C \sto \N \cup \{\infty\}$ as
\begin{equation*}
	m_N = \infty \chi_{\Delta_{\infty}} + \chi_{\Delta_1} + 2\chi_{\Delta_2} + 3\chi_{\Delta_3} + \cdots
\end{equation*}
Clearly, $m_N$ is dependent with the choice of $\{\Delta_n\}$, but by the definition, $m_N$ can be identified as an equivalent class with respect to $\mu$. And moreover,
\begin{equation*}
	\Delta_n = \{~z \colon m_N(z) = n~\}
\end{equation*}

Therefore, we can recover the $\{\Delta_n\}$ by the $m_N$. By combining with above theorem, we can classify the normal operators.

\begin{thm}
	Two normal operators are equivalent if and only if they have same multiplicity function.
\end{thm}

\chapter{Compact Operators, Fredholm Theory and Perturbations}

The compact operator is as similar as the finite dimensional operator with respect to the spectrums, the representations and so on. In fact, all compact operators can form the unique closed ideal in $\oper$. Moreover, it contains some important classes of operators, like the trace class, which provides an extra topology on $\oper$ and this topology plays an important role in the von Neumann algebra. In fact, the topology is coincided with the $WOT$ in some cases, but it can give a new method to obtain some properties of general von Neumann algebras. For non-compact operators, there is a "weak version" of the compact operator, the Fredholm operator. By researching the Fredholm operators, it provides us an approach to find some "invariant variable" under the compact perturbations. Finally, we have known that finite dimensional normal operator can always be diagnolizable, but for infinite dimensional case, this statement is not true. But by some small compact perturbation, the normal operator can be diagonalizable, and this result has some applications of representation theory. 

\section{Spectrums}

\subsection{Elementary Properties}

\begin{defn}
	Let $\Hs$ be a Hilbert space and $B_{\Hs}$ be the closed unit ball in $\Hs$ and $T \in \oper$. $T$ is compact if and only if the closure of $T(B_{\Hs})$ is compact. Then let $\coper$ denote the set of all compact operators.
\end{defn}
\begin{rem}
	Clearly, if $T$ is finite rank, $T \in \coper$. Denote $\foper$ as the set of all finite rank operators. Therefore, $\foper \subset \coper$.
	\begin{equation*}
		\foper = \{~T \in \oper \colon \ran{T} \text{ is finite dimension}~\}
	\end{equation*}
\end{rem}

Since $\Hs$ is a complete metric space, the compactness of $\clo{T(B_{\Hs})}$ is equivalent to that any sequence in $\clo{T(B_{\Hs})}$ has a convergent subsequence with the convergent point in $\clo{T(B_{\Hs})}$. By this fact, we can get the following theorem.

\begin{thm}
	Let $\Hs$ be a Hilbert space.
	\begin{enumerate}[label=\arabic*)]
		\item $\coper$ is a linear space.
		\item $\coper$ is closed in norm.
		\item $\coper$ is an ideal in $\oper$.
		\item If $T \in \coper$, then $\st{T} \in \coper$.
	\end{enumerate}
\end{thm}
\begin{rem}
	Therefore, $\coper$ is a $\st{C}$-subalgebra, and moreover, $\coper$ is a closed ideal of $\oper$.
\end{rem}

\begin{defn}
	Let $\Hs$ be a Hilbert space and $T \in \oper$. $T$ is called completely continuous if for any sequence $\{x_n\} \in \Hs$ with $x_n \sto x$ weakly, then $Tx_n \sto Tx$ in norm.
\end{defn}

\begin{prop}
	$T \in \oper$ is compact if and only if $T$ is completely continuous. 
\end{prop}
\begin{proof}
	Let $T$ be a compact operator and $\{x_n\} \in \Hs$ with $x_n \sto 0$ weakly. By the Principle of Uniform Boundedness, $M = \sup_n{\norm{x_n}} < \infty$. Assuming $M \leqslant 1$,
	\begin{equation*}
		\{Tx_n\} \subset \clo{T(B_{\Hs})}
	\end{equation*}
	By the fact that $\clo{T(B_{\Hs})}$ is compact, there is a subsequence $\{x_{n_k}\}$ s.t. $Tx_{n_k}  \sto y$ in norm. Since $T$ is also weakly continuous, $Tx_n \sto 0$ weakly. Thus $y = 0$. Then $T$ is completely continuous.\\
	Conversely, assume $T$ is completely continuous. \\
	Firstly, if $\Hs$ is separable and since $\Hs$ is reflexive, $B_{\Hs}$ is a weak-compact metric space. Therefore, for any $\{x_n\} \subset B_{\Hs}$, there is a subsequence $\{x_{n_k}\}$ and $x$ s.t. $x_{n_k} \sto x$ weakly. Therefore, $Tx_{n_k} \sto x$ in norm, i.e. $T$ is compact.\\
	For general case, let $\{x_n\} \subset B_{\Hs}$, then $\Hs_1 = \clo{\spn{\{x_n\}}}$ is separable. Therefore, since
	\begin{equation*}
		T|_{\Hs_1}(\{x_n\}) = T(\{x_n\}) \subset T|_{\Hs_1}(B_{\Hs_1})
	\end{equation*}
	$T$ is compact.
\end{proof}

By above theorem, we can see the power of compact operators. Intuitively, compact operators can "strengthen" the topology. They map the weakly convergent sequences be norm convergent sequence. How can they do that? We have known the weak topology is agree with the norm topology on the finite dimensional space. So, compact operators may be the "extension" of finite rank operators. In fact, we can describe this property more rigorously.

\begin{thm}
	$T \in \oper$ is compact if and only if there is a sequence $\{T_n\} \subset \foper$ s.t. $T_n \sto T$ in norm.
\end{thm}
\begin{proof}
	Assume $T$ is compact. Therefore, $\clo{T(B_{\Hs})}$ is separable. Let $\{e_n\}_{n=1}^{\infty}$ be the basis of the dense subspace of $\clo{T(B_{\Hs})}$. Then define projections
	\begin{equation*}
		P_n \colon \Hs \longrightarrow \spn{\{e_1, e_2, \cdots, e_n\}}
	\end{equation*}
	and let $T_n = P_nT$. Clearly, $T_n \in \foper$. Now, clearly, $\norm{Th - T_nh} \sto 0$ for any $h \in \Hs$. Since $\clo{T(B_{\Hs})}$ is compact, for any given $\varepsilon > 0$, there are $h_1, \cdots, h_m \in \Hs$ s.t.
	\begin{equation*}
		T(B_{\Hs}) \subset \bigcup_{i=1}^{m}B_{\varepsilon}(Th_i)
	\end{equation*}
	where $B_{\varepsilon}(h_i)$ is the open ball centred at $Th_i$ with radius $\varepsilon$. Therefore, for any $h \in B_{\Hs}$, choose $h_j$ s.t. $\norm{Th-Th_j} < \varepsilon$.
	\begin{eqnarray*}
		\norm{Th-T_nh} &\leqslant& \norm{Th - Th_j} + \norm{Th_j - T_nh_j} + \norm{P_n(Th_j-Th)} \\
		&\leqslant& 2\norm{Th - Th_j} +  \norm{Th_j - T_nh_j} \\
		&<& 2\varepsilon +  \norm{Th_j - T_nh_j}
	\end{eqnarray*}
	Since $\norm{Th_j - T_{n}h_j} < \varepsilon$ for any $h_j$ and $n > n_0$ for some $n_)$,  
	\begin{equation*}
		\norm{Th-T_nh} < 3\varepsilon \text{ for } n > n_0
	\end{equation*}
	Then $T_n \sto T$ uniformly, i.e. $T_n \sto T$ in norm. \\
	The converse is clearly since $\foper \subset \coper$ and $\coper$ is norm closed.
\end{proof}
\begin{cor}
	All projections $\{P_i\}_{i \in I}$ in $\oper$ form an approximate identity for the ideal $\coper$.
\end{cor}

\subsection{Spectrums of Compact Operators}

The spectrum of a compact operator also has similar properties as a finite rank operator.

\begin{thm}
	If $T \in \coper$ and $\lambda \neq 0$ satisfying
	\begin{equation*}
		\inff{\{~\norm{(T-\lambda)h} \colon \norm{h}=1~\}} = 0
	\end{equation*}
	then $\lambda \in \sigma_p(T)$.
\end{thm}
\begin{proof}
	There is a sequence $\{h_n\}$ with $\norm{h_n}=1$ s.t. $\norm{(T-\lambda)h_n} \sto 0$. Since $T$ is compact, there is a subsequence $\{h_{n_k}\}$ and a $h_0$ s.t. $\norm{Th_{n_k}-h_0} \sto 0$, therefore
	\begin{equation*}
		h_{n_k} = \frac{1}{\lambda}((\lambda-T)h_{n_k}+Th_{n_k}) \sto \frac{1}{\lambda}h_0
	\end{equation*}
	Then $\norm{\frac{1}{\lambda}h_0}=1=\abs{\frac{1}{\lambda}}\norm{h_0}$, thus $\norm{h_0} \neq 0$. Since $Th_{n_k} \sto \frac{1}{\lambda}Th_0$ and $Th_{n_k} \sto h_0$,
	\begin{equation*}
		h_0 = \frac{1}{\lambda}Th_0, \text{ i.e. } Th_0 = \lambda h_0
	\end{equation*}
\end{proof}

In fact, we have known that
\begin{equation*}
	\sigma_{ap}(T) = \sigma_l(T) = \{~\lambda \in \C \colon \inff{\{\norm{(T-\lambda)h} \colon \norm{h}=1\}} = 0~\}
\end{equation*}
and $\lambda \notin \sigma_{ap}(T)$ is equivalent to that $\ker{(T-\lambda)} = \{0\}$ and $\ran{(T-\lambda)}$ is closed. Combining with the Riesz Theorem, any closed and bounded subset in a normed space is compact if and only if the normed space is finite dimensional, we have the following corollary.

\begin{cor}
	If $T \in \coper$ and $\lambda \neq 0$ and $\ker{(T-\lambda)} = \{0\}$, then $\ran{(T-\lambda)}$ is closed.
\end{cor}

Here is another important corollary, which says the point spectrum play an important role.
\begin{cor}
	If $T \in \coper$, $\lambda \notin \sigma_p(T)$ with $\lambda \neq 0$ and $\clo{\lambda} \notin \sigma_p(\st{T})$, then $\lambda \notin \sigma(T)$.
\end{cor}
\begin{proof}
	By above theorem, $\lambda \notin \sigma_p(T)$ with $\lambda \neq 0$ means $\lambda \notin \sigma_l(T)$, thus $\ker{(T-\lambda)} = \{0\}$ and $\ran{(T-\lambda)}$ is closed.\\ Similarly, for $\st{T}$, $\ker{(\st{T}-\clo{\lambda})} = \{0\}$ and $\ran{(\st{T}-\lambda)}$ is closed. Therefore,
	\begin{equation*}
		\ran{(T-\lambda)} = \clo{\ran{(T-\lambda)}} = (\ker{(\st{T}-\clo{\lambda})})^{\bot} = \Hs
	\end{equation*}
	Thus $T-\lambda$ is a bijection, and by the Inverse Mapping Theorem, $(T-\lambda)^{-1} \in \oper$, i.e. $\lambda \notin \sigma(T)$.
\end{proof}
\begin{rem}
	In other words, for a compact operator $T$, if $\lambda \in \sigma(T)$ with $\lambda \neq 0$, then $\lambda \in \sigma_p(T)$ or $\lambda \in \sigma_p(\st{T})$.
\end{rem}

In fact, any nonzero point in $\sigma(T)$ for a compact operator $T$ is isolated and moreover, it is an eigenvalue. To prove this, we need some lemmas.

\begin{lem}
	If $\M$ and $\fml{N}$ are two closed linear subspaces of $\Hs$ with $\M \subset \fml{N}$, then for any $\varepsilon > 0$, there exists a $y \in \fml{N}$ with $\norm{y} = 1$ s.t. $\dist{(y,\M)} \leqslant 1-\varepsilon$.
\end{lem}
\begin{proof}
	For $y \in \fml{N}$, define $\delta(y) = \dist{(y,\M)}$. Choosing $y_1 \in \fml{N} \backslash \M$, there exists a $x_0 \in \M$ s.t.
	\begin{equation*}
		\delta(y_1) \leqslant \norm{x_0-y_1} \leqslant (1+\varepsilon) \delta (y_1)
	\end{equation*}
	Let $y_2 = y_1-x_0$, then
	\begin{equation*}
		(1+\varepsilon)\delta(y_2) = (1+\varepsilon)\inff{\{\norm{y_1-x_0-x} \colon x \in \M\}} = (1+\varepsilon)\delta(y_1)
	\end{equation*}
	Thus $(1+\varepsilon)\delta(y_2) > \norm{x_0 - y_1} = \norm{y_2}$. Let $y = \norm{y_2}^{-1}y_2$, then $y_2 \in \fml{N}$.
	\begin{eqnarray*}
		\norm{y-x} &=& \norm{\norm{y_2}^{-1}y_2-x} = \norm{y_2}^{-1}\norm{y_2-\norm{y_2}x} \\
		&>& ((1+\varepsilon)\delta(y_2))^{-1} \norm{y_2-\norm{y_2}x} \\
		&\geqslant& (1+\varepsilon)^{-1} > 1 - \varepsilon
	\end{eqnarray*}
\end{proof}

\begin{prop}
	If $T \in \coper$ and $\{\lambda_n\}$ is a sequence of distinct elements in $\sigma_p(T)$, then $\lim_{n \sto \infty} \lambda_n = 0$.
\end{prop}
\begin{proof}
	For each $n$, choosing a nonzero $x_n \in \ker{(T-\lambda_n)}$,
	\begin{equation*}
		\M_n = \spn{\{~x_1,x_2,\cdots,x_n~\}}
	\end{equation*}
	By preceding lemma, there is a $y_n \in \M_n$ with $\norm{y_n}=1$ s.t.
	\begin{equation*}
		\dist{(y_n,\M_{n-1})} > \frac{1}{2}
	\end{equation*}
	Let $y_n = \sum_{i=1}^{n} \alpha_i x_n$, thus
	\begin{equation*}
		(T-\lambda_n)y_n = \sum_{i=1}^{n-1} \alpha_i (\lambda_i-\lambda_n)x_i \in \M_{n-1}
	\end{equation*}
	Therefore, for $n > m$,
	\begin{eqnarray*}
		T(\lambda_n^{-1}y_n)-T(\lambda_m^{-1}y_m) &=& \lambda_n^{-1}(T-\lambda_n)y_n - \lambda_m^{-1}(T-\lambda_m)y_m + (y_n - y_m) \\
		&=& y_n - (y_m + \lambda_n^{-1}(T-\lambda_n)y_n + \lambda_m^{-1}(T-\lambda_m)y_m)
	\end{eqnarray*}
	Since the part in the bracketed is in $\M_{n-1}$,
	\begin{equation*}
		\norm{T(\lambda_n^{-1}y_n)-T(\lambda_m^{-1}y_m)} \leqslant \dist{(y_n,\M_{n-1})} > \frac{1}{2}
	\end{equation*}
	Thus $\{\lambda_n^{-1}y_n\}$ has no bounded subset by the fact that $T$ is compact.
	\begin{equation*}
		\norm{\lambda_n^{-1}y_n} = \abs{\lambda_n}^{-1} \sto \infty
	\end{equation*}
	That means $\lim_{n \sto \infty} \lambda_n = 0$.
\end{proof}

\begin{prop}
	If $T \in \coper$ and a nonzero $\lambda \in \sigma(T)$, then $\lambda$ is a isolated point in $\sigma(T)$.
\end{prop}
\begin{proof}
	If there is a sequence $\{\lambda_n\} \subset \sigma(T)$ s.t. $\lambda_n \sto \lambda$, then each $\lambda_n$ is in either $\sigma_p(T)$ or $\sigma_p(\st{T})$. Then if there exists a subsequence $\{\lambda_{n_k}\} \subset \sigma_p(T)$. But by above proposition, $\lim_{k \sto \infty} \lambda_{n_k} =0$, which is a contradiction. Similarly, if $\{\lambda_{n_k}\} \subset \sigma_p(\st{T})$, $\lim_{k \sto \infty} \lambda_{n_k} =0$, which is also a contradiction.
\end{proof}

Now, we can see any nonzero point in the spectrum of a compact operator is a eigenvalue.

\begin{lem}
	If $T \in \coper$ and a nonzero $\lambda \in \sigma(T)$, then $\ker{(T-\lambda)}$ is finite dimentional.
\end{lem}
\begin{proof}
	If there is an infinite orthonormal sequence $\{e_n\}$ in $\ker{(T-\lambda)}$, then $\{Te_n\}$ has a convergent subsequence $\{Te_{n_k}\}$, thus it is Cauchy.
	\begin{equation*}
		\norm{Te_{n_k}-Te_{n_j}}^2 = \norm{\lambda e_{n_k}-\lambda e_{n_j}}^2 = 2 \abs{\lambda} > 0
	\end{equation*}
	which is a contradiction.
\end{proof}

\begin{thm} \label{thm12}
	If $T \in \coper$ and a nonzero $\lambda \in \sigma(T)$, then $\lambda \in \sigma_p(T)$ and $\dim{\ker{(T-\lambda)}} = \dim{\st{\ker{(T-\lambda)}}} < \infty$ and $\ran{(T-\lambda)}$ is closed.
\end{thm}
\begin{proof}
	By the \textbf{Proposition} \ref{prop10} in the subsection \textbf{2.1.3}, since each $\lambda \in \sigma(T)$ is isolated, we can define
	\begin{equation*}
		E(\lambda) = \int_{\Gamma(\{\lambda\})} (z-T)^{-1} dz 
	\end{equation*}
	where $\Gamma(\{\lambda\})$ is the closed curve enclosed $\{\lambda\}$ and disjoint with other $\lambda$ in $\sigma(T)$. Then, each $E(\lambda)$ is a projection.
	\begin{equation*}
		\Hs_{\lambda} = E(\lambda)\Hs,~ T_{\lambda} = T|_{\Hs_{\lambda}} \colon \Hs_{\lambda} \sto \Hs_{\lambda}
	\end{equation*}
	Since $\sigma(T_{\lambda}) = \{\lambda\}$ and $\lambda \neq 0$, $T_{\lambda}$ is invertible. But clearly, $T_{\lambda}$ is compact. That means any bounded and closed subset in $\Hs_{\lambda}$ is compact, thus $\dim{\Hs_{\lambda}} < \infty$ by the Riesz Theorem. Therefore, by the result of finite linear algebra, $\lambda$ is the eigenvalue of $T_{\lambda}$, i.e. $\lambda \in \sigma_p(T)$. By above lemma, $\dim{\ker{(T-\lambda)}} < \infty$.\\
	Let $\Delta = \sigma(T) \backslash \{\lambda\}$, $\Hs_{\Delta} = E(\{\Delta\})\Hs$ and $T_{\Delta} = T|_{\Hs_{\Delta}}$. Then since $\lambda \notin \Delta$,
	\begin{equation*}
		\ran{(T_{\Delta}-\lambda)} = \Hs_{\Delta}
	\end{equation*}
	Therefore, 
	\begin{eqnarray*}
		\ran{(T-\lambda)} &=& (T-\lambda)\Hs_{\lambda}+(T-\lambda)\Hs_{\Delta} \\
		&=& \ran{(T_{\lambda}-\lambda)} + \Hs_{\Delta}
	\end{eqnarray*}
	Moreover, since $\dim{\Hs_{\lambda}} < \infty$, $\ran{(T_{\lambda}-\lambda)}$ is closed. Thus $\ran{(T-\lambda)}$ is closed.\\
	Finally, note that
	\begin{eqnarray*}
		\Hs / \ran{(T-\lambda)} &=& (\Hs_{\Delta} + \Hs_{\lambda}) / (\ran{(T_{\lambda}-\lambda)} + \Hs_{\Delta}) \\
		&\cong& \Hs_{\lambda} / \ran{(T_{\lambda}-\lambda)}
	\end{eqnarray*}
	Since $\dim{\Hs_{\lambda}} < \infty$,
	\begin{eqnarray*}
		\dim{(\Hs / \ran{(T-\lambda)})} &=& \dim{\Hs_{\lambda}} - \dim{\ran{(T_{\lambda}-\lambda)}} = \dim{\ker{(T_{\lambda}-\lambda)}} \\
		&=& \dim{\ker{(T-\lambda)}} < \infty
	\end{eqnarray*}
	And since
	\begin{equation*}
		(\Hs / \ran{(T-\lambda)})^{*} \cong \ran{(T-\lambda)}^{\bot} = \ker{\st{(T-\lambda)}}
	\end{equation*}
	$\dim{\ker{(T-\lambda)}} = \dim{\st{\ker{(T-\lambda)}}}$.
\end{proof}

Combining all of above results, we can get an explicit structure of the spectrum of compact operator.

\begin{thm}[Riesz]
	If $\Hs$ is a infinite dimensional Hilbert space and $T \in \coper$, then one and only one of the following possibilities occurs.
	\begin{enumerate}[label=\arabic*)]
		\item $\sigma(T) = \{0\}$.
		\item $\sigma(T) = \{0,\lambda_1,\cdots,\lambda_n\}$, where each $\lambda_k \neq 0$, and each $\lambda_k$ is the eigenvalue of $T$ with $\dim{\ker{(T-\lambda_k)}}<\infty$.
		\item $\sigma(T) = \{0,\lambda_1,\lambda_2,\cdots\}$, where each $\lambda_k \neq 0$, and each $\lambda_k$ is the eigenvalue of $T$ with $\dim{\ker{(T-\lambda_k)}}<\infty$, and moreover, $\lim_{n \sto \infty} \lambda_n =0$.
	\end{enumerate}
\end{thm}

Because of its discrete spectrum, we can using the spectral measure to decompose the compact normal operator.

\begin{thm}[Spectral Theorem]
	If $T$ is a compact normal operator on a Hilbert space $\Hs$, then $T$ has at most countable eigenvalues $\{\lambda_n\}$, and there are corresponding projections $P_n \colon \Hs \sto \ker{(T-\lambda_n)}$ with $P_nP_m=P_mP_n=0$ s.t.
	\begin{equation*}
		T = \sum_{n=1}^{\infty} \lambda_n P_n
	\end{equation*}
	where $\{\lambda_n\}$ are all distinctive eigenvalues and the convergence is with respect to the norm topology.
\end{thm}
\begin{proof}
	Let $E$ be the spectral measure of $T$, then we see
	\begin{equation*}
		N = \int_{\sigma(N)} z dE
	\end{equation*}
	If $\dim{\Hs} = \infty$, since $\sigma(N)$ is consisted of at most countable eigenvalues $\{\lambda_n\}_{n=1}^{\infty}$ and $0$, then we can set $P_n = E(\{\lambda_n\})$ for $n = 1,2,\cdots$, which is well-defined by the \textbf{Proposition} \ref{prop11} in the subsection \textbf{3.1.2}, above integral can be
	\begin{eqnarray*}
		N &=& \lim_{n \sto \infty} (\int_{B_{\frac{1}{n}}(0)} z dz + \sum_{k=1}^{n} \lambda_k P_k) \\
		&=& \sum_{n=1}^{\infty} \lambda_n P_n
	\end{eqnarray*} 
	And moreover, $P_n$ is the projection from $\Hs$ onto $\ker{(T-\lambda_n)}$. \\
	If $\dim{\Hs} < \infty$, above theorem is clearly true.
\end{proof}

Also, we can see the Functional Calculus of the compact normal operators. Firstly, Taking same notation as above theorem and let $P_0 = 1-\sum_{n=1}^{\infty}$, in fact, $P_0$ is the projection from $\Hs$ to $\ker{T}$. By the Functional Calculus of normal operators, we know
\begin{equation*}
	\st{W}(T) = \{~\phi(T) \colon \phi \in \lfs{\infty}(\sigma(T))~\}
\end{equation*}
Since $\sigma(T)$ is discrete, $\lfs{\infty}(\sigma(T)) = l^{\infty}(\C)$, and for any $(a_n)_{n=0}^{\infty} \in l^{\infty}(\C)$,
\begin{equation*}
	(a_n)(T) = a_0 P_0 + \sum_{n=1}^{\infty} a_n P_n
\end{equation*}
Thus we can see the separating vector for $\st{W}(T)$, if $e$ is a separating vector and decomposing $e$ to $\{P_n\}_{n=0}^{\infty}$
\begin{equation*}
	e = \sum_{n=0}^{\infty} e_n,~ e_n \in P_n \text{ for each n}
\end{equation*} 
Then for $(a_n)_{n=0}^{\infty} \in l^{\infty}(\C)$
\begin{equation*}
	(a_n)(T)e = (a_0 P_0 + \sum_{n=1}^{\infty} a_n P_n)(\sum_{n=0}^{\infty} e_n) = \sum_{n=0}^{\infty} a_n e_n
\end{equation*}
Since $e$ is separating, $\sum_{n=0}^{\infty} a_n e_n = 0$ for any $(a_n) \in l^{\infty}(\C)$ implies $a_n = 0$ for all $n$. That means that $e_n \neq 0$ for any $n$. Then the corresponding measure $\mu$ is defined as
\begin{equation*}
	\mu(\{\lambda_n,\lambda_m\}) = \norm{E(\{\lambda_n,\lambda_m\})e}^2 = \norm{e_n+e_m}^2
\end{equation*}

Now, we can see the multiplicity function of compact normal operator. By similar construction in the \textbf{Theorem} \ref{thm10} and \textbf{Theorem} \ref{thm9} in the section \textbf{3.4}, the multiplicity function is like
\begin{equation*}
	m_T(\lambda) = \dim{\ker{(T-\lambda)}}
\end{equation*}
That means two compact normal operators are equivalent if and only if they have same dimension of all eigenspaces.

Finally,, we can prove $\coper$ is the unique closed ideal in $\oper$ if $\Hs$ is separable. 
\begin{prop}
	If $N$ is a normal operator in $\oper$ with the specture measure $E$, then $N$ is compact if and only if for any $\varepsilon > 0$,
	\begin{equation*}
		\dim{E(\{z \in \C \colon \abs{z} > \varepsilon\})} < \infty
	\end{equation*}
\end{prop}
\begin{proof}
	Let $\Delta_{\varepsilon} = \{z \in \C \colon \abs{z} > \varepsilon\}$ and $E_{\varepsilon} = E(\Delta_{\varepsilon})$.\\
	Assume that for any given $\varepsilon > 0$, $\dim{E_{\varepsilon}} < \infty$, then
	\begin{eqnarray*}
		N - NE_{\varepsilon} &=& \int z dE - \int z\chi_{\Delta_{\varepsilon}} dE \\
		&=& \int z\chi_{\C \backslash \Delta_{\varepsilon}} dE = \phi(N)
	\end{eqnarray*}
	where $\phi(z) = z\chi_{\C \backslash \Delta_{\varepsilon}}(z)$. Therefore,
	\begin{equation*}
		\norm{N - NE_{\varepsilon}} = \sup{\{\abs{z} \colon \C \backslash \Delta_{\varepsilon}\}} < \varepsilon
	\end{equation*}
	Thus $N \in \coper$. \\
	Conversely, if $N$ is compact, then for any $\varepsilon > 0$, put $\phi(z) = z^{-1}\chi_{\Delta_{\varepsilon}}$, then
	\begin{equation*}
		N\phi(N) = \int \chi_{\Delta_{\varepsilon}} dE = E_{\varepsilon} 
	\end{equation*}
	Since $E_{\varepsilon}$ is a compact projection, i.e. $\ran{E_{\varepsilon}}$ is closed, by the Riesz Theorem, $\dim{\ran{E_{\varepsilon}}} < \infty$.
\end{proof}

\begin{thm}
	If $\Hs$ is a separable Hilbert space and $\I$ is an ideal of $\oper$ that contains a non-compact operator, then $\I = \oper$.
\end{thm}
\begin{proof}
	Let $T \in \I \backslash \coper$ then 
	\begin{equation*}
		\st{T}T = \int_{\sigma(\st{T}T)} t dE(t)
	\end{equation*}
	By above theorem, there is an $\varepsilon > 0$ s.t. $P = E(\varepsilon,\infty)$ has infinite rank. 
	\begin{equation*}
		P = (\int t^{-1}\chi_{(\varepsilon,\infty)}(t)dE(t))\st{T}T \in \I
	\end{equation*}
	Since $\Hs$ is separable, $\dim{P\Hs} = \dim{\Hs} = \aleph_0$, there is a unitary $U$ from $\Hs$ to $P\Hs$. Therefore, $1 = \st{U}PU \in \I$. $\I = \oper$.
\end{proof}

\begin{prop}
	If $\I$ is a closed ideal of $\oper$, the $\coper \subset \I$ or $\I = \{0\}$.
\end{prop}
\begin{proof}
	Since $\I$ is closed, $\I$ is self-adjoint by the  \textbf{Proposition} \ref{prop12} in the subsection \textbf{2.2.5}. Then by the \textbf{Theorem} \ref{thm6} in the subsection \textbf{2.2.5}, we know $\I = \I \cap \st{\I}$ is a hereditary subalgebra. \\
	Therefore, if $\I$ is nonzero and $T \in \I$ is nonzero, then there is a finite rank projection $P$ s.t.
	\begin{equation*}
		0 \leqslant P \leqslant \st{T}T
	\end{equation*}
	Thus, $P \in \I$. Morover, any finite rank projection is in $\I$. Since $\I$ is norm closed, $\coper \subset \I$.
\end{proof}

Combining above propositions and theorems, we can get the final result.
\begin{cor}
	If $\Hs$ is a separable Hilbert space, then the only nontrivial closed ideal of $\oper$ is $\coper$.
\end{cor}

\section{Compact Operator Algebras}

For a normal operator, it can be decomposed as the direct sum of $*$-cyclic normal operators. Therefore, we want to reseach the similar property of compact operators. Like researching the normal operator, we firstly begin with the representation of compact operators. Let $\A$ denote a $\st{C}$-subalgebra in $\coper$.

\subsection{Minimal Projections}

\begin{defn}
	If $\A$ is a $\st{C}$-subalgebra in $\coper$
	\begin{enumerate}[label=\arabic*)]
		\item A projection $E$ in $\A$ is minimal if $E \neq 0$ and there are no nonzero projection $P$ in $\A$ s.t. $P < E$.
		\item $\A$ is called irreducible if $\A$ has no proper reducing subspaces.
	\end{enumerate}
\end{defn}

\begin{prop}
	Let $E$ be a projection in $\A$.
	\begin{enumerate}[label=\arabic*)]
		\item $E$ is minimal if and only if
		\begin{equation*}
			E\A E = \{~\lambda E \colon \lambda \in \C~\}
		\end{equation*}
		\item Every projection in $\A$ is the direct sum of a finite number of pairwise orthogonal minimal projections in $\A$.
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, clearly, $E \A E$ is a $\st{C}$-subalgebra of $\coper$. Thus for any self-adjoint operator $A \in E \A E$, each nonzero spectrum point $\lambda$ of $A$ is isolated. That means $\chi_{\{\lambda\}}$ is continuous, thus $E(\{\lambda\})$ is a projection in $E \A E$. However, the minimality of $E$ implies that $E(\{\lambda\}) = E$. Therefore, by the fact that $E \A E$ can be generated by all self-adjoint operators in $E \A E$, $E\A E = \{\lambda E \colon \lambda \in \C\}$. The converse is trivial.
	\item For $2)$, since each projection in $P$ $\A$ is compact, $P$ has finite rank. Thus $P$ can he direct sum of a finite number of pairwise orthogonal minimal projections.
\end{proof}

Using the minimal projection, we can get an important trait the irreducible compact subalgebra has.
\begin{thm}
	If $\A$ is an irreducible $\st{C}$-subalgebra of $\coper$, then $\A = \coper$.
\end{thm}
\begin{proof}
	Let $E$ be a minimal projection in $\A$.\\
	Claim: The rank of $E$ is one. \\
	If $\rank{E} > 1$, then there are nonzero $g,h \in E$ with $g \bot h$. Let $A \in \A$ and $\lambda \in \C$ s.t. $EAE = \lambda A$. Then
	\begin{equation*}
		\langle Ag,h \rangle = \langle EAEg,h \rangle = \lambda \langle g,h \rangle = 0
	\end{equation*}
	Thus, $h \bot \clo{\A g}$. But since $\A$ is irreducible, $\clo{\A g} = \Hs$. So $h = 0$ contradicted to the assumption.
	\item Claim: If $P$ is any rank one projection, then $P \in \A$. \\
	Let $e \in E$ and $p \in P$. By the irreducibility of $\A$, $\Hs = \clo{\A e}$. Then for any given $\varepsilon > 0$, 
	\begin{equation*}
		\norm{Ae - p} < \varepsilon,~ \text{ for some } A \in \A
	\end{equation*}
	Let $P^{'} = AE$, then $P^{'} \in \A$. And moreover, for any $h \in \Hs$
	\begin{eqnarray*}
		\norm{(P-P^{'})h} &=& \norm{\langle h,p \rangle p - \langle h, Ae \rangle Ae}\\ 
		&=& \norm{\langle h,p-Ae \rangle Ae + \langle h,p \rangle (p-Ae)} \\
		&\leqslant& \norm{h} \norm{Ae} \varepsilon + \norm{h}\norm{p} \varepsilon
	\end{eqnarray*}
	Thus by the fact that $\A$ is norm closed, $P \in \A$. \\
	Therefore, any finite rank projection in $\A$, i.e. $\A = \coper$.
\end{proof}

\begin{cor}
	For any Hilbert space $\Hs$, $\coper$ is simple.
\end{cor}
\begin{proof}
	Let $\I$ be an closed ideal in $\coper$. Then $\clo{\I e}$ for any nonzero $e$ is a reducing space for $\coper$. Thus $\clo{\I e} = \Hs$ since $\coper$ is irreducible. That means $\I$ is irreducible. Thus by above theorem, $\I = \coper$.
\end{proof}
\begin{rem}
	In fact, the converse of the result in above proof is also true. $\B$ is a irreducible subalgebra contained in $\oper$ if and only if $\clo{\B e} = \Hs$ for any $e \in \Hs$. And because of this, we can get the genera version of the corollary that if $\B$ is a irreducible subalgebra contained in $\oper$, then any ideal of it is irreducible.
\end{rem}

\begin{cor}
	Let $\Hs$ be a Hilbert space. If $\B$ is a irreducible $\st{C}$-subalgebra of $\oper$ and $\B \cap \coper \neq 0$, then $\coper \subset \B$.
\end{cor}
\begin{proof}
	Let $\I = \B \cap \coper$. Then $\I$ is a closed ideal in $\B$. By above corollary, $\I = \coper$, i.e. $\coper \subset \B$.
\end{proof}

Now, the unit element of a compact operator subalgebra can be provided.
\begin{prop}
	If $E$ is a minimal projection in $\A$, $e$ is any nonzero vector in $\Hs$ and $\Hs_e = \clo{\A e}$, then $\A|_{\Hs_e} = \fml{B}_0(\Hs_e)$.
\end{prop}
\begin{proof}
	Let $\A_e = \A|_{\Hs_e}$. We just need to show $\A_e$ is irreducible in $\fml{B}(\Hs_e)$. Let $P$ be a projection in $\fml{B}(\Hs_e)$ commuting with $\A_e$. Put 
	\begin{equation*}
		T = P - \langle Pe,e \rangle 1
	\end{equation*}
	Then $T \in \A_e^{'}$, for any $A,B \in \A$,
	\begin{eqnarray*}
		\langle TAe, Be \rangle &=& \langle T \st{B}A E e, E e \rangle \\
		&=& \langle T E \st{B}A E e,e \rangle
	\end{eqnarray*}
	Since $E$ is minimal, $E \st{B}A E = \lambda E$ for some $\lambda \in \C$. Therefore,
	\begin{equation*}
		\langle TAe, Be \rangle = \lambda \langle Te, e \rangle = \lambda (\langle Pe, e \rangle - \langle Pe, e \rangle) = 0
	\end{equation*}
	Since $A,B$ are arbitrary and $\Hs_e = \clo{\A e}$, $T = 0$, that means $P = \langle Pe,e \rangle 1$. Thus, $P = 0$ or $1$.
\end{proof}

\subsection{Representations of Compact Operator Algebras}

For the representation of a compact operator subalgebra, it can be decomposed as the direct sum of irreducible parts.
\begin{thm}
	If $(\rho, \fml{K})$ is a non-degenerate representation of $\A$, then there are irreducible representations $\{\rho_i\}_{i \in I}$ s.t. each $\rho_i$ is equivalent to a subrepresentation of the identity representation $i \colon \A \sto \oper$.
\end{thm}
\begin{proof}
	Claim: There is a minimal projection $E \in \A$ s.t. $\rho(E) \neq 0$. \\
	In fact, there is a self-adjoint operator $A \in \A$ s.t. $\rho(A) \neq 0$. Otherwise, $\rho$ is the zero representation. Then there is a spectral projection $F$ for $A$ with $\rho(F) \neq 0$. Then since $F$ is the direct sum of finite numbers minimal projections, that means $\rho$ must not vanish on at least one of them.
	\item For this $E$, choosing a unit vector $e_0 \in \rho(E)$ and define $\fml{K}_0 = \clo{\rho(\A)e_0}$ and $\rho_0(A) = \rho(A)|_{\fml{K}_0}$. Then \\
	Claim: $(\rho_0,\fml{K}_0)$ is equivalent to a subrepresentation of the identity representation of $\A$.\\
	Define the unitary $U$ from $\fml{K}_0$ to $\Hs_0 = \clo{\A e}$, where $e$ is the unit vector in $E$. 
	\begin{center}
		\begin{tabular}{l c c l}
			$U \colon$ & $\fml{K}_0$ & $\longrightarrow$ & $\Hs_0$ \\
			~ & $\rho(A)e_0$ & $\longmapsto$ & $Ae$
		\end{tabular}
	\end{center}
	Since $E$ is minimal, there exists a unique $\lambda$ s.t. $E \st{A}A E = \lambda E$ for $A \in \A$.
	\begin{eqnarray*}
		\norm{\rho(A)e_0}^2 &=& \norm{\rho(AE)e_0}^2 = \langle \rho(E \st{A}AE)e_0,e_0 \rangle\\
		&=& \lambda \langle e_0,e_0 \rangle = \lambda \langle e,e \rangle \\
		&=& \langle E \st{A}AE e_0,e_0 \rangle \\
		&=& \norm{Ae}^2
	\end{eqnarray*}
	Therefore, $U$ is surjective isometry, and can extend to $\fml{K}_0$. And moreover,
	\begin{equation*}
		U\rho(A)\rho(B)e_0 = A Be ~\Rightarrow~ U\rho(A) \st{U} Be = A|_{\Hs_0} Be
	\end{equation*}
	Thus, $U\rho_0(A)\st{U} = A|_{\Hs_0}$. By above proposition, $\rho_0$ is irreducible.
	\item Then by Zorn's Lemma, we can get a maximal family of $(\rho_i, \fml{K}_i)_{i \in I}$ as above construction. And by the maximality and the non-degenerality, 
	\begin{equation*}
		\rho = \oplus_{i \in I} \rho_i,~ \fml{K} = \oplus_{i \in I} \fml{K}_i \qedhere
	\end{equation*}
\end{proof}
\begin{rem}
	If $\rho$ is degenerate, then let $\Hs_0 = \clo{\rho(\A) \Hs}$. The representation $(\rho_0(A) = \rho(A)|_{\Hs_0}, \Hs_0)$ is a non-degenerate representation, thus above theorem can be applied to it. Moreover, $\rho = \rho_0 \oplus 0$. 
\end{rem}

Now, we can use above theorem to get the structure of any finite dimensional $\st{C}$-algebra.
\begin{cor}
	For any finite dimensional $\st{C}$-algebra $\A$ and let $M(n)$ be the set of $n \times n$ matrices with complex entries acting on the inner product space $\C^{n}$, there are $n_1,\cdots,n_p \in \N$, s.t.
	\begin{equation*}
		\A \cong M(n_1) \oplus M(n_2) \oplus \cdots \oplus M(n_p)
	\end{equation*}
\end{cor}

Also, there are some other corollaries of above theorem.

\begin{cor} \label{cor10}
	\begin{enumerate}[label=\arabic*)]
		\item If $(\rho, \fml{K})$ is an irreducible representation of $\A$, then $\rho(\A) = \fml{B}_0(\fml{K})$.
		\item If $\Hs$ and $\fml{K}$ are Hilbert spaces and $\rho \colon \coper \sto \fml{B}_0(K)$ is an $*$-isomorphism, then there is a unitary $U \colon \Hs \sto \fml{K}$, s.t.
		\begin{equation*}
			\rho(T) = U T \st{U}, \text{ for any } T \in \coper
		\end{equation*}
		\item If $\Hs$ and $\fml{K}$ are Hilbert spaces and $\rho \colon \oper \sto \fml{B}(K)$ is an $*$-isomorphism, then there is a unitary $U \colon \Hs \sto \fml{K}$, s.t.
		\begin{equation*}
			\rho(A) = U A \st{U}, \text{ for any } A \in \oper
		\end{equation*}
	\end{enumerate}
\end{cor}
\begin{proof}
	$1)$ is the direct result from above theorem. And $2)$ can be obtained by $1)$. \\
	For $3)$, since $\rho(\coper)$ is an ideal of $\fml{K}$ and $\fml{K}$ is irreducible, $\rho(\coper)$ is irreducible by above corollary. Thus $\rho(\coper) = \fml{B}_0(\fml{K})$. Then by $2)$, there is a unitary $U \colon \Hs \sto \fml{K}$, s.t.
	\begin{equation*}
		\rho(A) = U A \st{U}, \text{ for any } A \in \coper
	\end{equation*}
	Let $\{E_i\}$ be the approximatel identity for $\coper$ consisting with all finite projections. For any $A \leqslant 0$ in $\Hs$, then it can see
	\begin{equation*}
		A_i = A^{\frac{1}{2}} E_i A^{\frac{1}{2}} \sto A \text{ in } SOT
	\end{equation*}
	Therefore, $\rho(A_i) = U A_i \st{U} \sto U A \st{U} = T$ in $SOT$. Since $A_i \leqslant A$, $\rho(A_i) \leqslant \rho(A)$ and thus $T \leqslant \rho(A)$ by the fact that $\{A_i\}$ is increasing. Conversely, $\rho(A_i) \leqslant T$ implies that $A_i \leqslant \rho^{-1}(T)$. Thus $A \leqslant \rho^{-1}(T)$, thus $\rho(A) \leqslant T$.
\end{proof}

Here is an important example, which can be used to construct the $AF$ algebra.

\begin{exam}
	Let $M(n)$ be the set of $n \times n$ matrices with complex entries acting on the inner product space $\C^{n}$. If
	\begin{equation*}
		\rho \colon M(m) \longrightarrow M(n)
	\end{equation*}
	is a $*$-homomorphism, then there is an integer $k$ s.t. $km \leqslant n$ and a unitary $U$ in $M(n)$ and 
	\begin{equation*}
		\rho(x) = U(\underbrace{x \oplus x \oplus \cdots \oplus x}_k \oplus 0)\st{U}
	\end{equation*}
	In general, define $\mathbf{m} = (m_1, m_2, \cdots, m_p)$, where $m_i \in \N$, and
	\begin{equation*}
		M(\mathbf{m}) = M(m_1) \oplus M(m_2) \oplus \cdots M(m_p)
	\end{equation*}
	Then for $\mathbf{m} = (m_1, m_2, \cdots, m_p)$ and $\mathbf{n}=(n_1, n_2, \cdots, n_q)$, if $\rho \colon M(\mathbf{m}) \rightarrow M(\mathbf{n})$ is a $*$-homomorphism, then there this a $q \times p$ matirx $[k_{ij}]$ with integer entries s.t.
	\begin{equation*}
		\rho(x_1,\cdots,x_p) = U_1(\underbrace{x_1 \oplus \cdots \oplus x_1}_{k_{11}} \oplus 0)\st{U}_1 \oplus \cdots \oplus U_q(\underbrace{x_p \oplus \cdots \oplus x_p}_{k_{qp}} \oplus 0)\st{U}_q
	\end{equation*}
	By above corollary, we see for any finite dimensional $\st{C}$-algebras $\A$, there exists a $\mathbf{n}=(n_1, n_2, \cdots, n_q)$ s.t. $\A \cong M(\mathbf{n})$. Then we can get the form of the $*$-homomorphism between any two finite dimensional $\st{C}$-algebras. \\
	If $\rho$ is a $*$-homomorphism between two finite dimensional $\st{C}$-algebras\\ $\A \cong M(\mathbf{m})$ and $\B \cong M(\mathbf{n})$, where $\mathbf{m} = (m_1, m_2, \cdots, m_p)$ and $\mathbf{n}=(n_1, n_2, \cdots, n_q)$, then $\rho$ is determined up to a $q \times p$ matirx $[k_{ij}]$ with integer entries. In fact, we can use it to construct the $AF$ algebras.
\end{exam}

\subsection{Decompositions of Compact Operator Algebras}

By above theorem and the Zorn's Lemma, for the non-degenerate $\A$, there is a maximal family $\{E_i\}_{i \in I}$ of pairwise orthogonal minimal projections in $\A$ and let $\Hs_i = \clo{\A E_i \Hs}$ s.t.
\begin{equation*}
	\Hs = \oplus_{i \in I} \Hs_i~,~ \A|_{\Hs_i} = \fml{B}_0(\Hs_i)
\end{equation*}
But we cannot just using this as the decomposition of the compact operator algebra $\A$, since there are some "equivalent" relationships of these $\Hs_i$. Firstly, we say that $\Hs_i$ does not dependent on $\Hs_j$, if there is a $A \in \A$ s.t. $\A|_{\Hs_i} = 0$ and $\A|_{\Hs_j} \neq 0$.

\begin{prop}
 	$\Hs_i$ does not dependent on $\Hs_j$ if and only if
 	\begin{equation*}
 		A|_{\Hs_i \oplus \Hs_j} = \fml{B}_0(\Hs_i) \oplus \fml{B}_0(\Hs_j)
 	\end{equation*}
 \end{prop}
 \begin{proof}
 	Assume that $\Hs_i$ does not dependent on $\Hs_j$. Let
 	\begin{equation*}
 		\I = \{~A \in \A \colon A|_{\Hs_j} = 0~\}
 	\end{equation*}
 	Since $\Hs_j$ is reducing, $\I$ is a closed ideal. Moreover, $\I|_{\Hs_i}$ is a closed ideal of $\A|_{\Hs_i} = \fml{B}_0(\Hs_i)$. By the assumption, $\I|_{\Hs_i}$ is not zero, thus $\I|_{\Hs_i} = \fml{B}_0(\Hs_i)$. Let $K_i$ and $K_j$ be arbitrary compact operators on $\Hs_i$ and $\Hs_j$. And $A \in \A$ s.t. $A|_{\Hs_j} = K_j$. Since $\I|_{\Hs_i} = \fml{B}_0(\Hs_i)$, there exists $B \in \I$ s.t. $B|_{\Hs_i} = K_i - A|_{\Hs_i}$. Thus,
 	\begin{equation*}
 		(A+B)|_{\Hs_i} = K_i,~~\&~~ (A+B)|_{\Hs_j} = K_j
 	\end{equation*}
 	The converse is trivial.
 \end{proof}
\begin{rem}
	By this proposition, if $\Hs_i$ does not dependent with $\Hs_j$, $\Hs_j$ does not $\Hs_i$. $\Hs_i$ and $\Hs_j$ are independent if they are not dependent.
\end{rem}

Now we want to research the same properties of the dependent subspaces have, and then we can devide all ${\Hs_i}_{i \in I}$ into dependency class.

\begin{prop}
	If $\Hs_i$ and $\Hs_j$ are dependent, then
	\begin{equation*}
		\norm{A|_{\Hs_i}} = \norm{A|_{\Hs_j}}~, \text{ for any } A \in \A
	\end{equation*}
	Moreover, two dependent spaces are isomorphic, and each dependency class is finite.
\end{prop}
\begin{proof}
	By the hypothesis, if $A \in \A$ s.t. $A|_{\Hs_i} = 0$, then $A|_{\Hs_j} = 0$. Then we can define the map
	\begin{equation*}
		\rho \colon  \fml{B}_0(\Hs_j)  \longrightarrow  \fml{B}_0(\Hs_i)
	\end{equation*}
	For any $K \in \fml{B}_0(\Hs_j)$, there is a $A \in \A$ s.t. $A|_{\Hs_j} = K$, then we define that $\rho(K) = A|_{\Hs_i}$.
	\item Claim: $\rho$ is well-defined. \\
	If $B \in \A$ s.t. $B|_{\Hs_j} = K$, then $(A-B)|_{\Hs_j} = 0$. By the dependency of $\Hs_j$ and $\Hs_i$, $(A-B)|_{\Hs_i} = 0$, i.e. $A|_{\Hs_i} = B|_{\Hs_i}$.
	\item $\rho$ is a $*$-isomorphism. \\
	If $K \in \fml{B}_0(\Hs_j)$ s.t. $\rho(K) = 0$, then there is a $A \in \A$ s.t. $A|_{\Hs_j} = K$ and $A|_{\Hs_i} = 0$. Also, by the dependency, $K = A|_{\Hs_j} = 0$. Clearly, $\rho$ is a $*$-homomorphism, then $\rho$ is a $*$-monomorphism, i.e. $\rho$ is an isometry. And the surjectivity of $\rho$ is similar by the dependency of $\Hs_j$ and $\Hs_i$.
	\item Then by the \textbf{Corollary} \ref{cor10} in above subsection, we can find a unitary from $\Hs_j$ to $\Hs_i$. Thus $\dim{\Hs_j} = \dim{\Hs_i}$. And if there are infinite element in a dependency class, by the compactness of $A$, $\norm{A|_{\Hs_i}} \sto 0$, which is a contradiction.
\end{proof}

\begin{thm}
	If $\A$ is a $\st{C}$-subalgebra of compact operators, then
	\begin{equation*}
		\Hs \cong \Hs_0 \oplus \oplus_{d \in D} \Hs_d^{(k_d)}
	\end{equation*}
	and
	\begin{equation*}
		\A \cong \{~0 \oplus \oplus_{d \in D} K_d^{(k_d)} \colon K_d \in \fml{B}_0(\Hs_d)~\}
	\end{equation*}
\end{thm}
\begin{proof}
	Firstly, by above mention, if $\A$ is non-degenerate, there are $\{\Hs_i\}_{i \in I}$ s.t. 
	\begin{equation*}
		\Hs = \oplus_{i \in I} \Hs_i~,~ \A|_{\Hs_i} = \fml{B}_0(\Hs_i)
	\end{equation*}
	But by above theorem, we can divide $\{\Hs_i\}$ into the dependency classes, and re-labeled as 
	\begin{equation*}
		\{~\underbrace{\Hs_1,\cdots,\Hs_1}_{k_1},\underbrace{\Hs_2,\cdots,\Hs_2}_{k_2}, \cdots~\}
	\end{equation*}
	Thus, for the non-degenerate $\A$,
	\begin{equation*}
		\Hs \cong \oplus_{d \in D} \Hs_d^{(k_d)}, \A \cong \{~\oplus_{d \in D} K_d^{(k_d)} \colon K_d \in \fml{B}_0(\Hs_d)~\}
	\end{equation*}
	If $\A$ is degenerate, let $\Hs_0 = (\clo{\A \Hs})^{\bot}$, then this theorem holds.
\end{proof}

For a non-degenerate $\A$, let $\hat{\A}$ denote the set of all equivalent classes of irreducible representations of $\A$. For any $\zeta \in \hat{\A}$, let $\rho_{\zeta} \in \zeta$. By the theorem, for any representation $\rho$ of $\A$, there are irreducible representations $\{\rho_i\}$ s.t. $\rho = \oplus_i \rho_i$, then we define the mutiplicity function of $\rho$,
\begin{equation*}
	m_{\rho}(\zeta) = \#\{i \colon \rho_i \in \zeta\}
\end{equation*}
Now, we can easily apply above theorem to the representation. 

\begin{thm}
	If $\rho$ is a representation of $\A$ and $m_{\rho}$ is the multiplicity function, then
	\begin{equation*}
		\rho \cong \oplus \{~\rho_{\zeta}^{(m_{\rho}(\zeta))} \colon \zeta \in \hat{\A}~\}
	\end{equation*}
	Moreover, any two representations of $\A$ are equivalent if and only if they have same multiplicity functions.
\end{thm}

\section{Trace Class and Ultraweak Topology}

There some interesting subalgebras in the compact operator algebras, and some of them can provide extra topologies on operator algebras, which will be helpful in the research of general von Neumann algebras.

\subsection{Trace Class and Hilbert-Schmit Operators}

\begin{defn}
	Let $T \in \oper$. If there is a a orthonormal basis $\fml{E}$ of $\Hs$ s.t.
	\begin{equation*}
		\sum_{e \in \fml{E}} \langle \abs{T}e,e \rangle < \infty
	\end{equation*}
	then $T$ is called trace class. Let $\toper$ denote the set of all trace classes operators.
\end{defn}

In this definition, the orthonormal basis just need to exist. But how can that condition garantees for any orthonormal basis of $\Hs$ the condition is always satisfied?

\begin{prop}
	If $\fml{E}$ and $\fml{F}$ are two orthonormal bases for $\Hs$, then for any $T \in \oper$,
	\begin{equation*}
		\sum_{e \in \fml{E}} \norm{Te}^2 = \sum_{f \in \fml{F}} \norm{\st{T}f}^2 = \sum_{e \in \fml{E}}\sum_{f \in \fml{F}} \abs{\langle Te,f \rangle}^2
	\end{equation*}
\end{prop}
\begin{proof}
	By the Parseval's Identity,
	\begin{equation*}
		\norm{Te}^2 = \sum_{f \in \fml{F}} \abs{\langle Te,f \rangle}^2
	\end{equation*}
	Then we get above identity.
\end{proof}

\begin{cor}
	The sum 
	\begin{equation*}
		\sum_{e \in \fml{E}} \langle \abs{T}e,e \rangle
	\end{equation*}
	is independent with the choise of the $\fml{E}$.
\end{cor}

Therefore, by this corollary, above definition is valid. Moreover, we can define one more norm on $\toper$, for $T \in \toper$ and some orthonormal basis $\fml{E}$,
\begin{equation*}
	\norm{T}_1 = \sum_{e \in \fml{E}} \langle \abs{T}e,e \rangle
\end{equation*}

Then by using this norm, called the trace norm, on $\toper$, the $\toper$ can be a Banach space.

\begin{defn}
	$T \in \oper$ is called a Hilbert-Schimdt operator if $\abs{T}^2$ is trace class. Let $\hoper$ denote the set of all Hilbert-Schimdt operators. 
\end{defn}

Also, we can define the norm on $\hoper$, for any orthonormal basis $\fml{E}$ in $\Hs$,
\begin{equation*}
	\norm{T}_2 = (\sum_{e \in \fml{E}} \langle \abs{T}^2e,e \rangle)^{\frac{1}{2}} = (\sum_{e \in \fml{E}} \norm{\abs{T}e}^2)^{\frac{1}{2}} = (\sum_{e \in \fml{E}} \norm{Te}^2)^{\frac{1}{2}} = \norm{\abs{T}^2}_1^{\frac{1}{2}}
\end{equation*}
And $\hoper$ can be also a Banach space.

In order to research the trace class, it is convinient to get some properties of the Hilbert-Schmidt operators.

\begin{prop}
	Let $T \in \hoper$.
	\begin{enumerate}[label=\arabic*)]
		\item $\norm{T}_2 = (\sum_{e \in \fml{E}} \norm{Te}^2)^{\frac{1}{2}}$.
		\item $\norm{\st{T}}_2 = \norm{T}_2$.
		\item $\norm{T} \leqslant \norm{T}_2$.
		\item If $A \in \oper$, then $AT,TA \in \hoper$ and 
		\begin{equation*}
			\norm{AT}_2, \norm{TA}_2 \leqslant \norm{A} \norm{T}_2
		\end{equation*}
		\item $\hoper$ is an ideal of $\oper$ and $\norm{\cdot}_2$ is a norm on $\hoper$.
	\end{enumerate}
\end{prop}
\begin{proof}
	The first three results are trivial. For $4)$, fix an orthonormal basis $\fml{E}$ and an $A \in \oper$, for a $e \in \fml{E}$,
	\begin{equation*}
		\norm{ATe}^2 \leqslant \norm{A}^2 \norm{Te}^2 = \norm{A}^2 \norm{\abs{T}e}^2
	\end{equation*}
	Therefore, $\norm{AT}_2 \leqslant \norm{A} \norm{T}_2$. \\
	For $5)$, we just need to prove the addition is continuous and closed. For a fixed normal basis $\fml{E}$ and $T,S \in \hoper$, then 
	\begin{equation*}
		\{\norm{Te} \colon e \in \fml{E}\}, \{\norm{Se} \colon e \in \fml{E}\} \in l^{2}(\fml{E})
	\end{equation*}
	By the triangle inequality for $l^{2}(\fml{E})$, 
	\begin{equation*}
		\norm{S+T}_2 = \left(\sum_{E}(\norm{Te}+\norm{Se})^2 \right)^{\frac{1}{2}} \leqslant \norm{T}_2 + \norm{S}_2 \qedhere
	\end{equation*}
\end{proof}
\begin{rem}
	Therefore, $\hoper$ with the fixed involution and the norm $\norm{\cdot}_2$ is a $\st{C}$-algebra.
\end{rem}

By using these results, we can see the Hilbert-Schmidt operator is compact.

\begin{cor}
	If $T \in \hoper$ and $\varepsilon > 0$, there is a $A \in \foper$ s.t.
	\begin{equation*}
		\norm{T-A}_2 \leqslant \varepsilon
	\end{equation*}
	Consequently, every Hilbert-Schmidt operator is compact.
\end{cor}
\begin{proof}
	For this fixed $\varepsilon > 0$, since $T \in \hoper$, there is a finite set $I \in \fml{E}$ s.t.
	\begin{equation*}
		\sum_{\fml{E} \backslash I} \norm{Te}^2 < \varepsilon^2
	\end{equation*}
	Let $\hat{E} = \spn{E}$ and $B = T|_{\hat{E}} \in \foper$, then
	\begin{equation*}
		\norm{T-B}_2 = (\sum_{\fml{E} \backslash I} \norm{Te}^2)^{\frac{1}{2}} < \varepsilon \qedhere
	\end{equation*}
\end{proof}

Then, there are similar consequences of the $\toper$.

\begin{prop}
	If $T \in \oper$, then the following statements are equivalent.
	\begin{enumerate}[label=\arabic*)]
		\item $T \in \toper$.
		\item $\abs{T}^{\frac{1}{2}} \in \hoper$.
		\item $T$ is the product of two Hilbert-Schmidt operators.
		\item $\abs{T}$ is the product of two Hilbert-Schmidt operators.
	\end{enumerate}
\end{prop}
\begin{proof}
	Since $\norm{\abs{T}^{\frac{1}{2}}}{e}^2$, $1)$ implies $2)$. And by the Polar Decomposition,
	\begin{equation*}
		T = W \abs{T} = (W \abs{T}^{\frac{1}{2}})\abs{T}^{\frac{1}{2}}
	\end{equation*}
	thus $2)$ implies $3)$. And $3)$ implies $3)$, because of the Polar Decomposition. \\
	Suppose $\abs{T} = BC$ for $B,C \in \hoper$, then for any orthonormal $\fml{E}$ and $e \in \fml{E}$
	\begin{equation*}
		\langle \abs{T}e, e \rangle = \langle Ce \st{B}e \rangle \leqslant \norm{Ce}\norm{\st{B}e}
	\end{equation*}
	Therefore, we have 
	\begin{eqnarray*}
		\sum_{\fml{E}} \langle \abs{T}e, e \rangle &\leqslant& \sum_{\fml{E}} \norm{Ce}\norm{\st{B}e} \\
		&\leqslant& (\sum_{\fml{E}} \norm{Ce}^2)^{\frac{1}{2}} (\sum_{\fml{E}} \norm{Be}^2)^{\frac{1}{2}} \\ 
		&=& \norm{C}_2 \norm{B}_2
	\end{eqnarray*}
	Thus, $T \in \toper$.
\end{proof}

\begin{defn}
	If $T \in \toper$ and $\fml{E}$ is any orthonormal basis, the trace of $T$ is defined as
	\begin{equation*}
		\tr{T} = \sum_{\fml{E}} \langle Te,e \rangle
	\end{equation*}
\end{defn}

It need to check that this definition is well-defined.

\begin{prop}
	If $T \in \toper$ and $\fml{E}$ is any orthonormal basis, then $\sum_{\fml{E}} \abs{\langle Te,e \rangle} < \infty$, and the sum $\sum_{\fml{E}} \langle Te,e \rangle$ is independent with the choice of $\fml{E}$.
\end{prop}
\begin{proof}
	By above proposition, $T = \st{C}B$ for $C,B \in \hoper$. Since\\ $\norm{(C-\lambda B)e}^2 \leqslant 0$ for any $\lambda \in \C$,
	\begin{equation*}
		2 \Rea{\clo{\lambda} \langle Be,Ce \rangle} \leqslant \norm{Be}^2+\abs{\lambda} \norm{Ce}^2
	\end{equation*}
	Choosing a $\lambda$ s.t. $\abs{\lambda} = 1$ and
	\begin{equation*}
		\clo{\lambda} \langle Be,Ce \rangle = \abs{\langle Be,Ce \rangle}
	\end{equation*}
	Then we have,
	\begin{equation*}
		\abs{\langle Te,e \rangle} = \abs{\langle Be,Ce \rangle} \leqslant \frac{1}{2}(\norm{Be}^2+\norm{Ce}^2)
	\end{equation*}
	Thus $\sum_{\fml{E}} \abs{\langle Te,e \rangle} \leqslant \frac{1}{2}(\norm{B}_2^2+\norm{C}_2^2)$. \\ 
	And since 
	\begin{eqnarray*}
		\Rea{\langle Te,e \rangle} &=& \frac{1}{4} (\norm{(B+C)e}^2 - \norm{(B+C)e}^2) \\
		\Img{\langle Te,e \rangle} &=& \frac{1}{4} (\norm{(iB+C)e}^2 - \norm{(iB+C)e}^2)
	\end{eqnarray*}
	then
	\begin{equation*}
		\sum_{\fml{E}} \langle Te,e \rangle = \Rea{\langle Te,e \rangle} + i\Img{\langle Te,e \rangle}
	\end{equation*}
	The sum is independent with the choice of the orthonormal basis $\fml{E}$.
\end{proof}

For convenience, there is another notation to denote the rank one operators.
\begin{defn}
	For two vectors $g,h \in \Hs$, the rank one operator $g \otimes h$ is defined as
	\begin{equation*}
		g \otimes h (f) = \langle f,h \rangle g
	\end{equation*}
\end{defn}

There are some elementary properties for this rank one operator.
\begin{prop} \label{prop18}
	Let $g,h \in \Hs$.
	\begin{enumerate}[label=\arabic*)]
		\item $e \otimes e$ is the projection onto $\C e$.
		\item $\ran{g \otimes h} = \C g$ and $\ker{g \otimes h} = (\C h)^{\bot}$ for $g \neq 0$.
		\item $(g \otimes h)^{*} = h \otimes g$.
		\item The map $(g,h) \sto g \otimes h$ is a sesquilinear from $\Hs \times \Hs$ to $\oper$.
		\item $\norm{g \otimes h} = \norm{g} \norm{h}$.
		\item If $T \in \oper$, then $T(g \otimes h) = (Tg) \otimes h$ and $(g \otimes h) T = g \otimes (\st{T}h)$.
		\item Every any finite rank operator can be expressed as
		\begin{equation*}
			\sum_{k=1}^{n} g_k \otimes h_k
		\end{equation*}
		for some $g_1, \cdots, g_n \in \Hs$ and $h_1, \cdots, h_n \in \Hs$.
		\item Every any finite rank operator can be expressed as
		\begin{equation*}
			\sum_{k=1}^{n} g_k \otimes h_k
		\end{equation*}
		for some $g_1, \cdots, g_n \in \Hs$ and $h_1, \cdots, h_n \in \Hs$.
		\item For $C = \sum_{k=1}^n g_k \otimes h_k$ and $A \in \oper$,
		\begin{equation*}
			\tr{AC} = \sum_{k=1}^n \langle Ag_k,h_k \rangle
		\end{equation*}
	\end{enumerate}
\end{prop}

There are more interesting properties of the trace class.

\begin{thm}
	\begin{enumerate}[label=\arabic*)]
		\item $\toper \subset \coper$ and conversely, if $A \in \coper$ and $\{\alpha_n\}$ are the eigenvalues of $\abs{A}$, then $A \in \toper$ if and only if $(\alpha_n) \in l^{1}$. In this case, $\norm{A}_1 = \sum \alpha_n$.
		\item $\toper$ is an ideal of $\oper$.
		\item $\tr{} \colon \toper \sto \C$ is a positive non-degenerate linear functional.
		\item $\foper$ is a dense subset in $\toper$ with respect to $\norm{\cdot}_1$.
		\item If $T \in \toper$, then for any $A \in \oper$,
		\begin{equation*}
			\tr{TA} = \tr{AT},~\text{and } \abs{\tr{AT}} \leqslant \norm{A}\norm{T}_1
		\end{equation*}
		\item $\norm{T}_1 = \norm{\st{T}}_1$ for any $T \in \toper$.
		\item If $T \in \toper$ and $A \in \oper$, then
		\begin{equation*}
			\norm{TA}_1,~ \norm{AT}_1 \leqslant \norm{A} \norm{T}_1
		\end{equation*}
	\end{enumerate}
\end{thm}
\begin{proof}
	If $A \in \coper$, also $\abs{A} \in \coper$, then there is an orthonormal basis $\{e_n\}$ for $\Hs$ and the correponding eigenvalues $\{\alpha_n\} \in l^{\infty}(\C)$ s.t.
	\begin{equation*}
		\abs{A} = \sum_{n} \alpha_n P_{e_n} = \sum_{n} \alpha_n e_n \otimes e_n
	\end{equation*}
	Then we have that
	\begin{equation*}
		\sum_n \langle \abs{A}e_n, e_n \rangle = \sum_n \alpha_n
	\end{equation*}
	By the Polar Decomposion, $A \in \toper$ is equivalent the $\abs{A} \in \toper$. Thus, $\{\alpha_n\} \in l^{1}(\C)$ is equivalent to $A \in \toper$, and $\norm{A}_1 = \sum \alpha_n$.
	\item For $2)$, similarly as the $\hoper$, we just need to prove that the addition is continuous and closed. Let $A \in \toper$ and $B \in \toper$, and by the Polar Decomposition,
	\begin{equation*}
		A = W\abs{A},~ B = V \abs{B},~ A+B = U\abs{A+B}
	\end{equation*}
	And $\abs{A+B} = \sum_{n} \gamma_n e_n \otimes e_n$ for an orthonormal basis $\{e_n\}$. By $1)$, we just need to check that $\{\gamma_n\} \in l^{1}(\C)$.
	\begin{eqnarray*}
		\sum_n \gamma_n &=& \sum_n \langle \abs{A+B}e_n,e_n \rangle = \sum_n \abs{\langle Ae_n, Ue_n \rangle + \langle Be_n, Ue_n \rangle} \\
		&=& \sum_n \abs{\langle \abs{A}e_n, \st{W}Ue_n \rangle + \langle \abs{B}e_n, \st{V}Ue_n \rangle} \\
		&=& \sum_n \abs{\langle \abs{A}^{\frac{1}{2}}e_n, \abs{A}^{\frac{1}{2}}\st{W}Ue_n \rangle + \langle \abs{B}^{\frac{1}{2}}e_n, \abs{B}^{\frac{1}{2}}\st{V}Ue_n \rangle} \\
		&\leqslant& \sum_n (\norm{\abs{A}^{\frac{1}{2}}e_n}\norm{\abs{A}^{\frac{1}{2}}\st{W}Ue_n}+\norm{\abs{B}^{\frac{1}{2}}e_n}\norm{\abs{B}^{\frac{1}{2}}\st{V}Ue_n}) \\
		&\leqslant& \left(\sum_n \norm{\abs{A}^{\frac{1}{2}}e_n}^2 \right)^{\frac{1}{2}}\left(\sum_n \norm{\abs{A}^{\frac{1}{2}}\st{W}Ue_n}^2 \right)^{\frac{1}{2}} \\
		&& \negmedspace{} + \left(\sum_n \norm{\abs{B}^{\frac{1}{2}}e_n}^2 \right)^{\frac{1}{2}}\left(\sum_n \norm{\abs{B}^{\frac{1}{2}}\st{V}Ue_n}^2 \right)^{\frac{1}{2}} \\
		&\leqslant& \norm{\abs{A}^{\frac{1}{2}}}_2^2 + \norm{\abs{B}^{\frac{1}{2}}}_2^2 \\
		&=& \norm{A}_1 + \norm{B}_1
	\end{eqnarray*}
	\item $3)$ is trivial and $4)$ can be obtained by similar argument as the $\hoper$.
	\item For $5)$, let $T \in \toper$ and $T = \st{C}B$ for some $B,C \in \hoper$, then by above mention,
	\begin{eqnarray*}
		\Rea{\tr{\st{C}B}} &=& \frac{1}{4} (\norm{(B+C)e}^2 - \norm{(B+C)e}^2) \\
		&=& \frac{1}{4} (\norm{(\st{B}+\st{C})e}^2 - \norm{(\st{B}+\st{C})e}^2) \\
		&=& \Rea{\tr{C\st{B}}}
	\end{eqnarray*}
	And similarly, $\Img{\tr{\st{C}B}} = - \Img{\tr{C\st{B}}}$, thus
	\begin{equation*}
		\tr{\st{C}B} = \clo{\tr{C\st{B}}}
	\end{equation*}
	Therefore, we have that for any $A \in \oper$ 
	\begin{equation*}
		\tr{AT} = \tr{(A\st{C})B} = \clo{\tr{C\st{A} \st{B}}} = \tr{(\st{C}B)A} = \tr{TA}
	\end{equation*}
	Let $T = W \abs{T}$ be the Polar Decomposition. Then by the CBS Inequality,
	\begin{eqnarray*}
		\abs{\tr{AT}} &\leqslant& \sum_{\fml{E}}  \norm{\abs{T}^{\frac{1}{2}}e}\norm{\abs{T}^{\frac{1}{2}}\st{W}\st{A}e} \\
		&\leqslant& \left(\sum \norm{\abs{T}^{\frac{1}{2}}e}^2 \right)^{\frac{1}{2}}\left(\sum \norm{\abs{T}^{\frac{1}{2}}\st{W}\st{A}e}^2 \right)^{\frac{1}{2}} \\
		&\leqslant& \norm{\abs{T}^{\frac{1}{2}}}_2\norm{\abs{T}^{\frac{1}{2}}\st{W}\st{A}}_2 \\
		&\leqslant& \norm{\abs{T}^{\frac{1}{2}}}_2^2 \norm{\st{W}\st{A}} \\
		&\leqslant& \norm{T}_1 \norm{A}
	\end{eqnarray*}	
	\item For $6)$, let $T = W \abs{T} \in \toper$, then $T\st{T} = W \abs{T}^2 \st{W}$. So by the uniqueness of root, $\abs{\st{T}} = W \abs{T} \st{W}$. Therefore,
	\begin{equation*}
		\norm{\st{T}}_1 = \tr{\abs{\st{T}}} = \tr{W \abs{T} \st{W}} = \tr{W \st{W} \abs{T}}
	\end{equation*} 
	Since $W \st{W} \abs{T} = \abs{T}$, $\norm{\st{T}}_1 = \norm{T}_1$.
	\item For $7)$, let $T = W \abs{T} \in \toper$ and $AT = V \abs{AT}$. So
	\begin{equation*}
		\abs{AT} = S \abs{T}, \text{ where } S = \st{V}A W
	\end{equation*}
	Thus $\norm{S} \leqslant \norm{A}$, then
	\begin{equation*}
		\norm{AT}_1 = \tr{\abs{AT}} = \tr{S \abs{T}} \leqslant \norm{S} \norm{T}_1 \leqslant \norm{A}\norm{T}_1 \qedhere
	\end{equation*}
\end{proof}
\begin{rem}
	By this theorem, $(\toper, \norm{\cdot}_1)$ is also a $\st{C}$-algebra.
\end{rem}

\begin{thm} \label{thm11}
	If $\{g_n\}$ and $\{h_n\}$ are two square summable sequences, then 
	\begin{equation*}
		T = \sum_{n} g_n \otimes h_n \in \toper, \text{ and } \norm{T}_1 \leqslant \sum_{n} \norm{g_n}\norm{h_n}
	\end{equation*}
	Conversely, if $T \in \toper$, then there are two square summable sequences $\{g_n\}$ and $\{h_n\}$ s.t.
	\begin{equation*}
		\sum_n \norm{g_n}^2 = \norm{T}_1 = \sum_n \norm{h_n}^2, \text{ and } T = \sum_{n} g_n \otimes h_n
	\end{equation*}
\end{thm}
\begin{proof}
	Let $\{e_n\}$ be an orthonormal sequence of $\Hs$ and $G_n = \sum_{k=1}^{n} g_n \otimes e_n$. If $n > m$, then
	\begin{equation*}
		\norm{G_n-G_m}_2^2 = \sum_{k=m+1}^{n} \norm{(G_n-G_m)e_k}^2 = \sum_{k=m+1}^{n} \abs{\langle e_k,g_K \rangle}^2 \leqslant \sum_{k=m+1}^{n} \norm{g_k}^2
	\end{equation*}
	Since $\{g_n\}$ is square summable, $\{G_n\}$ is Cauchy with respect to the norm $\norm{\cdot}_2$. Therefore, there is a $G \in \hoper$ s.t.
	\begin{equation*}
		G = \lim_n G_n = \sum_n g_n \otimes e_n
	\end{equation*}
	Similarly, there is a $H = \sum_n e_n \otimes h_n$ in $\hoper$. And then by the definition, $T = GH \in \toper$.
	\item Conversely, if $T \in \toper$ and $T = W\abs{T}$ is the Polar Decomposition, there exist an orthonormal basis $\{e_n\}$ for $\ker{\abs{T}}^{\bot} = \ker{T}^{\bot}$ and a sequence $\{\alpha_n\} \in l^{1}(\C)$, s.t. 
	\begin{equation*}
		\abs{T} = \sum_n \alpha_n e_n \otimes e_n
	\end{equation*}
	Then put $h_n = \sqrt{\alpha_n}e_n$ and $g_n = W h_n$. Since $W$ is a partial isometry, $\{g_n\}$ is an orthonormal set. And clearly, 
	\begin{equation*}
		\norm{g_n}^2 = \norm{h_n}^2 = \alpha_n \Rightarrow \sum_n \norm{g_n}^2 = \sum_n \norm{h_n}^2 = \sum_n \alpha_n = \norm{T}_1
	\end{equation*}
	and $T = \sum_n g_n \otimes h_n$.
\end{proof}
\begin{rem}
	In fact, if $g_n$ and $h_n$ are chosen like above mention,
	\begin{equation*}
		\norm{T}_1 = \sum_n \norm{g_n}\norm{h_n}
	\end{equation*}
\end{rem}

Also, the structure of $\hoper$ can be more explicit.

\begin{thm}
	\begin{enumerate}[label = \arabic*)]
		\item For $\hoper$, define the inner product $\langle \cdot,\cdot \rangle$ as
		\begin{equation*}
			\langle T,G \rangle = \tr{\st{G}T}
		\end{equation*}
		Then $\norm{\cdot}_2$ can be induced by this inner product, and moreover, $\hoper$ is a Hilbert space with respect to this inner product.
		\item If $A \in \coper$ and $\{\alpha_n\}$ are the eigenvalues of $\abs{A}$, then $A \in \hoper$ if and only if $(\alpha_n) \in l^{2}$. In this case, $\norm{A}_1 = \sum \alpha_n^2$.
		\item The Hilbert space $\hoper$ containing $\foper$ as a dense subspace with respect to the norm $\norm{\cdot}_2$.
	\end{enumerate}
\end{thm}

\subsection{Dual Spaces}

In above subsection, we have seen $\toper$ is indeed a $\st{C}$-algebra, thus a Banach algebra with respect to the norm $\norm{\cdot}_1$. Therefore, we can get the following important properties.

\begin{thm}
	For $A \in \toper$, define the functional
	\begin{center}
		\begin{tabular}{l c c l}
			$\Phi_A \colon$ & $\coper$ & $\longrightarrow$ & $\C$ \\
			~ & $C$ & $\longmapsto$ & $\tr{AC}$
		\end{tabular}
	\end{center}
	Then $\Phi_A \in \st{\coper}$. Therefore, there is a map
	\begin{center}
		\begin{tabular}{l c c l}
			$\rho \colon$ & $\toper$ & $\longrightarrow$ & $\st{\coper}$ \\
			~ & $A$ & $\longmapsto$ & $\Phi_A$
		\end{tabular}
	\end{center}
	Moreover, $\rho$ is an isomorphic isomorphism, i.e. $\toper \cong \st{\coper}$. 
\end{thm}
\begin{proof}
	Since $\coper \subset \toper$, by above proposition, $\Phi_A \in \st{\coper}$. Moreover, 
	\begin{equation*}
		\sup{\{~\abs{\tr{AC}} \colon \norm{C}_1 \leqslant 1~\}} \leqslant \norm{A}_1 \Rightarrow  \norm{\Phi_A} \leqslant \norm{A}_1
	\end{equation*}
	That means $\norm{\rho} \leqslant 1$.
	\item Check: $\rho$ is surjective.\\
	Let $\Phi \in \st{\coper}$ and define the sesquilinear map $f$ on $\Hs$,
	\begin{equation*}
		f(g,h) = \Phi(g \otimes h), \text{ and } \abs{f(g,h)} \leqslant \norm{\Phi}\norm{g}\norm{h}
	\end{equation*}
	Therefore, there exists $A \in \oper$ s.t.
	\begin{equation*}
		f(g,h) = \Phi(g \otimes h) = \langle Ag, h \rangle,~\forall g,h \in \Hs
	\end{equation*}
	For any $C \in \foper$, then there are finite number $\{g_k\}$ and $\{h_k\}$ for $k=1,\cdots,n$ s.t. $C = \sum_{k=1}^{n} g_k \otimes h_k$
	\begin{eqnarray*}
		\Phi(C) &=& \Phi(\sum_{k=1}^{n} g_k \otimes h_k) = \sum_{k=1}^{n} \langle A g_k , h_k \rangle \\
		&=& \tr{AC} = \Phi_A(C)
	\end{eqnarray*}
	Since $\foper$ is norm-dense in $\coper$ and $\Phi$ and $\Phi_A$ are bounded, $\Phi = \Phi_A$.
	\item Check: $\rho$ is isometric.\\
	Let $\fml{E}$ be an orthonormal basis and $A \in \toper$ with the Polar Decomposition $A = W\abs{A}$, then for any finite subset $E$ in $\fml{E}$
	\begin{eqnarray*}
		\norm{\Phi_A} &\geqslant& \abs{\Phi(\sum_{e \in E}(e \otimes e)\st{W})} = \abs{\Phi_A(\sum_{e \in E}e \otimes We)} \\
		&=& \sum_{e \in E} \abs{\langle Ae,We \rangle} \\
		&=& \sum_{e \in E} \langle \abs{A}e, e \rangle
	\end{eqnarray*}
	Then $\norm{\Phi_A} \geqslant \norm{A}_1$ as $\{E\}$ can be an increasing net in $\fml{E}$.
\end{proof}

\begin{thm}
	For $B \in \oper$, define the functional
	\begin{center}
		\begin{tabular}{l c c l}
			$\Psi_B \colon$ & $\toper$ & $\longrightarrow$ & $\C$ \\
			~ & $A$ & $\longmapsto$ & $\tr{AB}$
		\end{tabular}
	\end{center}
	Then $\Psi_B \in \st{\toper}$. Therefore, there is a map
	\begin{center}
		\begin{tabular}{l c c l}
			$\rho \colon$ & $\oper$ & $\longrightarrow$ & $\st{\toper}$ \\
			~ & $B$ & $\longmapsto$ & $\Psi_B$
		\end{tabular}
	\end{center}
	Moreover, $\rho$ is an isomorphic isomorphism, i.e. $\oper \cong \st{\toper}$. 
\end{thm}
\begin{proof}
	Clearly, $\Psi_B \in \st{\toper}$ with $\norm{\Psi_B} \leqslant \norm{B}$.
	\item Check: $\rho$ is isometric. \\
	For a given $\varepsilon > 0$, there exists a unit $g$ s.t. 
	\begin{equation*}
		\norm{Bg} > \norm{B}-\varepsilon
	\end{equation*}
	And choosing a $h \in \Hs$, s.t. $\norm{Bg} = \langle Bg,h \rangle$. Let $C = g \otimes h$, then $C \in \toper$ and $\norm{C}_1 = 1$.  Thus,
	\begin{equation*}
		\norm{\Psi_B} \geqslant \abs{\tr{BC}} = \langle Bg,h \rangle = \norm{Bg} > \norm{B}-\varepsilon
	\end{equation*}
	Therefore, $\norm{\Psi_B} = \norm{B}$.
	\item Check: $\rho$ is surjective.\\
	Let $\Psi \in \st{\toper}$. Similarly as above theorem, there is a $B \in \oper$ s.t. $\langle Bg,h \rangle = \Psi(g \otimes h)$ for all $g,h \in \Hs$. And also, $\Psi = \Psi_B$ on the $\foper$. By the extension, $\Psi = \Psi_B$.
\end{proof}

\begin{thm}
	$\st{(\oper, WOT)} = \st{(\oper, SOT)} = \foper$.
\end{thm}
\begin{proof}
	By the \textbf{Proposition} \ref{prop13} in the subsection \textbf{3.3.3},  $L \in \st{(\oper, WOT)}$ can be expressed as
	\begin{equation*}
		L(T) = \sum_{k=1}^n \langle Tg_k, h_k \rangle = \tr{CT} = \Psi_C(T), \text{ where } C = \sum_{k=1}^n g_k \otimes h_k
	\end{equation*}
	Thus, $\st{(\oper, WOT)} = \st{(\oper, SOT)} = \foper$.
\end{proof}

\subsection{Ultraweak Topology}

By above subsection, we know that
\begin{equation*}
	\oper \cong \st{(\toper, \norm{\cdot}_1)}
\end{equation*}
Thus, $\oper$ can be equiped with the $weak^{*}$ topology with respect to the $\st{(\toper, \norm{\cdot}_1)}$. The subbasis of a point $A \in \oper$ is like,
\begin{equation*}
	V_{\varepsilon}(A) = \{~B \in \oper \colon \abs{\tr{T(A-B)}} < \varepsilon, \forall T \in \toper~\}
\end{equation*}
for any $\varepsilon > 0$. This topology on $\oper$ is called the ultraweak topology or $\sigma-weak$ topology. Therefore, for a net $\{A_{\alpha}\}$ in $\oper$, $A_{\alpha} \sto A$ if and only of for any $T \in \toper$
\begin{equation*}
	\tr{TA_{\alpha}} \sto \tr{TA}
\end{equation*}
Moreover, by the \textbf{Theorem} \ref{thm11} in above subsection, for any $T \in \toper$, there exist two sequences $\{g_n\}$ and $\{h_n\}$ s.t. $T = \sum_n g_n \otimes h_n$ and then
\begin{equation*}
	\tr{TA} = \sum_n \langle A g_n, h_n \rangle
\end{equation*}
Then, for a net $\{A_{\alpha}\}$ in $\oper$, $A_{\alpha} \sto A$ if and only of for any two summable sequences $\{g_n\}$ and $\{h_n\}$ in $\Hs$, 
\begin{equation*}
	\sum_n \langle A_{\alpha} g_n, h_n \rangle \sto \sum_n \langle A g_n, h_n \rangle
\end{equation*}

Then there are some trivial properties of this topology.

\begin{prop}
	\begin{enumerate}[label = \arabic*)]
		\item If $\Hs$ is separable, then the closed unit ball in $\oper$ with the ultraweak topology is a compact metric space.
		\item The ultraweak topology and the $WOT$ agree on bounded subsets of $\oper$.
		\item A sequence in $\oper$ converges $weak^{*}$ if and only if it converges $WOT$.
	\end{enumerate}
\end{prop}
\begin{proof}
	$1)$ is clearly by the form of subbasis of the ultraweak topology. 
	\item For $2)$, by above mention, the ultraweak topology is bigger than the $WOT$, that means the identity map
	\begin{equation*}
		i \colon (\oper, weak^{*}) \longrightarrow (\oper, WOT)
	\end{equation*}
	is continuous. When it restricts to any bounded subset $\mathcal{S}$, since $\mathcal{S}$ is $weak^{*}$-compact by $1)$, $i$ is a homeomorphism.
	\item By the Principle of Uniform Boundedness, $WOT$-convergent sequence is bounded, thus by $2)$, it is $weak^{*}$-convergent. And the converse is trivial.
\end{proof}

Now, we want to find more relations between the ultraweak topology and the $WOT$. Firstly, the inflation can provide us some information about that.

\begin{prop}
	If $1 \leqslant d \leqslant \infty$ and $C \in \fml{B}_1(\fml{H}^{(d)})$ with the matrix representation $C = [C_{jk}]$, then
	\begin{enumerate}[label = \arabic*)]
		\item $K = \sum_k C_{kk}$ converges $weak^{*}$ in $\toper$ and
		\begin{equation*}
			\norm{\sum_k C_{kk}} \leqslant \norm{C}_1
		\end{equation*}
		\item if $T \in \oper$ and $K$ is as $1)$, then
		\begin{equation*}
			\tr{T^{(d)}C} = \tr{TK} = \sum_{k=1}^{d} \tr{TC_{kk}}
		\end{equation*}
		and this converges absolutely for $d = \infty$.
	\end{enumerate}
\end{prop}
\begin{proof}
	We just need to prove this proposition in the infinite case.
	\item For $1)$, let $P_k$ be the projection from $\Hs^{(\infty)}$ onto the $k$-th coordinate space. Then $C_{kk} = P_k C P_k$. And clearly, for $1 \leqslant n < m < \infty$, $\sum_{k=n}^{m}C_{kk} \in \toper$, if $L \in \fml{B}_0(\fml{H}^{(\infty)})$,
	\begin{eqnarray*}
		\abs{\tr{(L \sum_{k=n}^{m}C_{kk})}} &=& \abs{\sum_{k=n}^{m} \tr{(LP_kCP_k)}} = \abs{\sum_{k=n}^{m} \tr{(CP_kLP_k)}} \\
		&=& \abs{\tr{(C \sum_{k=n}^{m} P_kLP_k)}} \\
		&\leqslant& \norm{C}_1 \norm{\sum_{k=n}^{m} P_kLP_k} \\
		&=& \norm{C}_1 \sup{\{\norm{P_kLP_k} \colon n \leqslant k \leqslant m\}} \\
		&\leqslant& \norm{C}_1 \norm{L}
	\end{eqnarray*}
	Then by the \textbf{Proposition} \ref{prop14} in the subsection \textbf{3.2.1}, (Confused!)
	\begin{equation*}
		\norm{\sum_{k=n}^{m}C_{kk}}_1 = \sup{\left\{~\abs{\tr{(L\sum_{k=n}^{m}C_{kk})}} \colon \norm{L} \leqslant 1,~ \ \in \fml{B}_0(\fml{H}^{(\infty)}~\right\}}
	\end{equation*}
	And since $L \in \fml{B}_0(\fml{H}^{(\infty)}$, $\norm{P_kLP_k} \sto 0$. Therefore, $1)$ holds.
	\item For $2)$, let $\{e_i \colon i \in I\}$ be a orthonormal basis of $\Hs$ and $\{e_{ki} \colon 1 \leqslant k \leqslant \infty, i \in I\}$ be a orthonormal basis of $\Hs^{(\infty)}$, then for any $T \in \fml{B}(\fml{H})$, $TC \in \fml{B}_1(\fml{H}^{(\infty)})$ and
	\begin{equation*}
		\tr{(T^{(\infty)}C)} = \sum_{i \in I} \sum_{k=1}^{\infty} \langle T^{(\infty)}C e_{ki},e_{ki} \rangle
	\end{equation*}
	Fixing $k$, we have that
	\begin{equation*}
		\langle T^{(\infty)}Ce_{ki},e_{ki} \rangle = \langle TC_{kk}e_{i},e_{i} \rangle = \tr{((e_i \otimes e_i)TC_{kk})}
	\end{equation*}
	By the $weak^{*}$-convergence of $K = \sum_{k} C_{kk}$, 
	\begin{eqnarray*}
		\langle TKe_i,e_i \rangle &=& \sum_{k=1}^{\infty} \tr{((e_i \otimes e_i)TC_{kk})} \\
		&=& \sum_{k=1}^{\infty} \langle TC_{kk}e_{ki},e_{ki} \rangle \\
		&=& \sum_{k=1}^{\infty} \langle T^{(\infty)}Ce_{ki},e_{ki} \rangle
	\end{eqnarray*}
	Since above series is absolutely convergent, 
	\begin{equation*}
		\tr{(T^{(\infty)}C)} = \sum_{k=1}^{\infty} \sum_{i \in I} \langle TC_{kk}e_{ki},e_{ki} \rangle = \sum_{k=1}^{\infty} \tr{(TC_{kk})} = \tr{TK}
	\end{equation*}
\end{proof}

\begin{thm} \label{thm15}
	\begin{enumerate}[label = \arabic*)]
		\item If $C \in \toper$ with rank at most $d$, where $1 \leqslant d \leqslant \infty$, then there are $g,h \in \Hs^{(d)}$ s.t. $\norm{g}^2 = \norm{h}^2 \leqslant \norm{C}_1$ and 
		\begin{equation*}
			\langle T^{(d)}g,h \rangle = \tr{TC},~ \forall T \in \oper
		\end{equation*}
		\item If $1 \leqslant d \leqslant \infty$ and $g,h \in \Hs^{(d)}$, then there is a $C \in \toper$ with rank at most $d$ s.t.
		\begin{equation*}
			\langle T^{(d)}g,h \rangle = \tr{TC},~ \forall T \in \oper
		\end{equation*}
		\item If $C \in \fml{B}_1(\fml{H}^{(\infty)}$, then there are $g,h \in \Hs^{(\infty)}$ s.t. $\norm{g}^2 = \norm{h}^2 \leqslant \norm{C}_1$ and
		\begin{equation*}
			\langle T^{(\infty)}g,h \rangle = \tr{T^{(\infty)}C},~ \forall T \in \oper
		\end{equation*}
		\item If $g,h \in \Hs^{(\infty)}$, then there is a $C \in \fml{B}_1(\fml{H}^{(\infty)})$ s.t. $\norm{g}^2 = \norm{h}^2 \leqslant \norm{C}_1$ and
		\begin{equation*}
			\langle T^{(\infty)}g,h \rangle = \tr{T^{(\infty)}C},~ \forall T \in \oper
		\end{equation*}
	\end{enumerate}
\end{thm}
\begin{proof}
	Just need to prove the case when $d = \infty$.
	\item For $1)$, let $C = \sum_k g_k \otimes h_k$ with $\norm{g_k}^2 = \norm{h_k}^2 = \norm{C}_1$. Then $g = (g_k)$ and $h = (h_k)$ are in $\Hs^{(\infty)}$, and it is clear that 
	\begin{equation*}
		\langle T^{(\infty)}g,h \rangle = \tr{TC},~ \forall T \in \oper
	\end{equation*}
	And the converse is similar.
	\item If $C = (C_{jk}) \in \fml{B}_1(\fml{H}^{(\infty)})$, then by above proposition, $K = \sum_k C_{kk} \in \toper$ and $\norm{K}_1 \leqslant \norm{C}_1$. Moreover, $\tr{(T^{(\infty)}C)} = \tr{(TK)}$. Then by $1)$, there are $g = (g_k)$ and $h = (h_k)$ in $\Hs^{(\infty)}$ with $\norm{g_k}^2 = \norm{h_k}^2 = \norm{K}_1 \leqslant \norm{C}_1$ s.t.
	\begin{equation*}
		\tr{(T^{(\infty)}C)} = \tr{(TK)} = \langle T^{(\infty)}g,h \rangle.
	\end{equation*}
	And $4)$ is also trivial.
\end{proof}
\begin{rem}
	In fact, it is the generalization of the result combining the \textbf{Proposition} \ref{prop18} and the \textbf{Theorem} \ref{thm11} in the subsection \textbf{5.3.1}.
\end{rem}

Then, we can see one more relation between the ultraweak topology and the $WOT$.

\begin{thm}
	If $\{T_i\}$ is a net in $\oper$, then the following statements are equivalent.
	\begin{enumerate}[label = \arabic*)]
		\item $T_i \sto 0$ in $weak^{*}$.
		\item $T_i^{\infty} \sto 0$ in $weak^{*}$.
		\item $T_i^{\infty} \sto 0$ in $WOT$.
	\end{enumerate}
\end{thm}
\begin{proof}
	If $C \in \fml{B}_1(\fml{H}^{(\infty)})$ and $K = \sum_k C_{kk}$, then by above theorem,
	\begin{equation*}
		\tr{T_i^{(\infty)}C} = \tr{(T_iK)}
	\end{equation*}
 	Therefore, $1)$ implies $2)$. Since the the ultraweak topology and the $WOT$ agree on any bounded subset, $2)$ implies $3)$. Let $K \in \toper$, then there are $h,g \in \Hs^{\infty}$ s.t. $\tr{(KT_i)} = \langle T_i^{\infty}f,g \rangle$. Thus, $3)$ implies $1)$.
\end{proof}

\begin{cor}
	\begin{enumerate}[label=\arabic*)]
		\item If $\mathcal{S} \subset \oper$ is a subset and $\mathcal{S}_1 = \clo{\mathcal{S}}^{wk^{*}}$, then 
		\begin{equation*}
			\clo{\{S^{(\infty)} \colon S \in \mathcal{S}\}}^{WOT} = \clo{\{S^{(\infty)} \colon S \in \mathcal{S}\}}^{wk^{*}} = \mathcal{S}_1^{(\infty)}
		\end{equation*}
		Therefore, $\mathcal{S}$ is $weak^{*}$-closed if and only if $\mathcal{S}^{(\infty)}$ is $WOT$-closed.
		\item If $\A$ is a $\st{C}$-subalgebra of $\oper$, then
		\begin{equation*}
			\clo{\A}^{wk^{*}} = \A^{''}
		\end{equation*}
		That means any von Neumann algebra is $weak^{*}$-closed.
	\end{enumerate}
\end{cor}
\begin{proof}
	$1)$ is a direct result from above theorem.
	\item For $2)$, let $\A_1 = \clo{\A}^{wk^{*}}$. Then by $1)$ and the Double Commutant Theorem,
	\begin{equation*}
		\A_1^{(\infty)} = \{\A^{(\infty)}\}^{''} = \{\A^{''}\}^{(\infty)}
	\end{equation*}
	Thus, $\A_1 = \A^{''} $.
\end{proof}
\begin{rem}
	Conversely, an algebra $\A$ is $weak^{*}$-closed, it is trivially $WOT$-closed. Therefore, we have another powerful topology to research von Neumann algebras and it is very important.
\end{rem}

\section{Fredholm Theory}

Let $\pi \colon \oper \sto \oper / \coper$ be the quotient map. Then 
\begin{equation*}
	\pi(A) = A + \coper
\end{equation*}
And the $\st{C}$-algebra $\oper / \coper$ is called the Calkin algebra. Therefore, in order to research the compact perturbations, the Calkin algebra plays an important role. 

\subsection{Fredholm Operators}

\begin{defn}
	Let $A \in \oper$ and $\pi \colon \oper \sto \oper / \coper$ be the quotient map. If $\pi(A)$ is left-invertible (or right) in the Calkin algebra, then $A$ is called a left (or right) semi-Fredholm operator. If $\pi(A)$ is invertible in the Calkin algebra, then $A$ is called a Fredholm operator.
\end{defn}

There are some equivalent conditions of the Fredholm operators.
\begin{thm}
	If $A \in \oper$, then the following statements are equivalent.
	\begin{enumerate}[label = \arabic*)]
		\item $A$ is left semi-Fredholm.
		\item $\ran{A}$ is closed and $\dim{\ker{A}} < \infty$.
		\item There is a $B \in \oper$ and a finite rank $F \in \oper$ s.t.
		\begin{equation*}
			BA = 1 + F
		\end{equation*}
	\end{enumerate}
\end{thm}
\begin{proof}
	$1) \Rightarrow 2)$: There is a $B$ s.t. $\pi(B)\pi(A) = 1$, i.e $\pi(BA-1) = 0$. That means there is a $K \in \coper$ s.t. $BA = 1 + K$. Then, by the \textbf{Theorem} \ref{thm12} in the subsection \textbf{5.1.2},
	\begin{equation*}
		\ker{A} \subset \ker{BA} = \ker{(1+K)} < \infty
	\end{equation*}
	And $\ran{BA} = \ran{(1+K)}$ is closed. By the \textbf{Lemma} \ref{lem1} in the subsection \textbf{2.4.4}, there is a constant $C > 0$ s.t. for any $h \in (\ker{BA})^{\bot}$, 
	\begin{equation*}
		C\norm{h} \leqslant \norm{BAh} \leqslant \norm{B}\norm{Ah} \Rightarrow \norm{Ah} > C^{'}\norm{h}
	\end{equation*}
	Therefore, $A((\ker{BA})^{\bot})$ is closed. Because
	\begin{equation*}
		\ran{A} = A((\ker{BA})^{\bot}) + A(\ker{BA})
	\end{equation*}
	and $\ker{BA} < \infty$, then $\ran{A}$ is closed.
	\item $2) \Rightarrow 3)$: Define $A_1 \colon (\ker{A})^{\bot} \sto \ran{A}$, then $A_1$ is invertible by the Inverse Mapping Theorem. Let $F$ be the projection onto $\ker{A}$ and $P$ be the projection onto $\ran{A}$, then
	\begin{equation*}
		BA = 1 - F, \text{ where } B = A_1^{-1}P
	\end{equation*}
	$3)$ implies $1)$ trivially.
\end{proof}

Above theorem provides the information of the range and the kernel of Fredholm operators. Besides that, we can also find the equivalent conditions of Fredholm operators from another point of view.
\begin{thm}
	If $A \in \oper$, then the following statements are equivalent. 
	\begin{enumerate}[label=\arabic*)]
		\item $A$ is left semi-Fredholm.
		\item There is no unit sequence $\{h_n\}$ s.t. $h_n \sto 0$ weakly and $Ah_n \sto 0$ in norm.
		\item There is no orthonormal sequence $\{e_n\}$ s.t. $Ae_n \sto 0$ in norm.
		\item There is a $\delta > 0$ s.t. $\{h \in \Hs \colon \norm{Ah} \leqslant \delta \norm{h}\}$ contains no infinite dimensional manifold.
		\item Let $\abs{A} = \int t dE(t)$, then there is a $\delta > 0$ s.t. $E([0,\delta])\Hs$ is finite dimensional.
	\end{enumerate}
\end{thm}
\begin{proof}
	$1) \Rightarrow 2)$: Let $B \in \oper$ and $T \in \coper$ s.t. $BA = 1+K$. For a unit sequence $\{h_n\}$ with $h_n \sto 0$ weakly, since $K$ is completely continuous,
	\begin{equation*}
		\abs{1 - \norm{BAh_n}} = \abs{\norm{h_n} - \norm{BAh_n}} \leqslant \norm{Kh_n} \sto 0
	\end{equation*}
	Therefore, $\norm{BAh_n} \sto 1$, i.e. $Ah_n$ cannot converge to $0$ in norm.
	\item $2) \Rightarrow 3)$: Orthonormal sequences alway converge weakly $0$.
	\item $3) \Rightarrow 4)$: Assume it is not true. For any $n$, there is a manifold $\fml{M}_n$ s.t. 
	\begin{equation*}
		\norm{Ah} \leqslant \frac{1}{n} \norm{h},~\forall~ h \in \fml{M}_n
	\end{equation*}
	Let $e_k \in \fml{M}_k$ for $1 \leqslant k \leqslant n$ and $\{e_k\}_{k=1}^n$ be orthonormal and $E$ be the projection onto $\spn{\{e_k\}_{k=1}^n}$. Since $\fml{M}_{n+1}$ is infinite dimensional,  $\fml{M}_{n+1} \cap E^{\bot} \neq \{0\}$. Thus, there is a unit $e_{n+1} \in \M_{n+1}$ s.t. $e_{n+1} \bot E$. But $Ae_n \sto 0$ in norm contradicted to $3)$.
	\item $4) \Rightarrow 5)$: If $\delta > 0$ and $h \in E([0,\delta])\Hs$, then
	\begin{eqnarray*}
		\norm{Ah}^2 &=& \langle \st{A}A h,h \rangle = \langle \abs{A}^2 h,h \rangle \\
		&=& \int_0^{\delta} t^2 dE_{hh}(t) \\
		&\leqslant& \delta^2 E_{hh}([0,\delta]) = \delta^2 \norm{h}^2
	\end{eqnarray*}
	That means
	\begin{equation*}
		E([0,\delta])\Hs \subset \{h \in \Hs \colon \norm{Ah} \leqslant \delta \norm{h}\}
	\end{equation*}
	\item $5) \Rightarrow 1)$: Let $\M = (E([0,\delta])\Hs)^{\bot}$. Then $\abs{A}$ maps $\M$ onto $\M$ bijectively. Put
	\begin{equation*}
		B_1 = \int_{\delta}^{\infty} t^{-1} dE(t)
	\end{equation*}
	then $B_1 \abs{A} = 1|_{\M}$. Let $A = U \abs{A}$. Since $\M \subset \ran{\abs{A}}$, $U$ maps $\M$ isometrically to $U(\M)$. Then there is a $V$ s.t. $VU = 1|_{\M}$ and $V|_{U(\M)^{\bot}} = 0$. Put $B = B_1V$, then for any $h \in \M$,
	\begin{equation*}
		BAh = B_1 V U \abs{A} h = h
	\end{equation*}
	If $h \in \M^{\bot}$, we know that $BAh = 0$. Thus,
	\begin{equation*}
		BA = E((\delta,\infty)) = 1 - E([0,\delta])
	\end{equation*}
	Thus, by above theorem, $A$ is left semi-Fredholm.
\end{proof}

\begin{thm}
	$A \in \oper$ is left semi-Fredholm operator if and only if for any $K \in \coper$,
	\begin{equation*}
		\dim{\ker{(A+K)}} < \infty
	\end{equation*}
\end{thm}
\begin{proof}
	If there is $B \in \oper$ and $L \in \coper$ s.t. $BA = 1+L$. If $K \in \coper$, 
	\begin{equation*}
		B(A+K) = 1 + (L + BK)
	\end{equation*}
	Thus $A+K$ is left semi-Fredholm, then $\dim{\ker{(A+K)}} < \infty$.\\
	Conversely, if there is a orthonormal sequence $\{e_n\}$ s.t. $Ae_n \sto 0$ in norm. By passing a subsequence, it may assume that $\sum \norm{Ae_n}^2 < \infty$. Thus for any $h \in \Hs$, 
	\begin{eqnarray*}
		\sum \abs{\langle h,e_n \rangle}\norm{Ae_n} &\leqslant& \left(\sum \abs{\langle h,e_n \rangle}^2\right)^{\frac{1}{2}}\left(\sum \norm{Ae_n}^2\right)^{\frac{1}{2}} \\
		&\leqslant& C\norm{h}
	\end{eqnarray*}
	Thus $Kh = \sum \langle h,e_n \rangle Ae_n$ is a bounded operator and clealy it can be approximated by finite rank operators $K_nh=\sum_{k=1}^n \langle h,e_k \rangle Ae_k$, thus $K \in \coper$. But $(A-K)e_n = 0$ for all $n$, that means $\dim{\ker{(A-K)}} = \infty$.
\end{proof}

\begin{cor}
	$A \in \oper$ is Fredholm if and only if $\ran{A}$ is closed and both $\ker{A}$ and $\ker{\st{A}}$ are finite dimensional.
\end{cor}

\subsection{Fredholm Index}

\begin{defn}
	If $A$ is a semi-Fredholm operator, then the Fredholm index of $A$ is defined as
	\begin{equation*}
		\ind{A} = \dim{\ker{A}} - \dim{\ker{\st{A}}}
	\end{equation*}
\end{defn}
\begin{rem}
	In fact, $\ind{A} \in \Z \cup \{\pm \infty\}$. If $A$ is Fredholm, $\ind{A} \in \Z$. And clearly, $\ind{(\lambda+K)} = 0$ for all nonzero $\lambda \in C$ and $K \in \coper$.
\end{rem}

\begin{prop}
	\begin{enumerate}[label=\arabic*)]
		\item If $A$ is a semi-Fredholm, then so is $\st{A}$ and
		\begin{equation*}
			\ind{\st{A}} = - \ind{A}
		\end{equation*}
		\item If $N$ is normal, then $N$ is semi-Fredholm if and only if $N$ is Fredholm, in which case $\ind{N} = 0$.
		\item If $A$ and $B$ are Fredholm, then $A \oplus B$ is Fredholm and 
		\begin{equation*}
			\ind{A \oplus B} = \ind{A} + \ind{B}
		\end{equation*}
	\end{enumerate}
\end{prop}
\begin{proof}
	$1)$ and $3)$ is trivial and $2)$ is since $\norm{N} = \norm{\st{N}}$.
\end{proof}

In fact, for $A \in \operr{H}{H^{'}}$, we can similarly defined the Fredholm operator and the Fredholm index, and all of above mention are valid.

\begin{prop}
	If $\Hs$ and $\fml{H^{'}}$ are finite dimensional Hilbert spaces and $A \in \operr{H}{H^{'}}$, then $A$ is Fredholm and $\ind{A} = \dim{\Hs} - \dim{\Hs^{'}}$.
\end{prop}
\begin{proof}
	The fact that $A$ is Fredholm is trivial by the definition.
	\begin{eqnarray*}
		\ind{A} &=& \dim{\ker{A}} - \dim{(\ran{A})^{\bot}} \\
		&=& \dim{\Hs} - \dim{\ran{A}} - (\dim{\Hs^{'}} - \dim{\ran{A}}) \\
		&=& \dim{H} - \dim{H^{'}} 
	\end{eqnarray*}
\end{proof}

\begin{lem}
	Let $A \in \operr{H}{H^{'}}$ and $\Hs = \M \oplus \fml{N}$ and $\Hs^{'} = \M^{'} \oplus \fml{N}^{'}$. Suppose $A$ has the form
	\begin{equation*}
		A = \left(
			\begin{array}{cc}
				A_1 & X \\
				0 & A_2
			\end{array}
		\right)
	\end{equation*}
	If $\dim{\fml{N}} < \infty$ and $\dim{\fml{N}^{'}} < \infty$ and $A_1$ is invertible, then $A$ is Fredholm and $\ind{A} = \dim{\fml{N}}-\dim{\fml{N}^{'}}$.
\end{lem}
\begin{proof}
	Just need to show $\ker{\st{A}} = \ker{\st{A_2}}$ and $\dim{\ker{A}} = \dim{\ker{A_2}}$, then since $A_2 \in \fml{B}(\fml{N})=\fml{B}_0(\fml{N})$, 
	\begin{equation*}
		\ind{A} = \dim{\ker{A}} - \dim{\ker{\st{A}}} = \ind{A_2} = \dim{\fml{N}}-\dim{\fml{N}^{'}}
	\end{equation*}
	But $\ker{\st{A}} = \ker{\st{A_2}}$ and $\dim{\ker{A}} = \dim{\ker{A_2}}$ are clearly because $A_1$ is invertible.
\end{proof}

\begin{thm}
	If $A,B \in \oper$ are Fredholm operator, then $BA$ is also a Fredholm operator and
	\begin{equation*}
		\ind{BA} = \ind{A} + \ind{B}
	\end{equation*}
\end{thm}
\begin{proof}
	There are $X,Y \in \oper$ s.t. $XA = 1+K$ and $YB=1+K^{'}$ for some $K,K^{'} \in \coper$. Then 
	\begin{equation*}
		(XY)(BA) = X(1+K^{'})A = 1 + (K+XK^{'}A)
	\end{equation*}
	Therefore, $BA$ is left semi-Fredholm. Similarly, $BA$ is right semi-Fredholm.\\
	Then for the index, let
	\begin{eqnarray*}
		\M^{'} = \ran{A} \cap (\ker{B})^{\bot} &,& \fml{N}^{'} = \M^{' \bot} \\
		\M = A^{-1}(\M^{'}) \cap (\ker{A})^{\bot} &,& \fml{N} = \M^{\bot} \\
		\M^{''} = B(\M^{'}) &,& \fml{N^{''}} = \M^{'' \bot}
	\end{eqnarray*}
	Therefore,
	\begin{equation*}
		\Hs = \M \oplus \fml{N} = \M^{'} \oplus \fml{N^{'}} = \M^{''} \oplus \fml{N^{''}}
	\end{equation*}
	And since $A(\M) = \M^{'}$, we can see
	\begin{eqnarray*}
		A = \left(
			\begin{array}{cc}
				A_1 & X \\
				0 & A_2
			\end{array}
		\right)
		&\colon& \M \oplus \fml{N} \longrightarrow \M^{'} \oplus \fml{N^{'}} \\
		B = \left(
			\begin{array}{cc}
				B_1 & Y \\
				0 & B_2
			\end{array}
		\right)
		&\colon& \M^{'} \oplus \fml{N^{'}} \longrightarrow \M^{''} \oplus \fml{N^{''}} \\
		BA = \left(
			\begin{array}{cc}
				B_1A_1 & Z \\
				0 & B_2A_2
			\end{array}
		\right)
		&\colon& \M \oplus \fml{N} \longrightarrow \M^{''} \oplus \fml{N^{''}}
	\end{eqnarray*}
	It can see that $\fml{N}$, $\fml{N^{'}}$ and $\fml{N^{''}}$ are finite dimensional. Moreover, $A_1$, $B_1$ and $B_1A_1$ are invertible. Then using above lemma,
	\begin{eqnarray*}
		\ind{BA} &=& \dim{\fml{N}} - \dim{\fml{N^{''}}} \\
		&=& \dim{\fml{N}} - \dim{\fml{N^{'}}} + \dim{\fml{N^{'}}} - \dim{\fml{N^{''}}} \\
		&=& \ind{B} + \ind{A}
	\end{eqnarray*}
\end{proof}
\begin{rem}
	In fact, above theorem can also be valid if $A$ and $B$ are semi-Fredholm.
\end{rem}

\begin{thm}
	If $A \in \oper$ is a Fredholm operator, then for any $K \in \oper$, $A+K$ is Fredholm and $\ind{(A+K)} = \ind{A}$.
\end{thm}
\begin{proof}
	$A+K$ is Fredholm is trivial. Let $X$ be Fredholm and $L \in \coper$, s.t. $XA = 1+L$, then
	\begin{equation*}
		0 = \ind{(1+L)} = \ind{XA} = \ind{X} + \ind{A}
	\end{equation*}
	And since $X(A+K) = 1+(L+XK)$, 
	\begin{equation*}
		\ind{X(A+K)} = \ind{(A+K)} + \ind{X} = 0
	\end{equation*}
	Therefore, $\ind{(A+K)} = \ind{A}$.
\end{proof}

Now, we can see that the index of a Fredholm is invariant under a small perturbation.

\begin{thm}
	If $A \in \oper$ is a Fredholm operator, then there is an $\varepsilon>0$ s.t. for any $Y \in \oper$ with $\norm{Y} < \varepsilon$, then $A+Y$ is Fredholm and $\ind{A+Y} = \ind{A}$.
\end{thm}
\begin{proof}
	Let $\Hs = \ker{A}^{\bot} \oplus \ker{A} = \ran{A} \oplus \ker{\st{A}}$. Then,
	\begin{equation*}
		A = \left(
			\begin{array}{cc}
				A_1 & 0 \\
				0 & 0
			\end{array}
		\right)
	\end{equation*}
	And $A_1$ is invertible since $\ran{A}$ is closed. By the perturbation of inverse, there is a $\varepsilon > 0$ s.t. if $\norm{Y_1} < \varepsilon$, $A_1+Y_1$ is invertible. If $Y \in \oper$ with $\norm{Y} < \varepsilon$, and 
	\begin{equation*}
		Y = \left(
				\begin{array}{cc}
				Y_1 & Y_2 \\
				Y_3 & Y_4
				\end{array}
			\right)
	\end{equation*}
	Thus $A_1+Y_1$ is invertible and 
	\begin{equation*}
		A + Y =
		\left(
			\begin{array}{cc}
			A_1+Y_1 & Y_2 \\
			Y_3 & Y_4
			\end{array}
		\right)
		= 
		\left(
			\begin{array}{cc}
				A_1+Y_1 & 0 \\
				0 & 0
			\end{array}
		\right)
		+
		\left(
			\begin{array}{cc}
			0 & Y_2 \\
			Y_3 & Y_4
			\end{array}
		\right)
	\end{equation*}
	The first part is Fredholm and the second part is finite rank. Thus $A+Y$ is Fredholm, and $\ind{A+Y} = \ind{A}$ by above theorem.
\end{proof}

\begin{cor}
	Let $\fml{F}$ denote the set of all Fredholm operators. Then the map
	\begin{equation*}
		\ind{} \colon (\fml{F},\norm{\cdot}) \longrightarrow \Z
	\end{equation*}
	is continuous with respect to the discrete topology on $\Z$. 
\end{cor}

\subsection{Essential Spectrum}

Let $\pi \colon \oper \sto \oper / \coper$ be the quotient map. We have know that the inverse of the invertible element in the Calkin algebra is Fredholm. Thus, the spectrum of the element in the Calkin algebra may be interesting.

\begin{defn}
	If $A \in \oper$, the essential spectrum of $A$ is defined as
	\begin{equation*}
		\sigma_e(A) = \sigma(\pi(A))
	\end{equation*}
	Similarly, $\sigma_{le} = \sigma_l(\pi(A))$ and $\sigma_{re} = \sigma_r(\pi(A))$.
\end{defn}

By the properties of the general spectrum and the Fredholm operators, we have following properties of the essential spectrum.

\begin{prop}
	Let $A \in \oper$.
	\begin{enumerate}[label = \arabic*)]
		\item $\sigma_{le}(A) \subset \sigma_l(A)$ and $\sigma_{re}(A) \subset \sigma_r(A)$ and $\sigma_e(A) \subset \sigma(A)$.
		\item $\sigma_{le}(A)$, $\sigma_{re}(A)$ and $\sigma_e(A)$ are compact.
		\item For any $K \in \coper$, $A+K$ and $A$ have same left (or right) essential spectrum.
		\item $\lambda \in \sigma_{le}(A)$ is and only if $\dim{\ker{(A-\lambda)}} = \infty$ or $\ran{(A-\lambda)}$ is not closed.
		\item $\lambda \in \sigma_{re}(A)$ is and only if $\dim{\ran{(A-\lambda)}^{\bot}} = \infty$ or $\ran{(A-\lambda)}$ is not closed.
	\end{enumerate}
\end{prop}

\begin{prop}
	If $A \in \oper$, then
	\begin{equation*}
		\sigma_{ap}(A) = \sigma_{le}(A) \cup \{\lambda \in \sigma_p(A) \colon \dim{\ker{(A-\lambda)}} < \infty\}
	\end{equation*}
\end{prop}
\begin{proof}
	If $\lambda \in \sigma_{ap}(A)$, then by the \textbf{Proposition} \ref{prop15} and \ref{prop16} in the subsection \textbf{3.3.1}, we know that either $\ran{(A-\lambda)}$ is not closed or $\ker{(A-\lambda)} \neq \{0\}$. If $\ran{(A-\lambda)}$ is not closed or $\dim{\ker{(A-\lambda)}} = \infty$, $\lambda \in \sigma_{le}(A)$. The converse is similar.
\end{proof}

For normal operators, by above proposition, there are more interesting results about the essential spectrum.

\begin{lem}
	If $N$ is a normal operator and $\lambda \in \sigma(N)$, then $\ran{(N-\lambda)}$ is closed if and only if $\lambda$ is not a limit point of $\sigma(N)$.
\end{lem}
\begin{proof}
	Assume $\lambda$ is isolated in $\sigma(N)$. Let $X = \sigma(N) \backslash \{\lambda\}$ and $\Hs_1 = E(X) \Hs$. Hence, $(N-\lambda)\Hs_1$ is closed as $\sigma(N|_{\Hs_1}) = X$. Since
	\begin{equation*}
		\Hs_1^{\bot} = E(\{\lambda\}) \Hs = \ker{(A-\lambda)}
	\end{equation*}
	$\ran{(N-\lambda)} = (N-\lambda)\Hs_1$. Therefore, $\ran{(N-\lambda)}$ is closed. \\
	Conversely, assume $\lambda$ is not isolated in $\sigma(N)$. Then there is a positive sequence $\{r_n\}$ s.t. $r_n \sto 0$ decreasingly. Each open set
	\begin{equation*}
		A_n = \{~z \in \C \colon r_{n+1} < \abs{z - \lambda} < r_n~\}
	\end{equation*}
	has non-empty intersection with $\sigma(N)$, i.e. $E(A_n)\Hs \neq \{0\}$ for all $n$. Let $e_n \in A_n$ be the unit element and $e_n \in \ker{(N-\lambda)}^{\bot}$ and
	\begin{equation*}
		\norm{(N-\lambda)e_n}^2 = \int_{A_n} \abs{z-\lambda}^2 d E_{e_n,e_n}(z) \leqslant r_n^2 \sto 0
	\end{equation*}
	Therefore,
	\begin{equation*}
		\inf{\{\norm{(N-\lambda)h} \colon \norm{h} = 1,~h \in \ker{(N-\lambda)}^{\bot}\}} = 0
	\end{equation*}
	i.e. $\ran{(N-\lambda)}$ is not closed.
\end{proof}

\begin{thm} \label{thm14}
	If $N$ is normal, then $\sigma_e(N) = \sigma_{le}(N) = \sigma_{re}(N)$ and
	\begin{equation*}
		\sigma(N) \backslash \sigma_e(N) = \{\lambda \in \sigma(N) \colon \lambda \text{ is isolated and } \dim{\ker{(N-\lambda)}} < \infty\}
	\end{equation*}
\end{thm}
\begin{proof}
	The first part can be obtained by applying the \textbf{Corrllary} \ref{cor11} in the subsection \textbf{3.3.1} to the Calkin algebra.\\
	If $\lambda$ is isolated in $\sigma(N)$, then $\ran{(N-\lambda)}$ is closed. Thus, 
	\begin{equation*}
		\dim{\ker{(N-\lambda)}} < \infty \Rightarrow \lambda \notin \sigma_{le}(N)
	\end{equation*}
	The converse is similar.
\end{proof}

Let $\gamma(A) = \inf{\{\norm{Ah} \colon \norm{h} = 1,~ h \bot \ker{A}\}} = \chi(0)$. In fact, $\gamma(A) = \gamma(\st{A})$. Moreover,
\begin{equation*}
	\gamma(A)\dist{(h,\ker{A})} \leqslant \norm{Ah}
\end{equation*}

\begin{lem}
	If $\M, \fml{N}$ are closed subspace of $\Hs$ and $\fml{N}$ is finite dimensional and $\dim{\M} > \dim{\fml{N}}$, then there is a non-zero vector $m \in \M$ s.t.
	\begin{equation*}
		\norm{m} = \dist{(m,\fml{N})}
	\end{equation*}
\end{lem}
\begin{proof}
	Let $P$ be the projection onto $\M$, so $\dim{P(\fml{N})} \leqslant \dim{\fml{N}} < \dim{\M}$. Thus $P(\fml{N})$ is a proper subspace of $\M$. Let $m \in \M \cap P(\fml{N})^{\bot}$. For any $n \in \fml{N}$,
	\begin{equation*}
		0 = \langle Pn,m \rangle = \langle n, Pm \rangle = \langle n,m \rangle
	\end{equation*}
	Thus $m \bot \fml{N}$, i.e. $\norm{m} = \dist{(m,\fml{N})}$.
\end{proof}

\begin{lem}
	If $A$ is left semi-Fredholm and $B \in \oper$ s.t. $\norm{B} < \gamma(A)$, then $A+B$ is left semi-Fredholm and 
	\begin{enumerate}[label=\arabic*)]
		\item $\dim{\ker{(A+B)}} \leqslant \dim{\ker{A}}$.
		\item $\dim{\ran{(A+B)}^{\bot}} \leqslant \dim{\ran{A}^{\bot}}$.
	\end{enumerate}
\end{lem}
\begin{proof}
	Check: $\{h \colon \norm{(A+B)h} \leqslant \delta \norm{h}\}$ for some $\delta < \gamma - \norm{B}$ contains no infinite dimensional subspace. \\
	If there is an infinite dimensional subspace, then it would contain a finite dimensional subspace $\M$ with $\dim{\M} > \dim{\ker{A}}$. Therefore, there is a $h \in \ker{A}$ s.t.$\norm{h} = \dist{(h,\ker{A})}$.Then
	\begin{eqnarray*}
		\gamma(A)\norm{h} &=& \gamma(A) \dist{(h,\ker{A})} \leqslant \norm{Ah} \\
		&\leqslant& \norm{(A+B)h} +\norm{Bh} \leqslant (\delta+\norm{B})\norm{h} \\
		&<& \gamma(A)\norm{h}
	\end{eqnarray*}
	which is a contradiction. Therefore, $A+B$ is a left semi-Fredholm.

	\item Check: $\dim{\ker{(A+B)}} \leqslant \dim{\ker{A}}$. \\
	If $h \in \ker{(A+B)}$, then $Ah = -Bh$. Then
	\begin{equation*}
		\gamma(A)\dist{(h,\ker{A})} \leqslant \norm{Bh} \leqslant \norm{B}\norm{h} < \gamma(A) \norm{h}
	\end{equation*}
	Therefore, $\dist{(h,\ker{A})} < \norm{h}$. By above lemma,
	\begin{equation*}
		\dim{\ker{(A+B)}} \leqslant \dim{\ker{A}}
	\end{equation*}

	\item Finally, if $\dim{\ran{A}^{\bot}} = \infty$, $2)$ holds clearly. But if $\dim{\ran{A}^{\bot}} < \infty$, $A$ is also right semi-Fredholm, i.e. $\st{A}$ is left semi-Fredholm, and by $1)$, $2)$ holds.
\end{proof}
\begin{rem}
	Clearly, these results can also be valid for right semi-Fredholm and Fredholm.
\end{rem}

\begin{prop}
	If $A$ is semi-Fredholm and either $\ker{A} = \{0\}$ or $\ran{A} = \Hs$, then there is a $\delta > 0$ s.t. if $\norm{B-A} < \delta$, the 
	\begin{equation*}
		\dim{\ker{A}} = \dim{\ker{B}},~ \dim{\ran{A}} = \dim{\ran{B}}
	\end{equation*}
\end{prop}
\begin{proof}
	In fact, there is a $\delta > 0$ s.t. if $\norm{B-A} < \delta$, then $\ind{A} = \ind{B}$ and 
	\begin{equation*}
		\dim{\ker{B}} \leqslant \dim{\ker{A}},~ \dim{\ran{B}^{\bot}} \leqslant \dim{\ran{A}^{\bot}}
	\end{equation*}
	Since one of these is $0$, the results are true.
\end{proof}

\begin{thm}
	If $\lambda \notin \sigma_{le}(A) \cap \sigma_{re}(A)$, then there is a $\delta > 0$ s.t. \\ $\dim{\ker{(A - \mu)}}$ and $\dim{\ran{(A - \mu)}^{\bot}}$ are constant for $0< \abs{\lambda - \mu} < \delta$.
\end{thm}
\begin{proof}
	Assume $\lambda = 0$ and $\ker{A}$ is finite dimensional. And $A^n$ is also left semi-Fredholm for all $n$. Let $\M_n = \ran{A^n}$. Note $\M_{n+1} \subset \M_n$ and $\A \M_{n} = \M_{n+1}$. Let $\M = \cap \M_n$ and $B = A|_{\M}$.
	\item Claim: $B(\M) = \M$.\\
	Since $\ker{A}$ is finite dimensional and $\{\M_n\}$ is decreasing, there is a $m$ s.t. for all $n \geqslant m$, $\M_n \cap \ker{A} = \M_m \cap \ker{A}$. For any $h \in \M$ and $n \geqslant m$, there is $f_n \in \M_n$ s.t. $h = Af_n$. 
	\begin{equation*}
		f_m - f_n \in \M_n \cap \ker{A} = \M_m \cap \ker{A}
	\end{equation*}
	Therefore, $f_m \in \M_n$ for all $n \geqslant m$. Thus $f_m \in \M$ and
	\begin{equation*}
		h = Af_m = Bf_m \in B(\M)
	\end{equation*}
	Thus $B$ is semi-Fredholm and $\ind{B} = \dim{\ker{B}}$. Then there is a $\delta_1 > 0$ s.t. for $\abs{\mu} < \delta_1$,
	\begin{equation*}
		\dim{\ker{B-\mu}} \leqslant \dim{\ker{B}},~ \dim{\ran{(B-\mu)}^{\bot}} = 0 \text{ and } \ind{(B-\mu)} = \ind{B}
	\end{equation*}
	And thus $\dim{\ker{B-\mu}} = \dim{\ker{B}}$. \\
	Also There is a $\delta_2$ s.t. $\ind{(A-\mu)} = \ind{A}$ for all $\abs{\mu} < \delta_2$. Then let $\delta = \min{\{\delta_1,\delta_2\}}$.
	\item Claim: $\ker{(A-\mu)} \subset \M$ for $0 < \abs{\mu} < \delta$. \\
	If $h \in \ker{(A-\mu)}$, then $A^n h = \mu^n h$. So $h = A^n \mu^{-n} h \in \M$.\\
	Finally, for $0 < \abs{\mu} < \delta$,
	\begin{equation*}
		\dim{\ker{(A-\mu)}} = \dim{\ker{(B-\mu)}} = \dim{\ker{B}}
	\end{equation*}
	And since $\ind{(A-\mu)}$ is constant, $\dim{\ran{(A - \mu)}^{\bot}}$ is also constant.
\end{proof}

\begin{thm}
	If $\lambda \in \partial{\sigma(A)}$, then either $\lambda$ is an isolated point of $\sigma(A)$ or $\lambda \in \sigma_{le}(A) \cap \sigma_{re}(A)$.
\end{thm}
\begin{proof}
	Suppose $\lambda \in \partial{\sigma(A)}$ and $\lambda \notin \sigma_{le}(A) \cap \sigma_{re}(A)$. Therefore, $A-\lambda$ is semi-Fredholm. By above theorem, there is a $\delta > 0$ s.t. $\dim{\ker{(A - \mu)}}$ and $\dim{\ran{(A - \mu)}^{\bot}}$ are constant for $0< \abs{\lambda - \mu} < \delta$. Since $\lambda \in \partial{\sigma(A)}$, there is a $\nu \in \rho(A)$ with $0< \abs{\nu - \mu} < \delta$. Therefore,
	\begin{equation*}
		\ker{(A-\mu)} = \{0\} = \ran{(A-\mu)}^{\bot}, \text{ for } 0 < \abs{\lambda - \mu} < \delta
	\end{equation*}
	And $A-\mu$ is semi-Fredholm, $\ran{(A-\mu)}$ is closed, thus $A-\mu$ is invertible for $0 < \abs{\lambda - \mu} < \delta$, which means that $\lambda$ is isolated.
\end{proof}

\begin{prop}
	Let $\lambda$ be an isolated point of $\sigma(A)$, then the following statements are equivalent.
	\begin{enumerate}[label = \arabic*)]
		\item $\lambda \notin \sigma_{le}(A) \cap \sigma_{re}(A)$.
		\item $A-\lambda$ is Fredholm and $\ind{(A-\lambda)} = 0$.
		\item The Riesz idempotent $E(\{\lambda\})$ is finite rank.
	\end{enumerate}
\end{prop}
\begin{proof}
	$1) \Rightarrow 2)$: Since $\lambda \notin \sigma_{le}(A) \cap \sigma_{re}(A)$, $\ran{(A-\lambda)}$ is closed and either $\dim{\ker{(A-\lambda)}} < \infty$ or $\dim{\st{\ker{(A-\lambda)}}} < \infty$. Assume $\dim{\ker{(A-\lambda)}} < \infty$. Since $\lambda$ is isolated, we can use similar argument in the \textbf{Theorem} \ref{thm12} in the subsection \textbf{5.1.2} to get
	\begin{equation*}
		\dim{\ker{(A-\lambda)}} = \dim{\st{\ker{(A-\lambda)}}} < \infty
	\end{equation*}
	And if we assume $\dim{\st{\ker{(A-\lambda)}}} < \infty$, we can also get same result. Thus $A-\lambda$ is Fredholm and $\ind{(A-\lambda)} = 0$.
	\item $2) \Rightarrow 3)$: By the definition,
	\begin{equation*}
		(A-\lambda)E(\{\lambda\}) = \int_{\Gamma} \frac{(z-\lambda)\chi_{\{\lambda\}(z)}}{z - A} dz = 0 \Rightarrow E(\{\lambda\})\Hs \subset \ker{(A-\lambda)}
	\end{equation*}
	Thus $E(\{\lambda\})$ is finite rank.
	\item $3) \Rightarrow 1)$: As above mention, $E(\{\lambda\})\Hs \subset \ker{(A-\lambda)}$. In fact, the converse is also true.\\
	Claim: $\ker{(A-\lambda)} \subset E(\{\lambda\})\Hs$. \\
	Let $\Delta = \sigma(A) \backslash \{\lambda\}$, $\Hs_{\Delta} = E(\{\Delta\})\Hs$ and $A_{\Delta} = A|_{\Hs_{\Delta}}$, and similarly for $\{\lambda\}$. Then $A_{\Delta} - \lambda$ is invertible. If $h \in \ker{(A-\lambda)}$, 
	\begin{eqnarray*}
	0 = (A-\lambda)h &=& (A-\lambda)E(\{\lambda\})h+(A-\lambda)E(\Delta)h \\
	&=& (A_{\lambda}-\lambda)E(\{\lambda\})h + (A_{\Delta}-\lambda)E(\Delta)h
	\end{eqnarray*}
	Since $E(\{\lambda\}) \bot E(\Delta)$, 
	\begin{equation*}
		(A_{\lambda}-\lambda)E(\{\lambda\})h = (A_{\Delta}-\lambda)E(\Delta)h = 0
	\end{equation*}
	And the fact that $A_{\Delta} - \lambda$ is invertible implies that $E(\Delta)h = 0$, thus $h \in \Hs_{\{\lambda\}}$. \\
	Thus, $\ker{(A-\lambda)} = E(\{\lambda\})\Hs$ is finite. Moreover, by the similar argument in in the \textbf{Theorem} \ref{thm12} in the subsection \textbf{5.1.2}, $\ran{(A-\lambda)}$ is closed. Thus, $A-\lambda$ is semi-Fredholm.
\end{proof}

\section{Compact Perturbations}

\subsection{Weyl-von Neumann Theorem}

In finite dimensional case, any normal operator can be diagonalized, but it is not true for the infinite dimensional case. In fact, it can hold by doing some extra efforts. Firstly, we can do that for a self-adjoint operator. 

Like the definition of Hilbert-Schmidt operators, we define $B \in \fml{B}_p(\Hs)$ if $\abs{B}^{\frac{p}{2}} \in \hoper$, and 
\begin{equation*}
	\norm{B}_p = \norm{\abs{B}^{\frac{p}{2}}}_2^{\frac{2}{p}} = (\sum_e \norm{Be}^p)^{\frac{1}{p}}
\end{equation*}
Clearly, $\norm{B} \leqslant \norm{B}_p$. And moreover, if $B$ has finite rank $m$, then
\begin{equation*}
	\norm{B}_p \leqslant m^{\frac{1}{p}} \norm{T}
\end{equation*}
In fact, $\fml{B}_p(\Hs) \subset \coper$.

\begin{thm}[Weyl-von Neumann Theorem]
	If $A$ is a self-adjoint operator on a separable Hilbert space, $\varepsilon > 0$ and $1 < p < \infty$, then there is a diagonalizable self-adjoint operator $D$ s.t. 
	\begin{equation*}
		A-D \in \fml{B}_p(\Hs), \text{ and } \norm{A-D}_p < \varepsilon
	\end{equation*}
\end{thm}

To prove it, we need a lemma.

\begin{lem}
	If $A$ is a self-adjoint operator on a separable Hilbert space, $h \in \Hs$, $\varepsilon > 0$ and $1 < p < \infty$, then there is a finite rank projection $P$ and a self-adjoint $K \in \fml{B}_p(\Hs)$, s.t. $f \in P$, $\norm{K}_p < \varepsilon$ and $A+K$ is reduced by $P$.
\end{lem}
\begin{proof}
	Let $E$ be the spectral measure for $A$ and $\sigma(A) \subset [a,b]$ and intervals $\{\Delta_k\}_{k=1}^{n}$ be a partition of $[a,b]$ with length $(b-a)/n$. Put
	\begin{equation*}
		f_k = E(\Delta_k) f, \text{ and } g_k = \frac{f_k}{\norm{f_k}} \text{ for } f_k \neq 0
	\end{equation*}
	Let $\lambda_k$ be the midpoint of $\Delta_k$ then
	\begin{equation*}
		\norm{(A-\lambda_k)g_k} \leqslant \frac{(b-a)}{n}
	\end{equation*}
	Define $P$ as the projection onto $\spn{g_1,\cdots,g_n}$. Since $P^{\bot}g_k = 0$,
	\begin{equation*}
		\norm{P^{\bot} Ag_k} = \norm{P^{\bot}(A-\lambda_k)g_k} \leqslant \frac{(b-a)}{n}
	\end{equation*}
	Since $g_k \in E(\Delta_k)$, $Ag_k \in E(\Delta_k)$. Thus, $Ag_k \bot g_j$ for $j \neq k$.
	\begin{equation*}
		P^{\bot} Ag_k = Ag_k - \sum_{j=1}^{n} \langle Ag_k,g_j \rangle g_j = Ag_k - \langle Ag_k,g_k \rangle g_k \in E(\Delta_k)
	\end{equation*}
	Thus $P^{\bot}Ag_k \bot P^{\bot}Ag_j$ for $j \neq k$. Then
	\begin{eqnarray*}
		\norm{P^{\bot}APh} &=& \norm{\sum_{k=1}^n \langle h,g_k \rangle P^{\bot}Ag_k} \\
		&=& \sum_{k=1}^n \abs{\langle h,g_k \rangle}^2 \norm{P^{\bot}Ag_k}^2 \\
		&\leqslant& \left(\frac{(b-a)}{n} \right)^2 \norm{h}^2
	\end{eqnarray*}
	Therefore, $\norm{P^{\bot}AP} \leqslant {(b-a)}/{n}$ and by above mention
	\begin{equation*}
		\norm{P^{\bot}AP}_p \leqslant n^{\frac{1}{p}} \left(\frac{(b-a)}{n} \right) = \frac{(b-a)}{n^q},~ q = 1 - \frac{1}{p}
	\end{equation*}
	Put $B = PAP + P^{\bot}AP^{\bot}$ and $K = -(P^{\bot}AP + PAP^{\bot})$, then $B = A + K$. Clearly, $K$ is self-adjoint and $P$ reduces $B$ and 
	\begin{equation*}
		\norm{K}_p \leqslant \frac{2(b-a)}{n^q}
 	\end{equation*}
 	Thus for any $\varepsilon > 0$, $\norm{K}_p < \varepsilon$ for some partition.
\end{proof}

Then we can prove the Weyl-von Neumann Theorem.

\begin{proof}[Proof of Weyl-von Neumann Theorem]
	Let $\{h_j\}$ be a dense subset in $\Hs$ and put $f = h_1$, then by above lemma, there is a finite rank projection $P_1$ and a self-adjoint operator $K_1$ s.t. $A+K_1$ is reduced by $P_1$ and $h_1 \in P_1$ and $\norm{K_1}_p < \varepsilon / 2$. Then applying above lemma to $(A+K_1)|_{P_1^{\bot}}$ and the vector $f = P_1^{\bot} h_2$, we get $K_2$ and $P_2$ and extend $K_2$ on $\Hs$ by defining $K_2 h =0$ for $h \in P_1$. By reduction, we get finite rank projections $\{P_n\}$ and $\{K_n\}$ s.t.
	\begin{enumerate}[label = \arabic*)]
		\item $P_j P_n = 0$ for $j \neq n$;
		\item $\norm{K_n}_p < \varepsilon / 2^n$;
		\item $h_n \in P_1 + \cdots + P_n$;
		\item $A+K_1+\cdots+K_n$ is reduced by $P_1 + \cdots + P_n$;
		\item $K_n(P_1 + \cdots + P_{n-1}) = 0$.
	\end{enumerate}
	Then let $K = \sum K_n$, then $\norm{K_n}_p < \varepsilon$. And let $D = A + K$. Clearly, $D$ is self-adjoint. Since $1 = \sum_n P_n$ and $D$ is reduced by any $P_n$, if $D_n = D|_{P_n}$, $D = \oplus D_n$. And since $P_n$ is finite, each $D_n$ can be diagonalized, thus $D$ is diagonalizable.
\end{proof}

\subsection{Weyl-von Neumann-Berg Theorem}

Now, we can apply above theorem to the normal operators. But it can be more general. Since a class of commutative finite rank normal operators can be diagonalizable simutaneously, we want to see the similar result for the infinite dimensional case.

By the \textbf{Theorem} \ref{thm13} in the section \textbf{4.3}, we can get a trivial corollary.

\begin{cor}
	If $N_1, \cdots, N_n$ are commutating normal operators on a separable Hilbert space, then there is a self-adjoint operator $A$ and continuous functions $f_1,\cdots,f_n$ s.t. $N_j = f_j(A)$ for $1 \leqslant j \leqslant n$.
\end{cor}

\begin{thm}[Weyl-von Neumann-Berg Theorem]
	If $N_1, \cdots, N_n$ are commutating normal operators on a separable Hilbert space and $\varepsilon > 0$, then there are diagonalizable normal operators $D_1,\cdots,D_n$ and compact operators $K_1,\cdots,K_n$ s.t. for $1 \leqslant j \leqslant n$, $\norm{K_j} < \varepsilon$ and $N_j = D_j + K_j$.
\end{thm}

By above corollary and the Weyl-von Neumann Theorem, $A = D + K$ with $\norm{K} < \varepsilon$, but we need to prove that $f(A) - f(D) \in \coper$, and $\norm{f(A) - f(D)} M< \varepsilon$.

\begin{lem}
	\begin{enumerate}[label=\arabic*)]
		\item Let $A$ be a self-adjoint operator with $A = D + K$ for some diagonalizable $D$ and compact operator $K$. Then for any continuous function $f$ on $\sigma(A)$, there is a compact operator $K^{'}$ s.t. $f(A) = f(D) + K^{'}$.
		\item If $f$ is a continuous function on $\R$, then the map $A \sto f(A)$ is uniformly continuous on a bounded sets of self-adjoint operators.
	\end{enumerate}
\end{lem}
\begin{proof}
	For $1)$, if $A = D + K$, then for any $m \geqslant 1$, $A^m = D^m + K_m$ for some compact operatr $K_m$. Therefore, for each polynomial $p$, 
	\begin{equation*}
		p(A) = p(D) + K_p, \text{ for some operator } K_p \in \coper
	\end{equation*}
	Let $\{p_k\}$ be a sequence converging uniformly to $f$ on a closed interval containing $\sigma(A) \cup \sigma(D)$, thus
	\begin{equation*}
		\norm{p_k(A) - f(A)} \sto 0,~ \norm{p_k(D) - f(D)} \sto 0
	\end{equation*}
	Therefore, we have
	\begin{equation*}
		K_{pk} = p_k(A) - p_k(D) \sto f(A) - f(D) = K^{'} \text{ in norm}
	\end{equation*}
	and $K^{'} \in \coper$.
	\item For $2)$, we just need to prove this if $f$ is a polynomial since on a compact set the limit of a sequence of uniformly continuous functions is also uniformly continuous. Note that
	\begin{equation*}
		T^{n+1} - S^{n+1} = T^n(T-S) + (T^n - S^n)S
	\end{equation*}
	That means $T \sto T^n$ is uniformly continuous on a bounded set of self-adjoint operators. Therefore, $A \sto f(A)$ for any polynomial $f$.
\end{proof}

\begin{proof}[Weyl-von Neumann-Berg Theorem]
	By above corollary, let $A$ be the self-adjoint operator and $f_1,\cdots,f_n$ be continuous functions on $\sigma(A)$ s.t. $N_j = f_j(A)$ for any $1 \leqslant j \leqslant n$. By the Weyl-von Neumann Theorem, there are self-adjoint operators $D$ and $K$ with $K \in \coper$ and $\norm{K} < \varepsilon$ s.t. $A = D + K$. Then by above lemma,
	\begin{equation*}
		N_j - f_j(D) \in \coper, \norm{N_j - f_j(D)} = \norm{f_j(A) - f_j(D)} < \varepsilon \qedhere
	\end{equation*}
\end{proof}

\begin{cor}
	If $N$ is a normal operator on a separable Hilbert space and $\varepsilon > 0$, then there is a diagonalizable normal operator $D$ s.t. $N = D \oplus K + K_1 $ and $\sigma(D) = \sigma_e(D) = \sigma_e(N)$, where $K$ and $K_1$ are compact.
\end{cor}
\begin{proof}
	By above theorem, $N = D_1 + K_1$ for the normal diagnolizable operator $D_1$ and self-adjoint compact operator $K_1$ with $\norm{K_1} < \varepsilon$. Then by the Fredholm Theory, $\sigma_e(D_1) = \sigma_e(N)$. By the \textbf{Theorem} \ref{thm14} in the subsetction \textbf{5.4.3} and the separability of the Hilbert space, 
	\begin{equation*}
		\{\mu_j\}_{j=1}^{\infty} = \sigma(D_1) \backslash \sigma_e(D_1)
	\end{equation*}
	where each $\mu_j$ has finite multiplicity and is repeated as often as their multiplicity. Let $\{h_j\}$ be the coresponding eigenvectors then
	\begin{equation*}
		D_1 = D \oplus \sum_{j=1}^{\infty} \mu_j h_j \otimes h_j
	\end{equation*}
	where $D$ is a diagonalizable normal operator on a subspace of $\Hs$ with $\sigma(D) = \sigma_e(D) = \sigma_e(D_1)$. Put 
	\begin{equation*}
		K = \sum_{j=1}^{\infty} \mu_j h_j \otimes h_j
	\end{equation*}
	then $K$ is compact. Therefore,
	\begin{equation*}
		N = D \oplus K + K_1 \qedhere
	\end{equation*}	
\end{proof}

In above corollary, we cannot value the norm of $K$, but in some special case, we can do this. Firstly, we need some lemmas.
\begin{lem}
	Let $\A$ be a Banach algebra and $a \in \A$.
	\begin{enumerate}[label=\arabic*)]
		\item If $\alpha \in \rho(a)$, then $\dist{(\alpha,\sigma(a))} \geqslant \norm{(a-\alpha)^{-1}}^{-1}$.
		\item If $b,k \in \A$ with $\norm{k} < \varepsilon$ for some $\varepsilon > 0$ s.t. $a = b + k$, then 
		\begin{equation*}
			\{~\alpha \colon \alpha \in \rho(a),~ \norm{(a-\alpha)^{-1}}^{-1} > \varepsilon~\} \subset \rho(b)
		\end{equation*}
	\end{enumerate}
\end{lem}
\begin{proof}
	For $1)$, if $\alpha \in \rho(a)$ and by the perturbation of inverse, 
	\begin{equation*}
		\abs{\beta} < \norm{(a-\alpha)^{-1}}^{-1} \Rightarrow \beta + \alpha \in \rho(a)
 	\end{equation*}
 	Therefore, $1)$ holds. \\
 	For $2)$, if
 	\begin{equation*}
 		\alpha \in \{~\alpha \colon \alpha \in \rho(a),~ \norm{(a-\alpha)^{-1}}^{-1} > \varepsilon~\}
 	\end{equation*}
 	then by the fact that $\norm{k} < \varepsilon$, 
 	\begin{equation*}
 		\norm{(a-\alpha)^{-1} k} \leqslant \norm{(a-\alpha)^{-1}} \norm{k} < 1
 	\end{equation*}
 	Therefore, $1 - (a-\alpha)^{-1} k$ is invertible. It shows
 	\begin{equation*}
 		b - \alpha = a - \alpha - k = (a - \alpha)(1 - (a-\alpha)^{-1} k)
 	\end{equation*}
 	is invertible, i.e. $\alpha \in \rho(a)$.
\end{proof}

\begin{lem}
	If $A \in \oper$ is a normal operator, then for any $\lambda \in \rho(A)$
	\begin{equation*}
		\norm{(A-\lambda)^{-1}} = \dist{(\lambda, \sigma(A))}^{-1}
	\end{equation*}
\end{lem}
\begin{proof}
	Let $E$ be the spectral measure for $A$, then
	\begin{equation*}
		(A-\lambda)^{-1} = \int_{\sigma(A)} (z - \lambda)^{-1} dE(z)
	\end{equation*}
	Then, the norm
	\begin{equation*}
		\norm{(A-\lambda)^{-1}} = \sup{\{\abs{(z-\lambda)}^{-1} \colon z \in \sigma(A)\}} = \dist{(\lambda, \sigma(A))}^{-1} \qedhere
	\end{equation*}
\end{proof}

Combining above lemmas, if $N = D + K$ with $\norm{K} < \varepsilon$, then 
\begin{equation*}
	\sigma(D) \subset \{ \lambda \colon \dist{(\lambda,\sigma(N))} \leqslant \varepsilon\}
\end{equation*}
Then we can refine above corollary.

\begin{prop}
	If $N$ is a normal operator on a separable Hilbert space with $\sigma(N) = \sigma_e(N)$ and $\varepsilon > 0$, then there is a diagonalizable normal operator $D$ s.t. $N \cong D \oplus K + K_1 $ and $\sigma(D) = \sigma_e(D) = \sigma_e(N)$, where $K$ and $K_1$ are compact with $\norm{K}, \norm{K_1} < \varepsilon$
\end{prop}
\begin{proof}
	By above corollary, $N = D_1 + K_1$ for the normal diagnolizable operator $D_1$ and self-adjoint compact operator $K_1$ with $\norm{K_1} < \varepsilon$. And
	\begin{equation*}
		D_1 = D_2 \oplus \sum_{j=1}^{\infty} \mu_j h_j \otimes h_j
	\end{equation*}
	where $D_2$ is a diagonalizable normal operator on a subspace of $\Hs$ with $\sigma(D_2) = \sigma_e(D_2) = \sigma_e(D_1)$. Since 
	\begin{equation*}
		\sigma(D_1) = \sigma_e(D_1) \cup \{\mu_j\},~ \sigma_e(D_1) = \sigma_e(N) = \sigma(N)
	\end{equation*}
	then by above mention for any $\mu_j$, there is a $\lambda_j \in \sigma_e(D_2)$, s.t.
	\begin{eqnarray*}
		\abs{\mu_j - \lambda_j} &=& \dist{(\mu_j, \sigma_e(D_2))} = \dist{(\mu_j, \sigma_e(D_1))} \\
		&=& \dist{(\mu_j, \sigma(N))} \\
		&\leqslant& \varepsilon
	\end{eqnarray*}
	Then since $D_2$ is diagonalizable, let $g_j$ be the corresponding vector  with respect to $\lambda_j$,
	\begin{equation*}
		D_1 = D \oplus \sum_{j=1}^{\infty} (-\lambda_j) g_j \otimes g_j \oplus \sum_{j=1}^{\infty} \mu_j h_j \otimes h_j
	\end{equation*}
	And in fact,
	\begin{equation*}
		D_1 \cong D \oplus \sum_{j=1}^{\infty} (\mu_j-\lambda_j) h_j \otimes h_j
	\end{equation*}
	where $D$ a diagonalizable normal operator on a subspace of $\Hs$ with $\sigma(D) = \sigma_e(D) = \sigma_e(N)$. Put 
	\begin{equation*}
		K = \sum_{j=1}^{\infty} (\mu_j-\lambda_j) h_j \otimes h_j
	\end{equation*}
	then $K$ is compact with $\norm{K} < \varepsilon$. Therefore,
	\begin{equation*}
		N \cong D \oplus K + K_1 \qedhere
	\end{equation*}	
\end{proof}

\subsection{Approximately Unitary Equivalence}

For two operators $N$ and $M$, if there is a unitary $U$ s.t. $N = \st{U}MU$, $N$ and $M$ are same in some sense and we say that these two are unitary equivalent. But this relation is too strong, so there is another weaker relation, approximately unitary equivalence.

\begin{lem}
	If $N$ and $M$ are diagonalizable normal operators on a separable Hilbert space with
	\begin{equation*}
		\sigma(N) = \sigma_e(N) = \sigma_e(M) = \sigma(M)
	\end{equation*}
	and $\varepsilon > 0$, then there is a unitary operator $U$ s.t. $N-\st{U}MU \in \toper$ with $\norm{N-\st{U}MU}_1 < \varepsilon$. 
\end{lem}
\begin{proof}
	By the condition, if $\nu$ is an isolated point of $\sigma(N)$, it must be an eigenvalue with infinite multiplicity, and thus it is an eigenvalue of $M$ with infinite multiplicity. If $\nu$ is a limit point of $\sigma(N)$, then there is a sequence in $\sigma(M)$ converging to $\nu$. \\
	Let $\{\nu_n\}$ and $\{\mu_m\}$ be all eigenvalues of $N$ and $M$ repectively and repeated as often as their multiplicity. Since $\sigma(N) = \sigma_e(N)$, all of them have infinite multiplicity. Moreover, for any $\nu_j$, there is a sequence $\{\mu_{n_j}\}$ converging to it.
	\item Claim: There is a renumbering of the two sets $\{\nu_{n_k}\}$ and $\{\mu_{m_k}\}$ s.t. 
	\begin{equation*}
		\abs{\nu_{n_k} - \mu_{m_k}} < \frac{\varepsilon}{2^k},~ \forall k \in \{n_1, \cdots, n_{2k}\} \cap \{m_1, \cdots, m_{2k}\}
	\end{equation*}
	Step 1: Let $n_1 = 1$ and $m_1$ be the smallest integer with 
	\begin{equation*}
		\abs{\nu_1 - \mu_{m_1}} < \frac{\varepsilon}{2}
	\end{equation*}
	Step 2: If $m_1 > 1$, put $m_2 = 1$, otherwise, put $m_2 =2$. Then let $\nu_2$ be the smallest integer larger than $1$ s.t.
	\begin{equation*}
		\abs{\nu_2 - \mu_{m_2}} < \frac{\varepsilon}{2^2}
	\end{equation*}
	Step 3: Continuing Step 1 and Step 2 to get $\{n_k\}$ and $\{m_k\}$ for $1 \leqslant k \leqslant 2j$. Then let $n_{2j+1}$ be the smallest integer and $n \neq n_k$ for $1 \leqslant k \leqslant 2j$ and $m_{2j+1}$ be the smallest integer grater than $m_k$ for $1 \leqslant k \leqslant 2j$ with
	\begin{equation*}
		\abs{\nu_{n_{2j+1}} - \mu_{m_{2j+1}}} < \frac{\varepsilon}{2^{2j+1}}
	\end{equation*}
	Similarly, we get $n_{2j+2}$ and $m_{2j+1}$ with same properties. Therefore, by induction, this claim holds.\\
	Since $N$ and $M$ are diagonalizable on a separable Hilbert space, there are two orthonormal basis $\{e_n\}$ and $\{f_m\}$ s.t. 
	\begin{equation*}
		Ne_n = \nu_n e_n, \text{ and } Mf_m = \mu_m f_m
	\end{equation*}
	Define $U$ as $Ue_{n_k} = f_{m_k}$ for all $k$, then clearly $U$ is a unitary. And,
	\begin{equation*}
		(N-\st{U}MU)e_{n_k} = (\nu_{n_k} - \mu_{m_k}) e_{n_k}
	\end{equation*}
	thus $\norm{N-\st{U}MU}_1 < \varepsilon$.
\end{proof}

\begin{thm}
	If $N$ and $M$ are normal operators on a separable Hilbert space with same essential spectrum, then there is a unitary $U$ s.t. $N-\st{U}MU$ is compact.
\end{thm}
\begin{proof}
	According the last corollary in above subsection, there are diagonalizable normal operators $N_1$ and $M_1$ s.t.
	\begin{equation*}
		N = N_1 \oplus K_1 + K, ~ M = M_1 \oplus K_1^{'} + K^{'}
	\end{equation*}
	where $K_1, K$ and $K_1^{'}, K^{'}$ are compact operators. And since $\sigma_e(N) = \sigma_e(M)$, 
	\begin{equation*}
		\sigma(N_1) = \sigma_e(N_1) = \sigma_e(M_1) = \sigma(M_1)
	\end{equation*}
	By above lemma, there is a unitary $V$ s.t. $N_1-\st{V}M_1V \in \coper$. Therefore, put $U = V \oplus id$,
	\begin{equation*}
		N - \st{U}MU = (N_1-\st{V}M_1V) \oplus (K_1 - K_1^{'}) + \st{U}(K-K^{'})U 
	\end{equation*}
	is compact.
\end{proof}

By above theorem, any two normal operators with same essential spectrum actually differ by some compact operator. By we cannot estimate the norm of this compact operator. However, the last proposition in above subsection can provide us a clue. If the two normal operators $N$ and $M$ satisfy
\begin{equation*}
	\sigma(N) = \sigma_e(N) = \sigma_e(M) = \sigma(M)
\end{equation*}
then there are similar $N_1, K_1, K$ and $M_1,  K_1^{'}, K^{'}$ s.t.
\begin{equation*}
	N = N_1 \oplus K_1 + K, ~ M = M_1 \oplus K_1^{'} + K^{'}
\end{equation*}
But the differece is that the norm of $K_1$ and $K_1^{'}$ can be arbitrary small. Therefore, by above theorem, the unitary $U$ can be choosing s.t. $N - \st{U}MU$ has arbitrary small norm.

In general case, we need a definition to describe this definition.

\begin{defn}
	Two normal operators $A$ and $B$ are approximately unitarily equivalent, denoted by $A \cong_a B$, if there is a sequence of unitaries $\{U_n\}$ s.t. 
	\begin{equation*}
		\norm{A - \st{U_n}BU_n} \sto 0
	\end{equation*}
	Moreover, if $A - \st{U_n}BU_n \in \coper$ and $A \cong_a B$, then $A$ and $B$ are called strongly approximately unitarily equivalent, denoted by $A \cong_{sa} B$.
\end{defn}

\begin{lem}
	If $\A$ is a \Cs and $\{a_n\}$ is a sequence of normal elements of $\A$ s.t. $a_n \sto a$ in norm, then $\sigma(a_n) \sto \sigma(a)$.
\end{lem}
\begin{proof}
	Since $\A$ is a $\st{C}$-algebra, by the continuity of the involution and the multiplication, $a$ is normal. By the Continuous Functional Calculus, we know
	\begin{equation*}
		\Cg{a_n} \cong C(\sigma(a_n)),~ \Cg{a} \cong C(\sigma(a))
	\end{equation*}
	For any $f_k \in C(\sigma(a_k))$, extending $f_k$ on $\cup \sigma(a_n) \cup \sigma(a)$ by setting $f_k = 0$ on other areal. Then $f_k \in B(\cup \sigma(a_n) \cup \sigma(a))$, and $\norm{f_k}$ does not change. And this mention can also apply to any $f$ in $C(\sigma(a))$.\\
	Let $g_k(z) = z \in C(\sigma(a_k))$ and $g(z) = z \in C(\sigma(a))$, then extending $g_k$ and $g$ on $\cup \sigma(a_n) \cup \sigma(a)$. Therefore, $\norm{g_k} = \norm{a_k}$ and $\norm{g} = \norm{a}$. Take $\alpha \in \sigma(a)$, then since $a_n \sto a$ in norm, $g_n \sto g$ in norm (?), therefore for any $0 < \varepsilon < \abs{g(\alpha)}$, there is a $n_0$ s.t. for all $n > n_0$
	\begin{equation*}
		\abs{g_n(\alpha)-g(\alpha)} \leqslant \norm{g_n - g} < \varepsilon
	\end{equation*}
	Then we can choose some $\alpha_n \in g_n^{-1}(g_n(\alpha)) \in \sigma(\alpha_n)$ since $g_n(\alpha) \neq 0$. Therefore, $\alpha_n \sto \alpha$. And the converse is similar.
\end{proof}

\begin{thm}
	If $N$ and $M$ are normal operators on a separable Hilbert spaces, then the following statements are equivalent.
	\begin{enumerate}[label = \arabic*)]
		\item $N \cong_{sa} M$.
		\item $N \cong_a M$.
		\item $\sigma_e(N) = \sigma_e(M)$ and for any $\lambda \in \sigma_e(N) = \sigma_e(M)$,
		\begin{equation*}
			\dim{\ker{(N-\lambda)}} = \dim{\ker{(M-\lambda)}}
		\end{equation*}
	\end{enumerate}
\end{thm}
\begin{proof}
	Let $E_N$ and $E_M$ be the spectral measures for $N$ and $M$. $1)$ implies $2)$ clearly.
	\item $2) \Rightarrow 3)$: Let $\{U_n\}$ be the unitaries s.t. $\norm{N - \st{U_n}MU_n} \sto 0$. Then by above lemma, 
	\begin{equation*}
		X = \sigma(M) = \sigma(N)
	\end{equation*}
	If $\lambda \in X$ is isolated, then $\lambda$ is eigenvalue for $M$ and $N$. And the characteristic function $\chi_{\{\lambda\}}(z)$ satisfies
	\begin{equation*}
		\chi_{\{\lambda\}}(\st{U}_nMU_n) \longrightarrow \chi_{\{\lambda\}}(N)
	\end{equation*}
	in norm. That means $E_N(\{\lambda\})$ and $E_M(\{\lambda\})$ has same rank, thus 
	\begin{equation*}
		\dim{\ker{(N-\lambda)}} = \dim{\ker{(M-\lambda)}}
	\end{equation*}
	for any isolated point $\lambda$ in $X$. Since the essential spectrum consists of all points in the spectrum that are not isolated eigenvalues of finite multiplicity, thus $\sigma_e(M) = \sigma_e(N)$.
	\item $3) \Rightarrow 1)$: By the Spectral Theorem, 
	\begin{equation*}
		N = N_1 \oplus N_2, \text{ and } M = M_1 \oplus M_2,
	\end{equation*}
	where $\sigma(M_2) = \sigma_e(M_2) = \sigma_e(M) = \sigma_e(N) = \sigma_e(N_2) = \sigma(N_2)$ and the spectrum of $N_1$ and $M_1$ consists of all eigenvalues of $N$ and $M$ with finite multiplicity, and thus $N_1 \cong M_1$. Let $V$ be the unitary s.t. $\st{V}M_1V = N_1$. Moreover, since
	\begin{equation*}
		\sigma(M_2) = \sigma_e(M_2) = \sigma_e(N_2) = \sigma(N_2)
	\end{equation*}
	by above mention there is a sequence of unitaries $\{W_n\}$ s.t.
	\begin{equation*}
		\st{W}_n M_2 W_n \longrightarrow N_2
 	\end{equation*}
 	in norm and $N_2 - \st{W}_n M_2 W_n \in \coper$. Then putting $U_n = W_n \oplus V_n$, thus $N \cong_{sa} M$. 
\end{proof}

\chapter{Von Neumann Algebras}

Abelian von Neuman algebras can be explicitly described as $L^{\infty}(\mu)$. For general von Neumann algebras, they have more complex structure but more interesting properties. Firstly, we have seen the relation between the $WOT$ and the ultraweak topology, therefore, the ultraweak topology can provide some different things of the von Neumann algebra. Then, since the weak closedness of von Neumann algebras, all projections in a von Neumann algebra can completely generate the whole algebra. Thus projections are fundamental elements in the von Neumann algebra. Researching the properties of them and classifying them can help us to classify general von Neumann algebras. By the properties of the projections contained in a von Neumann algebras, general von Neumann algebras can be classified as $5$ different categories and we can see that the abelian one is belong to what category.

\section{General Von Neumann Algebras}

\subsection{Elementary Properties}

\begin{prop}
	If $\{A_i\}$ is an increasing net of self-adjoint operators on $\Hs$ s.t. $\sup_i{\norm{A_i}} < \infty$, then there is an operator $A$ s.t. the following hold.
	\begin{enumerate}[label = \arabic*)]
		\item $A_i \leqslant A$ for all $i$ and if $B$ is any self-adjoint operator with $A_i \leqslant B$ for all $i$, then $A \leqslant B$. Thus $A = \sup_i A_i$.
		\item $A_i \sto A$ in $WOT$.
		\item $A_i \sto A$ in $SOT$.
		\item $A_i \sto A$ in $weak^{*}$.
	\end{enumerate}
\end{prop}
\begin{proof}
	Without loss of generality, assume all $A_i$ are positive.\\
	For any $h \in \Hs$, $\{\langle A_i h, h \rangle\}$ is an increasing positive sequence and bounded by $\alpha \norm{h}^2$ for $\alpha = \sup_i{\norm{A_i}}$. Then
	\begin{equation*}
		F(h,h) = \lim_i \langle A_i h, h \rangle,~ \abs{F(h,h)} \leqslant \alpha \norm{h}^2
	\end{equation*}
	Clearly, $F$ is a sesquilinear and by the Polar Identity, 
	\begin{equation*}
		\abs{F(g,h)} \leqslant \alpha \norm{g} \norm{h}
	\end{equation*}
	Then there is a $A \in \oper$ s.t. 
	\begin{equation*}
		\langle Ag,h \rangle = F(g,h) = \lim_i \langle A_i g, h \rangle
	\end{equation*}
	Therefore, $A$ is positive, $A \sto A_i$ in $WOT$, $A_i \leqslant A$ and $\norm{A} \leqslant \alpha$. Then
	\begin{equation*}
		0 \leqslant A - A_i \leqslant A \Rightarrow (A-A_i)^{\frac{1}{2}} \leqslant A^{\frac{1}{2}},~ \forall~ i
	\end{equation*}
	If $h \in \Hs$, then
	\begin{eqnarray*}
		\norm{(A-A_i)h}^2 &\leqslant& \norm{(A-A_i)^{\frac{1}{2}}}^2 \norm{(A-A_i)^{\frac{1}{2}}h}^2 \\
		&\leqslant& \norm{A} \norm{(A-A_i)^{\frac{1}{2}}h}^2 \\
		&=& \norm{A} \langle (A-A_i)h,h  \rangle \sto 0
	\end{eqnarray*}
	Thus $A_i \sto A$ in $SOT$. \\
	Finally, to see that $A_i \sto A$ in $weak^{*}$, consider $\{A_i^{(\infty)}\}$, and by $2)$, there is a $A^{(\infty)}$ s.t. $A_i^{(\infty)} \sto A^{(\infty)}$ in $WOT$, therefore, $A_i \sto A$ in $weak^{*}$.
\end{proof}

\begin{cor} \label{cor12}
	If $\A$ is a $\st{C}$-algebra contained in $\oper$ but without the identity and $\A$ is $weak^{*}$-closed, then there is a projection $P$ in $\A$ s.t.
	\begin{equation*}
		A = PA = AP,~ \forall~ A \in \A
	\end{equation*}
	Therefore, $P$ is the identity for $\A$ and $\A|_{P}$ is a von Neumann algebra.
\end{cor}
\begin{proof}
	There is an approximate identity $\{A_i\}$. By above proposition, 
	\begin{equation*}
		P = \sup_i A_i \in \A, \text{ and } A_i \sto P \text{ in } weak^{*}
	\end{equation*}
	Then for any $A \in \A$, $\norm{AA_i - A} \sto 0$ and $AA_i \sto AP$ in $weak^{*}$. Thus $A = AP =PA$.
\end{proof}

\begin{prop}
	\begin{enumerate}[label = \arabic*)]
		\item If $\A$ is a von Neumann algebra and $\fml{E}$ is a family of projections in $\A$, then $\bigvee \fml{E}$ and $\bigwedge \fml{E}$ belong to $\A$.
		\item If $\A$ is a von Neumann algebra and $1 \leqslant d \leqslant \infty$, then $\A^{(d)}$ is a von Neumann algebra and 
		\begin{equation*}
			(\A^{(d)})^{'} = \{~T=(T_{ij}) \in \fml{B}(\Hs^{(d)}) \colon T_{ij} \in \A^{'} ~\}
		\end{equation*}
		\item If $\A_i$ is a von Neumann algebra in $\fml{B}(\Hs_i)$ for all $i$ and $\Hs = \bigoplus_{i} \Hs_i$, then
		\begin{equation*}
			\A = \bigoplus_{i} \A_i = \{~ \bigoplus_i A_i \colon A_i \in \A_i,~ \sup_i{\norm{A_i}} < \infty~\}
		\end{equation*}
		is a von Neumann algebra.
	\end{enumerate}
\end{prop}

\begin{prop}
	Let $\{T_i\}$ and $\{S_i\}$ be nets in $\oper$.
	\begin{enumerate}[label=\arabic*)]
		\item If $T_i \sto 0$ in $WOT$ and $S_i \sto$ in $SOT$, then $S_iT_i,T_iS_i \sto 0$ in $SOT$.
		\item If $T_i \sto 0$ in $SOT$ and $K \in \coper$, then $T_iK$ and $KT_i$ convergence to $0$ in norm. If $T_i \sto 0$ in $WOT$ then $T_iK \sto 0$ in norm and $KT_i \sto 0$ in $SOT$.
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, since $T_i \sto 0$ in $WOT$, by the Principle of Uniform Boundedness, $\{T_i\}$ is norm boundedness. Since for any $h \in \Hs$, $\norm{S_i h} \sto 0$,
	\begin{equation*}
		\norm{T_iS_i h} \leqslant \norm{T_i} \norm{S_i h} \sto 0
	\end{equation*}
	And $\norm{S_iT_i h} \sto 0$ clearly.
	To prove $2)$, firstly for finite rank $K_n$ and let $h_1,\cdots,h_n$ and $g_1,\cdots,g_n$ be in $\Hs$,
	\begin{equation*}
		K_n = \sum_{i=1}^n h_i \otimes g_i
	\end{equation*}
	That means $\ran{K_n} = \spn{\{h_1, \cdots, h_n\}}$. Let $P_n$ be the projection onto $\ran{K_n}$, then $T_iK_n = T_iP_n$, 
	\begin{equation*}
		T_iK_n = T_iP_n \colon \ran{K_n} \longrightarrow \spn{\{T_ih_1, \cdots, T_ih_n\}}
	\end{equation*}
	And since the $WOT$ and the $SOT$ and the norm topology are same on a finite dimensional space, $T_iK_n \sto 0$ in norm for $T_i \sto 0$ in $WOT$ or in $SOT$. For any $K \in \coper$, there is a sequence of finite rank operators $\{K_n\}$ s.t. $K_n \sto K$ in norm. Since
	\begin{equation*}
		\norm{T_iK} = \norm{T_iK - T_iK_n} + \norm{T_iK_n}
	\end{equation*}
	$T_iK$ convergences to $0$ in norm for $T_i \sto 0$ in $WOT$ or in $SOT$.
	\begin{equation*}
		K_nT_i = \sum_{l=1}^{n} h_n \otimes (\st{T_i}g_n)
	\end{equation*}
	Thus,
	\begin{eqnarray*}
		\norm{K_nT_i} &\leqslant& \sum_{l=1}^{n} \norm{h_n \otimes (\st{T_i}g_n)} \\
		&=& \sum_{l=1}^n \norm{h_n}\norm{\st{T_i} g_n}
	\end{eqnarray*}
	If $T_i \sto 0$ in $SOT$, then $\norm{\st{T_i} g_n} \sto 0$ for all $n$, i.e. $\norm{K_nT_i} \sto 0$. Thus for $K \in \coper$, $KT_i \sto 0$ in norm. If $T_i \sto 0$ in $WOT$, for any $x \in \Hs$,
	\begin{eqnarray*}
		\langle K_n T_i x, K_n T_i x \rangle &=& \langle \sum_{l=1}^n \langle T_i x, h_l \rangle g_l, \sum_{m=1}^n \langle T_i x, h_m \rangle g_m \rangle \\
		&=& \sum_{l=1}^n \sum_{m=1}^n \langle T_i x, h_l \rangle \langle T_i x, h_m \rangle \langle g_l, g_m \rangle
	\end{eqnarray*}
	Therefore, if $T_i \sto 0$ in $WOT$, $\norm{KT_i x} \sto 0$ for $x \in \Hs$, i.e. $KT_i \sto 0$ in $SOT$.
\end{proof}

\subsection{Central Cover}

\begin{defn}
	For a von Neumann algebra $\A$, if $\fml{Z} = \A \cap \A^{'}$ is the center of $\A$, the central cover or central cover of $A \in \A$ is the projection
	\begin{equation*}
		C_A = \inf{\{~C \colon C \in \fml{Z} \text{ is a projection},~AC = A~\}}
	\end{equation*}
\end{defn}
\begin{rem}
	By above proposition, $C_A$ is definitely a projection satisfying
	\begin{equation*}
		AC_A = C_A = A
	\end{equation*}
\end{rem}

\begin{prop} \label{prop19}
	Let $\A$ be a von Neumann algebra.
	\begin{enumerate}[label=\arabic*)]
		\item If $A \in \A$, $E = (\ker{A})^{\bot}$ and $F = \clo{\ran{A}}$, then
		\begin{equation*}
			C_A = C_{\st{A}} = C_{\st{A}A} = C_{A\st{A}} = C_E = C_F
		\end{equation*}
		\item If $E$ is a projection in $\A$, then
		\begin{equation*}
			C_E = \clo{\spn{\{Ah \colon h \in E,~ A \in \A\}}}
		\end{equation*}
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, $C_A = C_{\st{A}}$ is trivial by the definition. If $C$ is a central projection s.t. $AC = A$, then $\st{A}AC = \st{A}A$. Conversely, if $\st{A}AC = \st{A}A$, then $\abs{A}C = \abs{A}$ by taking the root. By the Polar Decomposition, $AC = A$. Thus $C_A = C_{\st{A}A}$. \\
	Firstly, $E \in \A$. If $C$ is a central projection s.t. $AC = A$, then 
	\begin{equation*}
		C(\ker{A}) \subset \ker{A} \Rightarrow EC = CE = E \Rightarrow E \leqslant C
	\end{equation*}
	Therefore, $C_E \leqslant C_A$. Conversely, if $C$ is a central projection s.t. $E \leqslant C$, then 
	\begin{equation*}
		AC = AEC = AE = A
	\end{equation*}
	Thus $C_A \leqslant C_E$. Moreover, $C_F = C_E$.
	\item For $2)$, let
	\begin{equation*}
		P = \clo{\spn{\{Ah \colon h \in E,~ A \in \A\}}}
	\end{equation*}
	and clearly $P \in \A^{'}$. Moreover, for any $B \in \A^{'}$ and $h \in E$,
	\begin{equation*}
		BAh = ABh \in P \Rightarrow BP \subset P \Rightarrow P \in \A^{''} = \A
	\end{equation*}
	Therefore, $P$ is a central projection with $E \leqslant P$, thus $C_E \leqslant P$. Conversely, if $C$ is a central projection s.t. $EC = E$, then for $A \in \A$ and $h \in E$,
	\begin{equation*}
		C(Ah) = AC(Eh) = AEh = Ah \Rightarrow CP = P = PC
	\end{equation*}
	Thus $P \leqslant C$, then $P \leqslant C_E$.
\end{proof}

\begin{defn}
	If $\A$ is a con Neumann algebra and $E$ is a projection, defining
	\begin{equation*}
		\A_{E} = \{~A_E \colon A \in \A~\}
	\end{equation*}
	where $A_E = EA|_E$.
\end{defn}
\begin{rem}
	In general, $\A_E$ is not an algebra. However, if $E \in \A$, there is a $*$-isomorphism between $\A_E$ and $E\A E$. If $E \in \A^{'}$, there is a $*$-homomorphism between $\A_E$ and $E\A E$. $E \A E$ is clear a $\st{C}$-subalgebra of $\A$.
\end{rem}

\begin{prop} \label{prop20}
	Let $\A$ be a von Neumann algebra.
	\begin{enumerate}[label=\arabic*)]
		\item If $E \in \A^{'}$ is a projection, then $\A_E$ is a von Neumann algebra in $\fml{B}(E)$ and $(\A_E)^{'} = (\A)^{'}_E$.
		\item If $E \in \A$ is a projection, then $\A_E$ is a von Neumann algebra in $\fml{B}(E)$ and $(\A_E)^{'} = (\A)^{'}_E$.
		\item If $\fml{Z}$ is the center of $\A$ and $E$ is a projection in $\A$ or $\A^{'}$, then the center of $\A_E$ is $\fml{Z}_E$.
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, it is clear since $E$ reduces $\A$. 
	\item Assume that $E \in \A$. $\A_E$ and $(\A^{'})_E$ are $*$-algebra clearly. If $B \in \A^{'}$ and $A \in \A$, then for $h \in E$, 
	\begin{equation*}
		B_E A_E h = EBEAh = EAEBh = A_E B_E h
	\end{equation*}
	Therefore, $(\A)^{'}_E \subset (\A_E)^{'}$.
	\item Check: $(\A_E)^{'} \subset (\A)^{'}_E$ \\
	Let $U \in (\A_E)^{'} \subset \fml(B)(E)$ be a unitry, $A_1,\cdots,A_n \in \A$ and $h_1,\cdots,h_n \in E$, then
	\begin{eqnarray*}
		\norm{\sum_{k=1}^n A_k U h_k}^2 &=& \sum_{i,j}^n \langle A_iUh_i,A_jUh_j \rangle = \sum_{i,j}^n \langle (E\st{A_j}A_iE)Uh_i, Uh_j \rangle \\
		&=& \sum_{i,j}^n \langle U(E\st{A_j}A_iE)h_i, Uh_j \rangle = \sum_{i,j}^n \langle E\st{A_j}A_iEh_i, h_j \rangle \\
		&=& \norm{\sum_{k=1}^n A_k h_k}^2
	\end{eqnarray*}
	Therefore, for $C = \clo{\spn{\{Ah \colon h \in E,~ A \in \A\}}}$, there is a partical isometry with the initial space $C$,
	\begin{equation*}
		W(\sum_{k=1}^n A_k h_k) = \sum_{k=1}^n A_k U h_k
	\end{equation*}
	and $WC^{\bot} = 0$. By above proposition $C = C_E$. Therefore, for any $A \in \A$,
	\begin{equation*}
		WAC^{\bot} = WC^{\bot}A = 0 = AWC^{\bot}
	\end{equation*}
	and on $C$,
	\begin{equation*}
		WA \sum_{k=1}^n A_k h_k = W \sum_{k=1}^n A A_k h_k = A \sum_{k=1}^n A_kUh_k = AW\sum_{k=1}^n A_k h_k
	\end{equation*}
	Therefore, $W \in \A^{'}$ with $Wh = Uh$ for $h \in E$. So $W_E = U$. Since any element in $(\A_E)^{'}$ can be the linear combination of four unitaries, $(\A_E)^{'} \subset (\A)^{'}_E$.
	\item Check: $\A_E \subset \fml{B}(E)$ is von Neumann. \\
	Let $T \in (\A_E)^{''}$ and extending $T$ on $\Hs$ by setting $T = 0$ on $E^{\bot}$. If $B \in \A^{'}$, then $B_E \in (\A_E)^{'}$. For $h \in E$,
	\begin{equation*}
		TBh = (TE)Bh = T B_E h = B_E Th = B_E Th =B Th
	\end{equation*}
	And on the other hand,
	\begin{equation*}
		TBE^{\bot} = TE^{\bot}B = 0 = BTE^{\bot}
	\end{equation*}
	Thus $T \in \A^{''} = \A$, and $(\A_E)^{''} = \A_E$.
	\item For $3)$, by above mention, 
	\begin{equation*}
		\A_E \cap (\A_E)^{'} = \A_E \cap (\A)^{'}_E = \fml{Z}_E \qedhere
	\end{equation*}
\end{proof}

\subsection{Kaplansky Density Theorem}

For $\st{C}$-algebra $\A$, let $\mathcal{B}(\A)$ be the norm-closed unit ball in $\A$.

\begin{thm}[Kaplansky Density Theorem]
	If $\B$ is a $\st{C}$-subalgebra of $\oper$ and $\A = \clo{\B}^{SOT}$, then 
	\begin{enumerate}[label = \arabic*)]
		\item $\mathcal{B}(\A)$ is the $SOT$ closure of $\mathcal{B}(\B)$.
		\item $\mathcal{B}(\Rea{\A})$ is the $SOT$ closure of $\mathcal{B}(\Rea{\B})$.
		\item $\mathcal{B}(\A)_{+}$ is the $SOT$ closure of $\mathcal{B}(\B)_{+}$.
		\item the $SOT$ closure of the unitaries in $\B$ contains the unitaries of $\A$.
	\end{enumerate}
\end{thm}

\begin{lem}
	If $f \in C(\R)$ with $f(0)=0$ and there are positive constants $a,b$ s.t. 
	\begin{equation*}
		\abs{f(t)} \leqslant a\abs{t} + b,~ \forall~ t \in \R
	\end{equation*}
	then for any net $\{T_i\} \subset \Rea{\A}$ with $T_i \sto T$ in $SOT$, $f(T_i) \sto f(T)$ in $SOT$.
\end{lem}
\begin{proof}
	For any $g \in C(\R)$, then the map $g \colon \Rea{\oper} \sto \Rea{\oper}$ makes sence. Denote the set of all such $g$ s.t. $g$ is continuous w.r.t. the $SOT$ by $\mathcal{S}$ and let $\mathcal{S}_b$ be set of all norm bounded elements in $\mathcal{S}$. Clearly, $\mathcal{S}_b \mathcal{S} \subset \mathcal{S}$.\\
	Let $e(t) = t / (1+t^2)$ and $A,B \in \Rea{\oper}$,
	\begin{eqnarray*}
		e(A)-e(B) &=& (1+A^2)^{-1}(A(1+B^2)-(1+A^2)B)(1+B^2)^{-1} \\
		&=& (1+A^2)^{-1}(A-B)(1+B^2)^{-1} \\
		&& \negmedspace{} + (1+A^2)^{-1}A(B-A)B(1+B^2)^{-1}
	\end{eqnarray*}
	Then for any $h \in \Hs$,
	\begin{equation*}
		\norm{e(A)-e(B)} \leqslant \norm{(A-B)(1+B^2)^{-1}h} + \norm{(A-B)(1+B^2)^{-1}h}
	\end{equation*}
	Therefore, $e \in \mathcal{S}_b$. Put $e_{\alpha}(t) = e(\alpha)$, then $e_{\alpha}(t) \in \mathcal{S}_b$ for each $\alpha > 0$. Since $\{e_{\alpha} \colon \alpha > 0\}$ can separate the points in $\R \backslash \{0\}$ and $\mathcal{S}_b$ is closed,
	\begin{equation*}
		C_0(\R \backslash \{0\}) \subset \mathcal{S}_b
	\end{equation*}
	If $f$ satisfy above assumption, $t \sto f(t) / (1+t^2)$ belongs to $C_0(\R \backslash \{0\})$, and hence to $\mathcal{S}_b$. Since the identity funtion also belongs to $\mathcal{S}$ and the condition $f$ satisfies,
	\begin{equation*}
		t \longrightarrow \frac{tf(t)}{1+t^2} \in \mathcal{S}_b
	\end{equation*}
	And thus 
	\begin{equation*}
		t \longrightarrow \frac{t^2f(t)}{1+t^2} \in \mathcal{S}
	\end{equation*}
	Therefore,
	\begin{equation*}
		f(t) = \frac{t^2f(t)}{1+t^2} + \frac{f(t)}{1+t^2} \in \mathcal{S} \qedhere
	\end{equation*}
\end{proof}

Then by using above lemma and constructing some special functions, we can easily prove the Kaplansky Theorem.

\begin{proof}[proof of Kaplansky Theorem]
	Fix a $A \in \mathcal{B}(\Rea{\A})$ and a net $\{B_i\} \subset \Rea{\B}$ s.t. $B_i \sto A$ in $SOT$.
	\item For $2)$, if $f = (t \wedge 1) \vee (-1)$, then $f$ satisfies above lemma. Therefore,
	\begin{equation*}
		f(B_i) \longrightarrow f(A) =  A \text{ in } SOT
	\end{equation*}
	but $f(B_i) \in \mathcal{B}(\Rea{\B})$.
	\item Similarly, $3)$ holds by constructing the function $f(t) = (t \wedge 1) \vee 0$.
	\item Let $U \in \A$ be a unitary. Then by the functional calculus, there is a $A \in \Rea{\A}$ s.t.
	\begin{equation*}
		U = \exp{i A} = \cos{A} + i \sin{A}
	\end{equation*}
	Then let $\{B_i\} \subset \Rea{\B}$ be a net s.t. $B_i \sto A$ in $SOT$. Since both $\sin{t}$ and $\cos{t} - 1$  satisfy above lemma, 
	\begin{equation*}
		U_i =  \cos{B_i} + i \sin{B_i} \longrightarrow U \text{ in } SOT
	\end{equation*}
	and $U_i \in \B$ is a unitary.
	\item For $1)$, fix a $A \in \mathcal{B}(\A)$ and consider the $\st{C}-$algebras $M_2(\B)$ and $M_2(\A)$, then $M_2(\A)$ is the $SOT$-closure of $M_2(\B)$.
	\begin{equation*}
		\left(
			\begin{array}{cc}
				0 & A \\
				\st{A} & 0
			\end{array}
		\right)
		\in \mathcal{B}(\Rea{M_2(\A)})
	\end{equation*}
	therefore, by $1)$ there is a net $\{T_i\} \subset \mathcal{B}(\Rea{M_2(\B)})$ converges to above element in $SOT$. Put
	\begin{equation*}
		T_i = \left(
			\begin{array}{cc}
				X_i & B_i \\
				\st{B}_i & Y_i
			\end{array}
		\right)
	\end{equation*}
	Since $\norm{T_i} \leqslant 1$, $\norm{B_i} \leqslant 1$. Clearly, $B_i \sto A$  in $SOT$.
\end{proof}

\section{Topologies on Von Neumann Algebras}

\subsection{Pedersen Up-Down Theorem}

The order of all self-adjoint operators in von Neumann algebras can provide another important property of von Neumann algebras.

\begin{defn}
	For any subset $\mathcal{S} \subset \Rea{\oper}$, define
	\begin{eqnarray*}
		\mathcal{S}^{\sigma} &=& \{~T \colon \exists \{S_n\} \subset \mathcal{S}  \text{  increasing sequence, } S_n \sto T \text{ in } SOT~\} \\
		\mathcal{S}_{\sigma} &=& \{~T \colon \exists \{S_n\} \subset \mathcal{S}  \text{  decreasing sequence, } S_n \sto T \text{ in } SOT~\}
	\end{eqnarray*}
\end{defn}
\begin{rem}
	Note that $\mathcal{S}  \subset \mathcal{S}^{\sigma}$ and $\mathcal{S}_{\sigma} = -(-\mathcal{S})^{\sigma}$.
\end{rem}

\begin{lem}
	If $A$ and $B$ are two positive operators with $A  \leqslant B$, then
	\begin{equation*}
		A(1+A)^{-1} \leqslant B(1+B)^{-1}
	\end{equation*}
\end{lem}
\begin{proof}
	Because of $A(1+A)^{-1} = 1  - (1+A)^{-1}$ and the fact if $0 \leqslant A \leqslant B$, $B^{-1} \leqslant A^{-1}$, the lemma holds.
\end{proof}

\begin{lem}
	If $\B$ is a $\st{C}$-algebra and $\A = \clo{\B}^{SOT}$ and $P$ is a projection in $\A$, then for each sequence of unit $\{h_n\}$ in $\Hs$  there is a $A \in ((\mathcal{B}(\B_+))^{\sigma})_{\sigma}$ s.t.
	\begin{equation*}
		A(1-P)h_n = 0  = (1-A)Ph_n,~ \forall  n \geqslant 1
	\end{equation*}
\end{lem}
\begin{proof}
	By the Kaplansky Density Theorem and the sparability of $\Hs$, there is a sequence $\{C_n\}$ in $\mathcal{B}(\B_+)$ s.t. $C_n \sto P$ in $SOT$. Then it can assume that for $1 \leqslant j \leqslant  n$,
	\begin{equation*}
		\norm{C_n(1-P)h_j} < \frac{1}{n2^n},~ \norm{(1-C_n)Ph_j} < \frac{1}{n}
	\end{equation*}
	For $n < m$ define
	\begin{equation*}
		A_{nm} = \left(1+ \sum_{k=n}^m kC_k \right)^{-1}\sum_{k=n}^m kC_k
	\end{equation*}
	Then each $A_{nm} \in \mathcal{B}(\B_+)$ and $A_{nm} \leqslant \sum_{k=n}^m kC_k$. Thus for $j \leqslant n$,
	\begin{equation*}
		\langle A_{nm}(1-P)h_j, (1-P)h_j \rangle \leqslant \sum_{k=n}^m \frac{1}{2^k} < \frac{1}{2^{n-1}}
	\end{equation*}
	Since $\sum_{k=n}^m kC_k \geqslant mC_m$, by above lemma
	\begin{equation*}
		A_{nm} \leqslant (1+mC_m)^{-1} (mC_m) \Rightarrow 1-A_{nm} \leqslant (1+mC_m)^{-1}
	\end{equation*}
	By the fact for $0 \leqslant t \leqslant 1$, $(1+mt)^{-1} \leqslant (1+m)^{-1}(1+m(1-t))$ and $C_m \in \mathcal{B}(\B_+)$, 
	\begin{equation*}
		1- A_{nm} \leqslant (1+m)^{-1}(1+m(1-C_m))
	\end{equation*}
	Then it impilies that
	\begin{eqnarray*}
		\langle (1-A_{nm})Ph_j,Ph_j \rangle &\leqslant& \frac{1}{m} \langle (1+m(1-C_m))Ph_j,Ph_j \rangle \\
		&\leqslant& \frac{1}{m} (\norm{Ph_j}+m\norm{(1-C_m)Ph_j}) \\
		&\leqslant& \frac{2}{m}
	\end{eqnarray*}
	Fix a $n$, $\{A_{nm} \colon m > n\}$ is increasing by above lemma. Since it is bounded, there is a $A_n$  s.t. $A_{nm} \sto A_n$ fin $SOT$ and $A_n \in (\mathcal{B}(\B_+))^{\sigma}$. On the other hand, when $n+1 < m$, also by above lemma, it implies that $A_{n+1,m} \leqslant A_{nm}$, thus $A_{n+1} \leqslant A_n$. Thus there is a operator $A$ s.t. $A_n \sto A$ in $SOT$, and thus $A \in ((\mathcal{B}(\B_+))^{\sigma})_{\sigma}$. Moreover, by above
	\begin{eqnarray*}
		\langle A_n(1-P)h_j, (1-P)h_j \rangle &\leqslant& \frac{1}{2^{n-1}} \\
		\langle (1-A_n)Ph_j,Ph_j \rangle &\leqslant& 0
	\end{eqnarray*}
	As $n \sto \infty$, $A(1-P)h_n = 0  = (1-A)Ph_n$ for all $n$.
\end{proof}

\begin{thm}[Pedersen Up-Down Theorem]
	If $\Hs$ is a separable,  $\B$ is a \Cs contained in $\oper$, and $\A = \clo{\B}^{SOT}$, then
	\begin{equation*}
		\mathcal{B}(\A_+) = ((\mathcal{B}(\B_+))^{\sigma})_{\sigma} \text{ and } \Rea{\A} = (\Rea{\B})^{\sigma})_{\sigma}
	\end{equation*}
\end{thm}
\begin{proof}
	Firstly, by above lemma, for any projection $P \in \A$ and a dense subset in $\{h \in \Hs \colon \norm{h} =1\}$, there is a $A \in ((\mathcal{B}(\B_+))^{\sigma})_{\sigma}$ s.t. $A(1-P) = 0  = (1-A)P$.\\
	For $A \in (\mathcal{B}(\A_+)$ with the spectral measure $E$ and $k \leqslant 1$,
	\begin{equation*}
		P_k = E \left(\bigcup_{j=1}^{2^k-1}(\frac{j}{2^k}, \frac{j+1}{2^k}] \right)
	\end{equation*}
	then by the integral, $A  =  \sum_{k=1}^{\infty}  2^{-k}P_k$ converging by the norm. Then for each $k$, there is a decreasing sequence $\{Z_{kn}\}$ in $(\mathcal{B}(\B_+))^{\sigma}$ s.t. $Z_{kn} \sto  P_k$ in $SOT$, define
	\begin{equation*}
		T_n = \sum_{k=1}^n \frac{1}{2^k} Z_{kn} + \frac{1}{2^n} \geqslant A
	\end{equation*}
	Since $(\mathcal{B}(\B_+))^{\sigma}$ is convex, $T_n \in (\mathcal{B}(\B_+))^{\sigma}$. Moreover, because of $Z_{+1,n+1} < 1$,
	\begin{equation*}
		T_{n} - T_{n+1}  = \sum_{k=1}^n \frac{1}{2^k} (Z_{kn} -  Z_{k,n+1}) + \frac{1}{2^n} (\frac{1}{2^{n+1}}Z_{n+1,n+1} + \frac{1}{2^{n+1}}) \leqslant 0
	\end{equation*}
	Thus $\{T_n\}$ is decreasing and there is some $T \in ((\mathcal{B}(\B_+))^{\sigma})_{\sigma}$ with $T \geqslant A$ s.t. $T_n \sto T$ in $SOT$.
	\item Check: $A = T \in ((\mathcal{B}(\B_+))^{\sigma})_{\sigma}$ \\
	Since $0 \leqslant Z_{kn} - P_k \leqslant 1$, the series $\sum_k 2^{-k}(Z_{kn}-P_k)$ is convergent. Then for any unit $h \in \Hs$ and $\varepsilon > 0$, chose $N$ s.t. $2^{-N} < \varepsilon$, then there is an $n_0$ s.t. 
	\begin{equation*}
		0 \leqslant \langle (Z_{kn}-P_k) h,h \rangle < \frac{\varepsilon}{2}, \text{ for } 1 \leqslant k \leqslant N \text{ and } n \geqslant n_0
	\end{equation*}
	Therefore,
	\begin{equation*}
		\lim_{n \sto \infty} \sum_{k=1}^{\infty} \frac{1}{2^k} \langle (Z_{kn}-P_k) h,h \rangle = 0,~ \forall h \in \Hs
	\end{equation*}
	However,
	\begin{equation*}
		0 \leqslant T_n - A = T_n - \sum_{k=1}^{\infty} \frac{1}{2^k} P_k \leqslant \frac{1}{2^n} + \sum_{k=1}^{\infty} \frac{1}{2^k}(Z_{kn}-P_k)
	\end{equation*}
	Therefore, $T_n \sto A$ in $WOT$, but $T_n \sto T$ in $SOT$, thus $T = A$. 
	\item Check: $\Rea{\A} = (\Rea{\A})^{\sigma})_{\sigma}$ \\
	Fix $A \in \Rea{\A}$ and let $\alpha = -\norm{A}$.  Therefore, $A+\alpha \leqslant 0$. Let $\beta = \norm{A+\alpha}$, so $T=\beta^{-1}(A+\alpha) \in \mathcal{B}(\A_+)$ and $A = \beta T -\alpha$. But $\beta T \in ((\mathcal{B}(\B_+))^{\sigma})_{\sigma}$  and $-\alpha \in \mathcal{B}(\B)$. Thus $A  \in ((\mathcal{B}(\Rea{\B}))^{\sigma})_{\sigma}$.
\end{proof}

The Up-Down Theorem can reveal the basic property of general von Neumann algebras.

\begin{thm} \label{thm16}
	If $\A$ is a \Cs contained in $\oper$, then $\A$ is $weak^*$-closed if and only if it contains the supremum of every bounded increasing net of self-adjoint operators in the algebra.
\end{thm}
\begin{proof}
	$\A$ is $weak^*$-closed, thus $\A$ is  a von Neumann algebra. Therefore, by above proposition $\A$ has this property. Assume that $\A$ is a \Cs and if $\{A_i\}$ is an increasing net in $\Rea{\A}$ with $A_i \sto A$ in $SOT$, then $A \in \A$. Then by taking the negatives of the increasing parts, it is also true for that if $\{A_i\}$ is an decreasing net in $\Rea{\A}$ with $A_i \sto A$ in $SOT$, then $A \in \A$. Therefore, 
	\begin{equation*}
		\Rea{\A} = ((\mathcal{B}(\Rea{\A}))^{\sigma})_{\sigma}
	\end{equation*}
	Then if $\Hs$ is separable, by the Up-Down Theorem $\A$ is $weak^*$-closed. \\
	For the general case, let $\B = \clo{\A}^{SOT}$. It is sufficient to show that any projection contained in $\B$ is contained in $\A$. Let $P$ be the projection in $\B$ and $g \in P$ and $h \in P^{\bot}$. Then by above lemma, there is an $T \in \A_+$ s.t. $Tg = g$ and $Th = 0$. Let $R$ be projection onto $\clo{\ran{T}}$ and $Rg = g$ and $Rh = 0$, moreover $R \in \A$ because of the hypothesis and the Spectral Theorem. For any $g \in P$ and $h \in P^{\bot}$, denote the $R$ by $R_{gh}$. Fix $g \in P$ and 
	\begin{equation*}
		\fml{F} = \{~h_1, h_2, \cdots, h_m\} \subset P^{\bot}
	\end{equation*}
	then $R_{\fml{F}} = R_{gh_1} \wedge R_{gh_2} \wedge \cdots \wedge R_{gh_m} \in \A$. And $\{R_{\fml{F}}\}$ is a decreasing net and thus $R_g = \lim-SOT R_{\fml{F}} \in \A$. And since $R_g P^{\bot} = 0$, $R_g \leqslant P$ for all $g \in P$. Then let
	\begin{equation*}
		\fml{G} = \{~g_1, g_2, \cdots, g_n\} \subset P
	\end{equation*}
	$R_{\fml{G}} = R_{g_1} \vee R_{g_2} \vee \cdots \vee R_{g_n} \in \A$. And $\{R_{\fml{G}}\}$ is an increasing net and thus $R = \lim-SOT R_{\fml{F}} \in \A$. Therefore, $R = P \in \A$.
\end{proof}

\subsection{Normal Homomorphisms}

\begin{defn}
	If $\A$ and $\B$ are von Neumann algebras and $\rho \colon \A \sto \B$ is a linear positive map, then $\rho$ is normal if for any increasing net $\{A_i\}$ in $\A$ with $A_i \sto A$ in $SOT$, $\rho(A_i) \sto \rho(A)$ in $SOT$.
\end{defn}
\begin{rem}
	In particular, if $E \in \A$, $A \mapsto EAE$ is a normal homomorphism. The normal homomorphsims should be postive linear maps that are continuous with respect to the $SOT$, but in above definition, there is an extra condition. In fact, this extra condition has an equivalent expression.
\end{rem}

If $\A$ is a von Neumann algebra, the $\A$ is $weak^*$-closed, therefore $\A$ is the dual space of some Banach space. Let $\A_*$ be the space of all $weak^*$-continuous functionals on $\A$, then $\A  = (\A_*)^*$. And also 
\begin{equation*}
	\A_* \cong \toper / \A_{\bot},
\end{equation*}
where $\A_{\bot}$ is the space of all trace class annihilating the $\A$. Therefore, for any $L \in \A_*$, there is $T \in \toper$ s.t. for all $A \in \A$, 
\begin{equation*}
	L(A) = \tr{(AT)}
\end{equation*}
In fact, if $L$ is positive, then $T$ can be chosen as a positive element.

\begin{lem}
	If $\phi$ and $\psi$ are positive functionals on a von Neumann algebra $\A$ s.t. there is an operator $A \in \A_+$ with $\phi(A)  < \psi(A)$, then there is an operator $B \in \A_+$ s.t. $B \leqslant A$ and $\phi(T) < \psi(T)$ for all $T \in \A$ with $0 <  T \leqslant  B$. If $A$ is projection, then $B$ can be chosen as a projection.
\end{lem}
\begin{proof}
	Let $\mathcal{C}$ be the set of all $C \in \A_+$ s.t. $C \leqslant A$ and $\phi(C) \leqslant \psi(C)$. And give $\mathcal{C}$ with the usual order. Then if $\{C_i\}$ is the chain in $\mathcal{C}$ and let $C = \sup_i C_i \in \A_+$  and $C \leqslant A$. Since $\phi$ and $\psi$ is positive, $C \in \mathcal{C}$. Then by the Zorn's Lemma, there is a maximal element $C$ in $\mathcal{C}$. Put $B = A-C$. If $T \in \A_+$ with $0 < T \leqslant B$, by the maximality of $C$, $T \notin \mathcal{C}$, thus $\phi(T) < \psi(T)$. Moreover, if $A$ is a projection, $B \leqslant A$ implies that $\clo{\ran{B}} \leqslant A$. If $B = \int_0^1 t dP(t)$ be the spectral decomposition, then for any $\varepsilon >  0$, $P = P([\varepsilon,1])$. Then $P$ satisfies above condition.
\end{proof}

\begin{thm}
	If $\psi$ is a positive linear functional on the von Neumann algebra $\A$, then the following statements are equvilaten.
	\begin{enumerate}[label = \arabic*)]
		\item $\psi$ is normal.
		\item If $\{E_i\}$ is a pairwise orthogonal family of projections in $\A$, then 
		\begin{equation*}
			\psi(\sum E_i) = \sum \psi(E_i)
		\end{equation*}
		\item $\psi$ is $weak^*$-continuous.
		\item There is a positive trace class operator $C$ s.t. $\psi(A) = \tr{(AT)}$ for all $A \in \A$.
	\end{enumerate}
\end{thm}
\begin{proof}
	Without loss the generality, assuming that $\psi(1) = 1$.
	\item $1) \Rightarrow 2)$: It is trivial.
	\item $2) \Rightarrow 3)$: Since $0 \leqslant \psi(E) \leqslant 1$ for any non-zero projection $E$, for any $h \in \Hs$,
	\begin{equation*}
		\psi(E) \leqslant \langle Eh,h \rangle
	\end{equation*}
	Therefore, by preceding lemma, there is a projection $F$ with $0 \leqslant F \leqslant E$ s.t.
	\begin{equation*}
		\psi(T) \leqslant \langle hT,h \rangle,~ \forall 0 \leqslant  T \leqslant F
	\end{equation*}
	Since $FAF \leqslant \norm{A}F$, 
	\begin{equation*}
		\psi(FAF) \leqslant \norm{A} \langle FAFh,h \rangle
	\end{equation*}
	Then by the CBS inequality, for any $A \in \mathcal{B}(\A)$
	\begin{equation*}
		\abs{\psi(AF)}^2 \leqslant \psi(F\st{A}AF) \leqslant \norm{A}^2 \langle F\st{A}AFh,h \rangle = \norm{A}^2 \norm{AFh}^2
	\end{equation*}
	Therefore, $\psi(\cdot F) \colon \A \sto \C$ is $SOT$-continuous. \\
	Let $\{E_i\}$ be the maximal family of pairwise orthogonal projections in $\A$ s.t. $\psi(\cdot E_i)$ is $SOT$-continous on $\A$. Let $E = \sum_i E_i$. Clearly, $E = 1$. If $E \neq 1$, then there is a projection $F \leqslant E^{\bot}$ s.t. $\psi(\cdot F)$ is $SOT$-continous on $\A$, which contradicts the maximality of $\{E_i\}$. Then by $2)$,
	\begin{equation*}
		\psi(\sum_i E_i) = \psi(1) = 1
	\end{equation*}  
	Therefore, for any $\varepsilon > 0$, there is a finite set $I_0$ of index s.t. for any $J$ with $I_0 \subset J$, and let $P_J = \sum_J E_j$,
	\begin{equation*}
		\psi{P_J^{\bot}} = 1- \psi(P_J) < \varepsilon
	\end{equation*}
	Then for any $A \in \mathcal{B}(\A)$, 
	\begin{equation*}
		\abs{\psi(AP_J^{\bot})}^2  \leqslant \psi(A\st{A})\psi(P_J) < \varepsilon
	\end{equation*}
	And thus for any $J$ with $I_0 \subset J$,
	\begin{equation*}
		\norm{\psi - \psi(\cdot P_J)} = \sup{\{~\abs{\psi(AP_J)} \colon A \in \mathcal{B}(\A)~\}} < \sqrt{\varepsilon}
	\end{equation*}
	Since $\psi(\cdot P_J) \in \A_*$, $\psi \in \A_*$.
	\item $3) \Rightarrow 4)$: Firstly, assume that $\psi(A) = \langle Ag,h \rangle$ for some $g,h \in \Hs$. \\
	Check: $\psi(A) = \langle Af, f \rangle$ for some $f \in \Hs$. \\
	By the fact that $A \in \A_+$, $\langle Ag,h \rangle \leqslant 0$, 
	\begin{eqnarray*}
		4\langle Ag,h \rangle &=& \langle A(g+h),g+h \rangle - \langle A(g-h),g-h \rangle \\
		&\leqslant& \langle A(g+h),g+h \rangle
	\end{eqnarray*}
	Let $\phi(A) = \frac{1}{4}\langle A(g+h),g+h \rangle$, then $\psi(A) \leqslant \phi(A)$. By the \textbf{Proposition} \ref{prop17} in the subsection \textbf{3.2.7}, there is a $T \in \A^{'}$ with $0 \leqslant T \leqslant 1$ s.t. 
	\begin{equation*}
		\psi(A) =  \langle AT(g+h),g+h \rangle
	\end{equation*}
	Let $f = T^{\frac{1}{2}}(g+h)$, then $\psi(A) = \langle Af, f \rangle =  \tr{(Af \otimes f)}$, where $f \otimes f$ is a positive trace class. \\
	For general case, since $\psi \in \A_*$, by above mention, there is a $D \in \coper$ s.t. $\psi(A) = \tr{(AD)}$. By the \textbf{Theorem} \ref{thm15} in the subsection \textbf{5.3.3}, there are $g, h \in \Hs^{(\infty)}$  s.t.
	\begin{equation*}
		\psi(A)  = \tr{(AD)} = \langle A^{(\infty)}g,h \rangle = \langle A^{(\infty)}f,f \rangle
	\end{equation*} 
	Then there is a $C \in \coper$, s.t.
	\begin{equation*}
		\langle A^{(\infty)}f,f \rangle = \tr{(AC)}
	\end{equation*}
	And in fact, if $f = (f_i) \in \Hs^{(\infty)}$, $C = \sum_i f_i \otimes f_i \geqslant 0$.
	\item $4) \Rightarrow 1)$: It is trivial by definition.
\end{proof}

Then by using the above theorem, the equivalent statement as the following corollary shows can make the definition of normal homomorphism more nature.

\begin{cor}
	If $\A$ and $\B$ are von Neumann algebras and $\rho \colon \A \sto \B$ is a positive linear map, then $\rho$ is normal if and only if it is $weak^*$-continuous. 
\end{cor}
\begin{proof}
	If $\rho$ is $weak^*$-continuous, then it is clearly normal. Conversely, if $\rho$ is normal and $\phi \in \B_*$ such that $\phi$ is positive, then $\phi \circ  \rho$ is a normal functional on $\A$. By preceding theorem and the fact that all element in $\B_*$ can be linear combination of four positive elements, $\phi \circ  \rho$ is $weak^*$-continuous for all $\phi \in \B_*$. Therefore, by the Hahn-Banach Theorem, $\rho$ is $weak^*$-continuous.
\end{proof}

\begin{prop}
	Every $*$-isomorphism between von Neumann algebras is normal.
\end{prop}
\begin{proof}
	Let $\rho \colon \A \sto \B$ be $*$-isomorphism between von Neumann algebras $\A$ and $\B$. If $\{\A_i\}$ is an increasing net of self-adjoint operators in $\A$ with $A = \sup_i A_i$, then $\{\rho(\A_i)\}$ is an increasing net in $\B$ with $\rho(\A_i) \leqslant \rho(A)$ for all $A_i$. Thus 
	\begin{equation*}
		B = \sup_i  \rho(A_i) \leqslant \rho(A)
	\end{equation*}
	Conversely, $A_i = \rho^{-1}\rho(A_i)  \leqslant \rho^{-1}(B)$ for all $A_i$. That means $A \leqslant \rho^{-1}(B)$. Therefore, $A =  \rho(B)$.
\end{proof}

\subsection{Ideals}

Rather than considering norm closed ideals in $\st{C}$-algebras, in von Neumann algebras, $WOT$-closed ideal should be paid more attention on, or equivalently, $weak^*$-closed ideal.

\begin{thm}
	Let $\A$ be a von Neumann algebra.
	\begin{enumerate}[label=\arabic*)]
		\item $\B$ is a $weak^*$-closed hereditary subalgebra of $\A$ if and only if there is a unique projection $P$ in $\A$ s.t. $\B = P \A P$.
		\item $\I$ is a $weak^*$-closed left ideal of $\A$ if and only if there is a unique projection $P$ in $\A$ s.t. $\I = \A P$.
		\item $\I$ is a $weak^*$-closed ideal of $\A$ if and only if there is a unique central projection $P$ in $\A$ s.t. $\I = \A P = P \A$.
	\end{enumerate}
\end{thm}
\begin{proof}
	For $1)$, if $\B = P \A P = \A P \cap P \A = \A P \cap \st{(\A P)}$, $\B$ is hereditary by the fact that $\A P$ is a norm closed left ideal and \textbf{Theorem} \ref{thm6} in the subsection \textbf{3.2.5}. And clearly, $\B$ is $weak^*$-closed subalgebra. Conversely, if $\B$ is a $weak^*$-closed hereditary subalgebra, then by the \textbf{Corollary} \ref{cor12} in the subsection \textbf{6.1.1}, there is a central projection $P \in \B$ s.t. $\B = P \B = \B P$, thus $\B \subset P \A P$. If $A \in \A_+$, then $PAP  \leqslant \norm{A} P \in \B$. Since $\B$ is hereditary, $PAP \in \B$. Therefore, $\B =  P \A P$. The uniqueness of $P$ is because any such $P$ is the identity for $\B$.
	\item For $2)$, if $\I$ is a $weak^*$-closed left ideal of $\A$, then $\B = \I \cap \st{\I}$ is a $weak^*$-closed hereditary subalgebra. Then there is a projection $P \in \B \subset \I$ s.t. $\B =  P \A P$. Thus $\A P \subset \I$. Conversely, if $T \in \I$, then $\st{T}T \in \B_+ = \I_+$. Therefore, $\st{T}T P = \st{T}T$ and so $\abs{T}P = \abs{T}$. By the Polar Decomposition, $T = TP \in \A P$. Hence, $\I = \A P$. And the unqueness of $P$ is because the uniqueness of $P$ in $\B$.
	\item For $3)$, That $\I$ is a $weak^*$-closed ideal of $\A$, also norm closed, implies that $\I = \st{I}$. Then by $1)$ and $2)$, there is a projection $P \in \I$ s.t. $\I = \A P = P \A$. Moreover, for any $A \in \A$,
	\begin{equation*}
		PA = P(PA) = P (PAP) = (PA) P = AP
	\end{equation*}
	Therefore, $P$ is in the center of $\A$.
\end{proof}

For the ideal in a von Neumann algebra, it is always assumed as the $weak^*$-closed ideal. Thus, there is a direct corollary of above theorem about the simple von Neumann algebras.

\begin{cor}
		A von Neumann algebra $\A$ is simple if and only if 
		\begin{equation*}
			\fml{Z} = \A \cap \A^{'} = \C I
		\end{equation*}
\end{cor}

\begin{defn}
	A von Neumann algebra $\A$ is called factor, if 
	\begin{equation*}
		\fml{Z} = \A \cap \A^{'} = \C I
	\end{equation*}
\end{defn}
\begin{rem}
	By above corollary, factors are simple von Neumann algebras. Moreover, for a von Neuamnn algebra $\A$,  if $P \in \fml{Z}$ is a projection, then $\A = P \A + P^{\bot} \A$, where $P \A$ and $P^{\bot} \A$ are von Neumann algebras. And by above mention, $P \A = P \A P \cong \A_P$. Therefore, any von Neumann algebra is semi-simple and since $\I = P \A$ is an ideal, $\A / \I \cong P^{\bot} \A$
\end{rem}

\begin{thm}
	If $\A$ and $\B$ are von Neumann algebras and $\rho \colon \A \sto \B$ is a normal $*$-homomorphism, then $\ker{\rho}$ is $weak^*$-closed and $\rho(\A)$ is $weak^*$-closed in $\B$. Moreover, there is a central projection $P$ s.t. $\ker{\rho} =  P^{\bot} \A$ and $\rho$  is a $*$-isomorphism of $P \A$ onto $\ran{\rho}$.
\end{thm}
\begin{proof}
	Check: $\ker{\rho}$ is $weak^*$-closed. \\
	If $\{A_i\}$ is a bounded increasing net in $\Rea{\ker{\rho}}$, then put $A = \sup_i A_i$. Since $\rho$ is normal, $\rho(A) = \sup_i \rho(A_i) = 0$. Therefore, $A \in \ker{\rho}$. Then by \textbf{Theorem} \ref{thm16} in the subsection \textbf{6.2.1}, $\ker{\rho}$ is $weak^*$-closed.
	\item Check: $\ran{\rho}$ is $weak^*$-closed. \\
	Let $\{B_i\}$ is a bounded increasing net in $\Rea{\ran{\rho}}$ and $B = \sup_i B_i$. Then put
	\begin{equation*}
		\Gamma = \{~A \in \A_+ \colon \rho(A) \in \{B_i\}~\}
	\end{equation*}
	\item Claim: $\Gamma$ is directed with respect to the usual order. \\
	Suppose $A_i, A_j \in \Gamma$ with $\rho(A_i) = B_i$ and $\rho(A_j)  = B_j$. Pick $B_k$ s.t. $B_i, B_j \leqslant B_k$. Therefore, there is a $T \in \A_+$ s.t. $\rho(T) = B_k-B_i$. If $C_i =  A_i + T$, then $C_i \geqslant A_i$ and $\rho(C_i) = B_k$. Similarly, there is a $C_j \geqslant A_j$ s.t. $\rho(C_j) = B_k$. Therefore, $C_i-C_j \in \ker{\rho}$, and if $A = C_i + \abs{C_i-C_j}$, then $\rho(A) = B_k$ and $C_i, C_j \leqslant A$. \\
	Fix $\varepsilon > 0$, by proof of the Pedersen Up-Down Theorem, the map  $A  \sto (1+\varepsilon A)^{-1}A$ is an increasing funnction on $\oper_+$. Thus $\{(1+\varepsilon A)^{-1}A \colon A \in \Gamma\}$ is an increasing function in $\A$ with the bound $\varepsilon^{-1}$. Put
	\begin{equation*}
		A_{\varepsilon}  = \sup{\{(1+\varepsilon A)^{-1}A \colon A \in \Gamma\}}
	\end{equation*}
	and $\norm{A_{\varepsilon}} \leqslant \varepsilon^{-1}$. Since $\rho$ is normal,
	\begin{equation*}
		\rho(A_\varepsilon) = (1+\varepsilon B)^{-1}B \in \ran{\rho}
	\end{equation*}
	But $(1+\varepsilon B)^{-1}B \sto B$ in norm and $\ran{\rho}$ is norm closed, thus $B \in \ran{\rho}$.  \\
	The rest of the theorem can be obtained by using above theorem.
\end{proof}

\section{Projections}

\subsection{Equivalence of Projections}

Projections in a von Neumann algebra play the role as generators, which lead to researching global properties of the von Neumann algebra is based on the properties of its projections, to some extend. Firstly, there is some equivalent relation between projections.

\begin{defn}
	Let $E$ and $F$ be two projections in a von Neumann algebra $\A$. $E$ and $F$ are equivalent, denoted by $E \sim F$, if there is a partial isometry $W \in \A$ s.t. $\st{W}W = E$ and $W\st{W} = F$. If there is a $G \leqslant F$ s.t. $E \sim F$, then denoting $E \lesssim F$.
\end{defn}

There are some properties of the equivalent projections.

\begin{prop}
	\begin{enumerate}[label=\arabic*)]
		\item In an ablien algebra, two projections are equivalent if an only if they are equal. 
		\item Two projections in $\oper$ are equivalent if and only if they have same dimensional.
		\item If $\A$ is a von Neumann algebra and $A \in \A$, then $\cran{A} \sim \cran{\st{A}}$.
		\item Let $E$ be a projection in a von Neumann algebra $\A$. $E \sim 0$ if and only if $E = 0$.
		\item If $E$ and $F$ are two projections in $\A$ with $E \sim F$, then for any central projection $Z$, $ZE \sim ZF$.
	\end{enumerate}
\end{prop}
\begin{proof}
	$1)$ holds trivially. For $2)$, by the proof of the Polar Decomposition, for a partial isometry $W$, $(\ker{W})^{\bot}$ and $\ran{W}$ are isometrically isomorphism. For $3)$, let $A = W\abs{A}$ the Polar Decomposition. Then
	\begin{equation*}
		\st{W}W = \cran{\abs{A}} = \cran{\st{A}},~ W \st{W} = \cran{A}
	\end{equation*}
	For $4)$, $E = \st{W}W$ and $W\st{W} = 0$. That means $W = 0$, thus $ E = 0$. \\
	$5)$ holds since $Z = \st{Z}Z$ and $Z$ is in center.
\end{proof}

\begin{lem}
	For projections $E$ and $F$:
	\begin{enumerate}[label=\arabic*)]
		\item $\cran{EF} = E \wedge (E \wedge F^{\bot})^{\bot} = E - E \wedge F^{\bot}$;
		\item $\cran{EF^{\bot}} = E - E \wedge F$;
		\item $\cran{F^{\bot}E} = E \vee F - F$.
	\end{enumerate}
\end{lem}
\begin{proof}
	It is sufficien to prove $1)$. \\
	Check: $\ker{FE} = E^{\bot} + (E \vee F^{\bot})$. \\
	If $h \in \ker{FE}$ and expressing $h = g + f$ where $g \in E^{\bot}$ and $f \in E$, then $0 = FEh = Ff$. Thus $f \in F^{\bot}$, i.e. $f \in E \vee F^{\bot}$. Therefore,
	\begin{equation*}
		\ker{FE} \leqslant E^{\bot} + (E \vee F^{\bot})
	\end{equation*}
	Conversely, if $h = g + f$ with $g \in E^{\bot}$ and $f \in E \vee F^{\bot}$, then $FEh = Ff = 0$. Thus $\ker{FE} = E^{\bot} + (E \vee F^{\bot})$. \\
	Thus,
	\begin{equation*}
		\cran{EF} = (\ker{FE})^{\bot} = E \wedge (E \vee F^{\bot})^{\bot} = E - E \vee F^{\bot} \qedhere
	\end{equation*}
\end{proof}

\begin{prop}
	\begin{enumerate}[label = \arabic*)]
		\item If $E$ and $F$ are projections, then
			\begin{eqnarray*}
				E \vee F - F &\sim& E - E \wedge F \\
				E - E \wedge F^{\bot} &\sim& F -  E^{\bot} \wedge F 
			\end{eqnarray*}
		\item If $\{E_i\}$ and $\{F_i\}$ are two sets of pairwise orthogonal projections s.t. $E_i \sim_{W_i} F_i$ for all $i$, then
		\begin{equation*}
			E = \sum_i E_i \sim_W  F = \sum_i F_i
		\end{equation*}
		where $W =  \sum_i  W_i$.
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, by above proposition,
	\begin{equation*}
		\cran{F^{\bot}E}  \sim \cran{\st{F^{\bot}E}} = \cran{EF^{\bot}}
	\end{equation*}
	And by above lemma,
	\begin{equation*}
		\cran{F^{\bot}E} = E \vee F - F, \text{ and } \cran{EF^{\bot}} = E - E \wedge F
	\end{equation*}
	Therefore, the first equivalence is obtained. By $\cran{FE} \sim \cran{EF}$, the second is also true. 
	\item For $2)$, if $h \in \Hs$,
	\begin{eqnarray*}
		\norm{Eh}^2 &=&  \langle Eh,h \rangle = \sum_i \langle E_ih,h \rangle  \\
		&=& \sum_i \langle \st{W_i}W_ih,h \rangle = \sum_i \norm{W_i}^2
	\end{eqnarray*}
	Since $\{W_i h\}$ is an orthogonal set, $\sum_i W_i$ converges strongly. Therefore put $W = \sum_i W_i$. And by the fact that $\{E_i\}$  are pairwise orthogonal, for any finite subset $I$  of index, 
	\begin{equation*}
		\st{(\sum_{i \in I} W_i)}(\sum_{i \in I} W_i) = \sum_{i \in I} \st{W_i}W_i = \sum_{i \in I} E_i
	\end{equation*}
	Then by SOT convergence, $\sum_i \st{W_i}W_i = \sum_i E_i$, and it is also valid for $F$.
\end{proof}

\begin{prop}
	If $E$ and $F$ are two projections in $\A$, then the following statements are equivalent.
	\begin{enumerate}[label=\arabic*)]
		\item There are nonzero projections $E_1$ and $F_2$ in $\A$ s.t. $E_1 \leqslant E$ and $F_1 \leqslant F$, and $E_1 \sim F_1$
		\item $C_E C_F  \neq 0$.
		\item $E\A F \neq \{0\}$.
	\end{enumerate}
\end{prop}
\begin{proof}
	$1) \Rightarrow 2)$: By above lemma, $C_{E_1} =  C_{F_1}$ and $C_{E_1} \leqslant C_{E}$ and $C_{F_1} \leqslant C_{F}$, thus $C_E C_F  \neq 0$.
	\item $2) \Rightarrow 3)$: Since $C_E = \clo{\spn{\A E}}$ and $C_F = \clo{\spn{\A F}}$, if $E\A F = \{0\}$, $EC_F = 0$. Thus $C_E  \leqslant C_F^{bot}$, which is a contradition.
	\item $3) \Rightarrow 2)$: If $A \in \A$ s.t. $EAF \neq 0$, let $E_1 = \cran{EAF}$ and $F_1 = \cran{\st{EAF}} = \cran{F\st{A}E}$. Therefore, $E_1 \leqslant E$ and $F_1 \leqslant F$, and $E_1 \sim F_1$.
\end{proof}

\begin{thm}[Comparison Theorem]
	If $E$ and $F$ are two projections in $\A$, then there is a central projection $Z$ s.t.
	\begin{equation*}
		ZE \lesssim ZF, \text{ and } Z^{\bot}F \lesssim Z^{\bot}E
	\end{equation*}
\end{thm}
\begin{proof}
	Finding $Z$. \\
	By Zorn's Lemma, there is a maximal family $\{(E_i,F_i)\}$ of pairs of projections in $\A$ s.t. for all $i$,
	\begin{equation*}
		E_i \sim F_i,~ E_i \leqslant E,~ F_i \leqslant F
	\end{equation*}
	and $\{E_i\}$ and $\{F_i\}$ are pairwise orthogonal. Then by above proposition,
	\begin{equation*}
		E^{'} = \sum_i  E_i \sim \sum_i F_i = F^{'}
	\end{equation*}
	Then put $E^{''} = E - E^{'}$ and $F^{''} = F - F^{'}$. Therefore by the maximality and above proposition, $C_{E^{''}}C_{F^{''}} = 0$, then put $Z = C_{F^{''}}$.\\
	Check: $ZE \lesssim ZF$ and $Z^{\bot}F \lesssim Z^{\bot}E$. \\
	Let $W$ be the partial iosmetry s.t. $E^{'} = \st{W}W$ and $F^{'} = W\st{W}$. Then $ZE^{'} \sim_{ZW} ZF^{'}$. Therefore,
	\begin{equation*}
		EZ = E^{'}Z + E^{''}Z = E^{'}Z + E^{''}C_{E^{''}}C_{F^{''}} = E^{'}Z \sim ZF^{'} \leqslant ZF
	\end{equation*}
	Hence, $ZE \lesssim ZF$. Similarly, $Z^{\bot}F \lesssim Z^{\bot}E$.
\end{proof}

\begin{cor}
	If $\A$ is a factor and $E$ and $F$ are two projections in $\A$, then either $E \lesssim F$ or $F \lesssim E$.
\end{cor}

\begin{lem}
	If $\mathcal{L}$ is a complete lattice and $\tau \colon \mathcal{L} \sto \mathcal{L}$  is an order preserving map, then there is an $x_0 \in \mathcal{L}$ s.t. $x_0 = \tau(x_0)$.
\end{lem}
\begin{proof}
	Put $T = \{x \in \mathcal{L} \colon x \leqslant \tau(x)\}$ and $x_0 = \sup{T} \in \mathcal{L}$. If $x \in T$, then
	\begin{equation*}
		x \leqslant x_0, \text{ and } x \leqslant \tau(x) \leqslant \tau(x_0) \Rightarrow x_0 \leqslant \tau(x_0)
	\end{equation*}
	Conversely, above inequality implies that $\tau(x_0) \leqslant \tau(\tau(x_0))$, thus $\tau(x_0) \in T$. Therefore, $x_0 \geqslant \tau(x_0)$.
\end{proof}

\begin{thm}
	If $E$ and $F$ are two projections in $\A$ s.t. $E \lesssim F$ and $F \lesssim E$, then $E \sim F$.
\end{thm}
\begin{proof}
	Let $W$ and $V$ and two partial isometry s.t. $E = \st{W}W$ and $W\st{W} \leqslant F$ and $F = \st{V}V$ and $V\st{V} \leqslant E$. Let $\mathcal{L}$ be the set of all projection $G$ in $\A$ s.t. $G \leqslant F$. Then $\mathcal{L}$ is complete lattice. Define the map $\tau$ on $\mathcal{L}$ as
	\begin{center}
		\begin{tabular}{l c c l}
			$\tau \colon$ & $\mathcal{L}$ & $\longrightarrow$ & $\mathcal{L}$ \\
			~ & $G$ & $\longmapsto$ & $F-\st{W}(E-\st{V}GV)W$
		\end{tabular}
	\end{center}
	It is straightforward that $\tau$ is a order serving map, thus by above lemma, it has a fixed point $P$. Let $V_1 = PV$ and $W_1 = (E-\st{V}PV)W$, then
	\begin{eqnarray*}
		V_1\st{V_1} = P &,~& \st{V_1}V_1  = \st{V}PV \\
		W_1\st{W_1} = F - P &,~& \st{W_1}W_1 = E - \st{V}PV
	\end{eqnarray*}
	Thus $P \sim \st{V}PV$ and $F - P \sim E - \st{V}PV$, and by the additivity of equivalence, $F \sim E$.
\end{proof}

\subsection{Classification of Projections}

\begin{defn}
	A projection $E$ in a von Neumann algebra $\A$ is finite if the only projection $F$ in $\A$ s.t. $F \leqslant E$ and $F \sim F$ is $F = E$. Otherwise, $E$ is infinite. A von Neumann algebra $\A$ is called finite or infinite if the identity is finite or infinite.
\end{defn}
\begin{rem}
	This definition generalize the concept of finiteness. It is useful. In fact, any projection containing in an abelian von Neumann algebra $\A$ is finite. Finite von Neumann algebras have similar properties to ablian von Neumann algebras. Therefore under this classification of projections, the concept of abelian von Neuman algebras can be generalized.
\end{rem}

\begin{prop}
	\begin{enumerate}[label=\arabic*)]
		\item If $E$ is finite and $F \lesssim E$, then $F$ is finite.
		\item If $\A$ is a finite von Neumann algebra and $E$ is a projection in $\A$, then $\A_E$ is finite.
		\item If $\{E_i\}$ is a family of finite projections in $\A$ s.t. $\{C_{E_i}\}$ is pairwise orthogonal, then $\sum_i E_i$ is a finite projection.
		\item If $\{Z_i\}$ is a family of finite central projections, then $Z = \bigwedge_i Z_i$ is a finite central projection.
		\item If $\rho \colon \A \sto \B$ is a $*$-isomorphism and $E$ is a finite projection in $\A$, then $\rho(E)$ is a finite projection in $\B$.
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, assume that $F \leqslant E$. If $F_1 \leqslant F$ and $F_1 \sim F$, then by the addivity, 
	\begin{equation*}
		F_1 + (E - F) \sim E
	\end{equation*}
	By finiteness, $F_1 + (E - F) = E$. Therefore, $F_1 = F$, i.e. $F$ is finite. Then it is sufficient to prove that $F \sim E$ impiles that $F$ is finite. Let $W$ be the partial isometry s.t. $\st{W}W = F$ and $W\st{W} = E$. If $F_1 \leqslant F$ and $F_1 \sim F$, then $E_1 = WF_1$ satisfies
	\begin{equation*}
		E_1 \sim F_1 \sim F \sim E
	\end{equation*}
	Since $E$ is finite, $E_1 = E$. Therefore, $F = \st{W}E = \st{W}W E_1 = F_1$. Thus $F$ is finite. $2)$ holds by $1)$.
	\item For $3)$, put $E = \sum_i E_i$. Let $F \leqslant E$ be a projection in $\A$ s.t. $F \sim_{W} E$. For any $i$, 
	\begin{equation*}
		E - E_i \leqslant \sum_{j \neq i} C_{E_j} \Rightarrow (E - E_i)C_{E_i} = 0
	\end{equation*}
	Therefore, $E_i = EC_{E_i}$. Then for $W_i = WC_{E_i}$, $FC_{E_i} \sim_{W_i} EC_{E_i} = E_i$. Since $FC_{E_i} \leqslant EC_{E_i} = E_i$, $FC_{E_i} = E_i$. Therefore,
	\begin{equation*}
		E = \sum_i E_i = \sum_i FC_{E_i} \leqslant F \leqslant E
	\end{equation*}
	So $F = E$ and $E$ is finite.
	\item For $4)$, let $F \leqslant Z$ and $F \sim Z$, then $Z_i F \sim Z_i Z = Z_i$. Since $Z_i$ is finite, $Z_i F = Z_i$. Therefore, $F = Z$ and $Z$ is finite.
	\item $5)$ is true by definition.
\end{proof}

\begin{cor}
	If $\{\A_i\}$ is a collection of von Neumann algebras, then $\bigotimes \A_i$ is a finite von Neumann algebra if and only if each $\A_i$ is finite.
\end{cor}

There are some similar properties of finite von Neumann algebra as abelian von Neumann algebra.

\begin{prop}
	$\A$ is finite if and only if every left (or right) invertible element of $\A$ is invertible.
\end{prop}
\begin{proof}
	Assume that every left (or right) invertible element of $\A$ is invertible. If $E \sim_W 1$. Since $W\st{W} = 1$, $\st{W}W = 1 =E$. Thus, $\A$ is finite. Conversely, if $\A$ is finite and $A, B \in \A$ s.t. $AB = 1$, then $\ran{A} = 1$. But $\cran{\st{A}} \sim \cran{A}$. Therefore, $\cran{\st{A}} = 1$ by the finiteness. So, $\ker{A} = 0$. And combining the fact $\ran{A} = 1$, i.e $A$ is surjection, $A$ is invertible.
\end{proof}

\begin{prop}
	Let $\A$ be a finite von Neumann algebra.
	\begin{enumerate}[label=\arabic*)]
		\item If $E, E_1, F$ and $F_1$ are projections in $\A$ s.t. $E_1 \leqslant E$, $F_1 \leqslant F$ and $E \sim F$, $E_1 \sim F_1$, then 
		\begin{equation*}
			E - E_1 \sim F - F_1
		\end{equation*}
		\item If $E$ and $F$ are equivalent projections in $\A$, then there is a unitary  $U$ in $\A$ s.t. $\st{U}EU \sim F$.
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, by the Comparison Theorem, there is a central projection $Z$ s.t.
	\begin{eqnarray*}
		(E - E_1)Z &\lesssim& (F - F_1)Z \\
		(F - F_1)Z^{\bot} &\lesssim& (E - E_1)Z^{\bot}
	\end{eqnarray*}
	Choosing $F_2$ s.t. $F_2 \leqslant (F - F_1)Z$ and $F_2 \sim (E - E_1)Z$. Therefore, $F_2 + F_1Z \leqslant FZ$ and by the addivity
	\begin{equation*}
		F_2 + F_1Z \sim (E - E_1)Z + EZ \sim EZ \sim FZ
	\end{equation*}
	Since $FZ$ is finite, $F_2 + F_1Z = FZ$. Therefore, $F_2 = (F-F_1)Z$. That is, $(E - E_1)Z \sim (F - F_1)Z$. And similarly, $(E - E_1)Z^{\bot} \sim (F - F_1)Z^{\bot}$.
	\item For $2)$, by $1)$, $E \sim_W F$ implies that $E^{\bot} \sim_V F^{\bot}$. Then let $U = W + V$. $U$ is a unitary and $\st{U}EU \sim F$.
\end{proof}

\begin{defn}
	\begin{enumerate}[label=\arabic*)]
		\item $E$ is called an abelian projection in a von Neumann algebra if $E\A E \cong \A_E$ is an abelian von Neumann algebra.
		\item An von Neumann algebra $\A$ is called discrete if for every nonzero central projection $Z$ there is a nonzero abelian projection with $F \leqslant E$.
		\item An von Neumann algebra $\A$ is continuous if it contains no nonzero abelian projections.
		\item A projection $E$ in $\A$ is called discrete or continuous if $\A_E$ is discrete or continuous.
	\end{enumerate}
\end{defn}

\begin{prop}
	Let $\A$ be a von Neumann algebra.
	\begin{enumerate}[label=\arabic*)]
		\item A projection $E$ in $\A$ is discrete if and only if for every central projection $Z$ in $\A$ with $ZE \neq 0$, there is an abelian projection $F$ in $\A$ with $F \leqslant ZE$.
		\item A projection $E$ in $\A$ is continuous if and only if there is no nonzero abelian projection $F$ in $\A$ satifying $F \leqslant E$.
		\item Let $\B$ be a von Neumann algebra and $\rho \colon \A \sto \B$ be a normal, surjective $*$-homomorphism, and $E$ be a projection in $\A$. If $E$ is continous (or discrete or abelian), then $\rho(E)$ is continous (or discrete or abelian).
		\item If $E$ is continous (or discrete or abelian) in $\A$ and $F$ is a projection in $\A$ with $F \leqslant E$, then $F$ is continous (or discrete or abelian).
		\item If $\{E_i\}$ is a family of continous (or discrete or abelian) projections in $\A$ s.t. $\{C_{E_i}\}$ is pairwise orthogonal, then $\sum_i E_i$ is a continous (or discrete or abelian) projection.
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, it holds because that the center of $\A_E$ is $\fml{Z}_E$. Then for any $Z \in \fml{Z}$, there is an abelian projection $F \leqslant E$ in $\A$ with $FE \neq 0$ s.t. $EFE \leqslant EZE$, i.e. $F \leqslant ZE$. The converse is similar.
	\item The proof of $2)$ is similar as $1)$.
	\item For $3)$, it can assume $\rho$ is a $*$-isomorphism, then it follows by the definition.
	\item If $E \sim F$, then there is a normal, surjective $*$-homomorphism from $\A_E$ to $\A_F$. Therefore, by $3)$, it sufficiently assumes $F \leqslant E$. Then since $F \A F \subset E \A E$, if $E$ is abelian or continuous, $F$ is clearly abelian or continuous. \\
	Assume $E$ is discrete and $F \leqslant E$. Replacing $\A_E$ by $\A$, i.e. assuming $E = 1$ and $\A$ is discrete. Let $Z$ be a central projection with  $ZF \neq 0$. Thus
	\begin{equation*}
		ZC_F = C_{ZF} \neq 0
	\end{equation*}
	Then by the discreteness of $\A$, there is an abelian projection $G \leqslant ZC_F$. Therefore, 
	\begin{equation*}
		C_G C_{ZF} = C_{ZF} \neq 0
	\end{equation*}
	Then there are $G_1 \leqslant G$ and $F_1 \leqslant ZF$ s.t. $G_1 \sim F_1$. Thus $F_1 \lesssim G$, i.e. $F_1$ is abelian. Then by $1)$, $F$ is discrete. 
	\item Let $E_i$ be abelian. Since $\{C_{E_i}\}$ is pairwise orthogonal, if $A, B \in \A$, by the  fact, $EAE = \sum_i (EAE)C_{E_i}$ because $C_E = \sum_i C_{E_i}$,
	\begin{eqnarray*}
		(EAE)(EAE) &=& (\sum_i E_i A E_i)(\sum_j E_j B E_j) \\
		&=& \sum_i (E_i A E_i)(E_i B E_i) \\
		&=& \sum_i (E_i B E_i)(E_i A E_i) \\
		&=& (EBE)(EAE)
	\end{eqnarray*}
	Therefore, $E$ is abelian. \\
	Assume $E_i$ is discrete. If $Z$ is a central projection with $ZE \neq 0$, then for some $i$, $ZE_i \neq 0$. Then let $G_i \leqslant ZE_i$ be the abelian projection. If $ZE_i = 0$, let $G_i = 0$. Put $G = \sum_i G_i$ and since $C_{G_i} \leqslant C_{E_i}$, $G$ is abelian. Therefore, $E$ is discrete. Similarly, using $2)$, if $E_i$ is continuous, $E$ is continuous.
\end{proof}
\begin{rem}
	By $1)$ and $2)$, a projection in $\A$ is either discrete and continuous.
\end{rem}

\begin{cor}
	If $\{\A_i\}$ is a collection of von Neumann algebras and $\A = \bigoplus_i \A_i$, then $\A$ is continuous (or discrete or abelian) if and only if each $A_i$ is continuous (or discrete or abelian).
\end{cor}

If two projections $E$ and $F$ satisfy $E \lesssim F$, then $C_F \leqslant C_E$. But the converse is not alway true. However, if $E$ and $F$ are abelian, the converse holds.

\begin{lem}
	If $E$ is an abelian projection and $F \leqslant E$, then $F = C_F E$.
\end{lem}
\begin{proof}
	Since $E$ is abelian, $E \A E$ is abelian. In fact, $F \A (E-F) = \{0\}$. It is because that for any $A \in \A$,
	\begin{equation*}
		FA(E-F) = F(EAE)(E - F) = F(E - F)(EAE) = 0
	\end{equation*}
	Therefore, 
	\begin{equation*}
		C_F = \clo{\A F} \bot C_{E-F} = \clo{\A (E - F)}
	\end{equation*}
	In particular, $C_F(E-F) = 0$.
\end{proof}

\begin{prop}
	If $E$ and $F$ are abelian projections, then $F \lesssim E$ if and only if $C_F \leqslant C_E$.
\end{prop}
\begin{proof}
	Assume $C_F \leqslant C_E$. By Comparison Theorem, there is a central projection $Z$ s.t. $ZE \lesssim ZF$ and  $Z^{\bot}F \lesssim Z^{\bot}E$. It can assume that $ZE \leqslant ZF$ by above proposition. Since $ZF$ is abelian and by above lemma,
	\begin{equation*}
		ZE = ZF C_{ZE} = ZF C_E = ZF
	\end{equation*}
	Therefore,
	\begin{equation*}
		F = ZF + Z^{\bot}F = ZE + Z^{\bot}F \lesssim E  \qedhere
	\end{equation*}
\end{proof}

\subsection{Properties of Continuous Projections}

For continuous projections, there is some decomposition like Lebeshue Decomposition for general measures.

\begin{lem}
	If $E$ is not an abelian projection, then there are projections $E_1, E_2$ in $\A$ that are dominated by $E$ and s.t. $E_1 \bot E_2$ and $E_1 \sim E_2$.
\end{lem}
\begin{proof}
	Since $E$ is not abelian, there is a projection $F \leqslant E$ that does not belong to the center of $E \A E$, $\fml{Z}E$.
	\item Claim: $F \A (E-F) \neq \{0\}$. \\
	If for any $A \in \Rea{\A}$, $F A (E-F) = 0$. Then $FAE = FAF$ and $EAF = FAF$. Therefore,
	\begin{equation*}
		F(EAE) = FAE = FAF = EAF = (EAE)F
	\end{equation*}
	That is $F$ is in the center of $E \A E$, which is a contradiction.\\
	$F \A (E-F) \neq \{0\}$ implies that there are $E_1 \leqslant F$ and $E_2 \leqslant E-F$ s.t. $E_1 \sim E_2$.
\end{proof}

\begin{thm}
	If $E$ is continuous, then there are projections $E_1$ and $E_2$ in $\A$ s.t. $E_1 \bot E_2$, $E_1 \sim E_2$ and $E = E_1 + E_2$.
\end{thm}
\begin{proof}
	Concisder the collection of all sets of pairs $\{E_{1i},E_{2i}\}$ s.t. for all $i$,
	\begin{equation*}
		E_{1i} \sim E_{2i},~ E_{1i},E_{2i} \leqslant E_{ni} \bot E_{mj}
	\end{equation*}
	for $i \neq j$ and $m,n = 1,2$. Then by above lemma this set is not empty and then by Zorn's Lemma, there is a maximal element $\{E_{1i},E_{2i}\}$ and put
	\begin{equation*}
		E_1 = \sum_i E_{1i},~ E_2 = \sum_i E_{2i}
	\end{equation*}
	By the additivity, $E_1 \sim E_2$ and clearly, $E_1 \bot E_2$. And by the maximality and the continuity of $E$, $E = E_1 + E_2$.
\end{proof}

\begin{cor}
	The projection $E$ is continuous if and only if for every $F \leqslant E$, there are projections $F_1$ and $F_2$ in $\A$ s.t. $F_1 \bot F_2$, $F_1 \sim F_2$ and $F = F_1 + F_2$.
\end{cor}
\begin{proof}
	If $E$ is continuous, so is each its subprojection, thus by above theorem it is true. And the converse is trivial.
\end{proof}

\section{Type \texorpdfstring{\RNum{1}}{I} Von Neumann Algebras}

\subsection{Classification of Von Neumann Algebras}

Then by using the classifications of projections, von Neumann algebras can be classified as following categories.

\begin{defn}
	A von Neumann algebra $\A$ is:
	\begin{enumerate}[label = \arabic*)]
		\item Type \RNum{1}$_n$ if it is finite and discrete.
		\item Type \RNum{1}$_{\infty}$ if it is infinite and discrete.
		\item Type \RNum{2}$_1$ if it is finite and continuous.
		\item Type \RNum{2}$_{\infty}$ if it is infinite and continuous and every nonzero central projection dominates a nonzero finite projections.
		\item Type \RNum{3} if it contains no nonzero finite projections.
	\end{enumerate}
\end{defn}

\begin{prop}
	Let $\A$ be a von Neumann algebra and $E \in \A$ be a projection.
	\begin{enumerate}[label = \arabic*)]
		\item If $\A$ is Type \RNum{1} (\RNum{2}, or \RNum{3}), then $\A_E$ is Type \RNum{1} (\RNum{2}, or \RNum{3}).
		\item If $\A$ is Type \RNum{1}$_n$, then $\A_E$ is Type \RNum{1}$_n$.
		\item If $\A$ is Type \RNum{2}$_1$, then $\A_E$ is Type \RNum{2}$_1$.
	\end{enumerate}
\end{prop}
\begin{proof}
	Just need to prove the cases of Type \RNum{2} and Type \RNum{3}. Let $Z$ be a central projection in $\A$ s.t. $EZ \neq 0$. If $\A$ is Type \RNum{2}, then there is a nonzero finite projection $F$ with $F \leqslant Z$. Thus
	 \begin{equation*}
		EZF = EZ \neq 0
	\end{equation*}
	Then there are $E_1 \leqslant EZ$ and $F_1 \leqslant F$ s.t. $E_1 \sim F_1$. Therefore, $E_1$ is finite and thus $\A_E$ is Type \RNum{2}. If $\A$ is Type \RNum{3}, then $\A$ contains no nonzero finite projection, thus $\A_E$ contains no nonzero finite projection, and continuity of $\A_E$ is clear. Therefore, $\A_E$ is Type \RNum{3}.
\end{proof}

\begin{prop}
	Let $\{A_i\}$ be a class of von Neumann algebras and put $\A = \bigoplus_i \A_i$.
	\begin{enumerate}[label = \arabic*)]
		\item $\A$ is Type \RNum{1}$_n$ if and only if each $\A_i$ is Type \RNum{1}$_n$.
		\item $\A$ is Type \RNum{1}$_{\infty}$ if and only if each $\A_i$ is Type \RNum{1} and at least one of them is Type \RNum{1}$_{\infty}$.
		\item $\A$ is Type \RNum{2}$_1$ if and only if each $\A_i$ is Type \RNum{2}$_1$.
		\item $\A$ is Type \RNum{2}$_{\infty}$ if and only if each $\A_i$ is Type \RNum{2} and at least one of them is Type \RNum{2}$_{\infty}$.
		\item $\A$ is Type \RNum{3} if and only if each $\A_i$ is Type \RNum{3}.
	\end{enumerate}
\end{prop}

\begin{thm}
	If $\A$ is a von Neumann algebra, then there are unique pairwise orthogonal central projections $Z_1,\cdots,Z_5$ with $\sum_{i=1}^5 Z_i = 1$ s.t.
	\begin{enumerate}[label = \arabic*)]
		\item $\A Z_1$ is Type \RNum{1}$_n$.
		\item $\A Z_2$ is Type \RNum{1}$_{\infty}$.
		\item $\A Z_3$ is Type \RNum{2}$_1$.
		\item $\A Z_4$ is Type \RNum{2}$_{\infty}$.
		\item $\A Z_5$ is Type \RNum{3}. 
	\end{enumerate}
\end{thm}
\begin{proof}
	Define the central projections as
	\begin{eqnarray*}
		H &=& \sup{\{Z \colon Z \text{ is a central projection, } \A Z \text{ is Type \RNum{1}} \}} \\
		K &=& \sup{\{Z \colon Z \text{ is a central projection, } \A Z \text{ is Type \RNum{2}} \}}
	\end{eqnarray*}
	Then it is easy to see $\A H$ is Type \RNum{1} and $\A K$ is Type \RNum{2} and $HK=0$. Put
	\begin{equation*}
		Z_5 = 1 - (H + K)
	\end{equation*}
	Check: $\A Z_5$ is continuous. \\
	Assume there is an abelian projection $P$ in $\A Z_5$. Clearly, its central cover $C_P \leqslant Z_5$. If $G$ is any nonzero central projection in $\A C_P$. Then $G$ is also a central projection in $\A$. Moreover, $GP \neq 0$, and $(GP)\A (GP) = G(P\A P)$ is abelian. That means $\A C_P$ is Type \RNum{1}. Thus $C_P \leqslant H$. Therefore, $C_P = 0$. Then $P = 0$. Since $P$ is arbitrary, $\A Z_5$ is continuous.
	\item Check: $\A Z_5$ is Type \RNum{3}. \\
	Suppose there is a nonzero finite projection $P$ in $\A Z_5$. Similarly, $\A C_P$ is continuous. If $G$ is any central projection of $\A C_P$, then $G \in \fml{Z}$ and $G \leqslant C_P$. Thus $GC_P \neq 0$ and $GP$ is finite. Therefore, $\A C_P$ is Type \RNum{2}. Thus $C_P \leqslant K$, then $C_P = 0$ i.e. $P=0$.\\
	Then define $F = \sup{\{Z \colon Z \text{ is a finite central projection}}$. Put $Z_1 = HF$, $Z_2 = HF^{\bot}$, $Z_3 = KF$ and $Z_4 = KF^{\bot}$.
\end{proof}

\begin{cor}
	If $\A$ is a factor, then $\A$ is exactly one of the Type \RNum{1}$_n$, \RNum{1}$_{\infty}$, \RNum{2}$_1$, \RNum{2}$_{\infty}$ and \RNum{3}.
\end{cor}

\subsection{The Structure of Type \texorpdfstring{\RNum{1}}{I} Algebras}

\begin{defn}
	A projection is faithful if its central cover is identity.
\end{defn}



\end{document}
