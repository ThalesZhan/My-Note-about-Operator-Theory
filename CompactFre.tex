\chapter{Compact Operators, Fredholm Theory and Perturbations}

The compact operator is as similar as the finite dimensional operator with respect to the spectrums, the representations and so on. In fact, all compact operators can form the unique closed ideal in $\oper$. Moverover, it contains some important classes of operators, like the trace class, which provides an extral topology on $\oper$ and this topology plays an important role in the von Neumann algebra. In fact, the topology is conincided with the $WOT$ in some cases, but it can give a new method to obtain some properties of general von Neumann algebras. For non-compact operators, there is a "weak version" of the compact operator, the Fredholm operator. By researching the Fredholm operators, it provides us an approach to find some "invariant variable" under the compact perturbations. Finally, we have known that finite dimensional normal operator can always be diagnolizable, but for infinite dimensional case, this statement is not true. But by some small compact perturbation, the normal operator can be diagnalizable, and this result has some applications of representation theory. 

\section{Spectrums}

\subsection{Elementary Properties}

\begin{defn}
	Let $\Hs$ be a Hilbert space and $B_{\Hs}$ be the closed unit ball in $\Hs$ and $T \in \oper$. $T$ is compact if and only if the closure of $T(B_{\Hs})$ is compact. Then let $\coper$ denote the set of all compact operators.
\end{defn}
\begin{rem}
	Clearly, if $T$ is finite rank, $T \in \coper$. Denote $\foper$ as the set of all finite rank operators. Therefore, $\foper \subset \coper$.
	\begin{equation*}
		\foper = \{~T \in \oper \colon \ran{T} \text{ is finite dimension}~\}
	\end{equation*}
\end{rem}

Since $\Hs$ is a complete metric space, the compactness of $\clo{T(B_{\Hs})}$ is equivalent to that any sequence in $\clo{T(B_{\Hs})}$ has a convergent subsequence with the convergent point in $\clo{T(B_{\Hs})}$. By this fact, we can get the following theorem.

\begin{thm}
	Let $\Hs$ be a Hilbert space.
	\begin{enumerate}[label=\arabic*)]
		\item $\coper$ is a linear space.
		\item $\coper$ is closed in norm.
		\item $\coper$ is an ideal in $\oper$.
		\item If $T \in \coper$, then $\st{T} \in \coper$.
	\end{enumerate}
\end{thm}
\begin{rem}
	Therefore, $\coper$ is a $\st{C}$-subalgebra, and moreover, $\coper$ is a closed ideal of $\oper$.
\end{rem}

\begin{defn}
	Let $\Hs$ be a Hilbert space and $T \in \oper$. $T$ is called completely continuous if for any sequence $\{x_n\} \in \Hs$ with $x_n \sto x$ weakly, then $Tx_n \sto Tx$ in norm.
\end{defn}

\begin{prop}
	$T \in \oper$ is compact if and only if $T$ is completely continuous. 
\end{prop}
\begin{proof}
	Let $T$ be a compact operator and $\{x_n\} \in \Hs$ with $x_n \sto 0$ weakly. By the Principle of Uniform Boundedness, $M = \sup_n{\norm{x_n}} < \infty$. Assuming $M \leqslant 1$,
	\begin{equation*}
		\{Tx_n\} \subset \clo{T(B_{\Hs})}
	\end{equation*}
	By the fact that $\clo{T(B_{\Hs})}$ is compact, there is a subsequence $\{x_{n_k}\}$ s.t. $Tx_{n_k}  \sto y$ in norm. Since $T$ is also weakly continuous, $Tx_n \sto 0$ weakly. Thus $y = 0$. Then $T$ is completely continuous.\\
	Conversely, assume $T$ is completely continuous. \\
	Firstly, if $\Hs$ is separable and since $\Hs$ is reflexive, $B_{\Hs}$ is a weak-compact metric space. Therefore, for any $\{x_n\} \subset B_{\Hs}$, there is a subsequence $\{x_{n_k}\}$ and $x$ s.t. $x_{n_k} \sto x$ weakly. Therefore, $Tx_{n_k} \sto x$ in norm, i.e. $T$ is compact.\\
	For general case, let $\{x_n\} \subset B_{\Hs}$, then $\Hs_1 = \clo{\spn{\{x_n\}}}$ is separable. Therefore, since
	\begin{equation*}
		T|_{\Hs_1}(\{x_n\}) = T(\{x_n\}) \subset T|_{\Hs_1}(B_{\Hs_1})
	\end{equation*}
	$T$ is compact.
\end{proof}

By above theorem, we can see the power of compact operators. Intuitively, compact operators can "strengthen" the topology. They map the weakly convergent sequences be norm convergent sequence. How can they do that? We have known the weak topology is agree with the norm topology on the finite dimensional space. So, compact operators may be the "extension" of finite rank operators. In fact, we can descibe this property more rigorously.

\begin{thm}
	$T \in \oper$ is compact if and only if there is a sequence $\{T_n\} \subset \foper$ s.t. $T_n \sto T$ in norm.
\end{thm}
\begin{proof}
	Assume $T$ is compact. Therefore, $\clo{T(B_{\Hs})}$ is separable. Let $\{e_n\}_{n=1}^{\infty}$ be the basis of the dense subspace of $\clo{T(B_{\Hs})}$. Then define projections
	\begin{equation*}
		P_n \colon \Hs \longrightarrow \spn{\{e_1, e_2, \cdots, e_n\}}
	\end{equation*}
	and let $T_n = P_nT$. Clearly, $T_n \in \foper$. Now, clearly, $\norm{Th - T_nh} \sto 0$ for any $h \in \Hs$. Since $\clo{T(B_{\Hs})}$ is compact, for any given $\varepsilon > 0$, there are $h_1, \cdots, h_m \in \Hs$ s.t.
	\begin{equation*}
		T(B_{\Hs}) \subset \bigcup_{i=1}^{m}B_{\varepsilon}(Th_i)
	\end{equation*}
	where $B_{\varepsilon}(h_i)$ is the open ball centred at $Th_i$ with radius $\varepsilon$. Therefore, for any $h \in B_{\Hs}$, choose $h_j$ s.t. $\norm{Th-Th_j} < \varepsilon$.
	\begin{eqnarray*}
		\norm{Th-T_nh} &\leqslant& \norm{Th - Th_j} + \norm{Th_j - T_nh_j} + \norm{P_n(Th_j-Th)} \\
		&\leqslant& 2\norm{Th - Th_j} +  \norm{Th_j - T_nh_j} \\
		&<& 2\varepsilon +  \norm{Th_j - T_nh_j}
	\end{eqnarray*}
	Since $\norm{Th_j - T_{n}h_j} < \varepsilon$ for any $h_j$ and $n > n_0$ for some $n_)$,  
	\begin{equation*}
		\norm{Th-T_nh} < 3\varepsilon \text{ for } n > n_0
	\end{equation*}
	Then $T_n \sto T$ uniformly, i.e. $T_n \sto T$ in norm. \\
	The converse is clearly since $\foper \subset \coper$ and $\coper$ is norm closed.
\end{proof}
\begin{cor}
	All projections $\{P_i\}_{i \in I}$ in $\oper$ form an approximate identity for the ideal $\coper$.
\end{cor}

\subsection{Spectrums of Compact Operators}

The spectrum of a compact operator also has similar properties as a finite rank operator.

\begin{thm}
	If $T \in \coper$ and $\lambda \neq 0$ satisfying
	\begin{equation*}
		\inff{\{~\norm{(T-\lambda)h} \colon \norm{h}=1~\}} = 0
	\end{equation*}
	then $\lambda \in \sigma_p(T)$.
\end{thm}
\begin{proof}
	There is a sequence $\{h_n\}$ with $\norm{h_n}=1$ s.t. $\norm{(T-\lambda)h_n} \sto 0$. Since $T$ is compact, there is a subsequence $\{h_{n_k}\}$ and a $h_0$ s.t. $\norm{Th_{n_k}-h_0} \sto 0$, therefore
	\begin{equation*}
		h_{n_k} = \frac{1}{\lambda}((\lambda-T)h_{n_k}+Th_{n_k}) \sto \frac{1}{\lambda}h_0
	\end{equation*}
	Then $\norm{\frac{1}{\lambda}h_0}=1=\abs{\frac{1}{\lambda}}\norm{h_0}$, thus $\norm{h_0} \neq 0$. Since $Th_{n_k} \sto \frac{1}{\lambda}Th_0$ and $Th_{n_k} \sto h_0$,
	\begin{equation*}
		h_0 = \frac{1}{\lambda}Th_0, \text{ i.e. } Th_0 = \lambda h_0
	\end{equation*}
\end{proof}

In fact, we have known that
\begin{equation*}
	\sigma_{ap}(T) = \sigma_l(T) = \{~\lambda \in \C \colon \inff{\{\norm{(T-\lambda)h} \colon \norm{h}=1\}} = 0~\}
\end{equation*}
and $\lambda \notin \sigma_{ap}(T)$ is equivalent to that $\ker{(T-\lambda)} = \{0\}$ and $\ran{(T-\lambda)}$ is closed. Combining with the Riesz Theorem, any closed and bounded subset in a normed space is compact if and only if the normed space is finite dimensional, we have the following corollary.

\begin{cor}
	If $T \in \coper$ and $\lambda \neq 0$ and $\ker{(T-\lambda)} = \{0\}$, then $\ran{(T-\lambda)}$ is closed.
\end{cor}

Here is another important corollary, which says the point spectrum play an important role.
\begin{cor}
	If $T \in \coper$, $\lambda \notin \sigma_p(T)$ with $\lambda \neq 0$ and $\clo{\lambda} \notin \sigma_p(\st{T})$, then $\lambda \notin \sigma(T)$.
\end{cor}
\begin{proof}
	By above theorem, $\lambda \notin \sigma_p(T)$ with $\lambda \neq 0$ means $\lambda \notin \sigma_l(T)$, thus $\ker{(T-\lambda)} = \{0\}$ and $\ran{(T-\lambda)}$ is closed.\\ Similarly, for $\st{T}$, $\ker{(\st{T}-\clo{\lambda})} = \{0\}$ and $\ran{(\st{T}-\lambda)}$ is closed. Therefore,
	\begin{equation*}
		\ran{(T-\lambda)} = \clo{\ran{(T-\lambda)}} = (\ker{(\st{T}-\clo{\lambda})})^{\bot} = \Hs
	\end{equation*}
	Thus $T-\lambda$ is a bijection, and by the Inverse Mapping Theorem, $(T-\lambda)^{-1} \in \oper$, i.e. $\lambda \notin \sigma(T)$.
\end{proof}
\begin{rem}
	In other words, for a compact operator $T$, if $\lambda \in \sigma(T)$ with $\lambda \neq 0$, then $\lambda \in \sigma_p(T)$ or $\lambda \in \sigma_p(\st{T})$.
\end{rem}

In fact, any nonzero point in $\sigma(T)$ for a compact operator $T$ is isolated and moreover, it is an eigenvalue. To prove this, we need some lemmas.

\begin{lem}
	If $\M$ and $\fml{N}$ are two closed linear subspaces of $\Hs$ with $\M \subset \fml{N}$, then for any $\varepsilon > 0$, there exists a $y \in \fml{N}$ with $\norm{y} = 1$ s.t. $\dist{(y,\M)} \leqslant 1-\varepsilon$.
\end{lem}
\begin{proof}
	For $y \in \fml{N}$, define $\delta(y) = \dist{(y,\M)}$. Choosing $y_1 \in \fml{N} \backslash \M$, there exists a $x_0 \in \M$ s.t.
	\begin{equation*}
		\delta(y_1) \leqslant \norm{x_0-y_1} \leqslant (1+\varepsilon)\delta(y_1)
	\end{equation*}
	Let $y_2 = y_1-x_0$, then
	\begin{equation*}
		(1+\varepsilon)\delta(y_2) = (1+\varepsilon)\inff{\{\norm{y_1-x_0-x} \colon x \in \M\}} = (1+\varepsilon)\delta(y_1)
	\end{equation*}
	Thus $(1+\varepsilon)\delta(y_2) > \norm{x_0 - y_1} = \norm{y_2}$. Let $y = \norm{y_2}^{-1}y_2$, then $y_2 \in \fml{N}$ with $\norm{y_2}=1$.
	\begin{eqnarray*}
		\norm{y-x} &=& \norm{\norm{y_2}^{-1}y_2-x} = \norm{y_2}^{-1}\norm{y_2-\norm{y_2}x} \\
		&>& ((1+\varepsilon)\delta(y_2))^{-1} \norm{y_2-\norm{y_2}x} \\
		&\geqslant& (1+\varepsilon)^{-1} > 1 - \varepsilon
	\end{eqnarray*}
\end{proof}

\begin{prop}
	If $T \in \coper$ and $\{\lambda_n\}$ is a sequence of distinct elements in $\sigma_p(T)$, then $\lim_{n \sto \infty} \lambda_n = 0$.
\end{prop}
\begin{proof}
	For each $n$, choosing a nonzero $x_n \in \ker{(T-\lambda_n)}$,
	\begin{equation*}
		\M_n = \spn{\{~x_1,x_2,\cdots,x_n~\}}
	\end{equation*}
	By preceding lemma, there is a $y_n \in \M_n$ with $\norm{y_n}=1$ s.t.
	\begin{equation*}
		\dist{(y_n,\M_{n-1})} > \frac{1}{2}
	\end{equation*}
	Let $y_n = \sum_{i=1}^{n} \alpha_i x_n$, thus
	\begin{equation*}
		(T-\lambda_n)y_n = \sum_{i=1}^{n-1} \alpha_i (\lambda_i-\lambda_n)x_i \in \M_{n-1}
	\end{equation*}
	Therefore, for $n > m$,
	\begin{eqnarray*}
		T(\lambda_n^{-1}y_n)-T(\lambda_m^{-1}y_m) &=& \lambda_n^{-1}(T-\lambda_n)y_n - \lambda_m^{-1}(T-\lambda_m)y_m + (y_n - y_m) \\
		&=& y_n - (y_m + \lambda_n^{-1}(T-\lambda_n)y_n + \lambda_m^{-1}(T-\lambda_m)y_m)
	\end{eqnarray*}
	Since the part in the bracketed is in $\M_{n-1}$,
	\begin{equation*}
		\norm{T(\lambda_n^{-1}y_n)-T(\lambda_m^{-1}y_m)} \leqslant \dist{(y_n,\M_{n-1})} > \frac{1}{2}
	\end{equation*}
	Thus $\{\lambda_n^{-1}y_n\}$ has no bounded subset by the fact that $T$ is compact.
	\begin{equation*}
		\norm{\lambda_n^{-1}y_n} = \abs{\lambda_n}^{-1} \sto \infty
	\end{equation*}
	That means $\lim_{n \sto \infty} \lambda_n = 0$.
\end{proof}

\begin{prop}
	If $T \in \coper$ and a nonzero $\lambda \in \sigma(T)$, then $\lambda$ is a isolated point in $\sigma(T)$.
\end{prop}
\begin{proof}
	If there is a sequence $\{\lambda_n\} \subset \sigma(T)$ s.t. $\lambda_n \sto \lambda$, then each $\lambda_n$ is in either $\sigma_p(T)$ or $\sigma_p(\st{T})$. Then if there exists a subsequence $\{\lambda_{n_k}\} \subset \sigma_p(T)$. But by above proposition, $\lim_{k \sto \infty} \lambda_{n_k} =0$, which is a contradiction. Similarly, if $\{\lambda_{n_k}\} \subset \sigma_p(\st{T})$, $\lim_{k \sto \infty} \lambda_{n_k} =0$, which is also a contradiction.
\end{proof}

Now, we can see any nonzero point in the spectrum of a compact operator is a eigenvalue.

\begin{lem}
	If $T \in \coper$ and a nonzero $\lambda \in \sigma(T)$, then $\ker{(T-\lambda)}$ is finite dimentional.
\end{lem}
\begin{proof}
	If there is an infinite orthonormal sequence $\{e_n\}$ in $\ker{(T-\lambda)}$, then $\{Te_n\}$ has a convergent subsequence $\{Te_{n_k}\}$, thus it is Cauchy.
	\begin{equation*}
		\norm{Te_{n_k}-Te_{n_j}}^2 = \norm{\lambda e_{n_k}-\lambda e_{n_j}}^2 = 2 \abs{\lambda} > 0
	\end{equation*}
	which is a contradiction.
\end{proof}

\begin{thm} \label{thm12}
	If $T \in \coper$ and a nonzero $\lambda \in \sigma(T)$, then $\lambda \in \sigma_p(T)$ and $\dim{\ker{(T-\lambda)}} = \dim{\st{\ker{(T-\lambda)}}} < \infty$ and $\ran{(T-\lambda)}$ is closed.
\end{thm}
\begin{proof}
	By the \textbf{Proposition} \ref{prop10} in the subsection \textbf{2.1.3}, since each $\lambda \in \sigma(T)$ is isolated, we can define
	\begin{equation*}
		E(\lambda) = \int_{\Gamma(\{\lambda\})} (z-T)^{-1} dz 
	\end{equation*}
	where $\Gamma(\{\lambda\})$ is the closed curve enclosed $\{\lambda\}$ and disjoint with other $\lambda$ in $\sigma(T)$. Then, each $E(\lambda)$ is a projection.
	\begin{equation*}
		\Hs_{\lambda} = E(\lambda)\Hs,~ T_{\lambda} = T|_{\Hs_{\lambda}} \colon \Hs_{\lambda} \sto \Hs_{\lambda}
	\end{equation*}
	Since $\sigma(T_{\lambda}) = \{\lambda\}$ and $\lambda \neq 0$, $T_{\lambda}$ is invertible. But clearly, $T_{\lambda}$ is compact. That means any bounded and closed subset in $\Hs_{\lambda}$ is compact, thus $\dim{\Hs_{\lambda}} < \infty$ by the Riesz Theorem. Therefore, by the result of finite linear algebra, $\lambda$ is the eigenvalue of $T_{\lambda}$, i.e. $\lambda \in \sigma_p(T)$. By above lemma, $\dim{\ker{(T-\lambda)}} < \infty$.\\
	Let $\Delta = \sigma(T) \backslash \{\lambda\}$, $\Hs_{\Delta} = E(\{\Delta\})\Hs$ and $T_{\Delta} = T|_{\Hs_{\Delta}}$. Then since $\lambda \notin \Delta$,
	\begin{equation*}
		\ran{(T_{\Delta}-\lambda)} = \Hs_{\Delta}
	\end{equation*}
	Therefore, 
	\begin{eqnarray*}
		\ran{(T-\lambda)} &=& (T-\lambda)\Hs_{\lambda}+(T-\lambda)\Hs_{\Delta} \\
		&=& \ran{(T_{\lambda}-\lambda)} + \Hs_{\Delta}
	\end{eqnarray*}
	Moreover, since $\dim{\Hs_{\lambda}} < \infty$, $\ran{(T_{\lambda}-\lambda)}$ is closed. Thus $\ran{(T-\lambda)}$ is closed.\\
	Finally, note that
	\begin{eqnarray*}
		\Hs / \ran{(T-\lambda)} &=& (\Hs_{\Delta} + \Hs_{\lambda}) / (\ran{(T_{\lambda}-\lambda)} + \Hs_{\Delta}) \\
		&\cong& \Hs_{\lambda} / \ran{(T_{\lambda}-\lambda)}
	\end{eqnarray*}
	Since $\dim{\Hs_{\lambda}} < \infty$,
	\begin{eqnarray*}
		\dim{(\Hs / \ran{(T-\lambda)})} &=& \dim{\Hs_{\lambda}} - \dim{\ran{(T_{\lambda}-\lambda)}} = \dim{\ker{(T_{\lambda}-\lambda)}} \\
		&=& \dim{\ker{(T-\lambda)}} < \infty
	\end{eqnarray*}
	And since
	\begin{equation*}
		(\Hs / \ran{(T-\lambda)})^{*} \cong \ran{(T-\lambda)}^{\bot} = \ker{\st{(T-\lambda)}}
	\end{equation*}
	$\dim{\ker{(T-\lambda)}} = \dim{\st{\ker{(T-\lambda)}}}$.
\end{proof}

Combining all of above results, we can get an explicit structure of the spectrum of compact operator.

\begin{thm}[Riesz]
	If $\Hs$ is a infinite dimensional Hilbert space and $T \in \coper$, then one and only one of the following possibilities occurs.
	\begin{enumerate}[label=\arabic*)]
		\item $\sigma(T) = \{0\}$.
		\item $\sigma(T) = \{0,\lambda_1,\cdots,\lambda_n\}$, where each $\lambda_k \neq 0$, and each $\lambda_k$ is the eigenvalue of $T$ with $\dim{\ker{(T-\lambda_k)}}<\infty$.
		\item $\sigma(T) = \{0,\lambda_1,\lambda_2,\cdots\}$, where each $\lambda_k \neq 0$, and each $\lambda_k$ is the eigenvalue of $T$ with $\dim{\ker{(T-\lambda_k)}}<\infty$, and moreover, $\lim_{n \sto \infty} \lambda_n =0$.
	\end{enumerate}
\end{thm}

Because of its discrete spectrum, we can using the spectral measure to decompose the compact normal operator.

\begin{thm}[Spectral Theorem]
	If $T$ is a compact normal operator on a Hilbert space $\Hs$, then $T$ has at most countable eigenvalues $\{\lambda_n\}$, and there are corresponding projections $P_n \colon \Hs \sto \ker{(T-\lambda_n)}$ with $P_nP_m=P_mP_n=0$ s.t.
	\begin{equation*}
		T = \sum_{n=1}^{\infty} \lambda_n P_n
	\end{equation*}
	where $\{\lambda_n\}$ are all distinctive eigenvalues and the convergence is with respect to the norm topology.
\end{thm}
\begin{proof}
	Let $E$ be the spectral measure of $T$, then we see
	\begin{equation*}
		N = \int_{\sigma(N)} z dE
	\end{equation*}
	If $\dim{\Hs} = \infty$, since $\sigma(N)$ is consisted of at most countable eigenvalues $\{\lambda_n\}_{n=1}^{\infty}$ and $0$, then we can set $P_n = E(\{\lambda_n\})$ for $n = 1,2,\cdots$, which is well-defined by the \textbf{Proposition} \ref{prop11} in the subsection \textbf{3.1.2}, above integral can be
	\begin{eqnarray*}
		N &=& \lim_{n \sto \infty} (\int_{B_{\frac{1}{n}}(0)} z dz + \sum_{k=1}^{n} \lambda_k P_k) \\
		&=& \sum_{n=1}^{\infty} \lambda_n P_n
	\end{eqnarray*} 
	And moreover, $P_n$ is the projection from $\Hs$ onto $\ker{(T-\lambda_n)}$. \\
	If $\dim{\Hs} < \infty$, above theorem is clearly true.
\end{proof}

Also, we can see the Functional Calculus of the compact normal operators. Firstly, Taking same notation as above theorem and let $P_0 = 1-\sum_{n=1}^{\infty}$, in fact, $P_0$ is the projection from $\Hs$ to $\ker{T}$. By the Functional Calculus of normal operators, we know
\begin{equation*}
	\st{W}(T) = \{~\phi(T) \colon \phi \in \lfs{\infty}(\sigma(T))~\}
\end{equation*}
Since $\sigma(T)$ is discrete, $\lfs{\infty}(\sigma(T)) = l^{\infty}(\C)$, and for any $(a_n)_{n=0}^{\infty} \in l^{\infty}(\C)$,
\begin{equation*}
	(a_n)(T) = a_0 P_0 + \sum_{n=1}^{\infty} a_n P_n
\end{equation*}
Thus we can see the separating vector for $\st{W}(T)$, if $e$ is a separating vector and decomposing $e$ to $\{P_n\}_{n=0}^{\infty}$
\begin{equation*}
	e = \sum_{n=0}^{\infty} e_n,~ e_n \in P_n \text{ for each n}
\end{equation*} 
Then for $(a_n)_{n=0}^{\infty} \in l^{\infty}(\C)$
\begin{equation*}
	(a_n)(T)e = (a_0 P_0 + \sum_{n=1}^{\infty} a_n P_n)(\sum_{n=0}^{\infty} e_n) = \sum_{n=0}^{\infty} a_n e_n
\end{equation*}
Since $e$ is separating, $\sum_{n=0}^{\infty} a_n e_n = 0$ for any $(a_n) \in l^{\infty}(\C)$ implies $a_n = 0$ for all $n$. That means that $e_n \neq 0$ for any $n$. Then the corresponding measure $\mu$ is defined as
\begin{equation*}
	\mu(\{\lambda_n,\lambda_m\}) = \norm{E(\{\lambda_n,\lambda_m\})e}^2 = \norm{e_n+e_m}^2
\end{equation*}

Now, we can see the multiplicity function of compact normal operator. By similar construction in the \textbf{Theorem} \ref{thm10} and \textbf{Theorem} \ref{thm9} in the section \textbf{3.4}, the multiplicity function is like
\begin{equation*}
	m_T(\lambda) = \dim{\ker{(T-\lambda)}}
\end{equation*}
That means two compact normal operators are equivalent if and only if they have same dimension of all eigenspaces.

Finally,, we can prove $\coper$ is the unique closed ideal in $\oper$ if $\Hs$ is separable. 
\begin{prop}
	If $N$ is a normal operator in $\oper$ with the specture measure $E$, then $N$ is compact if and only if for any $\varepsilon > 0$,
	\begin{equation*}
		\dim{E(\{z \in \C \colon \abs{z} > \varepsilon\})} < \infty
	\end{equation*}
\end{prop}
\begin{proof}
	Let $\Delta_{\varepsilon} = \{z \in \C \colon \abs{z} > \varepsilon\}$ and $E_{\varepsilon} = E(\Delta_{\varepsilon})$.\\
	Assume that for any given $\varepsilon > 0$, $\dim{E_{\varepsilon}} < \infty$, then
	\begin{eqnarray*}
		N - NE_{\varepsilon} &=& \int z dE - \int z\chi_{\Delta_{\varepsilon}} dE \\
		&=& \int z\chi_{\C \backslash \Delta_{\varepsilon}} dE = \phi(N)
	\end{eqnarray*}
	where $\phi(z) = z\chi_{\C \backslash \Delta_{\varepsilon}}(z)$. Therefore,
	\begin{equation*}
		\norm{N - NE_{\varepsilon}} = \sup{\{\abs{z} \colon \C \backslash \Delta_{\varepsilon}\}} < \varepsilon
	\end{equation*}
	Thus $N \in \coper$. \\
	Conversely, if $N$ is compact, then for any $\varepsilon > 0$, put $\phi(z) = z^{-1}\chi_{\Delta_{\varepsilon}}$, then
	\begin{equation*}
		N\phi(N) &=& \int \chi_{\Delta_{\varepsilon}} dE = E_{\varepsilon} 
	\end{equation*}
	Since $E_{\varepsilon}$ is a compact projection, i.e. $\ran{E_{\varepsilon}}$ is closed, by the Riesz Theorem, $\dim{\ran{E_{\varepsilon}}} < \infty$.
\end{proof}

\begin{thm}
	If $\Hs$ is a separable Hilbert space and $\I$ is an ideal of $\oper$ that contains a non-compact operator, then $\I = \oper$.
\end{thm}
\begin{proof}
	Let $T \in \I \backslash \coper$ then 
	\begin{equation*}
		\st{T}T = \int_{\sigma(\st{T}T)} t dE(t)
	\end{equation*}
	By above theorem, there is an $\varepsilon > 0$ s.t. $P = E(\varepsilon,\infty)$ has infinite rank. 
	\begin{equation*}
		P = (\int t^{-1}\chi_{(\varepsilon,\infty)}(t)dE(t))\st{T}T \in \I
	\end{equation*}
	Since $\Hs$ is separable, $\dim{P\Hs} = \dim{\Hs} = \aleph_0$, there is a unitary $U$ from $\Hs$ to $P\Hs$. Therefore, $1 = \st{U}PU \in \I$. $\I = \oper$.
\end{proof}

\begin{prop}
	If $\I$ is a closed ideal of $\oper$, the $\coper \subset \I$ or $\I = \{0\}$.
\end{prop}
\begin{proof}
	Since $\I$ is closed, $\I$ is self-adjoint by the  \textbf{Proposition} \ref{prop12} in the subsection \textbf{2.2.5}. Then by the \textbf{Theorem} \ref{thm6} in the subsection \textbf{2.2.5}, we know $\I = \I \cap \st{\I}$ is a hereditary subalgebra. \\
	Therefore, if $\I$ is nonzero and $T \in \I$ is nonzero, then there is a finite rank projection $P$ s.t.
	\begin{equation*}
		0 \leqslant P \leqslant \st{T}T
	\end{equation*}
	Thus, $P \in \I$. Morover, any finite rank projection is in $\I$. Since $\I$ is norm closed, $\coper \subset \I$.
\end{proof}

Combining above propositions and theorems, we can get the final result.
\begin{cor}
	If $\Hs$ is a separable Hilbert space, then the only nontrivial closed ideal of $\oper$ is $\coper$.
\end{cor}

\section{Compact Operator Algebras}

For a normal operator, it can be decomposed as the direct sum of $*$-cyclic normal operators. Therefore, we want to reseach the similar property of compact operators. Like researching the normal operator, we firstly begin with the representation of compact operators. Let $\A$ denote a $\st{C}$-subalgebra in $\coper$.

\subsection{Minimal Projections}

\begin{defn}
	Let $\A$ is a $\st{C}$-subalgebra in $\coper$
	\begin{enumerate}[label=\arabic*)]
		\item A projection $E$ in $\A$ is minimal if $E \neq 0$ and there are no nonzero projection $P$ in $\A$ s.t. $P < E$.
		\item $\A$ is called irreducible if $\A$ has no proper reducing subspaces.
	\end{enumerate}
\end{defn}

\begin{prop}
	Let $E$ be a projection in $\A$.
	\begin{enumerate}[label=\arabic*)]
		\item $E$ is minimal if and only if
		\begin{equation*}
			E\A E = \{~\lambda E \colon \lambda \in \C~\}
		\end{equation*}
		\item Every projection in $\A$ is the direct sum of a finite number of pairwise orthogonal minimal projections in $\A$.
	\end{enumerate}
\end{prop}
\begin{proof}
	For $1)$, clearly, $E \A E$ is a $\st{C}$-subalgebra of $\coper$. Thus for any self-adjoint operator $A \in E \A E$, each nonzero spectrum point $\lambda$ of $A$ is isolated. That means $\chi_{\{\lambda\}}$ is continuous, thus $E(\{\lambda\})$ is a projection in $E \A E$. However, the minimality of $E$ implies that $E(\{\lambda\}) = E$. Therefore, by the fact that $E \A E$ can be generated by all self-adjoint operators in $E \A E$, $E\A E = \{\lambda E \colon \lambda \in \C\}$. The converse is trivial.
	\item For $2)$, since each projection in $P$ $\A$ is compact, $P$ has finite rank. Thus $P$ can he direct sum of a finite number of pairwise orthogonal minimal projections.
\end{proof}

Using the minimal projection, we can get an important trait the irreducible compact subalgebra has.
\begin{thm}
	If $\A$ is an irreducible $\st{C}$-subalgebra of $\coper$, then $\A = \coper$.
\end{thm}
\begin{proof}
	Let $E$ be a minimal projection in $\A$.\\
	Claim: The rank of $E$ is one. \\
	If $\rank{E} > 1$, then there are nonzero $g,h \in E$ with $g \bot h$. Let $A \in \A$ and $\lambda \in \C$ s.t. $EAE = \lambda A$. Then
	\begin{equation*}
		\langle Ag,h \rangle = \langle EAEg,h \rangle = \lambda \langle g,h \rangle = 0
	\end{equation*}
	Thus, $h \bot \clo{\A g}$. But since $\A$ is irreducible, $\clo{\A g} = \Hs$. So $h = 0$ contradicted to the assumption.
	\item Claim: If $P$ is any rank one projection, then $P \in \A$. \\
	Let $e \in E$ and $p \in P$. By the irreducibility of $\A$, $\Hs = \clo{\A e}$. Then for any given $\varepsilon > 0$, 
	\begin{equation*}
		\norm{Ae - p} < \varepsilon,~ \text{ for some } A \in \A
	\end{equation*}
	Let $P^{'} = AE$, then $P^{'} \in \A$. And moreover, for any $h \in \Hs$
	\begin{eqnarray*}
		\norm{(P-P^{'})h} &=& \norm{\langle h,p \rangle p - \langle h, Ae \rangle Ae}\\ 
		&=& \norm{\langle h,p-Ae \rangle Ae + \langle h,p \rangle (p-Ae)} \\
		&\leqslant& \norm{h} \norm{Ae} \varepsilon + \norm{h}\norm{p} \varepsilon
	\end{eqnarray*}
	Thus by the fact that $\A$ is norm closed, $P \in \A$. \\
	Therefore, any finite rank projection in $\A$, i.e. $\A = \coper$.
\end{proof}

\begin{cor}
	For any Hilbert space $\Hs$, $\coper$ is simple.
\end{cor}
\begin{proof}
	Let $\I$ be an closed ideal in $\coper$. Then $\clo{\I e}$ for any nonzero $e$ is a reducing space for $\coper$. Thus $\clo{\I e} = \Hs$ since $\coper$ is irreducible. That means $\I$ is irreducible. Thus by above theorem, $\I = \coper$.
\end{proof}
\begin{rem}
	In fact, the converse of the result in above proof is also true. $\B$ is a irreducible subalgebra contained in $\oper$ if and only if $\clo{\B e} = \Hs$ for any $e \in \Hs$. And because of this, we can get the genera version of the corollary that if $\B$ is a irreducible subalgebra contained in $\oper$, then any ideal of it is irreducible.
\end{rem}

\begin{cor}
	Let $\Hs$ be a Hilbert space. If $\B$ is a irreducible $\st{C}$-subalgebra of $\oper$ and $\B \cap \coper \neq 0$, then $\coper \subset \B$.
\end{cor}
\begin{proof}
	Let $\I = \B \cap \coper$. Then $\I$ is a closed ideal in $\B$. By above corollary, $\I = \coper$, i.e. $\coper \subset \B$.
\end{proof}


Now, the unit element of a compact operator subalgebra can be provided.
\begin{prop}
	If $E$ is a minimal projection in $\A$, $e$ is any nonzero vector in $\Hs$ and $\Hs_e = \clo{\A e}$, then $\A|_{\Hs_e} = \fml{B}_0(\Hs_e)$.
\end{prop}
\begin{proof}
	Let $\A_e = \A|_{\Hs_e}$. We just need to show $\A_e$ is irreducible in $\fml{B}(\Hs_e)$. Let $P$ be a projection in $\fml{B}(\Hs_e)$ commuting with $\A_e$. Put 
	\begin{equation*}
		T = P - \langle Pe,e \rangle 1
	\end{equation*}
	Then $T \in \A_e^{'}$, for any $A,B \in \A$,
	\begin{eqnarray*}
		\langle TAe, Be \rangle &=& \langle T \st{B}A E e, E e \rangle \\
		&=& \langle T E \st{B}A E e,e \rangle
	\end{eqnarray*}
	Since $E$ is minimal, $E \st{B}A E = \lambda E$ for some $\lambda \in \C$. Therefore,
	\begin{equation*}
		\langle TAe, Be \rangle = \lambda \langle Te, e \rangle = \lambda (\langle Pe, e \rangle - \langle Pe, e \rangle) = 0
	\end{equation*}
	Since $A,B$ are arbitrary and $\Hs_e = \clo{\A e}$, $T = 0$, that means $P = \langle Pe,e \rangle 1$. Thus, $P = 0$ or $1$.
\end{proof}

\subsection{Representations of Compact Operator Algebras}

For the representation of a compact operator subalgebra, it can be decomposed as the direct sum of irreducible parts.
\begin{thm}
	If $(\rho, \fml{K})$ is a non-degenerate representation of $\A$, then there are irreducible representations $\{\rho_i\}_{i \in I}$ s.t. each $\rho_i$ is equivalent to a subrepresentation of the identity representation $i \colon \A \sto \oper$.
\end{thm}
\begin{proof}
	Claim: There is a minimal projection $E \in \A$ s.t. $\rho(E) \neq 0$. \\
	In fact, there is a self-adjoint operator $A \in \A$ s.t. $\rho(A) \neq 0$. Otherwise, $\rho$ is the zero representation. Then there is a spectral projection $F$ for $A$ with $\rho(F) \neq 0$. Then since $F$ is the direct sum of finite numbers minimal projections, that means $\rho$ must not vanish on at least one of them.
	\item For this $E$, choosing a unit vector $e_0 \in \rho(E)$ and define $\fml{K}_0 = \clo{\rho(\A)e_0}$ and $\rho_0(A) = \rho(A)|_{\fml{K}_0}$. Then \\
	Claim: $(\rho_0,\fml{K}_0)$ is equivalent to a subrepresentation of the identity representation of $\A$.\\
	Define the unitary $U$ from $\fml{K}_0$ to $\Hs_0 = \clo{\A e}$, where $e$ is the unit vector in $E$. 
	\begin{center}
		\begin{tabular}{l c c l}
			$U \colon$ & $\fml{K}_0$ & $\longrightarrow$ & $\Hs_0$ \\
			~ & $\rho(A)e_0$ & $\longmapsto$ & $Ae$
		\end{tabular}
	\end{center}
	Since $E$ is minimal, there exists a unique $\lambda$ s.t. $E \st{A}A E = \lambda E$ for $A \in \A$.
	\begin{eqnarray*}
		\norm{\rho(A)e_0}^2 &=& \norm{\rho(AE)e_0}^2 = \langle \rho(E \st{A}AE)e_0,e_0 \rangle\\
		&=& \lambda \langle e_0,e_0 \rangle = \lambda \langle e,e \rangle \\
		&=& \langle E \st{A}AE e_0,e_0 \rangle \\
		&=& \norm{Ae}^2
	\end{eqnarray*}
	Therefore, $U$ is surjective isometry, and can extend to $\fml{K}_0$. And moreover,
	\begin{equation*}
		U\rho(A)\rho(B)e_0 = A Be ~\Rightarrow~ U\rho(A) \st{U} Be = A|_{\Hs_0} Be
	\end{equation*}
	Thus, $U\rho_0(A)\st{U} = A|_{\Hs_0}$. By above proposition, $\rho_0$ is irreducible.
	\item Then by Zorn's Lemma, we can get a maximal family of $(\rho_i, \fml{K}_i)_{i \in I}$ as above construction. And by the maximality and the non-degenerality, 
	\begin{equation*}
		\rho = \oplus_{i \in I} \rho_i,~ \fml{K} = \oplus_{i \in I} \fml{K}_i \qedhere
	\end{equation*}
\end{proof}
\begin{rem}
	If $\rho$ is degenerate, then let $\Hs_0 = \clo{\rho(\A) \Hs}$. The representation $(\rho_0(A) = \rho(A)|_{\Hs_0}, \Hs_0)$ is a non-degenerate representation, thus above theorem can be applied to it. Moreover, $\rho = \rho_0 \oplus 0$. 
\end{rem}

Now, we can use above theorem to get the structure of any finite dimensional $\st{C}$-algebra.
\begin{cor}
	For any finite dimensional $\st{C}$-algebra $\A$ and let $M(n)$ be the set of $n \times n$ matrices with complex entries acting on the inner product space $\C^{n}$., there are $n_1,\cdots,n_p \in \N$, s.t.
	\begin{equation*}
		\A \cong M(n_1) \oplus M(n_2) \oplus \cdots \oplus M(n_p)
	\end{equation*}
\end{cor}

Also, there are some other corollaries of above theorem.
\begin{cor} \label{cor10}
	\begin{enumerate}[label=\arabic*)]
		\item If $(\rho, \fml{K})$ is an irreducible representation of $\A$, then $\rho(\A) = \fml{B}_0(\fml{K})$.
		\item If $\Hs$ and $\fml{K}$ are Hilbert spaces and $\rho \colon \coper \sto \fml{B}_0(K)$ is an $*$-isomorphism, then there is a unitary $U \colon \Hs \sto \fml{K}$, s.t.
		\begin{equation*}
			\rho(T) = U T \st{U}, \text{ for any } T \in \coper
		\end{equation*}
		\item If $\Hs$ and $\fml{K}$ are Hilbert spaces and $\rho \colon \oper \sto \fml{B}(K)$ is an $*$-isomorphism, then there is a unitary $U \colon \Hs \sto \fml{K}$, s.t.
		\begin{equation*}
			\rho(A) = U A \st{U}, \text{ for any } A \in \oper
		\end{equation*}
	\end{enumerate}
\end{cor}
\begin{proof}
	$1)$ is the direct result from above theorem. And $2)$ can be obtained by $1)$. \\
	For $3)$, since $\rho(\coper)$ is an ideal of $\fml{K}$ and $\fml{K}$ is irreducible, $\rho(\coper)$ is irreducible by above corollary. Thus $\rho(\coper) = \fml{B}_0(\fml{K})$. Then by $2)$, there is a unitary $U \colon \Hs \sto \fml{K}$, s.t.
	\begin{equation*}
		\rho(A) = U A \st{U}, \text{ for any } A \in \coper
	\end{equation*}
	Let $\{E_i\}$ be the approximatel identity for $\coper$ consisting with all finite projections. For any $A \leqslant 0$ in $\Hs$, then it can see
	\begin{equation*}
		A_i = A^{\frac{1}{2}} E_i A^{\frac{1}{2}} \sto A \text{ in } SOT
	\end{equation*}
	Therefore, $\rho(A_i) = U A_i \st{U} \sto U A \st{U} = T$ in $SOT$. Since $A_i \leqslant A$, $\rho(A_i) \leqslant \rho(A)$ and thus $T \leqslant \rho(A)$ by the fact that $\{A_i\}$ is increasing. Conversely, $\rho(A_i) \leqslant T$ implies that $A_i \leqslant \rho^{-1}(T)$. Thus $A \leqslant \rho^{-1}(T)$, thus $\rho(A) \leqslant T$.
\end{proof}

Here is an important example, which can be used to constract the $AF$ algebra.

\begin{exam}
	Let $M(n)$ be the set of $n \times n$ matrices with complex entries acting on the inner product space $\C^{n}$. If
	\begin{equation*}
		\rho \colon M(m) \longrightarrow M(n)
	\end{equation*}
	is a $*$-homomorphism, then there is an integer $k$ s.t. $km \leqslant n$ and a unitary $U$ in $M(n)$ and 
	\begin{equation*}
		\rho(x) = U(\underbrace{x \oplus x \oplus \cdots \oplus x}_k \oplus 0)\st{U}
	\end{equation*}
	In general, define $\mathbf{m} = (m_1, m_2, \cdots, m_p)$, where $m_i \in \N$, and
	\begin{equation*}
		M(\mathbf{m}) = M(m_1) \oplus M(m_2) \oplus \cdots M(m_p)
	\end{equation*}
	Then for $\mathbf{m} = (m_1, m_2, \cdots, m_p)$ and $\mathbf{n}=(n_1, n_2, \cdots, n_q)$, if $\rho \colon M(\mathbf{m}) \rightarrow M(\mathbf{n})$ is a $*$-homomorphism, then there this a $q \times p$ matirx $[k_{ij}]$ with integer entries s.t.
	\begin{equation*}
		\rho(x_1,\cdots,x_p) = U_1(\underbrace{x_1 \oplus \cdots \oplus x_1}_{k_{11}} \oplus 0)\st{U}_1 \oplus \cdots \oplus U_q(\underbrace{x_p \oplus \cdots \oplus x_p}_{k_{qp}} \oplus 0)\st{U}_q
	\end{equation*}
	By above corollary, we see for any finite dimensional $\st{C}$-algebras $\A$, there exists a $\mathbf{n}=(n_1, n_2, \cdots, n_q)$ s.t. $\A \cong M(\mathbf{n})$. Then we can get the form of the $*$-homomorphism between any two finite dimensional $\st{C}$-algebras. \\
	If $\rho$ is a $*$-homomorphism between two finite dimensional $\st{C}$-algebras\\ $\A \cong M(\mathbf{m})$ and $\B \cong M(\mathbf{n})$, where $\mathbf{m} = (m_1, m_2, \cdots, m_p)$ and $\mathbf{n}=(n_1, n_2, \cdots, n_q)$, then $\rho$ is determined up to a $q \times p$ matirx $[k_{ij}]$ with integer entries. In fact, we can use it to construct the $AF$ algebras.
\end{exam}

\subsection{Decompositions of Compact Operator Algebras}

By above theorem and the Zorn's Lemma, for the non-degenerate $\A$, there is a maximal family $\{E_i\}_{i \in I}$ of pairwise orthogonal minimal projections in $\A$ and let $\Hs_i = \clo{\A E_i \Hs}$ s.t. 
\begin{equation*}
	\Hs = \oplus_{i \in I} \Hs_i~,~ \A|_{\Hs_i} = \fml{B}_0(\Hs_i)
\end{equation*}
But we cannot just using this as the decomposition of the compact operator algebra $\A$, since there are some "equivalent" relationships of these $\Hs_i$. Firstly, we say that $\Hs_i$ does not dependent on $\Hs_j$, if there is a $A \in \A$ s.t. $\A|_{\Hs_j} = 0$ and $\A|_{\Hs_i} \neq 0$.

 \begin{prop}
 	$\Hs_i$ does not dependent on $\Hs_j$ if and only if
 	\begin{equation*}
 		A|_{\Hs_i \oplus \Hs_j} = \fml{B}_0(\Hs_i) \oplus \fml{B}_0(\Hs_j)
 	\end{equation*}
 \end{prop}
 \begin{proof}
 	Assume that $\Hs_i$ does not dependent on $\Hs_j$. Let
 	\begin{equation*}
 		\I = \{~A \in \A \colon A|_{\Hs_j} = 0~\}
 	\end{equation*}
 	Since $\Hs_j$ is reducing, $\I$ is a closed ideal. Moreover, $\I|_{\Hs_i}$ is a closed ideal of $\A|_{\Hs_i} = \fml{B}_0(\Hs_i)$. By the assumption, $\I|_{\Hs_i}$ is not zero, thus $\I|_{\Hs_i} = \fml{B}_0(\Hs_i)$. Let $K_i$ and $K_j$ be arbitrary compact operators on $\Hs_i$ and $\Hs_j$. And $A \in \A$ s.t. $A|_{\Hs_j} = K_j$. Since $\I|_{\Hs_i} = \fml{B}_0(\Hs_i)$, there exists $B \in \I$ s.t. $B|_{\Hs_i} = K_i - A|_{\Hs_i}$. Thus,
 	\begin{equation*}
 		(A+B)|_{\Hs_i} = K_i,~~\&~~ (A+B)|_{\Hs_j} = K_j
 	\end{equation*}
 	The converse is trivial.
\end{proof}
\begin{rem}
	By this proposition, if $\Hs_i$ does not dependent with $\Hs_j$, $\Hs_j$ does not $\Hs_i$. $\Hs_i$ and $\Hs_j$ are independent if they are not dependent.
\end{rem}

Now we want to research the same properties of the dependent subspaces have, and then we can devide all ${\Hs_i}_{i \in I}$ into dependency class.

\begin{prop}
	If $\Hs_i$ and $\Hs_j$ are dependent, then
	\begin{equation*}
		\norm{A|_{\Hs_i}} = \norm{A|_{\Hs_j}}~, \text{ for any } A \in \A
	\end{equation*}
	Moreover, two dependent spaces are isomorphic, and each dependency class is finite.
\end{prop}
\begin{proof}
	By the hypothesis, if $A \in \A$ s.t. $A|_{\Hs_i} = 0$, then $A|_{\Hs_j} = 0$. Then we can define the map
	\begin{equation*}
		\rho \colon  \fml{B}_0(\Hs_j)  \longrightarrow  \fml{B}_0(\Hs_i)
	\end{equation*}
	For any $K \in \fml{B}_0(\Hs_j)$, there is a $A \in \A$ s.t. $A|_{\Hs_j} = K$, then we define that $\rho(K) = A|_{\Hs_i}$.
	\item Claim: $\rho$ is well-defined. \\
	If $B \in \A$ s.t. $B|_{\Hs_j} = K$, then $(A-B)|_{\Hs_j} = 0$. By the dependency of $\Hs_j$ and $\Hs_i$, $(A-B)|_{\Hs_i} = 0$, i.e. $A|_{\Hs_i} = B|_{\Hs_i}$.
	\item $\rho$ is a $*$-isomorphism. \\
	If $K \in \fml{B}_0(\Hs_j)$ s.t. $\rho(K) = 0$, then there is a $A \in \A$ s.t. $A|_{\Hs_j} = K$ and $A|_{\Hs_i} = 0$. Also, by the dependency, $K = A|_{\Hs_j} = 0$. Clearly, $\rho$ is a $*$-homomorphism, then $\rho$ is a $*$-monomorphism, i.e. $\rho$ is an isometry. And the surjectivity of $\rho$ is similar by the dependency of $\Hs_j$ and $\Hs_i$.
	\item Then by the \textbf{Corollary} \ref{cor10} in above subsection, we can find a unitary from $\Hs_j$ to $\Hs_i$. Thus $\dim{\Hs_j} = \dim{\Hs_i}$. And if there are infinite element in a dependency class, by the compactness of $A$, $\norm{A|_{\Hs_i}} \sto 0$, which is a contradiction.
\end{proof}

\begin{thm}
	If $\A$ is a $\st{C}$-subalgebra of compact operators, then
	\begin{equation*}
		\Hs \cong \Hs_0 \oplus \oplus_{d \in D} \Hs_d^{(k_d)}
	\end{equation*}
	and
	\begin{equation*}
		\A \cong \{~0 \oplus \oplus_{d \in D} K_d^{(k_d)} \colon K_d \in \fml{B}_0(\Hs_d)~\}
	\end{equation*}
\end{thm}
\begin{proof}
	Firstly, by above mention, if $\A$ is non-degenerate, there are $\{\Hs_i\}_{i \in I}$ s.t. 
	\begin{equation*}
		\Hs = \oplus_{i \in I} \Hs_i~,~ \A|_{\Hs_i} = \fml{B}_0(\Hs_i)
	\end{equation*}
	But by above theorem, we can divide $\{\Hs_i\}$ into the dependency classes, and re-labeled as 
	\begin{equation*}
		\{~\underbrace{\Hs_1,\cdots,\Hs_1}_{k_1},\underbrace{\Hs_2,\cdots,\Hs_2}_{k_2}, \cdots~\}
	\end{equation*}
	Thus, for the non-degenerate $\A$,
	\begin{equation*}
		\Hs \cong \oplus_{d \in D} \Hs_d^{(k_d)}, \A \cong \{~\oplus_{d \in D} K_d^{(k_d)} \colon K_d \in \fml{B}_0(\Hs_d)~\}
	\end{equation*}
	If $\A$ is degenerate, let $\Hs_0 = (\clo{\A \Hs})^{\bot}$, then this theorem holds.
\end{proof}

For a non-degenerate $\A$, let $\hat{\A}$ denote the set of all equivalent classes of irreducible representations of $\A$. For any $\zeta \in \hat{\A}$, let $\rho_{\zeta} \in \zeta$. By the theorem, for any representation $\rho$ of $\A$, there are irreducible representations $\{\rho_i\}$ s.t. $\rho = \oplus_i \rho_i$, then we define the mutiplicity function of $\rho$,
\begin{equation*}
	m_{\rho}(\zeta) = \#\{i \colon \rho_i \in \zeta\}
\end{equation*}
Now, we can easily apply above theorem to the representation. 

\begin{thm}
	If $\rho$ is a representation of $\A$ and $m_{\rho}$ is the multiplicity function, then
	\begin{equation*}
		\rho \cong \oplus \{~\rho_{\zeta}^{(m_{\rho}(\zeta))} \colon \zeta \in \hat{\A}~\}
	\end{equation*}
	Moreover, any two representations of $\A$ are equivalent if and only if they have same multiplicity functions.
\end{thm}

\section{Trace Class and Ultraweak Topology}

There some interesting subalgebras in the compact operator algebras, and some of them can provide extra topologies on operator algebras, which will be helpful in the research of general von Neumann algebras.

\subsection{Trace Class and Hilbert-Schmit Operators}

\begin{defn}
	Let $T \in \oper$. If there is a a orthonormal basis $\fml{E}$ of $\Hs$ s.t.
	\begin{equation*}
		\sum_{e \in \fml{E}} \langle \abs{T}e,e \rangle < \infty
	\end{equation*}
	then $T$ is called trace class. Let $\toper$ denote the set of all trace classes operators.
\end{defn}

In this definition, the orthonormal basis just need to exist. But how can that condition garantees for any orthonormal basis of $\Hs$ the condition is always satisfied?

\begin{prop}
	If $\fml{E}$ and $\fml{F}$ are two orthonormal bases for $\Hs$, then for any $T \in \oper$,
	\begin{equation*}
		\sum_{e \in \fml{E}} \norm{Te}^2 = \sum_{f \in \fml{F}} \norm{\st{T}f}^2 = \sum_{e \in \fml{E}}\sum_{f \in \fml{F}} \abs{\langle Te,f \rangle}^2
	\end{equation*}
\end{prop}
\begin{proof}
	By the Parseval's Identity,
	\begin{equation*}
		\norm{Te}^2 = \sum_{f \in \fml{F}} \abs{\langle Te,f \rangle}^2
	\end{equation*}
	Then we get above identity.
\end{proof}

\begin{cor}
	The sum 
	\begin{equation*}
		\sum_{e \in \fml{E}} \langle \abs{T}e,e \rangle
	\end{equation*}
	is independent with the choise of the $\fml{E}$.
\end{cor}

Therefore, by this corollary, above definition is valid. Moreover, we can define one more norm on $\toper$, for $T \in \toper$ and some orthonormal basis $\fml{E}$,
\begin{equation*}
	\norm{T}_1 = \sum_{e \in \fml{E}} \langle \abs{T}e,e \rangle
\end{equation*}

Then by using this norm, called the trace norm, on $\toper$, the $\toper$ can be a Banach space.

\begin{defn}
	$T \in \oper$ is called a Hilbert-Schimdt operator if $\abs{T}^2$ is trace class. Let $\hoper$ denote the set of all Hilbert-Schimdt operators. 
\end{defn}

Also, we can define the norm on $\hoper$, for any orthonormal basis $\fml{E}$ in $\Hs$,
\begin{equation*}
	\norm{T}_2 = (\sum_{e \in \fml{E}} \langle \abs{T}^2e,e \rangle)^{\frac{1}{2}} = (\sum_{e \in \fml{E}} \norm{\abs{T}e}^2)^{\frac{1}{2}} = (\sum_{e \in \fml{E}} \norm{Te}^2)^{\frac{1}{2}} = \norm{\abs{T}^2}_1^{\frac{1}{2}}
\end{equation*}
And $\hoper$ can be also a Banach space.

In order to research the trace class, it is convinient to get some properties of the Hilbert-Schmidt operators.

\begin{prop}
	Let $T \in \hoper$.
	\begin{enumerate}[label=\arabic*)]
		\item $\norm{T}_2 = (\sum_{e \in \fml{E}} \norm{Te}^2)^{\frac{1}{2}}$.
		\item $\norm{\st{T}}_2 = \norm{T}_2$.
		\item $\norm{T} \leqslant \norm{T}_2$.
		\item If $A \in \oper$, then $AT,TA \in \hoper$ and 
		\begin{equation*}
			\norm{AT}_2, \norm{TA}_2 \leqslant \norm{A} \norm{T}_2
		\end{equation*}
		\item $\hoper$ is an ideal of $\oper$ and $\norm{\cdot}_2$ is a norm on $\hoper$.
	\end{enumerate}
\end{prop}
\begin{proof}
	The first three results are trivial. For $4)$, fix an orthonormal basis $\fml{E}$ and an $A \in \oper$, for a $e \in \fml{E}$,
	\begin{equation*}
		\norm{ATe}^2 \leqslant \norm{A}^2 \norm{Te}^2 = \norm{A}^2 \norm{\abs{T}e}^2
	\end{equation*}
	Therefore, $\norm{AT}_2 \leqslant \norm{A} \norm{T}_2$.  \\
	For $5)$, we just need to prove the addition is continuous and closed. For a fixed normal basis $\fml{E}$ and $T,S \in \hoper$, then 
	\begin{equation*}
		\{\norm{Te} \colon e \in \fml{E}\}, \{\norm{Se} \colon e \in \fml{E}\} \in l^{2}(\fml{E})
	\end{equation*}
	By the triangle inequality for $l^{2}(\fml{E})$, 
	\begin{equation*}
		\norm{S+T}_2 = \left(\sum_{E}(\norm{Te}+\norm{Se})^2 \right)^{\frac{1}{2}} \leqslant \norm{T}_2 + \norm{S}_2 \qedhere
	\end{equation*}
\end{proof}
\begin{rem}
	Therefore, $\hoper$ with the fixed involution and the norm $\norm{\cdot}_2$ is a $\st{C}$-algebra.
\end{rem}

By using these results, we can see the Hilbert-Schmidt operator is compact.

\begin{cor}
	If $T \in \hoper$ and $\varepsilon > 0$, there is a $A \in \foper$ s.t.
	\begin{equation*}
		\norm{T-A}_2 \leqslant \varepsilon
	\end{equation*}
	Consequently, every Hilbert-Schmidt operator is compact.
\end{cor}
\begin{proof}
	For this fixed $\varepsilon > 0$, since $T \in \hoper$, there is a finite set $I \in \fml{E}$ s.t.
	\begin{equation*}
		\sum_{\fml{E} \backslash I} \norm{Te}^2 < \varepsilon^2
	\end{equation*}
	Let $\hat{E} = \spn{E}$ and $B = T|_{\hat{E}} \in \foper$, then
	\begin{equation*}
		\norm{T-B}_2 = (\sum_{\fml{E} \backslash I} \norm{Te}^2)^{\frac{1}{2}} < \varepsilon \qedhere
	\end{equation*}
\end{proof}

Then, there are similar consequences of the $\toper$.

\begin{prop}
	If $T \in \oper$, then the following statements are equivalent.
	\begin{enumerate}[label=\arabic*)]
		\item $T \in \toper$.
		\item $\abs{T}^{\frac{1}{2}} \in \hoper$.
		\item $T$ is the product of two Hilbert-Schmidt operators.
		\item $\abs{T}$ is the product of two Hilbert-Schmidt operators.
	\end{enumerate}
\end{prop}
\begin{proof}
	Since $\norm{\abs{T}^{\frac{1}{2}}}{e}^2$, $1)$ implies $2)$. And by the Polar Decomposition,
	\begin{equation*}
		T = W \abs{T} = (W \abs{T}^{\frac{1}{2}})\abs{T}^{\frac{1}{2}}
	\end{equation*}
	thus $2)$ implies $3)$. And $3)$ implies $3)$, because of the Polar Decomposition. \\
	Suppose $\abs{T} = BC$ for $B,C \in \hoper$, then for any orthonormal $\fml{E}$ and $e \in \fml{E}$
	\begin{equation*}
		\langle \abs{T}e, e \rangle = \langle Ce \st{B}e \rangle \leqslant \norm{Ce}\norm{\st{B}e}
	\end{equation*}
	Therefore, we have 
	\begin{eqnarray*}
		\sum_{\fml{E}} \langle \abs{T}e, e \rangle &\leqslant& \sum_{\fml{E}} \norm{Ce}\norm{\st{B}e} \\
		&\leqslant& (\sum_{\fml{E}} \norm{Ce}^2)^{\frac{1}{2}} (\sum_{\fml{E}} \norm{Be}^2)^{\frac{1}{2}} \\ 
		&=& \norm{C}_2 \norm{B}_2
	\end{eqnarray*}
	Thus, $T \in \toper$.
\end{proof}

\begin{defn}
	If $T \in \toper$ and $\fml{E}$ is any orthonormal basis, the trace of $T$ is defined as
	\begin{equation*}
		\tr{T} = \sum_{\fml{E}} \langle Te,e \rangle
	\end{equation*}
\end{defn}

It need to check that this definition is well-defined.

\begin{prop}
	If $T \in \toper$ and $\fml{E}$ is any orthonormal basis, then $\sum_{\fml{E}} \abs{\langle Te,e \rangle} < \infty$, and the sum $\sum_{\fml{E}} \langle Te,e \rangle$ is independent with the choice of $\fml{E}$.
\end{prop}
\begin{proof}
	By above proposition, $T = \st{C}B$ for $C,B \in \hoper$. Since $\norm{(C-\lambda B)e}^2 \leqslant 0$ for any $\lambda \in \C$,
	\begin{equation*}
		2 \Rea{\clo{\lambda} \langle Be,Ce \rangle} \leqslant \norm{Be}^2+\abs{\lambda} \norm{Ce}^2
	\end{equation*}
	Choosing a $\lambda$ s.t. $\abs{\lambda} = 1$ and
	\begin{equation*}
		\clo{\lambda} \langle Be,Ce \rangle = \abs{\langle Be,Ce \rangle}
	\end{equation*}
	Then we have,
	\begin{equation*}
		\abs{\langle Te,e \rangle} = \abs{\langle Be,Ce \rangle} \leqslant \frac{1}{2}(\norm{Be}^2+\norm{Ce}^2)
	\end{equation*}
	Thus $\sum_{\fml{E}} \abs{\langle Te,e \rangle} \leqslant \frac{1}{2}(\norm{B}_2^2+\norm{C}_2^2)$. \\ 
	And since 
	\begin{eqnarray*}
		\Rea{\langle Te,e \rangle} &=& \frac{1}{4} (\norm{(B+C)e}^2 - \norm{(B+C)e}^2) \\
		\Img{\langle Te,e \rangle} &=& \frac{1}{4} (\norm{(iB+C)e}^2 - \norm{(iB+C)e}^2)
	\end{eqnarray*}
	then
	\begin{equation*}
		\sum_{\fml{E}} \langle Te,e \rangle = \Rea{\langle Te,e \rangle} + i\Img{\langle Te,e \rangle}
	\end{equation*}
	Therefore, the sum is independent with the choice of the orthonormal basis $\fml{E}$.
\end{proof}

For convinience, there is another notation to denote the rank one operators.
\begin{defn}
	For two vectors $g,h \in \Hs$, the rank one operator $g \otimes h$ is defined as
	\begin{equation*}
		g \otimes h (f) = \langle f,h \rangle g
	\end{equation*}
\end{defn}

There are some elementary properties for this rank one operator.
\begin{prop}
	Let $g,h \in \Hs$.
	\begin{enumerate}[label=\arabic*)]
		\item $e \otimes e$ is the projection onto $\C e$.
		\item $\ran{g \otimes h} = \C g$ and $\ker{g \otimes h} = (\C h)^{\bot}$ for $g \neq 0$.
		\item $(g \otimes h)^{*} = h \otimes g$.
		\item The map $(g,h) \sto g \otimes h$ is a sesquilinear from $\Hs \times \Hs$ to $\oper$.
		\item $\norm{g \otimes h} = \norm{g} \norm{h}$.
		\item If $T \in \oper$, then $T(g \otimes h) = (Tg) \otimes h$ and $(g \otimes h) T = g \otimes (\st{T}h)$.
		\item Every any finite rank operator can be expressed as
		\begin{equation*}
			\sum_{k=1}^{n} g_k \otimes h_k
		\end{equation*}
		for some $g_1, \cdots, g_n \in \Hs$ and $h_1, \cdots, h_n \in \Hs$.
		\item For $C = \sum_{k=1}^n g_k \otimes h_k$ and $A \in \oper$,
		\begin{equation*}
			\tr{AC} = \sum_{k=1}^n \langle Ag_k,h_k \rangle
		\end{equation*}
	\end{enumerate}
\end{prop}

There are more interesting properties of the trace class.

\begin{thm}
	\begin{enumerate}[label=\arabic*)]
		\item $\toper \subset \coper$ and conversely, if $A \in \coper$ and $\{\alpha_n\}$ are the eigenvalues of $\abs{A}$, then $A \in \toper$ if and only if $(\alpha_n) \in l^{1}$. In this case, $\norm{A}_1 = \sum \alpha_n$.
		\item $\toper$ is an ideal of $\oper$.
		\item $\tr{} \colon \toper \sto \C$ is a positive non-degenerate linear functional.
		\item $\foper$ is a dense subset in $\toper$ with respect to $\norm{\cdot}_1$.
		\item If $T \in \toper$, then for any $A \in \oper$,
		\begin{equation*}
			\tr{TA} = \tr{AT},~\text{and } \abs{\tr{AT}} \leqslant \norm{A}\norm{T}_1
		\end{equation*}
		\item $\norm{T}_1 = \norm{\st{T}}_1$ for any $T \in \toper$.
		\item If $T \in \toper$ and $A \in \oper$, then
		\begin{equation*}
			\norm{TA}_1,~ \norm{AT}_1 \leqslant \norm{A} \norm{T}_1
		\end{equation*}
	\end{enumerate}
\end{thm}
\begin{proof}
	If $A \in \coper$, also $\abs{A} \in \coper$, then there is an orthonormal basis $\{e_n\}$ for $\Hs$ and the correponding eigenvalues $\{\alpha_n\} \in l^{\infty}(\C)$ s.t.
	\begin{equation*}
		\abs{A} = \sum_{n} \alpha_n P_{e_n} = \sum_{n} \alpha_n e_n \otimes e_n
	\end{equation*}
	Then we have that
	\begin{equation*}
		\sum_n \langle \abs{A}e_n, e_n \rangle = \sum_n \alpha_n
	\end{equation*}
	By the Polar Decomposion, $A \in \toper$ is equivalent the $\abs{A} \in \toper$. Thus, $\{\alpha_n\} \in l^{1}(\C)$ is equivalent to $A \in \toper$, and $\norm{A}_1 = \sum \alpha_n$.
	\item For $2)$, similarly as the $\hoper$, we just need to prove that the addition is continuous and closed. Let $A \in \toper$ and $B \in \toper$, and by the Polar Decomposition,
	\begin{equation*}
		A = W\abs{A},~ B = V \abs{B},~ A+B = U\abs{A+B}
	\end{equation*}
	And $\abs{A+B} = \sum_{n} \gamma_n e_n \otimes e_n$ for an orthonormal basis $\{e_n\}$. By $1)$, we just need to check that $\{\gamma_n\} \in l^{1}(\C)$.
	\begin{eqnarray*}
		\sum_n \gamma_n &=& \sum_n \langle \abs{A+B}e_n,e_n \rangle = \sum_n \abs{\langle Ae_n, Ue_n \rangle + \langle Be_n, Ue_n \rangle} \\
		&=& \sum_n \abs{\langle \abs{A}e_n, \st{W}Ue_n \rangle + \langle \abs{B}e_n, \st{V}Ue_n \rangle} \\
		&=& \sum_n \abs{\langle \abs{A}^{\frac{1}{2}}e_n, \abs{A}^{\frac{1}{2}}\st{W}Ue_n \rangle + \langle \abs{B}^{\frac{1}{2}}e_n, \abs{B}^{\frac{1}{2}}\st{V}Ue_n \rangle} \\
		&\leqslant& \sum_n (\norm{\abs{A}^{\frac{1}{2}}e_n}\norm{\abs{A}^{\frac{1}{2}}\st{W}Ue_n}+\norm{\abs{B}^{\frac{1}{2}}e_n}\norm{\abs{B}^{\frac{1}{2}}\st{V}Ue_n}) \\
		&\leqslant& \left(\sum_n \norm{\abs{A}^{\frac{1}{2}}e_n}^2 \right)^{\frac{1}{2}}\left(\sum_n \norm{\abs{A}^{\frac{1}{2}}\st{W}Ue_n}^2 \right)^{\frac{1}{2}} \\
		&& \negmedspace{} + \left(\sum_n \norm{\abs{B}^{\frac{1}{2}}e_n}^2 \right)^{\frac{1}{2}}\left(\sum_n \norm{\abs{B}^{\frac{1}{2}}\st{V}Ue_n}^2 \right)^{\frac{1}{2}} \\
		&\leqslant& \norm{\abs{A}^{\frac{1}{2}}}_2^2 + \norm{\abs{B}^{\frac{1}{2}}}_2^2 \\
		&=& \norm{A}_1 + \norm{B}_1
	\end{eqnarray*}
	\item $3)$ is trivial and $4)$ can be obtained by similar argument as the $\hoper$.
	\item For $5)$, let $T \in \toper$ and $T = \st{C}B$ for some $B,C \in \hoper$, then by above mention,
	\begin{eqnarray*}
		\Rea{\tr{\st{C}B}} &=& \frac{1}{4} (\norm{(B+C)e}^2 - \norm{(B+C)e}^2) \\
		&=& \frac{1}{4} (\norm{(\st{B}+\st{C})e}^2 - \norm{(\st{B}+\st{C})e}^2) \\
		&=& \Rea{\tr{C\st{B}}}
	\end{eqnarray*}
	And similarly, $\Img{\tr{\st{C}B}} = - \Img{\tr{C\st{B}}}$, thus
	\begin{equation*}
		\tr{\st{C}B} = \clo{\tr{C\st{B}}}
	\end{equation*}
	Therefore, we have that for any $A \in \oper$ 
	\begin{equation*}
		\tr{AT} = \tr{(A\st{C})B} = \clo{\tr{C\st{A} \st{B}}} = \tr{(\st{C})BA} = \tr{TA}
	\end{equation*}
	Let $T = W \abs{T}$ be the Polar Decomposition. Then by the CBS Inequality,
	\begin{eqnarray*}
		\abs{\tr{AT}} &\leqslant& \sum_{\fml{E}}  \norm{\abs{T}^{\frac{1}{2}}e}\norm{\abs{T}^{\frac{1}{2}}\st{W}\st{A}e} \\
		&\leqslant& \left(\sum \norm{\abs{T}^{\frac{1}{2}}e}^2 \right)^{\frac{1}{2}}\left(\sum \norm{\abs{T}^{\frac{1}{2}}\st{W}\st{A}e}^2 \right)^{\frac{1}{2}} \\
		&\leqslant& \norm{\abs{T}^{\frac{1}{2}}}_2\norm{\abs{T}^{\frac{1}{2}}\st{W}\st{A}}_2 \\
		&\leqslant& \norm{\abs{T}^{\frac{1}{2}}}_2^2 \norm{\st{W}\st{A}} \\
		&\leqslant& \norm{T}_1 \norm{A}
	\end{eqnarray*}
	\item For $6)$, let $T = W \abs{T} \in \toper$, then $T\st{T} = W \abs{T}^2 \st{W}$. So by the uniqueness of root, $\abs{\st{T}} = W \abs{T} \st{W}$. Therefore,
	\begin{equation*}
		\norm{\st{T}}_1 = \tr{\abs{\st{T}}} = \tr{W \abs{T} \st{W}} = \tr{W \st{W} \abs{T}}
	\end{equation*} 
	Since $W \st{W} \abs{T} = \abs{T}$, $\norm{\st{T}}_1 = \norm{T}_1$.
	\item For $7)$, let $T = W \abs{T} \in \toper$ and $AT = V \abs{AT}$. So
	\begin{equation*}
		\abs{AT} = S \abs{T}, \text{ where } S = \st{V}A W
	\end{equation*}
	Thus $\norm{S} \leqslant \norm{A}$, then
	\begin{equation*}
		\norm{AT}_1 = \tr{\abs{AT}} = \tr{S \abs{T}} \leqslant \norm{S} \norm{T}_1 \leqslant \norm{A}\norm{T}_1 \qedhere
	\end{equation*}
\end{proof}
\begin{rem}
	By this theorem, $(\toper, \norm{\cdot}_1)$ is also a $\st{C}$-algebra.
\end{rem}

\begin{thm}
	If $\{g_n\}$ and $\{h_n\}$ are two square summable sequences, then 
	\begin{equation*}
		T = \sum_{n} g_n \otimes h_n \in \toper, \text{ and } \norm{T}_1 \leqslant \sum_{n} \norm{g_n}\norm{h_n}
	\end{equation*}
	Conversely, if $T \in \toper$, then there are two square summable sequences $\{g_n\}$ and $\{h_n\}$ s.t.
	\begin{equation*}
		\sum_n \norm{g_n}^2 = \norm{T}_1 = \sum_n \norm{h_n}^2, \text{ and } T = \sum_{n} g_n \otimes h_n
	\end{equation*}
\end{thm}
\begin{proof}
	Let $\{e_n\}$ be an orthonormal sequence of $\Hs$ and $G_n = \sum_{k=1}^{n} g_n \otimes e_n$. If $n > m$, then
	\begin{equation*}
		\norm{G_n-G_m}_2^2 = \sum_{k=m+1}^{n} \norm{(G_n-G_m)e_k}^2 = \sum_{k=m+1}^{n} \abs{\langle e_k,g_K \rangle}^2 \leqslant \sum_{k=m+1}^{n} \norm{g_k}^2
	\end{equation*}
	Since $\{g_n\}$ is square summable, $\{G_n\}$ is Cauchy with respect to the norm $\norm{\cdot}_2$. Therefore, there is a $G \in \hoper$ s.t.
	\begin{equation*}
		G = \lim_n G_n = \sum_n g_n \otimes e_n
	\end{equation*}
	Similarly, there is a $H = \sum_n e_n \otimes h_n$ in $\hoper$. And then by the definition, $T = GH \in \toper$.
	\item Conversely, if $T \in \toper$ and $T = W\abs{T}$ is the Polar Decomposition, there exist an orthonormal basis $\{e_n\}$ for $\ker{\abs{T}}^{\bot} = \ker{T}^{\bot}$ and a sequence $\{\alpha_n\} \in l^{1}(\C)$, s.t. 
	\begin{equation*}
		\abs{T} = \sum_n \alpha_n e_n \otimes e_n
	\end{equation*}
	Then put $h_n = \sqrt{\alpha_n}e_n$ and $g_n = W h_n$. Since $W$ is a partial isometry, $\{g_n\}$ is an orthonormal set. And clearly, 
	\begin{equation*}
		\norm{g_n}^2 = \norm{h_n}^2 = \alpha_n \Rightarrow \sum_n \norm{g_n}^2 = \sum_n \norm{h_n}^2 = \sum_n \alpha_n = \norm{T}_1
	\end{equation*}
	and $T = \sum_n g_n \otimes h_n$.
\end{proof}
\begin{rem}
	In fact, if $g_n$ and $h_n$ are chosen like above mention,
	\begin{equation*}
		\norm{T}_1 = \sum_n \norm{g_n}\norm{h_n}
	\end{equation*}
\end{rem}

Also, the structure of $\hoper$ can be more explicit.

\begin{thm}
	\begin{enumerate}[label = \arabic*)]
		\item For $\hoper$, define the inner product $\langle \cdot,\cdot \rangle$ as
		\begin{equation*}
			\langle T,G \rangle = \tr{\st{G}T}
		\end{equation*}
		Then $\norm{\cdot}_2$ can be induced by this inner product, and moreover, $\hoper$ is a Hilbert space with respect to this inner product.
		\item If $A \in \coper$ and $\{\alpha_n\}$ are the eigenvalues of $\abs{A}$, then $A \in \hoper$ if and only if $(\alpha_n) \in l^{2}$. In this case, $\norm{A}_1 = \sum \alpha_n^2$.
		\item The Hilbert space $\hoper$ containing $\foper$ as a dense subspace with respect to the norm $\norm{\cdot}_2$.
	\end{enumerate}
\end{thm}

\subsection{Dual Spaces}

In above subsection, we have seen $\toper$ is indeed a $\st{C}$-algebra, thus a Banach algebra with respect to the norm $\norm{\cdot}_1$. Therefore, we can get the following important properties.

\begin{thm}
	For $A \in \toper$, define the functional
	\begin{center}
		\begin{tabular}{l c c l}
			$\Phi_A \colon$ & $\coper$ & $\longrightarrow$ & $\C$ \\
			~ & $C$ & $\longmapsto$ & $\tr{AC}$
		\end{tabular}
	\end{center}
	Then $\Phi_A \in \st{\coper}$. Therefore, there is a map
	\begin{center}
		\begin{tabular}{l c c l}
			$\rho \colon$ & $\toper$ & $\longrightarrow$ & $\st{\coper}$ \\
			~ & $A$ & $\longmapsto$ & $\Phi_A$
		\end{tabular}
	\end{center}
	Moreover, $\rho$ is an isomorphic isomorphism, i.e. $\toper \cong \coper$. 
\end{thm}
\begin{proof}
	Since $\coper \subset \toper$, by above proposition, $\Phi_A \in \st{\coper}$. Moreover, 
	\begin{equation*}
		\sup{\{~\abs{\tr{AC}} \colon \norm{C}_1 \leqslant 1~\}} \leqslant \norm{A}_1 \Rightarrow  \norm{\Phi_A} \leqslant \norm{A}_1
	\end{equation*}
	That means $\norm{\rho} \leqslant 1$.
	\item Check: $\rho$ is surjective.\\
	Let $\Phi \in \st{\coper}$ and define the sesquilinear map $f$ on $\Hs$,
	\begin{equation*}
		f(g,h) = \Phi(g \otimes h), \text{ and } \abs{f(g,h)} \leqslant \norm{\Phi}\norm{g}\norm{h}
	\end{equation*}
	Therefore, there exists $A \in \oper$ s.t.
	\begin{equation*}
		f(g,h) = \Phi(g \otimes h) = \langle Ag, h \rangle,~\forall g,h \in \Hs
	\end{equation*}
	For any $C \in \foper$, then there are finite number $\{g_k\}$ and $\{h_k\}$ for $k=1,\cdots,n$ s.t. $C = \sum_{k=1}^{n} g_k \otimes h_k$
	\begin{eqnarray*}
		\Phi(C) &=& \Phi(\sum_{k=1}^{n} g_k \otimes h_k) = \sum_{k=1}^{n} \langle A g_k , h_k \rangle \\
		&=& \tr{AC} = \Phi_A(C)
	\end{eqnarray*}
	Since $\foper$ is norm-dense in $\coper$ and $\Phi$ and $\Phi_A$ are bounded, $\Phi = \Phi_A$.
	\item Check: $\rho$ is isometric.\\
	Let $\fml{E}$ be an orthonormal basis and $A \in \toper$ with the Polar Decomposition $A = W\abs{A}$, then for any finite subset $E$ in $\fml{E}$
	\begin{eqnarray*}
		\norm{\Phi_A} &\geqslant& \abs{\Phi(\sum_{e \in E}(e \otimes e)\st{W})} = \abs{\Phi_A(\sum_{e \in E}e \otimes We)} \\
		&=& \sum_{e \in E} \abs{\langle Ae,We \rangle} \\
		&=& \sum_{e \in E} \langle \abs{A}e, e \rangle
	\end{eqnarray*}
	Then $\norm{\Phi_A} \geqslant \norm{A}_1$ as $\{E\}$ can be an increasing net in $\fml{E}$.
\end{proof}

\begin{thm}
	For $B \in \oper$, define the functional
	\begin{center}
		\begin{tabular}{l c c l}
			$\Psi_B \colon$ & $\toper$ & $\longrightarrow$ & $\C$ \\
			~ & $A$ & $\longmapsto$ & $\tr{AB}$
		\end{tabular}
	\end{center}
	Then $\Psi_B \in \st{\toper}$. Therefore, there is a map
	\begin{center}
		\begin{tabular}{l c c l}
			$\rho \colon$ & $\oper$ & $\longrightarrow$ & $\st{\toper}$ \\
			~ & $B$ & $\longmapsto$ & $\Psi_B$
		\end{tabular}
	\end{center}
	Moreover, $\rho$ is an isomorphic isomorphism, i.e. $\oper \cong \st{\toper}$. 
\end{thm}
\begin{proof}
	Clearly, $\Psi_B \in \st{\toper}$ with $\norm{\Psi_B} \leqslant \norm{B}$.
	\item Check: $\rho$ is isometric. \\
	For a given $\varepsilon > 0$, there exists a unit $g$ s.t. 
	\begin{equation*}
		\norm{Bg} > \norm{B}-\varepsilon
	\end{equation*}
	And choosing a $h \in \Hs$, s.t. $\norm{Bg} = \langle Bg,h \rangle$. Let $C = g \otimes h$, then $C \in \toper$ and $\norm{C}_1 = 1$.  Thus,
	\begin{equation*}
		\norm{\Psi_B} \geqslant \abs{\tr{BC}} = \langle Bg,h \rangle = \norm{Bg} > \norm{B}-\varepsilon
	\end{equation*}
	Therefore, $\norm{\Psi_B} = \norm{B}$.
	\item Check: $\rho$ is surjective.\\
	Let $\Psi \in \st{\toper}$. Similarly as above theorem, there is a $B \in \oper$ s.t. $\langle Bg,h \rangle = \Psi(g \otimes h)$ for all $g,h \in \Hs$. And also, $\Psi = \Psi_B$ on the $\foper$. By the extension, $\Psi = \Psi_B$.
\end{proof}

\begin{thm}
	$\st{(\oper, WOT)} = \st{(\oper, SOT)} = \foper$.
\end{thm}
\begin{proof}
	By the \textbf{Proposition} \ref{prop13} in the subsection \textbf{3.3.3}, any $L \in \st{(\oper, WOT)}$ can be expressed as
	\begin{equation*}
		L(T) = \sum_{k=1}^n \langle Tg_k, h_k \rangle = \tr{CT} = \Psi_C(T), \text{ where } C = \sum_{k=1}^n g_k \otimes h_k
	\end{equation*}
	Thus, $\st{(\oper, WOT)} = \st{(\oper, SOT)} = \foper$.
\end{proof}

\subsection{Ultraweak Topology}

By above subsection, we know that
\begin{equation*}
	\oper \cong \st{(\toper, \norm{\codt}_1)}
\end{equation*}
Thus, $\oper$ can be equiped with the $weak^{*}$ topology with respect to the $\st{(\toper, \norm{\codt}_1)}$. The subbasis of a point $A \in \oper$ is like,
\begin{equation*}
	V_{\varepsilon}(A) = \{~B \in \oper \colon \abs{\tr{T(A-B)}} < \varepsilon, \forall T \in \toper~\}
\end{equation*}
for any $\varepsilon > 0$. This topology on $\oper$ is called the ultraweak topology or $\sigma-weak$ topology. Therefore, for a net $\{A_{\alpha}\}$ in $\oper$, $A_{\alpha} \sto A$ if and only of for any $T \in \toper$
\begin{equation*}
	\tr{TA_{\alpha}} \sto \tr{TA}
\end{equation*}
Moreover, by the \textbf{Theorem} \ref{thm11} in above subsection, for any $T \in \toper$, there exist two sequences $\{g_n\}$ and $\{h_n\}$ s.t. $T = \sum_n g_n \otimes h_n$ and then
\begin{equation*}
	\tr{TA} = \sum_n \langle A g_n, h_n \rangle
\end{equation*}
Then, for a net $\{A_{\alpha}\}$ in $\oper$, $A_{\alpha} \sto A$ if and only of for any two summable sequences $\{g_n\}$ and $\{h_n\}$ in $\Hs$, 
\begin{equation*}
	\sum_n \langle A_{\alpha} g_n, h_n \rangle \sto \sum_n \langle A g_n, h_n \rangle
\end{equation*}

Then there are some trivial properties of this topology.

\begin{prop}
	\begin{enumerate}[label = \arabic*)]
		\item If $\Hs$ is separable, then the closed unit ball in $\oper$ with the ultraweak topology is a compact metric space.
		\item The ultraweak topology and the $WOT$ agree on bounded subsets of $\oper$.
		\item A sequence in $\oper$ converges $weak^{*}$ if and only if it converges $WOT$.
	\end{enumerate}
\end{prop}
\begin{proof}
	$1)$ is clearly by the form of subbasis of the ultraweak topology. 
	\item For $2)$, by above mention, the ultraweak topology is bigger than the $WOT$, that means the identity map
	\begin{equation*}
		i \colon (\oper, weak^{*}) \longrightarrow (\oper, WOT)
	\end{equation*}
	is continuous. When it restricts to any bounded subset $\mathcal{S}$, since $\mathcal{S}$ is $weak^{*}$-compact by $1)$, $i$ is a homeomorphism.
	\item By the Principle of Uniform Boundedness, $WOT$-convergent sequence is bounded, thus by $2)$, it is $weak^{*}$-convergent. And the converse is trivial.
\end{proof}

Now, we want to find more relations between the ultraweak topology and the $WOT$. Firstly, the inflation can provide us some information about that.

\begin{prop}
	If $1 \leqslant d \leqslant \infty$ and $C \in \fml{B}_1(\fml{H}^{(d)})$ with the matrix representation $C = [C_{jk}]$, then
	\begin{enumerate}[label = \arabic*)]
		\item $K = \sum_k C_{kk}$ converges $weak^{*}$ in $\toper$ and
		\begin{equation*}
			\norm{\sum_k C_{kk}} \leqslant \norm{C}_1
		\end{equation*}
		\item if $T \in \oper$ and $K$ is as $1)$, then
		\begin{equation*}
			\tr{T^{(d)}C} = \tr{TK} = \sum_{k=1}^{d} \tr{TC_{kk}}
		\end{equation*}
		and this converges absolutely for $d = \infty$.
	\end{enumerate}
\end{prop}
\begin{proof}
	We just need to prove this proposition in the infinite case.
	\item For $1)$, let $P_k$ be the projection from $\Hs^{(\infty)}$ onto the $k$-th coordinate space. Then $C_{kk} = P_k C P_k$. And clearly, for $1 \leqslant n < m < \infty$, $\sum_{k=n}^{m}C_{kk} \in \toper$, if $L \in \fml{B}_0(\fml{H}^{(\infty)})$,
	\begin{eqnarray*}
		\abs{\tr{(L \sum_{k=n}^{m}C_{kk})}} &=& \abs{\sum_{k=n}^{m} \tr{(LP_kCP_k)}} = \abs{\sum_{k=n}^{m} \tr{(CP_kLP_k)}} \\
		&=& \abs{\tr{(C \sum_{k=n}^{m} P_kLP_k)}} \\
		&\leqslant& \norm{C}_1 \norm{\sum_{k=n}^{m} P_kLP_k} \\
		&=& \norm{C}_1 \sup{\{\norm{P_kLP_k} \colon n \leqslant k \leqslant m\}} \\
		&\leqslant& \norm{C}_1 \norm{L}
	\end{eqnarray*}
	Then by the \textbf{Proposition} \ref{prop14} in the subsection \textbf{3.2.1}, (Confused!)
	\begin{equation*}
		\norm{\sum_{k=n}^{m}C_{kk}}_1 = \sup{\left\{~\abs{\tr{(L\sum_{k=n}^{m}C_{kk})}} \colon \norm{L} \leqslant 1,~ \ \in \fml{B}_0(\fml{H}^{(\infty)}~\right\}}
	\end{equation*}
	And since $L \in \fml{B}_0(\fml{H}^{(\infty)}$, $\norm{P_kLP_k} \sto 0$. Therefore, $1)$ holds.
	\item For $2)$, let $\{e_i \colon i \in I\}$ be a orthonormal basis of $\Hs$ and $\{e_{ki} \colon 1 \leqslant k \leqslant \infty, i \in I\}$ be a orthonormal basis of $\Hs^{(\infty)}$, then for any $T \in \fml{B}(\fml{H})$, $TC \in \fml{B}_1(\fml{H}^{(\infty)})$ and
	\begin{equation*}
		\tr{(T^{(\infty)}C)} = \sum_{i \in I} \sum_{k=1}^{\infty} \langle T^{(\infty)}C e_{ki},e_{ki} \rangle
	\end{equation*}
	Fixing $k$, we have that
	\begin{equation*}
		\langle T^{(\infty)}Ce_{ki},e_{ki} \rangle = \langle TC_{kk}e_{i},e_{i} \rangle = \tr{((e_i \otimes e_i)TC_{kk})}
	\end{equation*}
	By the $weak^{*}$-convergence of $K = \sum_{k} C_{kk}$, 
	\begin{eqnarray*}
		\langle TKe_i,e_i \rangle &=& \sum_{k=1}^{\infty} \tr{((e_i \otimes e_i)TC_{kk})} \\
		&=& \sum_{k=1}^{\infty} \langle TC_{kk}e_{ki},e_{ki} \rangle \\
		&=& \sum_{k=1}^{\infty} \langle T^{(\infty)}Ce_{ki},e_{ki} \rangle
	\end{eqnarray*}
	Since above series is absolutely convergent, 
	\begin{equation*}
		\tr{(T^{(\infty)}C)} = \sum_{k=1}^{\infty} \sum_{i \in I} \langle TC_{kk}e_{ki},e_{ki} \rangle = \sum_{k=1}^{\infty} \tr{(TC_{kk})} = \tr{TK}
	\end{equation*}
\end{proof}

\begin{thm}
	\begin{enumerate}[label = \arabic*)]
		\item If $C \in \toper$ with rank at most $d$, where $1 \leqslant d \leqslant \infty$, then there are $g,h \in \Hs^{(d)}$ s.t. $\norm{g}^2 = \norm{h}^2 \leqslant \norm{C}_1$ and 
		\begin{equation*}
			\langle T^{(d)}g,h \rangle = \tr{TC},~ \forall T \in \oper
		\end{equation*}
		\item If $1 \leqslant d \leqslant \infty$ and $g,h \in \Hs^{(d)}$, then there is a $C \in \toper$ with rank at most $d$ s.t.
		\begin{equation*}
			\langle T^{(d)}g,h \rangle = \tr{TC},~ \forall T \in \oper
		\end{equation*}
		\item If $C \in \fml{B}_1(\fml{H}^{(\infty)}$, then there are $g,h \in \Hs^{(\infty)}$ s.t. $\norm{g}^2 = \norm{h}^2 \leqslant \norm{C}_1$ and
		\begin{equation*}
			\langle T^{(\infty)}g,h \rangle = \tr{T^{(\infty)}C},~ \forall T \in \oper
		\end{equation*}
		\item If $g,h \in \Hs^{(\infty)}$, then there is a $C \in \fml{B}_1(\fml{H}^{(\infty)})$ s.t. $\norm{g}^2 = \norm{h}^2 \leqslant \norm{C}_1$ and
		\begin{equation*}
			\langle T^{(\infty)}g,h \rangle = \tr{T^{(\infty)}C},~ \forall T \in \oper
		\end{equation*}
	\end{enumerate}
\end{thm}
\begin{proof}
	Just need to prove the case when $d = \infty$.
	\item For $1)$, let $C = \sum_k g_k \otimes h_k$ with $\norm{g_k}^2 = \norm{h_k}^2 = \norm{C}_1$. Then $g = (g_k)$ and $h = (h_k)$ are in $\Hs^{(\infty)}$, and it is clear that 
	\begin{equation*}
		\langle T^{(\infty)}g,h \rangle = \tr{TC},~ \forall T \in \oper
	\end{equation*}
	And the converse is similar.
	\item If $C = (C_{jk}) \in \fml{B}_1(\fml{H}^{(\infty)})$, then by above proposition, $K = \sum_k C_{kk} \in \toper$ and $\norm{K}_1 \leqslant \norm{C}_1$. Moreover, $\tr{(T^{(\infty)}C)} = \tr{(TK)}$. Then by $1)$, there are $g = (g_k)$ and $h = (h_k)$ in $\Hs^{(\infty)}$ with $\norm{g_k}^2 = \norm{h_k}^2 = \norm{K}_1 \leqslant \norm{C}_1$ s.t.
	\begin{equation*}
		\tr{(T^{(\infty)}C)} = \tr{(TK)} = \langle T^{(\infty)}g,h \rangle.
	\end{equation*}
	And $4)$ is also trivial.
\end{proof}

Then, we can see one more relation between the ultraweak topology and the $WOT$.

\begin{thm}
	If $\{T_i\}$ is a net in $\oper$, then the following statements are equivalent.
	\begin{enumerate}[label = \arabic*)]
		\item $T_i \sto 0$ in $weak^{*}$.
		\item $T_i^{\infty} \sto 0$ in $weak^{*}$.
		\item $T_i^{\infty} \sto 0$ in $WOT$.
	\end{enumerate}
\end{thm}
\begin{proof}
	If $C \in \fml{B}_1(\fml{H}^{(\infty)})$ and $K = \sum_k C_{kk}$, then by above theorem,
	\begin{equation*}
		\tr{T_i^{(\infty)}C} = \tr{(T_iK)}
	\end{equation*}
 	Therefore, $1)$ implies $2)$. Since the the ultraweak topology and the $WOT$ agree on any bounded subset, $2)$ implies $3)$. Let $K \in \toper$, then there are $h,g \in \Hs^{\infty}$ s.t. $\tr{(KT_i)} = \langle T_i^{\infty}f,g \rangle$. Thus, $3)$ implies $1)$.
\end{proof}

\begin{cor}
	\begin{enumerate}[label=\arabic*)]
		\item If $\mathcal{S} \subset \oper$ is a subset and $\mathcal{S}_1 = \clo{\mathcal{S}}^{wk^{*}}$, then 
		\begin{equation*}
			\clo{\{S^{(\infty)} \colon S \in \mathcal{S}\}}^{WOT} = \clo{\{S^{(\infty)} \colon S \in \mathcal{S}\}}^{wk^{*}} = \mathcal{S}_1^{(\infty)}
		\end{equation*}
		Therefore, $\mathcal{S}$ is $weak^{*}$-closed if and only if $\mathcal{S}^{(\infty)}$ is $WOT$-closed.
		\item If $\A$ is a $\st{C}$-subalgebra of $\oper$, then
		\begin{equation*}
			\clo{\A}^{wk^{*}} = \A^{''}
		\end{equation*}
		That means any von Neumann algebra is $weak^{*}$-closed.
	\end{enumerate}
\end{cor}
\begin{proof}
	$1)$ is a direct result from above theorem.
	\item For $2)$, let $\A_1 = \clo{\A}^{wk^{*}}$. Then by $1)$ and the Double Commutant Theorem,
	\begin{equation*}
		\A_1^{(\infty)} = \{\A^{(\infty)}\}^{''} = \{\A^{''}\}^{(\infty)}
	\end{equation*}
	Thus, $\A_1 = \A^{''} = \A$.
\end{proof}
\begin{rem}
	Therefore, we have another powerful topology to research von Neumann algebras and it is very important.
\end{rem}

\section{Fredholm Theory}

Let $\pi \colon \oper \sto \oper / \coper$ be the quotient map. Then 
\begin{equation*}
	\pi(A) = A + \coper
\end{equation*}
And the $\st{C}$-algebra $\oper / \coper$ is called the Calkin algebra. Therefore, in order to research the compact perturbations, the Calkin algebra plays an important role. 

\subsection{Fredholm Operators}

\begin{defn}
	Let $A \in \oper$ and $\pi \colon \oper \sto \oper / \coper$ be the quotient map. If $\pi(A)$ is left-invertible (or right) in the Calkin algebra, then $A$ is called a left (or right) semi-Fredholm operator. If $\pi(A)$ is invertible in the Calkin algebra, then $A$ is called a Fredholm operator.
\end{defn}

There are some equivalent conditions of the Fredholm operators.
\begin{thm}
	If $A \in \oper$, then the following statements are equivalent.
	\begin{enumerate}[label = \arabic*)]
		\item $A$ is left semi-Fredholm.
		\item $\ran{A}$ is closed and $\dim{\ker{A}} < \infty$.
		\item There is a $B \in \oper$ and a finite rank $F \in \oper$ s.t.
		\begin{equation*}
			BA = 1 + F
		\end{equation*}
	\end{enumerate}
\end{thm}
\begin{proof}
	$1) \Rightarrow 2)$: There is a $B$ s.t. $\pi(B)\pi(A) = 1$, i.e $\pi(BA-1) = 0$. That means there is a $K \in \coper$ s.t. $BA = 1 + K$. Then, by the \textbf{Theorem} \ref{thm12} in the subsection \textbf{5.1.2},
	\begin{equation*}
		\ker{A} \subset \ker{BA} = \ker{(1+K)} < \infty
	\end{equation*}
	And $\ran{BA} = \ran{(1+K)}$ is closed. By the \textbf{Lemma} \ref{lem1} in the subsection \textbf{2.4.4}, there is a constant $C > 0$ s.t. for any $h \in (\ker{BA})^{\bot}$, 
	\begin{equation*}
		C\norm{h} \leqslant \norm{BAh} \leqslant \norm{B}\norm{Ah} \Rightarrow \norm{Ah} > C^{'}\norm{h}
	\end{equation*}
	Therefore, $A((\ker{BA})^{\bot})$ is closed. Because
	\begin{equation*}
		\ran{A} = A((\ker{BA})^{\bot}) + A(\ker{BA})
	\end{equation*}
	and $\ker{BA} < \infty$, then $\ran{A}$ is closed.
	\item $2) \Rightarrow 3)$: Define $A_1 \colon (\ker{A})^{\bot} \sto \ran{A}$, then $A_1$ is invertible by the Inverse Mapping Theorem. Let $F$ be the projection onto $\ker{A}$ and $P$ be the projection onto $\ran{A}$, then
	\begin{equation*}
		BA = 1 - F, \text{ where } B = A_1^{-1}P
	\end{equation*}
	$3)$ implies $1)$ trivially.
\end{proof}

Above theorem provides the information of the range and the kernel of Fredholm operators. Besides that, we can also find the equivalent conditions of Fredholm operators from another point of view.
\begin{thm}
	If $A \in \oper$, then the following statements are equivalent. 
	\begin{enumerate}[label=\arabic*)]
		\item $A$ is left semi-Fredholm.
		\item There is no unit sequence $\{h_n\}$ s.t. $h_n \sto 0$ weakly and $Ah_n \sto 0$ in norm.
		\item There is no orthonormal sequence $\{e_n\}$ s.t. $Ae_n \sto 0$ in norm.
		\item There is a $\delta > 0$ s.t. $\{h \in \Hs \colon \norm{Ah} \leqslant \delta \norm{h}\}$ contains no infinite dimensional manifold.
		\item Let $\abs{A} = \int t dE(t)$, then there is a $\delta > 0$ s.t. $E([0,\delta])\Hs$ is finite dimensional.
	\end{enumerate}
\end{thm}
\begin{proof}
	$1) \Rightarrow 2)$: Let $B \in \oper$ and $T \in \coper$ s.t. $BA = 1+K$. For a unit sequence $\{h_n\}$ with $h_n \sto 0$ weakly, since $K$ is completely continuous,
	\begin{equation*}
		\abs{1 - \norm{BAh_n}} = \abs{\norm{h_n} - \norm{BAh_n}} \leqslant \norm{Kh_n} \sto 0
	\end{equation*}
	Therefore, $\norm{BAh_n} \sto 1$, i.e. $Ah_n$ cannot converge to $0$ in norm.
	\item $2) \Rightarrow 3)$: Orthonormal sequences alway converge weakly $0$.
	\item $3) \Rightarrow 4)$: Assume it is not true. For any $n$, there is a manifold $\fml{M}_n$ s.t. 
	\begin{equation*}
		\norm{Ah} \leqslant \frac{1}{n} \norm{h},~\forall~ h \in \fml{M}_n
	\end{equation*}
	Let $e_k \in \fml{M}_k$ for $1 \leqslant k \leqslant n$ and $\{e_k\}_{k=1}^n$ be orthonormal and $E$ be the projection onto $\spn{\{e_k\}_{k=1}^n}$. Since $\fml{M}_{n+1}$ is infinite dimensional,  $\fml{M}_{n+1} \cap E^{\bot} \neq \{0\}$. Thus, there is a unit $e_{n+1} \in \M_{n+1}$ s.t. $e_{n+1} \bot E$. But $Ae_n \sto 0$ in norm contradicted to $3)$.
	\item $4) \Rightarrow 5)$: If $\delta > 0$ and $h \in E([0,\delta])\Hs$, then
	\begin{eqnarray*}
		\norm{Ah}^2 &=& \langle \st{A}A h,h \rangle = \langle \abs{A}^2 h,h \rangle \\
		&=& \int_0^{\delta} t^2 dE_{hh}(t) \\
		&\leqslant& \delta^2 E_{hh}([0,\delta]) = \delta^2 \norm{h}^2
	\end{eqnarray*}
	That means
	\begin{equation*}
		E([0,\delta])\Hs \subset \{h \in \Hs \colon \norm{Ah} \leqslant \delta \norm{h}\}
	\end{equation*}
	\item $5) \Rightarrow 1)$: Let $\M = (E([0,\delta])\Hs)^{\bot}$. Then $\abs{A}$ maps $\M$ onto $\M$ bijectively. Put
	\begin{equation*}
		B_1 = \int_{\delta}^{\infty} t^{-1} dE(t)
	\end{equation*}
	then $B_1 \abs{A} = 1|_{\M}$. Let $A = U \abs{A}$. Since $\M \subset \ran{\abs{A}}$, $U$ maps $\M$ isometrically to $U(\M)$. Then there is a $V$ s.t. $VU = 1|_{\M}$ and $V|_{U(\M)^{\bot}} = 0$. Put $B = B_1V$, then for any $h \in \M$,
	\begin{equation*}
		BAh = B_1 V U \abs{A} h = h
	\end{equation*}
	If $h \in \M^{\bot}$, we know that $BAh = 0$. Thus,
	\begin{equation*}
		BA = E((\delta,\infty)) = 1 - E([0,\delta])
	\end{equation*}
	Thus, by above theorem, $A$ is left semi-Fredholm.
\end{proof}

\begin{thm}
	$A \in \oper$ is left semi-Fredholm operator if and only if for any $K \in \coper$,
	\begin{equation*}
		\dim{\ker{(A+K)}} < \infty
	\end{equation*}
\end{thm}
\begin{proof}
	If there is $B \in \oper$ and $L \in \coper$ s.t. $BA = 1+L$. If $K \in \coper$, 
	\begin{equation*}
		B(A+K) = 1 + (L + BK)
	\end{equation*}
	Thus $A+K$ is left semi-Fredholm, then $\dim{\ker{(A+K)}} < \infty$.\\
	Conversely, if there is a orthonormal sequence $\{e_n\}$ s.t. $Ae_n \sto 0$ in norm. By passing a subsequence, it may assume that $\sum \norm{Ae_n}^2 < \infty$. Thus for any $h \in \Hs$, 
	\begin{eqnarray*}
		\sum \abs{\langle h,e_n \rangle}\norm{Ae_n} &\leqslant& \left(\sum \abs{\langle h,e_n \rangle}^2\right)^{\frac{1}{2}}\left(\sum \norm{Ae_n}^2\right)^{\frac{1}{2}} \\
		&\leqslant& C\norm{h}
	\end{eqnarray*}
	Thus $Kh = \sum \langle h,e_n \rangle Ae_n$ is a bounded operator and clealy it can be approximated by finite rank operators $K_nh=\sum_{k=1}^n \langle h,e_k \rangle Ae_k$, thus $K \in \coper$. But $(A-K)e_n = 0$ for all $n$, that means $\dim{\ker{(A-K)}} = \infty$.
\end{proof}

\begin{cor}
	$A \in \oper$ is Fredholm if and only if $\ran{A}$ is closed and both $\ker{A}$ and $\ker{\st{A}}$ are finite dimensional.
\end{cor}

\subsection{Fredholm Index}

\begin{defn}
	If $A$ is a semi-Fredholm operator, then the Fredholm index of $A$ is defined as
	\begin{equation*}
		\ind{A} = \dim{\ker{A}} - \dim{\ker{\st{A}}}
	\end{equation*}
\end{defn}
\begin{rem}
	In fact, $\ind{A} \in \Z \cup \{\pm \infty\}$. If $A$ is Fredholm, $\ind{A} \in \Z$. And clearly, $\ind{(\lambda+K)} = 0$ for all nonzero $\lambda \in C$ and $K \in \coper$.
\end{rem}

\begin{prop}
	\begin{enumerate}[label=\arabic*)]
		\item If $A$ is a semi-Fredholm, then so is $\st{A}$ and
		\begin{equation*}
			\ind{\st{A}} = - \ind{A}
		\end{equation*}
		\item If $N$ is normal, then $N$ is semi-Fredholm if and only if $N$ is Fredholm, in which case $\ind{N} = 0$.
		\item If $A$ and $B$ are Fredholm, then $A \oplus B$ is Fredholm and 
		\begin{equation*}
			\ind{A \oplus B} = \ind{A} + \ind{B}
		\end{equation*}
	\end{enumerate}
\end{prop}
\begin{proof}
	$1)$ and $3)$ is trivial and $2)$ is since $\norm{N} = \norm{\st{N}}$.
\end{proof}

In fact, for $A \in \operr{H}{H^{'}}$, we can similarly defined the Fredholm operator and the Fredholm index, and all of above mention are valid.

\begin{prop}
	If $\Hs$ and $\fml{H^{'}}$ are finite dimensional Hilbert spaces and $A \in \operr{H}{H^{'}}$, then $A$ is Fredholm and $\ind{A} = \dim{\Hs} - \dim{\Hs^{'}}$.
\end{prop}
\begin{proof}
	The fact that $A$ is Fredholm is trivial by the definition.
	\begin{eqnarray*}
		\ind{A} &=& \dim{\ker{A}} - \dim{(\ran{A})^{\bot}} \\
		&=& \dim{\Hs} - \dim{\ran{A}} - (\dim{\Hs^{'}} - \dim{\ran{A}}) \\
		&=& \dim{H} - \dim{H^{'}}
	\end{eqnarray*}
\end{proof}

\begin{lem}
	Let $A \in \operr{H}{H^{'}}$ and $\Hs = \M \oplus \fml{N}$ and $\Hs^{'} = \M^{'} \oplus \fml{N}^{'}$. Suppose $A$ has the form
	\begin{equation*}
		A = \left(
			\begin{array}{cc}
				A_1 & X \\
				0 & A_2
			\end{array}
		\right)
	\end{equation*}
	If $\dim{\fml{N}} < \infty$ and $\dim{\fml{N}^{'}} < \infty$ and $A_1$ is invertible, then $A$ is Fredholm and $\ind{A} = \dim{\fml{N}}-\dim{\fml{N}^{'}}$.
\end{lem}
\begin{proof}
	Just need to show $\ker{\st{A}} = \ker{\st{A_2}}$ and $\dim{\ker{A}} = \dim{\ker{A_2}}$, then since $A_2 \in \fml{B}(\fml{N})=\fml{B}_0(\fml{N})$, 
	\begin{equation*}
		\ind{A} = \dim{\ker{A}} - \dim{\ker{\st{A}}} = \ind{A_2} = \dim{\fml{N}}-\dim{\fml{N}^{'}}
	\end{equation*}
	But $\ker{\st{A}} = \ker{\st{A_2}}$ and $\dim{\ker{A}} = \dim{\ker{A_2}}$ are clearly because $A_1$ is invertible.
\end{proof}

\begin{thm}
	If $A,B \in \oper$ are Fredholm operator, then $BA$ is also a Fredholm operator and
	\begin{equation*}
		\ind{BA} = \ind{A} + \ind{B}
	\end{equation*}
\end{thm}
\begin{proof}
	There are $X,Y \in \oper$ s.t. $XA = 1+K$ and $YB=1+K^{'}$ for some $K,K^{'} \in \coper$. Then 
	\begin{equation*}
		(XY)(BA) = X(1+K^{'})A = 1 + (K+XK^{'}A)
	\end{equation*}
	Therefore, $BA$ is left semi-Fredholm. Similarly, $BA$ is right semi-Fredholm.\\
	Then for the index, let
	\begin{eqnarray*}
		\M^{'} = \ran{A} \cap (\ker{B})^{\bot} &,& \fml{N}^{'} = \M^{' \bot} \\
		\M = A^{-1}(\M^{'}) \cap (\ker{A})^{\bot} &,& \fml{N} = \M^{\bot} \\
		\M^{''} = B(\M^{'}) &,& \fml{N^{''}} = \M^{'' \bot}
	\end{eqnarray*}
	Therefore,
	\begin{equation*}
		\Hs = \M \oplus \fml{N} = \M^{'} \oplus \fml{N^{'}} = \M^{''} \oplus \fml{N^{''}}
	\end{equation*}
	And since $A(\M) = \M^{'}$, we can see
	\begin{eqnarray*}
		A = \left(
			\begin{array}{cc}
				A_1 & X \\
				0 & A_2
			\end{array}
		\right)
		&\colon& \M \oplus \fml{N} \longrightarrow \M^{'} \oplus \fml{N^{'}} \\
		B = \left(
			\begin{array}{cc}
				B_1 & Y \\
				0 & B_2
			\end{array}
		\right)
		&\colon& \M^{'} \oplus \fml{N^{'}} \longrightarrow \M^{''} \oplus \fml{N^{''}} \\
		BA = \left(
			\begin{array}{cc}
				B_1A_1 & Z \\
				0 & B_2A_2
			\end{array}
		\right)
		&\colon& \M \oplus \fml{N} \longrightarrow \M^{''} \oplus \fml{N^{''}}
	\end{eqnarray*}
	It can see that $\fml{N}$, $\fml{N^{'}}$ and $\fml{N^{''}}$ are finite dimensional. Moreover, $A_1$, $B_1$ and $B_1A_1$ are invertible. Then using above lemma,
	\begin{eqnarray*}
		\ind{BA} &=& \dim{\fml{N}} - \dim{\fml{N^{''}}} \\
		&=& \dim{\fml{N}} - \dim{\fml{N^{'}}} + \dim{\fml{N^{'}}} - \dim{\fml{N^{''}}} \\
		&=& \ind{B} + \ind{A}
	\end{eqnarray*}
\end{proof}
\begin{rem}
	In fact, above theorem can also be valid if $A$ and $B$ are semi-Fredholm.
\end{rem}

\begin{thm}
	If $A \in \oper$ is a Fredholm operator, then for any $K \in \oper$, $A+K$ is Fredholm and $\ind{(A+K)} = \ind{A}$.
\end{thm}
\begin{proof}
	$A+K$ is Fredholm is trivial. Let $X$ be Fredholm and $L \in \coper$, s.t. $XA = 1+L$, then
	\begin{equation*}
		0 = \ind{(1+L)} = \ind{XA} = \ind{X} + \ind{A}
	\end{equation*}
	And since $X(A+K) = 1+(L+XK)$, 
	\begin{equation*}
		\ind{X(A+K)} = \ind{(A+K)} + \ind{X} = 0
	\end{equation*}
	Therefore, $\ind{(A+K)} = \ind{A}$.
\end{proof}

Now, we can see that the index of a Fredholm is invariant under a small perturbation.

\begin{thm}
	If $A \in \oper$ is a Fredholm operator, then there is an $\varepsilon>0$ s.t. for any $Y \in \oper$ with $\norm{Y} < \varepsilon$, then $A+Y$ is Fredholm and $\ind{A+Y} = \ind{A}$.
\end{thm}
\begin{proof}
	Let $\Hs = \ker{A}^{\bot} \oplus \ker{A} = \ran{A} \oplus \ker{\st{A}}$. Then,
	\begin{equation*}
		A = \left(
			\begin{array}{cc}
				A_1 & 0 \\
				0 & 0
			\end{array}
		\right)
	\end{equation*}
	And $A_1$ is invertible since $\ran{A}$ is closed. By the perturbation of inverse, there is a $\varepsilon > 0$ s.t. if $\norm{Y_1} < \varepsilon$, $A_1+Y_1$ is invertible. If $Y \in \oper$ with $\norm{Y} < \varepsilon$, and 
	\begin{equation*}
		Y = \left(
				\begin{array}{cc}
				Y_1 & Y_2 \\
				Y_3 & Y_4
				\end{array}
			\right)
	\end{equation*}
	Thus $A_1+Y_1$ is invertible and 
	\begin{equation*}
		A + Y =
		\left(
			\begin{array}{cc}
			A_1+Y_1 & Y_2 \\
			Y_3 & Y_4
			\end{array}
		\right)
		= 
		\left(
			\begin{array}{cc}
				A_1+Y_1 & 0 \\
				0 & 0
			\end{array}
		\right)
		+
		\left(
			\begin{array}{cc}
			0 & Y_2 \\
			Y_3 & Y_4
			\end{array}
		\right)
	\end{equation*}
	The first part is Fredholm and the second part is finite rank. Thus $A+Y$ is Fredholm, and $\ind{A+Y} = \ind{A}$ by above theorem.
\end{proof}

\begin{cor}
	Let $\fml{F}$ denote the set of all Fredholm operators. Then the map
	\begin{equation*}
		\ind{} \colon (\fml{F},\norm{\cdot}) \longrightarrow \Z
	\end{equation*}
	is continuous with respect to the discrete topology on $\Z$. 
\end{cor}

\subsection{Essential Spectrum}

Let $\pi \colon \oper \sto \oper / \coper$ be the quotient map. We have know that the inverse of the invertible element in the Calkin algebra is Fredholm. Thus, the spectrum of the element in the Calkin algebra may be interesting.

\begin{defn}
	If $A \in \oper$, the essential spectrum of $A$ is defined as
	\begin{equation*}
		\sigma_e(A) = \sigma(\pi(A))
	\end{equation*}
	Similarly, $\sigma_{le} = \sigma_l(\pi(A))$ and $\sigma_{re} = \sigma_r(\pi(A))$.
\end{defn}

By the properties of the general spectrum and the Fredholm operators, we have following properties of the essential spectrum.

\begin{prop}
	Let $A \in \oper$.
	\begin{enumerate}[label = \arabic*)]
		\item $\sigma_{le}(A) \subset \sigma_l(A)$ and $\sigma_{re}(A) \subset \sigma_r(A)$ and $\sigma_e(A) \subset \sigma(A)$.
		\item $\sigma_{le}(A)$, $\sigma_{re}(A)$ and $\sigma_e(A)$ are compact.
		\item For any $K \in \coper$, $A+K$ and $A$ have same left (or right) essential spectrum.
		\item $\lambda \in \sigma_{le}(A)$ is and only if $\dim{\ker{(A-\lambda)}} = \infty$ or $\ran{(A-\lambda)}$ is not closed.
		\item $\lambda \in \sigma_{re}(A)$ is and only if $\dim{\ran{(A-\lambda)}^{\bot}} = \infty$ or $\ran{(A-\lambda)}$ is not closed.
	\end{enumerate}
\end{prop}

\begin{prop}
	If $A \in \oper$, then
	\begin{equation*}
		\sigma_{ap}(A) = \sigma_{le}(A) \cup \{\lambda \in \sigma_p(A) \colon \dim{\ker{(A-\lambda)}} < \infty\}
	\end{equation*}
\end{prop}
\begin{proof}
	If $\lambda \in \sigma_{ap}(A)$, then by the \textbf{Proposition} \ref{prop15} and \ref{prop16} in the subsection \textbf{3.3.1}, we know that either $\ran{(A-\lambda)}$ is not closed or $\ker{(A-\lambda)} \neq \{0\}$. If $\ran{(A-\lambda)}$ is not closed or $\dim{\ker{(A-\lambda)}} = \infty$, $\lambda \in \sigma_{le}(A)$. The converse is similar.
\end{proof}

For normal operators, by above proposition, there are more interesting results about the essential spectrum.

\begin{lem}
	If $N$ is a normal operator and $\lambda \in \sigma(N)$, then $\ran{(N-\lambda)}$ is closed if and only if $\lambda$ is not a limit point of $\sigma(N)$.
\end{lem}
\begin{proof}
	Assume $\lambda$ is isolated in $\sigma(N)$. Let $X = \sigma(N) \backslash \{\lambda\}$ and $\Hs_1 = E(X) \Hs$. Hence, $(N-\lambda)\Hs_1$ is closed as $\sigma(N|_{\Hs_1}) = X$. Since
	\begin{equation*}
		\Hs_1^{\bot} = E(\{\lambda\}) \Hs = \ker{(A-\lambda)}
	\end{equation*}
	$\ran{(N-\lambda)} = (N-\lambda)\Hs_1$. Therefore, $\ran{(N-\lambda)}$ is closed. \\
	Conversely, assume $\lambda$ is not isolated in $\sigma(N)$. Then there is a positive sequence $\{r_n\}$ s.t. $r_n \sto 0$ decreasingly. Each open set
	\begin{equation*}
		A_n = \{~z \in \C \colon r_{n+1} < \abs{z - \lambda} < r_n~\}
	\end{equation*}
	has non-empty intersection with $\sigma(N)$, i.e. $E(A_n)\Hs \neq \{0\}$ for all $n$. Let $e_n \in A_n$ be the unit element and $e_n \in \ker{(N-\lambda)}^{\bot}$ and
	\begin{equation*}
		\norm{(N-\lambda)e_n}^2 = \int_{A_n} \abs{z-\lambda}^2 d E_{e_n,e_n}(z) \leqslant r_n^2 \sto 0
	\end{equation*}
	Therefore,
	\begin{equation*}
		\inf{\{\norm{(N-\lambda)h} \colon \norm{h} = 1,~h \in \ker{(N-\lambda)}^{\bot}\}} = 0
	\end{equation*}
	i.e. $\ran{(N-\lambda)}$ is not closed.
\end{proof}

\begin{thm} \label{thm14}
	If $N$ is normal, then $\sigma_e(N) = \sigma_{le}(N) = \sigma_{re}(N)$ and
	\begin{equation*}
		\sigma(N) \backslash \sigma_e(N) = \{\lambda \in \sigma(N) \colon \lambda \text{ is isolated and } \dim{\ker{(N-\lambda)}} < \infty\}
	\end{equation*}
\end{thm}
\begin{proof}
	The first part can be obtained by applying the \textbf{Corrllary} \ref{cor11} in the subsection \textbf{3.3.1} to the Calkin algebra.\\
	If $\lambda$ is isolated in $\sigma(N)$, then $\ran{(N-\lambda)}$ is closed. Thus, 
	\begin{equation*}
		\dim{\ker{(N-\lambda)}} < \infty \Rightarrow \lambda \notin \sigma_{le}(N)
	\end{equation*}
	The converse is similar.
\end{proof}

Let $\gamma(A) = \inf{\{\norm{Ah} \colon \norm{h} = 1,~ h \bot \ker{A}\}} = \chi(0)$. In fact, $\gamma(A) = \gamma(\st{A})$. Moreover,
\begin{equation*}
	\gamma(A)\dist{(h,\ker{A})} \leqslant \norm{Ah}
\end{equation*}

\begin{lem}
	If $\M, \fml{N}$ are closed subspace of $\Hs$ and $\fml{N}$ is finite dimensional and $\dim{\M} > \dim{\fml{N}}$, then there is a non-zero vector $m \in \M$ s.t.
	\begin{equation*}
		\norm{m} = \dist{(m,\fml{N})}
	\end{equation*}
\end{lem}
\begin{proof}
	Let $P$ be the projection onto $\M$, so $\dim{P(\fml{N})} \leqslant \dim{\fml{N}} < \dim{\M}$. Thus $P(\fml{N})$ is a proper subspace of $\M$. Let $m \in \M \cap P(\fml{N})^{\bot}$. For any $n \in \fml{N}$,
	\begin{equation*}
		0 = \langle Pn,m \rangle = \langle n, Pm \rangle = \langle n,m \rangle
	\end{equation*}
	Thus $m \bot \fml{N}$, i.e. $\norm{m} = \dist{(m,\fml{N})}$.
\end{proof}

\begin{lem}
	If $A$ is left semi-Fredholm and $B \in \oper$ s.t. $\norm{B} < \gamma(A)$, then $A+B$ is left semi-Fredholm and 
	\begin{enumerate}[label=\arabic*)]
		\item $\dim{\ker{(A+B)}} \leqslant \dim{\ker{A}}$.
		\item $\dim{\ran{(A+B)}^{\bot}} \leqslant \dim{\ran{A}^{\bot}}$.
	\end{enumerate}
\end{lem}
\begin{proof}
	Check: $\{h \colon \norm{(A+B)h} \leqslant \delta \norm{h}\}$ for some $\delta < \gamma - \norm{B}$ contains no infinite dimensional subspace. \\
	If there is an infinite dimensional subspace, then it would contain a finite dimensional subspace $\M$ with $\dim{\M} > \dim{\ker{A}}$. Therefore, there is a $h \in \ker{A}$ s.t.$\norm{h} = \dist{(h,\ker{A})}$.Then
	\begin{eqnarray*}
		\gamma(A)\norm{h} &=& \gamma(A) \dist{(h,\ker{A})} \leqslant \norm{Ah} \\
		&\leqslant& \norm{(A+B)h} +\norm{Bh} \leqslant (\delta+\norm{B})\norm{h} \\
		&<& \gamma(A)\norm{h}
	\end{eqnarray*}
	which is a contradiction. Therefore, $A+B$ is a left semi-Fredholm.

	\item Check: $\dim{\ker{(A+B)}} \leqslant \dim{\ker{A}}$. \\
	If $h \in \ker{(A+B)}$, then $Ah = -Bh$. Then
	\begin{equation*}
		\gamma(A)\dist{(h,\ker{A})} \leqslant \norm{Bh} \leqslant \norm{B}\norm{h} < \gamma(A) \norm{h}
	\end{equation*}
	Therefore, $\dist{(h,\ker{A})} < \norm{h}$. By above lemma,
	\begin{equation*}
		\dim{\ker{(A+B)}} \leqslant \dim{\ker{A}}
	\end{equation*}

	\item Finally, if $\dim{\ran{A}^{\bot}} = \infty$, $2)$ holds clearly. But if $\dim{\ran{A}^{\bot}} < \infty$, $A$ is also right semi-Fredholm, i.e. $\st{A}$ is left semi-Fredholm, and by $1)$, $2)$ holds.
\end{proof}
\begin{rem}
	Clearly, these results can also be valid for right semi-Fredholm and Fredholm.
\end{rem}

\begin{prop}
	If $A$ is semi-Fredholm and either $\ker{A} = \{0\}$ or $\ran{A} = \Hs$, then there is a $\delta > 0$ s.t. if $\norm{B-A} < \delta$, the 
	\begin{equation*}
		\dim{\ker{A}} = \dim{\ker{B}},~ \dim{\ran{A}} = \dim{\ran{B}}
	\end{equation*}
\end{prop}
\begin{proof}
	In fact, there is a $\delta > 0$ s.t. if $\norm{B-A} < \delta$, then $\ind{A} = \ind{B}$ and 
	\begin{equation*}
		\dim{\ker{B}} \leqslant \dim{\ker{A}},~ \dim{\ran{B}^{\bot}} \leqslant \dim{\ran{A}^{\bot}}
	\end{equation*}
	Since one of these is $0$, the results are true.
\end{proof}

\begin{thm}
	If $\lambda \notin \sigma_{le}(A) \cap \sigma_{re}(A)$, then there is a $\delta > 0$ s.t. \\ $\dim{\ker{(A - \mu)}}$ and $\dim{\ran{(A - \mu)}^{\bot}}$ are constant for $0< \abs{\lambda - \mu} < \delta$.
\end{thm}
\begin{proof}
	Assume $\lambda = 0$ and $\ker{A}$ is finite dimensional. And $A^n$ is also left semi-Fredholm for all $n$. Let $\M_n = \ran{A^n}$. Note $\M_{n+1} \subset \M_n$ and $\A \M_{n} = \M_{n+1}$. Let $\M = \cap \M_n$ and $B = A|_{\M}$.
	\item Claim: $B(\M) = \M$.\\
	Since $\ker{A}$ is finite dimensional and $\{\M_n\}$ is decreasing, there is a $m$ s.t. for all $n \geqslant m$, $\M_n \cap \ker{A} = \M_m \cap \ker{A}$. For any $h \in \M$ and $n \geqslant m$, there is $f_n \in \M_n$ s.t. $h = Af_n$. 
	\begin{equation*}
		f_m - f_n \in \M_n \cap \ker{A} = \M_m \cap \ker{A}
	\end{equation*}
	Therefore, $f_m \in \M_n$ for all $n \geqslant m$. Thus $f_m \in \M$ and
	\begin{equation*}
		h = Af_m = Bf_m \in B(\M)
	\end{equation*}
	Thus $B$ is semi-Fredholm and $\ind{B} = \dim{\ker{B}}$. Then there is a $\delta_1 > 0$ s.t. for $\abs{\mu} < \delta_1$,
	\begin{equation*}
		\dim{\ker{B-\mu}} \leqslant \dim{\ker{B}},~ \dim{\ran{(B-\mu)}^{\bot}} = 0 \text{ and } \ind{(B-\mu)} = \ind{B}
	\end{equation*}
	And thus $\dim{\ker{B-\mu}} = \dim{\ker{B}}$. \\
	Also There is a $\delta_2$ s.t. $\ind{(A-\mu)} = \ind{A}$ for all $\abs{\mu} < \delta_2$. Then let $\delta = \min{\{\delta_1,\delta_2\}}$.
	\item Claim: $\ker{(A-\mu)} \subset \M$ for $0 < \abs{\mu} < \delta$. \\
	If $h \in \ker{(A-\mu)}$, then $A^n h = \mu^n h$. So $h = A^n \mu^{-n} h \in \M$.\\
	Finally, for $0 < \abs{\mu} < \delta$,
	\begin{equation*}
		\dim{\ker{(A-\mu)}} = \dim{\ker{(B-\mu)}} = \dim{\ker{B}}
	\end{equation*}
	And since $\ind{(A-\mu)}$ is constant, $\dim{\ran{(A - \mu)}^{\bot}}$ is also constant.
\end{proof}

\begin{thm}
	If $\lambda \in \partial{\sigma(A)}$, then either $\lambda$ is an isolated point of $\sigma(A)$ or $\lambda \in \sigma_{le}(A) \cap \sigma_{re}(A)$.
\end{thm}
\begin{proof}
	Suppose $\lambda \in \partial{\sigma(A)}$ and $\lambda \notin \sigma_{le}(A) \cap \sigma_{re}(A)$. Therefore, $A-\lambda$ is semi-Fredholm. By above theorem, there is a $\delta > 0$ s.t. $\dim{\ker{(A - \mu)}}$ and $\dim{\ran{(A - \mu)}^{\bot}}$ are constant for $0< \abs{\lambda - \mu} < \delta$. Since $\lambda \in \partial{\sigma(A)}$, there is a $\nu \in \rho(A)$ with $0< \abs{\nu - \mu} < \delta$. Therefore,
	\begin{equation*}
		\ker{(A-\mu)} = \{0\} = \ran{(A-\mu)}^{\bot}, \text{ for } 0 < \abs{\lambda - \mu} < \delta
	\end{equation*}
	And $A-\mu$ is semi-Fredholm, $\ran{(A-\mu)}$ is closed, thus $A-\mu$ is invertible for $0 < \abs{\lambda - \mu} < \delta$, which means that $\lambda$ is isolated.
\end{proof}

\begin{prop}
	Let $\lambda$ be an isolated point of $\sigma(A)$, then the following statements are equivalent.
	\begin{enumerate}[label = \arabic*)]
		\item $\lambda \notin \sigma_{le}(A) \cap \sigma_{re}(A)$.
		\item $A-\lambda$ is Fredholm and $\ind{(A-\lambda)} = 0$.
		\item The Riesz idempotent $E(\{\lambda\})$ is finite rank.
	\end{enumerate}
\end{prop}
\begin{proof}
	$1) \Rightarrow 2)$: Since $\lambda \notin \sigma_{le}(A) \cap \sigma_{re}(A)$, $\ran{(A-\lambda)}$ is closed and either $\dim{\ker{(A-\lambda)}} < \infty$ or $\dim{\st{\ker{(A-\lambda)}}} < \infty$. Assume $\dim{\ker{(A-\lambda)}} < \infty$. Since $\lambda$ is isolated, we can use similar argument in the \textbf{Theorem} \ref{thm12} in the subsection \textbf{5.1.2} to get
	\begin{equation*}
		\dim{\ker{(A-\lambda)}} = \dim{\st{\ker{(A-\lambda)}}} < \infty
	\end{equation*}
	And if we assume $\dim{\st{\ker{(A-\lambda)}}} < \infty$, we can also get same result. Thus $A-\lambda$ is Fredholm and $\ind{(A-\lambda)} = 0$.
	\item $2) \Rightarrow 3)$: By the definition,
	\begin{equation*}
		(A-\lambda)E(\{\lambda\}) = \int_{\Gamma} \frac{(z-\lambda)\chi_{\{\lambda\}(z)}}{z - A} dz = 0 \Rightarrow E(\{\lambda\})\Hs \subset \ker{(A-\lambda)}
	\end{equation*}
	Thus $E(\{\lambda\})$ is finite rank.
	\item $3) \Rightarrow 1)$: As above mention, $E(\{\lambda\})\Hs \subset \ker{(A-\lambda)}$. In fact, the converse is also true.\\
	Claim: $\ker{(A-\lambda)} \subset E(\{\lambda\})\Hs$. \\
	Let $\Delta = \sigma(A) \backslash \{\lambda\}$, $\Hs_{\Delta} = E(\{\Delta\})\Hs$ and $A_{\Delta} = A|_{\Hs_{\Delta}}$, and similarly for $\{\lambda\}$. Then $A_{\Delta} - \lambda$ is invertible. If $h \in \ker{(A-\lambda)}$, 
	\begin{eqnarray*}
	0 = (A-\lambda)h &=& (A-\lambda)E(\{\lambda\})h+(A-\lambda)E(\Delta)h \\
	&=& (A_{\lambda}-\lambda)E(\{\lambda\})h + (A_{\Delta}-\lambda)E(\Delta)h
	\end{eqnarray*}
	Since $E(\{\lambda\}) \bot E(\Delta)$, 
	\begin{equation*}
		(A_{\lambda}-\lambda)E(\{\lambda\})h = (A_{\Delta}-\lambda)E(\Delta)h = 0
	\end{equation*}
	And the fact that $A_{\Delta} - \lambda$ is invertible implies that $E(\Delta)h = 0$, thus $h \in \Hs_{\{\lambda\}}$. \\
	Thus, $\ker{(A-\lambda)} = E(\{\lambda\})\Hs$ is finite. Moreover, by the similar argument in in the \textbf{Theorem} \ref{thm12} in the subsection \textbf{5.1.2}, $\ran{(A-\lambda)}$ is closed. Thus, $A-\lambda$ is semi-Fredholm.
\end{proof}

\section{Compact Perturbations}

\subsection{Weyl-von Neumann Theorem}

In finite dimensional case, any normal operator can be diagonalized, but it is not true for the infinite dimensional case. In fact, it can hold by doing some extra efforts. Firstly, we can do that for a self-adjoint operator. 

Like the definition of Hilbert-Schmidt operators, we define $B \in \fml{B}_p(\Hs)$ if $\abs{B}^{\frac{p}{2}} \in \hoper$, and 
\begin{equation*}
	\norm{B}_p = \norm{\abs{B}^{\frac{p}{2}}}_2^{\frac{2}{p}} = (\sum_e \norm{Be}^p)^{\frac{1}{p}}
\end{equation*}
Clearly, $\norm{B} \leqslant \norm{B}_p$. And moreover, if $B$ has finite rank $m$, then
\begin{equation*}
	\norm{B}_p \leqslant m^{\frac{1}{p}} \norm{T}
\end{equation*}
In fact, $\fml{B}_p(\Hs) \subset \coper$.

\begin{thm}[Weyl-von Neumann Theorem]
	If $A$ is a self-adjoint operator on a separable Hilbert space, $\varepsilon > 0$ and $1 < p < \infty$, then there is a diagonalizable self-adjoint operator $D$ s.t. 
	\begin{equation*}
		A-D \in \fml{B}_p(\Hs), \text{ and } \norm{A-D}_p < \varepsilon
	\end{equation*}
\end{thm}

To prove it, we need a lemma.

\begin{lem}
	If $A$ is a self-adjoint operator on a separable Hilbert space, $h \in \Hs$, $\varepsilon > 0$ and $1 < p < \infty$, then there is a finite rank projection $P$ and a self-adjoint $K \in \fml{B}_p(\Hs)$, s.t. $f \in P$, $\norm{K}_p < \varepsilon$ and $A+K$ is reduced by $P$.
\end{lem}
\begin{proof}
	Let $E$ be the spectral measure for $A$ and $\sigma(A) \subset [a,b]$ and intervals $\{\Delta_k\}_{k=1}^{n}$ be a partition of $[a,b]$ with length $(b-a)/n$. Put
	\begin{equation*}
		f_k = E(\Delta_k) f, \text{ and } g_k = \frac{f_k}{\norm{f_k}} \text{ for } f_k \neq 0
	\end{equation*}
	Let $\lambda_k$ be the midpoint of $\Delta_k$ then
	\begin{equation*}
		\norm{(A-\lambda_k)g_k} \leqslant \frac{(b-a)}{n}
	\end{equation*}
	Define $P$ as the projection onto $\spn{g_1,\cdots,g_n}$. Since $P^{\bot}g_k = 0$,
	\begin{equation*}
		\norm{P^{\bot} Ag_k} = \norm{P^{\bot}(A-\lambda_k)g_k} \leqslant \frac{(b-a)}{n}
	\end{equation*}
	Since $g_k \in E(\Delta_k)$, $Ag_k \in E(\Delta_k)$. Thus, $Ag_k \bot g_j$ for $j \neq k$.
	\begin{equation*}
		P^{\bot} Ag_k = Ag_k - \sum_{j=1}^{n} \langle Ag_k,g_j \rangle g_j = Ag_k - \langle Ag_k,g_k \rangle g_k \in E(\Delta_k)
	\end{equation*}
	Thus $P^{\bot}Ag_k \bot P^{\bot}Ag_j$ for $j \neq k$. Then
	\begin{eqnarray*}
		\norm{P^{\bot}APh} &=& \norm{\sum_{k=1}^n \langle h,g_k \rangle P^{\bot}Ag_k} \\
		&=& \sum_{k=1}^n \abs{\langle h,g_k \rangle}^2 \norm{P^{\bot}Ag_k}^2 \\
		&\leqslant& \left(\frac{(b-a)}{n} \right)^2 \norm{h}^2
	\end{eqnarray*}
	Therefore, $\norm{P^{\bot}AP} \leqslant {(b-a)}/{n}$ and by above mention
	\begin{equation*}
		\norm{P^{\bot}AP}_p \leqslant n^{\frac{1}{p}} \left(\frac{(b-a)}{n} \right) = \frac{(b-a)}{n^q},~ q = 1 - \frac{1}{p}
	\end{equation*}
	Put $B = PAP + P^{\bot}AP^{\bot}$ and $K = -(P^{\bot}AP + PAP^{\bot})$, then $B = A + K$. Clearly, $K$ is self-adjoint and $P$ reduces $B$ and 
	\begin{equation*}
		\norm{K}_p \leqslant \frac{2(b-a)}{n^q}
 	\end{equation*}
 	Thus for any $\varepsilon > 0$, $\norm{K}_p < \varepsilon$ for some partition.
\end{proof}

Then we can prove the Weyl-von Neumann Theorem.

\begin{proof}[Proof of Weyl-von Neumann Theorem]
	Let $\{h_j\}$ be a dense subset in $\Hs$ and put $f = h_1$, then by above lemma, there is a finite rank projection $P_1$ and a self-adjoint operator $K_1$ s.t. $A+K_1$ is reduced by $P_1$ and $h_1 \in P_1$ and $\norm{K_1}_p < \varepsilon / 2$. Then applying above lemma to $(A+K_1)|_{P_1^{\bot}}$ and the vector $f = P_1^{\bot} h_2$, we get $K_2$ and $P_2$ and extend $K_2$ on $\Hs$ by defining $K_2 h =0$ for $h \in P_1$. By reduction, we get finite rank projections $\{P_n\}$ and $\{K_n\}$ s.t.
	\begin{enumerate}[label = \arabic*)]
		\item $P_j P_n = 0$ for $j \neq n$;
		\item $\norm{K_n}_p < \varepsilon / 2^n$;
		\item $h_n \in P_1 + \cdots + P_n$;
		\item $A+K_1+\cdots+K_n$ is reduced by $P_1 + \cdots + P_n$;
		\item $K_n(P_1 + \cdots + P_{n-1}) = 0$.
	\end{enumerate}
	Then let $K = \sum K_n$, then $\norm{K_n}_p < \varepsilon$. And let $D = A + K$. Clearly, $D$ is self-adjoint. Since $1 = \sum_n P_n$ and $D$ is reduced by any $P_n$, if $D_n = D|_{P_n}$, $D = \oplus D_n$. And since $P_n$ is finite, each $D_n$ can be diagonalized, thus $D$ is diagonalizable.
\end{proof}

\subsection{Weyl-von Neumann-Berg Theorem}

Now, we can apply above theorem to the normal operators. But it can be more general. Since a class of commutative finite rank normal operators can be diagonalizable simutaneously, we want to see the similar result for the infinite dimensional case.

By the \textbf{Theorem} \ref{thm13} in the section \textbf{4.3}, we can get a trivial corollary.

\begin{cor}
	If $N_1, \cdots, N_n$ are commutating normal operators on a separable Hilbert space, then there is a self-adjoint operator $A$ and continuous functions $f_1,\cdots,f_n$ s.t. $N_j = f_j(A)$ for $1 \leqslant j \leqslant n$.
\end{cor}

\begin{thm}[Weyl-von Neumann-Berg Theorem]
	If $N_1, \cdots, N_n$ are commutating normal operators on a separable Hilbert space and $\varepsilon > 0$, then there are diagonalizable normal operators $D_1,\cdots,D_n$ and compact operators $K_1,\cdots,K_n$ s.t. for $1 \leqslant j \leqslant n$, $\norm{K_j} < \varepsilon$ and $N_j = D_j + K_j$.
\end{thm}

By above corollary and the Weyl-von Neumann Theorem, $A = D + K$ with $\norm{K} < \varepsilon$, but we need to prove that $f(A) - f(D) \in \coper$, and $\norm{f(A) - f(D)} M< \varepsilon$.

\begin{lem}
	\begin{enumerate}[label=\arabic*)]
		\item Let $A$ be a self-adjoint operator with $A = D + K$ for some diagonalizable $D$ and compact operator $K$. Then for any continuous function $f$ on $\sigma(A)$, there is a compact operator $K^{'}$ s.t. $f(A) = f(D) + K^{'}$.
		\item If $f$ is a continuous function on $\R$, then the map $A \sto f(A)$ is uniformly continuous on a bounded sets of self-adjoint operators.
	\end{enumerate}
\end{lem}
\begin{proof}
	For $1)$, if $A = D + K$, then for any $m \geqslant 1$, $A^m = D^m + K_m$ for some compact operatr $K_m$. Therefore, for each polynomial $p$, 
	\begin{equation*}
		p(A) = p(D) + K_p, \text{ for some operator } K_p \in \coper
	\end{equation*}
	Let $\{p_k\}$ be a sequence converging uniformly to $f$ on a closed interval containing $\sigma(A) \cup \sigma(D)$, thus
	\begin{equation*}
		\norm{p_k(A) - f(A)} \sto 0,~ \norm{p_k(D) - f(D)} \sto 0
	\end{equation*}
	Therefore, we have
	\begin{equation*}
		K_{pk} = p_k(A) - p_k(D) \sto f(A) - f(D) = K^{'} \text{ in norm}
	\end{equation*}
	and $K^{'} \in \coper$.
	\item For $2)$, we just need to prove this if $f$ is a polynomial since on a compact set the limit of a sequence of uniformly continuous functions is also uniformly continuous. Note that
	\begin{equation*}
		T^{n+1} - S^{n+1} = T^n(T-S) + (T^n - S^n)S
	\end{equation*}
	That means $T \sto T^n$ is uniformly continuous on a bounded set of self-adjoint operators. Therefore, $A \sto f(A)$ for any polynomial $f$.
\end{proof}

\begin{proof}[Weyl-von Neumann-Berg Theorem]
	By above corollary, let $A$ be the self-adjoint operator and $f_1,\cdots,f_n$ be continuous functions on $\sigma(A)$ s.t. $N_j = f_j(A)$ for any $1 \leqslant j \leqslant n$. By the Weyl-von Neumann Theorem, there are self-adjoint operators $D$ and $K$ with $K \in \coper$ and $\norm{K} < \varepsilon$ s.t. $A = D + K$. Then by above lemma,
	\begin{equation*}
		N_j - f_j(D) \in \coper, \norm{N_j - f_j(D)} = \norm{f_j(A) - f_j(D)} < \varepsilon \qedhere
	\end{equation*}
\end{proof}

\begin{cor}
	If $N$ is a normal operator on a separable Hilbert space and $\varepsilon > 0$, then there is a diagonalizable normal operator $D$ s.t. $N - D \in \coper$ and $\sigma(D) = \sigma_e(D)$.
\end{cor}
\begin{proof}
	By above theorem, $N = D^{'} + K$ for the normal diagnolizable operator $D^{'}$ and self-adjoint compact operator $K$. By the \textbf{Theorem} \ref{thm14} in the subsetction \textbf{5.4.3} and the separability of the Hilbert space, 
	\begin{equation*}
		\{\mu_j\}_{j=1}^{\infty} = \sigma(D^{'}) \backslash \sigma_e(D^{'})
	\end{equation*}
	where each $\mu_j$ has finite multiplicity and is repeated as often as their multiplicity. Let $\{h_j\}$ be the coresponding eigenvectors then
	\begin{equation*}
		D^{'} = D + \sum_{j=1}^{\infty} \mu_j h_j \otimes h_j
	\end{equation*}
	where $D$ is a diagonalizable normal operator $D$ with $\sigma(D) = \sigma_e(D)$. And clearly,
	\begin{equation*}
		\sum_{j=1}^{\infty} \mu_j h_j \otimes h_j \in \coper
	\end{equation*}
	thus $N-D = K+\sum_{j=1}^{\infty} \mu_j h_j \otimes h_j \in \coper$.
\end{proof}

\subsection{Approximately Unitary Equivalence}

For two operators $N$ and $M$, if there is a unitary $U$ s.t. $N = \st{U}MU$, $N$ and $M$ are same in some sense and we say that these two are unitary equivalent. But this relation is too strong, so there is another weaker relation, approximately unitary equivalence.

\begin{lem}
	If $N$ and $M$ are diagonalizable normal operators on a separable Hilbert space with
	\begin{equation*}
		\sigma(N) = \sigma_e(N) = \sigma_e(M) = \sigma(M)
	\end{equation*}
	and $\varepsilon > 0$, then there is a unitary operator $U$ s.t. $N-\st{U}MU \in \toper$ with $\norm{N-\st{U}MU}_1 < \varepsilon$. 
\end{lem}
\begin{proof}
	By the condition, if $\nu$ is an isolated point of $\sigma(N)$, it must be an eigenvalue with infinite multiplicity, and thus it is an eigenvalue of $M$ with infinite multiplicity. If $\nu$ is a limit point of $\sigma(N)$, then there is a sequence in $\sigma(M)$ converging to $\nu$. \\
	Let $\{\nu_n\}$ and $\{\mu_m\}$ be all eigenvalues of $N$ and $M$ repectively and repeated as often as their multiplicity. Since $\sigma(N) = \sigma_e(N)$, all of them have infinite multiplicity. Moreover, for any $\nu_j$, there is a sequence $\{\mu_{n_j}\}$ converging to it.
	\item Claim: There is a renumbering of the two sets $\{\nu_{n_k}\}$ and $\{\mu_{m_k}\}$ s.t. 
	\begin{equation*}
		\abs{\nu_{n_k} - \mu_{m_k}} < \frac{\varepsilon}{2^k},~ \forall k \in \{n_1, \cdots, n_{2k}\} \cap \{m_1, \cdots, m_{2k}\}
	\end{equation*}
	Step 1: Let $n_1 = 1$ and $m_1$ be the smallest integer with 
	\begin{equation*}
		\abs{\nu_1 - \mu_{m_1}} < \frac{\varepsilon}{2}
	\end{equation*}
	Step 2: If $m_1 > 1$, put $m_2 = 1$, otherwise, put $m_2 =2$. Then let $\nu_2$ be the smallest integer larger than $1$ s.t.
	\begin{equation*}
		\abs{\nu_2 - \mu_{m_2}} < \frac{\varepsilon}{2^2}
	\end{equation*}
	Step 3: Continuing Step 1 and Step 2 to get $\{n_k\}$ and $\{m_k\}$ for $1 \leqslant k \leqslant 2j$. Then let $n_{2j+1}$ be the smallest integer and $n \neq n_k$ for $1 \leqslant k \leqslant 2j$ and $m_{2j+1}$ be the smallest integer grater than $m_k$ for $1 \leqslant k \leqslant 2j$ with
	\begin{equation*}
		\abs{\nu_{n_{2j+1}} - \mu_{m_{2j+1}}} < \frac{\varepsilon}{2^{2j+1}}
	\end{equation*}
	Similarly, we get $n_{2j+2}$ and $m_{2j+1}$ with same properties. Therefore, by induction, this claim holds.\\
	Since $N$ and $M$ are diagonalizable on a separable Hilbert space, there are two orthonormal basis $\{e_n\}$ and $\{f_m\}$ s.t. 
	\begin{equation*}
		Ne_n = \nu_n e_n, \text{ and } Mf_m = \mu_m f_m
	\end{equation*}
	Define $U$ as $Ue_{n_k} = f_{m_k}$ for all $k$, then clearly $U$ is a unitary. And,
	\begin{equation*}
		(N-\st{U}MU)e_{n_k} = (\nu_{n_k} - \mu_{m_k}) e_{n_k}
	\end{equation*}
	thus $\norm{N-\st{U}MU}_1 < \varepsilon$.
\end{proof}

\begin{thm}
	If $N$ and $M$ are normal operators on a separable Hilbert space with same essential spectrum, then there is a unitary $U$ s.t. $N-\st{U}MU$ is compact.
\end{thm}
\begin{proof}
	According the last corollary in above subsection, there are diagonalizable normal operators $N_1$ and $M_1$ s.t.
	\begin{equation*}
		N-N_1,~ M-M_1 \in \coper, \text{ and } \sigma(N_1) = \sigma_e(N_1) = \sigma_e(M_1) = \sigma(M_1)
	\end{equation*}
	By above lemma, there is a unitary $U$ s.t. $N_1-\st{U}M_1U \in \coper$. Therefore,
	\begin{equation*}
		N - \st{U}MU = (N-N_1) + (N_1-\st{U}M_1U) + \st{U}(M-M_1)U
	\end{equation*}
	is compact.
\end{proof}

In above theorem, we can not estimate the value of $\norm{N - \st{U}MU}$. But if there is an another condition these two normal operators satisfy, then $\norm{N - \st{U}MU}$ can be arbitratry small. And this property induce the concept of approximately unitary equivalence.

\begin{defn}
	Two normal operators $A$ and $B$ are approximately unitarily equivalent, denoted by $A \cong_a B$, if there is a sequence of unitaries $\{U_n\}$ s.t. 
	\begin{equation*}
		\norm{A - \st{U_n}BU_n} \sto 0
	\end{equation*}
	Moreover, if $A - \st{U_n}BU_n \in \coper$ and $A \cong_a B$, then $A$ and $B$ are called strongly approximately unitarily equivalent, denoted by $A \cong_{sa} B$.
\end{defn}

\begin{thm}
	If $N$ and $M$ are normal operators on a separable Hilbert spaces, then the following statements are equivalent.
	\begin{enumerate}[label = \arabic*)]
		\item $N \cong_{sa} M$.
		\item $N \cong_a M$.
		\item $\sigma_e(N) = \sigma_e(M)$ and for any $\lambda \in \sigma_e(N) = \sigma_e(M)$,
		\begin{equation*}
			\dim{\ker{(N-\lambda)}} = \dim{\ker{(M-\lambda)}}
		\end{equation*}
	\end{enumerate}
\end{thm}
\begin{proof}
	Let $E_N$ and $E_M$ be the spectral measures for $N$ and $M$. $1)$ implies $2)$ clearly.
	\item $2) \Rightarrow 3)$: 
\end{proof}


















